<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[HashMap源码分析]]></title>
    <url>%2F2019%2F01%2F28%2FHashMap%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[HashMap简介（jdk1.8）在jdk1.8中，HashMap底层由数组+链表+红黑树来实现，性能较之前有了较大的提升。如下为HashMap的继承体系结构：12public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable 在这里，AbstractMap已经实现了Map接口，再实现一遍并没有任何用处，java集合框架的创始人也承认其为一个小失误。 HashMap中，当链表节点较多时会转为红黑树进行存储，而红黑树这一数据结构涉及的知识点过多，关于红黑树的基础知识需要另外学习，本篇将以链表为主，红黑树为辅的形式分析其源码。 属性123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172/** * 默认的初始化容量为16 */ static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; /** * 最大容量 */ static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; /** * 默认负载因子为0.75 */ static final float DEFAULT_LOAD_FACTOR = 0.75f; /** * 链表转红黑树的阈值，当有8个节点的时候转换 */ static final int TREEIFY_THRESHOLD = 8; /** * 红黑树转链表的阈值，当有6个节点的时候转换 */ static final int UNTREEIFY_THRESHOLD = 6; /** * 转红黑树时table的最小容量，如果当前容量小于64则进行扩容而非转换 */ static final int MIN_TREEIFY_CAPACITY = 64; /** * 基本hash节点 */ static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + &quot;=&quot; + value; &#125; public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125; &#125; 注意：在HashMap中，table的容量只为2的n次方。 构造函数1234567891011121314151617181920212223242526//指定了初始容量和负载因子 public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal initial capacity: " + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal load factor: " + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity); &#125;//指定了初始容量，将会设置默认负载因子 public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR); &#125; public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted &#125; public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false); &#125; 在构造函数中，并没有对table数组进行初始化，而是在第一次put的时候进行初始化，这会在下文进行详细介绍。 tableSizeFortableSizeFor方法的主要功能是返回一个比给定整数大且最接近的2的幂次方整数，如给定10，返回2的4次方16。 12345678910static final int tableSizeFor(int cap) &#123; //防止当容量已经是2的幂次方(2^m)了，进行如下操作得到的最终结果会多乘个2，即2^(m+1) int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; 这个方法比较巧妙，n|=n&gt;&gt;&gt;1这一操作确保第一次出现1的位及其后一位（也就是头两位）都是1，而n |= n &gt;&gt;&gt; 2确保头四位都是1，n |= n &gt;&gt;&gt; 4确保头八位都是1，以此类推，一直到n |= n &gt;&gt;&gt; 16结束后就能确保第一次出现1的位及其后面所有位都为1。而此时，n+1即为最接近指定容量的2的幂次方整数。举个例子：123456789n: 0000 0000 0110 0001 = 97 n|=n&gt;&gt;&gt;1: 0000 0000 0111 0001 n|=n&gt;&gt;&gt;2: 0000 0000 0111 1001n|=n&gt;&gt;&gt;2: 0000 0000 0111 1101 n|=n&gt;&gt;&gt;4: 0000 0000 0111 1111...n|=n&gt;&gt;&gt;16: 0000 0000 0111 1111n+1: 0000 0000 1000 0000 = 128 hash1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 这个方法先得到key的hashCode，然后将其与高16位进行异或运算重新得到哈希值，之后再通过hash &amp; (table.length - 1) 定位到key在table中的索引位置。假设table的长度为16，具体过程如下： 12345h = key.hashCode(): 1111 1111 1111 1111 0000 0000 0011 0101h &gt;&gt;&gt; 16: 0000 0000 0000 0000 1111 1111 1111 1111hash = h ^ (h &gt;&gt;&gt; 16): 1111 1111 1111 1111 1111 1111 1100 1010table.length - 1: 0000 0000 0000 0000 0000 0000 0000 1111hash &amp; (table.length - 1):0000 0000 0000 0000 0000 0000 0000 1010 其中，&gt;&gt;&gt;为无符号右移，左边都将补0，而之所以要进行这一步，是为了当table的值很小时，能让hashCode的高位也参与运算，以减少碰撞的几率，否则仅在高位发生变化总是会发生碰撞。 我们知道，hash如果对table.length取模将得到key在table长度范围内的索引位置，但由于模运算效率较低，这里便采用了与运算进行优化，提高了效率。 get12345678910111213141516171819202122232425262728public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; &#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; //哈希表不为null &amp;&amp; 表的长度大于0 &amp;&amp; 根据hash值算出表索引的第一个节点不为null if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; //如果第一个节点的key与传入的key相同，则直接返回第一个节点 if (first.hash == hash &amp;&amp; //always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; //如果第一个节点是树节点，则调用红黑树的相关方法 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; //向下遍历链表直至找到key相同的节点并返回 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; //未找到符合要求的节点，返回null return null; &#125; getTreeNode12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849final TreeNode&lt;K,V&gt; getTreeNode(int h, Object k) &#123; //如果当前节点有父节点，则先找到其根节点，之后再调用find方法 return ((parent != null) ? root() : this).find(h, k, null);&#125;final TreeNode&lt;K,V&gt; root() &#123; for (TreeNode&lt;K,V&gt; r = this, p;;) &#123; //如果当前节点的父节点为空，则当前节点为根节点，将其返回 if ((p = r.parent) == null) return r; r = p; &#125;&#125;final TreeNode&lt;K,V&gt; find(int h, Object k, Class&lt;?&gt; kc) &#123; TreeNode&lt;K,V&gt; p = this; do &#123; int ph, dir; K pk; TreeNode&lt;K,V&gt; pl = p.left, pr = p.right, q; //传入的哈希值小于当前节点的哈希值，则向左遍历 if ((ph = p.hash) &gt; h) p = pl; //传入的哈希值大于当前节点的哈希值，则向右遍历 else if (ph &lt; h) p = pr; //传入的哈希值等于当前节点的哈希值，则再判断key值是否相同，因为不同的key有可能有相同的hash，这也正是哈希冲突所在 else if ((pk = p.key) == k || (k != null &amp;&amp; k.equals(pk))) return p; //如果左节点为空，则向右开始遍历 else if (pl == null) p = pr; //如果右节点为空，则向左开始遍历 else if (pr == null) p = pl; //走到这里说明左右节点都不为空，要开始判断究竟往左还是往右 else if ((kc != null || (kc = comparableClassFor(k)) != null) &amp;&amp; //如果不为null，说明key实现了Comparable接口 (dir = compareComparables(kc, k, pk)) != 0) //比较k和pk的大小，若k&lt;pk则dir&lt;0，k&gt;pk则dir&gt;0 p = (dir &lt; 0) ? pl : pr; //key所属类没有实现Comparable接口，则直接向右开始遍历 else if ((q = pr.find(h, k, kc)) != null) return q; //向右没有找到，则向左开始遍历 else p = pl; &#125; while (p != null); //找不到符合的返回null return null;&#125; 在这个方法中有些人可能会疑虑在同一个索引位置下的红黑树各节点hash值不应该相同吗，为什么还会有判断哈希值大小进入左右节点的操作。其实，不同的hash值在与table的长度相与后，是有可能进入同一个索引位置下的，考虑以下这种情况：123节点1的hash值： 1110 0000 0000 1000 0111节点2的hash值： 1001 1111 0000 1010 0111table.length-1：0000 0000 0000 0000 0111 可以看出，节点1与节点2在进行了hash &amp; (table.length - 1)后值都为0000 0000 0000 0000 0111，因此会放置在table中同一个索引位置下。 comparableClassFor、compareComparablescomparableClassFor方法判断对象x所属类c是否实现了Comparable接口，如果实现了则返回所属类c，否则返回null 123456789101112131415161718192021222324static Class&lt;?&gt; comparableClassFor(Object x) &#123; if (x instanceof Comparable) &#123; Class&lt;?&gt; c; Type[] ts, as; Type t; ParameterizedType p; //如果x是个字符串对象则直接返回String类，因为String类本身就已经实现了Comparable接口 if ((c = x.getClass()) == String.class) // bypass checks return c; //Type[] getGenericInterfaces，此方法将返回带泛型参数信息的本类直接实现的接口 if ((ts = c.getGenericInterfaces()) != null) &#123; for (int i = 0; i &lt; ts.length; ++i) &#123; //如果此接口为泛型接口 if (((t = ts[i]) instanceof ParameterizedType) &amp;&amp; //如果该泛型接口的原始类型为Comparable ((p = (ParameterizedType)t).getRawType() == Comparable.class) &amp;&amp; //如果该泛型接口只有一个泛型参数，且此泛型参数类型为c，则返回c (as = p.getActualTypeArguments()) != null &amp;&amp; as.length == 1 &amp;&amp; as[0] == c) // type arg is c return c; &#125; &#125; &#125; //如果该对象所属类没有实现Comparable接口，则返回null return null;&#125; 以上代码中，for (int i = 0; i &lt; ts.length; ++i)下的一系列判断其实就是想要看x所属类c是否实现了Comparable&lt;c&gt;。 1234static int compareComparables(Class&lt;?&gt; kc, Object k, Object x) &#123; return (x == null || x.getClass() != kc ? 0 : ((Comparable)k).compareTo(x));&#125; 此方法中，如果x与k的类相同，则进行比较。否则，返回0。 put1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162 public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true); &#125; /** * @param onlyIfAbsent 如果为true，则不改变已经存在的value，仅仅当不存在value的时候put进去 */ final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //如果table为空或者长度为0，则先调用resize()方法进行扩容 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; //如果通过hash计算得到的table该索引位置还没有节点，则创建一个新节点作为头节点 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); //该索引位置已存在节点 else &#123; Node&lt;K,V&gt; e; K k; //判断当前节点的hash与key是否与参数中的hash与key相同，如果相同，则说明p为要查找的节点，将其赋值给e if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //判断节点是否为红黑树节点，如果是则调用红黑树的相关方法 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; //如果节点不为红黑树节点而是链表节点，则遍历链表节点，并统计该链表的节点数binCount for (int binCount = 0; ; ++binCount) &#123; //如果已经到了链表尾部，则根据传入的hash与key等创建一个新节点加入链表尾部 if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); //如果链表的节点数超过阈值，则将其转换为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) //此时e节点即为目标节点，跳出循环 break; //将p设置为下一个节点 p = e; &#125; &#125;//如果e节点不为null，则说明链表中包含目标节点，用新值覆盖旧值并返回旧值 if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; //走到这一步说明插入了新的节点，size大小需要加一 ++modCount; if (++size &gt; threshold) //如果size超过了阈值，则进行扩容 resize(); afterNodeInsertion(evict); return null; &#125; putTreeVal在进行红黑树的操作时，依然会维护链表的结构。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455final TreeNode&lt;K,V&gt; putTreeVal(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, int h, K k, V v) &#123; Class&lt;?&gt; kc = null; boolean searched = false; TreeNode&lt;K,V&gt; root = (parent != null) ? root() : this; for (TreeNode&lt;K,V&gt; p = root;;) &#123; int dir, ph; K pk; //如果目标节点的hash值小于当前节点，则将dir设为-1，代表向左查找 if ((ph = p.hash) &gt; h) dir = -1; //如果目标节点的hash值大于当前节点，则将dir设为1，代表向右查找 else if (ph &lt; h) dir = 1; //如果目标节点的hash值等于当前节点，则判断key是否相等，如果相等，则说明当前节点为目标节点，将其返回 else if ((pk = p.key) == k || (k != null &amp;&amp; k.equals(pk))) return p; //如果要查找的key没有实现Comparable接口或者pk与k的所属类不同 else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) &#123; //第一次执行查找 if (!searched) &#123; TreeNode&lt;K,V&gt; q, ch; searched = true; //左右子树分别调用find进行查找，如果找到了则返回 if (((ch = p.left) != null &amp;&amp; (q = ch.find(h, k, kc)) != null) || ((ch = p.right) != null &amp;&amp; (q = ch.find(h, k, kc)) != null)) return q; &#125; //如果依然没有找到，则再进行最后一次比较 dir = tieBreakOrder(k, pk); &#125; TreeNode&lt;K,V&gt; xp = p; //如果p节点的左节点或者右节点为null，则说明找到了要放入的位置 if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123; Node&lt;K,V&gt; xpn = xp.next; TreeNode&lt;K,V&gt; x = map.newTreeNode(h, k, v, xpn); if (dir &lt;= 0) xp.left = x; else xp.right = x; //到这里维护了xp-&gt;x-&gt;xpn这一链表结构 xp.next = x; x.parent = x.prev = xp; if (xpn != null) ((TreeNode&lt;K,V&gt;)xpn).prev = x; //进行红黑树的插入平衡操作 moveRootToFront(tab, balanceInsertion(root, x)); return null; &#125; &#125;&#125; resize123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; //如果老table为空，则老t int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; //如果老table不为空 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; //且老table的容量已经大于最大容量 //将阈值设置为最大整型 threshold = Integer.MAX_VALUE; //直接返回老table，不再扩容 return oldTab; &#125; //将新容量设置为老容量的两倍 //如果新容量小于最大容量且老容量大于十六，则将新阈值也提高到原来的两倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; //如果table为空，但老阈值大于0，说明构造函数时指定了初始化容量但从未加入过元素，此时将老阈值赋给新容量，详解见下文 else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; //老table为空，且老阈值为0，说明构造函数时未指定初始化容量 else &#123; // zero initial threshold signifies using defaults //将新容量设置为默认初始化容量 newCap = DEFAULT_INITIAL_CAPACITY; //将新阈值设置为默认负载因子*默认初始化容量 newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; //如果新阈值为0，则用新容量*负载因子赋值 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; //如果新容量或者新阈值大于最大容量，则将新阈值设为最大整型，以后不再扩容 newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; //将新阈值赋值给阈值属性 threshold = newThr; @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) //用新容量大小创建一个新table Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; //将新table赋值给table属性 table = newTab; //如果老table不为空，则将其中的元素全部放到新table中去 if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; //如果该索引位置头节点不为空 if ((e = oldTab[j]) != null) &#123; //将老表该索引位置设为空，方便垃圾收集器回收 oldTab[j] = null; //如果该索引位置只有一个节点，则根据其hash计算值放入新表中 if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; //如果为树节点，则调用红黑树相关方法 else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); //该索引位置有多个节点 else &#123; // preserve order //存储原索引位置的头节点与尾节点 Node&lt;K,V&gt; loHead = null, loTail = null; //存储原索引位置+原容量的头节点与尾节点 Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; //如果hash与oldCap相与为0则存储在原索引位置，详解见下方 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) //e为头节点的情况 loHead = e; else loTail.next = e; loTail = e; &#125; //如果hash与oldCap相与不为0则存储在原索引位置+原容量，详解见下方 else &#123; if (hiTail == null) //e为头节点的情况 hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; //尾节点的next属性为空 loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; //尾节点的next属性为空 hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; //返回新表 return newTab;&#125; 我们可以看到在此方法中有一个条件判断else if (oldThr &gt; 0)，当table为空但阈值却大于零时，将阈值赋值给新容量。这里有个疑问是为什么会发生table为空但阈值却大于零这种情况？我们可以回过头看看构造函数，可以发现在所有构造函数中都没有对数组table进行过分配，而仅仅设置了阈值this.threshold = tableSizeFor(initialCapacity);，既然在构造时没有分配，那肯定就是在第一次扩容时分配的，也就正是上面的代码。 此处还有一个疑问是：为什么扩容后新的存储位置只为原位置或原位置+原容量？请看这么一个例子，假设oldCap=0100, newCap=1000,节点a的hash为1110,节点b的hash为1010。oldCap-1的值为0011，显然对于节点来说只有后两位决定了它们的位置（因为前两位无论如何都为0），而newCap-1的值为0111，此时后三位决定了它们的位置，与之前不同正在于节点的第三位是0还是1，而第三位的值正可以通过oldCap(在此也就是0100)相与来进行判断，如果相与结果为0000，则说明第三位的值为0，在和newCap-1相与后结果将不变，依然在原索引位置；而如果相与结果为0100，则说明节点第三位值是1，也就是原索引值加上原容量。 treeifyBin123456789101112131415161718192021222324252627282930313233final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) &#123; int n, index; Node&lt;K,V&gt; e; //如果table为空或者table的长度小于可转换为红黑树的最小容量，则调用resize方法扩容 if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); //如果根据hash计算得到的索引位置下的节点不为空，则遍历整条链表 else if ((e = tab[index = (n - 1) &amp; hash]) != null) &#123; TreeNode&lt;K,V&gt; hd = null, tl = null; do &#123; //将链表节点转换为红黑树节点 TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); //如果为第一次循环 if (tl == null) //将p设置为头节点 hd = p; //否则，不为第一次循环 else &#123; //将当前节点与上一个节点关联起来，维护链表结构 p.prev = tl; tl.next = p; &#125; tl = p; &#125; while ((e = e.next) != null); //将hash计算得到的索引位置的头节点赋为新的树节点 if ((tab[index] = hd) != null) //以头节点为根构建红黑树 hd.treeify(tab); &#125;&#125;TreeNode&lt;K,V&gt; replacementTreeNode(Node&lt;K,V&gt; p, Node&lt;K,V&gt; next) &#123; return new TreeNode&lt;&gt;(p.hash, p.key, p.value, next);&#125; treeify123456789101112131415161718192021222324252627282930313233343536373839404142434445464748final void treeify(Node&lt;K,V&gt;[] tab) &#123; TreeNode&lt;K,V&gt; root = null; //x的初始值为根节点，但开始时还未赋值给root for (TreeNode&lt;K,V&gt; x = this, next; x != null; x = next) &#123; next = (TreeNode&lt;K,V&gt;)x.next; x.left = x.right = null; //如果root还未被赋值，则将根节点赋值给它 if (root == null) &#123; //根节点没有父节点 x.parent = null; //红黑树根节点必须为黑色 x.red = false; root = x; &#125; else &#123; //见下文 K k = x.key; int h = x.hash; Class&lt;?&gt; kc = null; for (TreeNode&lt;K,V&gt; p = root;;) &#123; int dir, ph; K pk = p.key; if ((ph = p.hash) &gt; h) dir = -1; else if (ph &lt; h) dir = 1; else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) dir = tieBreakOrder(k, pk); TreeNode&lt;K,V&gt; xp = p; if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123; x.parent = xp; if (dir &lt;= 0) xp.left = x; else xp.right = x; //红黑树的插入平衡调整 root = balanceInsertion(root, x); break; &#125; &#125; &#125; &#125; //将根节点移到table索引位置的头节点 moveRootToFront(tab, root);&#125; treeify方法用来构建一棵以调用该方法的节点为根节点的红黑树。由于红黑树依然维护着链表结构，每次通过next属性获得下一个节点时，都会从根节点开始向下查找，根据hash值的大小找到合适的位置放入，并设置好parent与left或right属性以关联节点。 remove12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public V remove(Object key) &#123; Node&lt;K,V&gt; e; //如果未找到要删除的节点则返回空，否则返回要删除的节点的value值 return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value;&#125;/** * @param matchValue 如果为true，则只有当value也相等的时候才移除 */final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; //如果table不为空且table的长度不为0且table该索引位置的头节点不为空 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123; Node&lt;K,V&gt; node = null, e; K k; V v; //如果当前节点的hash值和key都与传入的相等，则当前节点就是目标节点，将其赋值给node if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; //如果当前节点不是目标节点，则遍历之后的节点 else if ((e = p.next) != null) &#123; //如果节点为树节点，则调用红黑树相关方法 if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else &#123; do &#123; //如果当前节点是目标节点，则将其赋值给node，并跳出循环 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; //将p设为下一节点 p = e; &#125; while ((e = e.next) != null); &#125; &#125; //如果找到了要删除的节点且要删除的节点的value与传入的value相等或者压根不需要匹配value if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; //如果节点为树节点，则调用红黑树移除方法 if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); //如果要删除的节点是头节点 else if (node == p) //直接将索引位置指向要删除节点的下一个节点 tab[index] = node.next; else //如果要删除的节点不是头节点，则将要删除节点的上下节点关联起来 p.next = node.next; ++modCount; //总节点数减一 --size; afterNodeRemoval(node); //返回被移除的节点 return node; &#125; &#125; //未找到要删除的节点，直接返回null return null;&#125; 常见问题有关HashMap的常见面试题总结请移步 HashMap常见面试题总结]]></content>
      <categories>
        <category>JDK源码阅读</category>
      </categories>
      <tags>
        <tag>JDK</tag>
        <tag>HashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见排序算法之堆排序]]></title>
    <url>%2F2019%2F01%2F28%2F%E5%B8%B8%E8%A7%81%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E4%B9%8B%E5%A0%86%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[前言排序算法的成本模型计算的是比较和交换的次数。less()方法对元素进行比较，exch()方法将元素交换位置。 123456789private static boolean less(Comparable v, Comparable w) &#123; return (v.compareTo(w) &lt; 0);&#125;private static void exch(Comparable[] a, int i, int j) &#123; Comparable swap = a[i]; a[i] = a[j]; a[j] = swap;&#125; 堆的定义堆的某个节点的值总是大于等于子节点的值，并且堆是一颗完全二叉树。当这棵树的每个结点都大于等于它的两个子节点时，它被称为堆有序。 堆可以用数组来表示，这是因为堆是完全二叉树，而完全二叉树很容易就存储在数组中。位置 k 的节点的父节点位置为 k/2，而它的两个子节点的位置分别为 2k 和 2k+1。 上浮在堆中，当一个节点比父节点大，那么需要交换这个两个节点。交换后还可能比它新的父节点大，因此需要不断地进行比较和交换操作，把这种操作称为上浮。 实现如下： 123456private void swim(int k) &#123; while (k &gt; 1 &amp;&amp; less(k/2, k)) &#123; exch(k, k/2); k = k/2; &#125;&#125; 下沉在堆中，当一个节点比子节点小，需要不断地向下进行比较和交换操作，把这种操作称为下沉。一个节点如果有两个子节点，应当与两个子节点中最大那个节点进行交换。 实现如下： 123456789private void sink(int k) &#123; while (2*k &lt;= N) &#123; int j = 2*k; if (j &lt; N &amp;&amp; less(j, j+1)) j++; if (!less(k, j)) break; exch(k, j); k = j; &#125;&#125; 堆排序堆排序可以分为两个阶段。在堆的构造阶段中，我们将原始数组重新组织安排进一个堆中；然后在下沉排序阶段，我们从堆中按递减顺序取出所有元素并得到排序结果。 堆的构造无序数组建立堆最直接的方法是从左到右遍历数组进行上浮操作。一个更高效的方法是从右至左进行下沉操作，如果一个节点的两个节点都已经是堆有序，那么进行下沉操作可以使得这个节点为根节点的堆有序。叶子节点不需要进行下沉操作，可以忽略叶子节点的元素，因此只需要遍历一半的元素即可。 下沉排序堆排序的主要工作都是在这一阶段完成的。这里我们将堆中的最大元素删除，然后放入堆缩小后数组中空出的位置。 12345678910111213141516171819202122232425262728293031public class Heap &#123; public static void sort(Comparable[] pq) &#123; int n = pq.length; for (int k = n/2; k &gt;= 1; k--) sink(pq, k, n); while (n &gt; 1) &#123; exch(pq, 1, n--); sink(pq, 1, n); &#125; &#125; private static void sink(Comparable[] pq, int k, int n) &#123; while (2*k &lt;= n) &#123; int j = 2*k; if (j &lt; n &amp;&amp; less(pq, j, j+1)) j++; if (!less(pq, k, j)) break; exch(pq, k, j); k = j; &#125; &#125; private static boolean less(Comparable[] pq, int i, int j) &#123; return pq[i-1].compareTo(pq[j-1]) &lt; 0; &#125; private static void exch(Object[] pq, int i, int j) &#123; Object swap = pq[i-1]; pq[i-1] = pq[j-1]; pq[j-1] = swap; &#125;&#125; 复杂度分析一个堆的高度为 logN，因此在堆中插入元素和删除最大元素的复杂度都为 logN。 对于堆排序，由于要对 N 个节点进行下沉操作，因此复杂度为 NlogN。 现代系统的许多应用很少使用它，因为它无法利用缓存。数组元素很少和相邻的其它元素进行比较，因此无法利用局部性原理，缓存未命中的次数很高。 最坏时间复杂度 О(nlogn) 最优时间复杂度 O(nlogn) 平均时间复杂度 O(nlogn) 空间复杂度 O(1) 不稳定 参考资料 Algorithms (Fourth Edition) CS-Notes 算法]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见排序算法之快速排序]]></title>
    <url>%2F2019%2F01%2F28%2F%E5%B8%B8%E8%A7%81%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[前言排序算法的成本模型计算的是比较和交换的次数。less()方法对元素进行比较，exch()方法将元素交换位置。 123456789private static boolean less(Comparable v, Comparable w) &#123; return (v.compareTo(w) &lt; 0);&#125;private static void exch(Comparable[] a, int i, int j) &#123; Comparable swap = a[i]; a[i] = a[j]; a[j] = swap;&#125; 思路快速排序是一种分治的排序算法，它将一个数组分成两个子数组，将两部分独立地排序。 快速排序和归并排序是互补的：归并排序将数组分成两个子数组分别排序，并将有序的子数组归并以将整个数组排序；而快速排序将数组排序的方式则是当两个子数组都有序时整个数组也就自然有序了。前者的递归调用发生在处理整个数组之前，而后者的递归调用则发生在处理整个数组之后。 实现过程 基本算法12345678910111213141516171819public class Quick &#123; public static void sort(Comparable[] a) &#123; shuffle(a); sort(a, 0, a.length - 1); &#125; private static void sort(Comparable[] a, int lo, int hi) &#123; if (hi &lt;= lo) return; int j = partition(a, lo, hi); sort(a, lo, j-1); sort(a, j+1, hi); &#125; private void shuffle(T[] nums) &#123; List&lt;Comparable&gt; list = Arrays.asList(nums); Collections.shuffle(list); list.toArray(nums); &#125;&#125; 该方法的关键在于切分。 切分方法一般策略是先随意地取a[lo]作为切分元素，即那个将会被排序的元素，然后我们从数组的左端开始向右扫描直到找到一个大于等于它的元素，再从数组的右端开始向左扫描直到找到一个小于等于它的元素。这两个元素显然是没有排定的，因此交换它们的位置。如此继续，我们就可以保证左指针i的左侧元素都不大于切分元素，右指针j的右侧元素都不小于切分元素。当两个指针相遇时，我们只需要将切分元素a[lo]和左子数组最右侧的元素（a[j]）交换然后返回j即可。 12345678910111213141516171819private static int partition(Comparable[] a, int lo, int hi) &#123; int i = lo; int j = hi + 1; Comparable v = a[lo]; while (true) &#123; while (less(a[++i], v)) &#123; if (i == hi) break; &#125; while (less(v, a[--j])) &#123; if (j == lo) break; &#125; if (i &gt;= j) break; exch(a, i, j); &#125; exch(a, lo, j); return j;&#125; 这个过程使得数组满足下面三个条件： 对于某个j，a[j]已经排定 a[lo]到a[j-1]中的所有元素都不大于a[j] a[j+1]到a[hi]中的所有元素都不小于a[j] 复杂度分析快速排序的最好情况是每次都正好将数组对半分。在这种情况下快速排序所用的比较次数正好满足分治递归的Cn=2Cn/2+n。2Cn/2表示将两个子数组排序的成本，n表示用切分元素和所有数组元素进行比较的成本，这个递归公式的解Cn~nlogn。（下文有具体数学推导） 而在最坏情况下，切分不平衡使得第一次从最小的元素切分，第二次从第二小的元素切分，如此继续，每次切分后两个子数组之一总是为空的，比较次数为(n - 1) + (n - 2) +...+ 1 = n × (n - 1 ) / 2。 而对于空间复杂度来说，主要考虑的是递归调用使用的栈空间，在最好的情况下（也就是对半分），递归深度为logn，最坏情况下的递归深度为n。 最坏时间复杂度 О(n²) 最优时间复杂度 O(nlogn) 平均时间复杂度 O(nlogn) 最坏空间复杂度 O(n) 最优空间复杂度 O(logn) 不稳定 最优时间复杂度的数学证明 算法改进切换到插入排序因为快速排序在小数组中也会递归调用自己，对于小数组，插入排序比快速排序的性能更好，因此在小数组中可以切换到插入排序。 只需要将代码中的if (hi &lt;= lo) return;改为if (hi &lt;= lo + M) {Insertion.sort(a, lo, hi); return;}。 三取样切分最好的情况下是每次都能取数组的中位数作为切分元素，但是计算中位数的代价很高。人们发现取 3 个元素并将大小居中的元素作为切分元素的效果最好。 三向切分法从左到右遍历数组一次，维护一个指针lt使得a[lo…lt-1]中的元素都小于v，一个指针gt使得a[gt+1…hi]中的元素都大于v，一个指针i使得a[lt..i-1]中的元素都等于v，a[i..gt]中的元素都还未确定。 一开始i和lo相等，对a[i]进行三向比较： a[i]小于v，将a[lt]和a[i]交换，将lt和i加一 a[i]大于v，将a[gt]和a[i]交换，将gt减一 a[i]等于v，将i加一 对于包含大量重复元素的数组，它将排序时间从线性对数级降低到了线性级别。 1234567891011121314151617181920212223242526272829public class Quick3way &#123; public static void sort(Comparable[] a) &#123; shuffle(a); sort(a, 0, a.length - 1); &#125; private static void sort(Comparable[] a, int lo, int hi) &#123; if (hi &lt;= lo) return; int lt = lo, gt = hi; Comparable v = a[lo]; int i = lo + 1; while (i &lt;= gt) &#123; int cmp = a[i].compareTo(v); if (cmp &lt; 0) exch(a, lt++, i++); else if (cmp &gt; 0) exch(a, i, gt--); else i++; &#125; // a[lo..lt-1] &lt; v = a[lt..gt] &lt; a[gt+1..hi]. sort(a, lo, lt-1); sort(a, gt+1, hi); &#125; private void shuffle(T[] nums) &#123; List&lt;Comparable&gt; list = Arrays.asList(nums); Collections.shuffle(list); list.toArray(nums); &#125;&#125; 参考资料 Algorithms (Fourth Edition) CS-NOTE 算法 排序算法之快速排序的时间复杂度和空间复杂度]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见排序算法之归并排序]]></title>
    <url>%2F2019%2F01%2F28%2F%E5%B8%B8%E8%A7%81%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E4%B9%8B%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[前言排序算法的成本模型计算的是比较和交换的次数。less()方法对元素进行比较，exch()方法将元素交换位置。 123456789private static boolean less(Comparable v, Comparable w) &#123; return (v.compareTo(w) &lt; 0);&#125;private static void exch(Comparable[] a, int i, int j) &#123; Comparable swap = a[i]; a[i] = a[j]; a[j] = swap;&#125; 原地归并方法该方法将两个不同的有序数组归并到第三个数组中。 123456789101112131415private static void merge(Comparable[] a, Comparable[] aux, int lo, int mid, int hi) &#123; // copy to aux[] for (int k = lo; k &lt;= hi; k++) &#123; aux[k] = a[k]; &#125; // merge back to a[] int i = lo, j = mid+1; for (int k = lo; k &lt;= hi; k++) &#123; if (i &gt; mid) a[k] = aux[j++]; else if (j &gt; hi) a[k] = aux[i++]; else if (less(aux[j], aux[i])) a[k] = aux[j++]; else a[k] = aux[i++]; &#125;&#125; 自顶向下的归并排序自顶向下的归并排序应用了分治的思想，要对子数组a[lo..hi]进行排序，先将它分为a[lo..mid]和a[mid+1..hi]两部分，分别通过递归调用将它们单独排序，最后将有序的子数组归并为最终的排序结果。 图为自顶向下的归并排序中归并结果的轨迹 1234567891011121314public class Merge &#123; public static void sort(Comparable[] a) &#123; Comparable[] aux = new Comparable[a.length]; sort(a, aux, 0, a.length-1); &#125; private static void sort(Comparable[] a, Comparable[] aux, int lo, int hi) &#123; if (hi &lt;= lo) return; int mid = lo + (hi - lo) / 2; sort(a, aux, lo, mid); sort(a, aux, mid + 1, hi); merge(a, aux, lo, mid, hi); &#125;&#125; 自底向上的归并排序实现归并排序的另一种方法是先归并那些微型数组，然后再成对归并得到子数组，如此这般地多次遍历整个数组，直到我们将整个数组归并到一起。 图为自底向上的归并排序中归并结果的轨迹 12345678910111213public class MergeBU &#123; public static void sort(Comparable[] a) &#123; int n = a.length; Comparable[] aux = new Comparable[n]; for (int len = 1; len &lt; n; len *= 2) &#123; for (int lo = 0; lo &lt; n-len; lo += len+len) &#123; int mid = lo+len-1; int hi = Math.min(lo+len+len-1, n-1); merge(a, aux, lo, mid, hi); &#125; &#125; &#125;&#125; 特点 归并排序的空间复杂度不是最优的 和选择排序一样，排序的性能不受输入数据的影响，但表现比选择排序好的多 复杂度分析 最坏情况时间复杂度 O(nlogn) 最好情况时间复杂度 O(nlogn) 平均情况时间复杂度 O(nlogn) 空间复杂度 O(n) 稳定 参考资料 Wikipedia Algorithms (Fourth Edition) 十大经典排序算法]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初级排序算法]]></title>
    <url>%2F2019%2F01%2F28%2F%E5%88%9D%E7%BA%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[前言排序算法的成本模型计算的是比较和交换的次数。less()方法对元素进行比较，exch()方法将元素交换位置。 123456789private static boolean less(Comparable v, Comparable w) &#123; return (v.compareTo(w) &lt; 0);&#125;private static void exch(Comparable[] a, int i, int j) &#123; Comparable swap = a[i]; a[i] = a[j]; a[j] = swap;&#125; 选择排序首先找到数组中最小的那个元素，其次将它和数组的第一个元素交换位置。再次，在剩下的元素中找到最小的元素，将它与数组的第二个元素交换位置。如此反复，直到将整个数组排序。 上图为选择排序的示例动画。红色表示当前最小值，黄色表示已排序序列，蓝色表示当前位置。 特点 运行时间和输入无关：一个已经有序的数组或主键全部相等的数组和一个元素随机排列的数组所用的排序时间一样长。 数据移动是最少的：每次交换都会改变两个数组的元素的值，因此选择排序用了N次交换。 复杂度分析比较次数与关键字的初始状态无关，总的比较次数N = (n - 1) + (n - 2) +...+ 1 = n × (n - 1 ) / 2。交换次数最好情况是已经有序，交换0次；最坏情况是逆序，交换n-1次。 最坏时间复杂度 О(n²) 最优时间复杂度 О(n²) 平均时间复杂度 О(n²) 空间复杂度 O(1) 不稳定 实现123456789101112public class Selection &#123; public static void sort(Comparable[] a) &#123; int n = a.length; for (int i = 0; i &lt; n; i++) &#123; int min = i; for (int j = i+1; j &lt; n; j++) &#123; if (less(a[j], a[min])) min = j; &#125; exch(a, i, min); &#125; &#125;&#125; 插入排序插入排序是一种简单直观的排序算法。它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。 特点 插入排序所需时间取决于输入中元素的初始顺序。 插入排序对于部分有序的数组十分高效。 复杂度分析最好情况是序列已经是升序排列了，在这种情况下，需要进行的比较操作需n-1次即可，不需要进行交换；最坏情况是降序排列，那么此时需要进行的比较共有n × (n - 1) / 2次，交换同样需要n × (n - 1) / 2次。 最坏时间复杂度 О(n²) 最优时间复杂度 О(n) 平均时间复杂度 О(n²) 空间复杂度 O(1) 稳定 实现12345678910public class Insertion &#123; public static void sort(Comparable[] a) &#123; int n = a.length; for (int i = 1; i &lt; n; i++) &#123; for (int j = i; j &gt; 0 &amp;&amp; less(a[j], a[j-1]); j--) &#123; exch(a, j, j-1); &#125; &#125; &#125;&#125; 希尔排序希尔排序，也称递减增量排序算法，是插入排序的一种更高效的改进版本。希尔排序的思想是使数组中任意间隔为h的元素都是有序的，这样的数组称为h有序数组。 实现希尔排序只需要在插入排序的代码中将移动元素的距离由1改为h即可。 一个h有序数组即一个由h个有序子数组组成的数组 上图表示以23, 10, 4, 1的步长序列进行希尔排序。 特点 希尔排序的时间复杂度与递增序列密切相关，所以分析希尔排序的时间复杂度是个比较麻烦的事。 希尔排序对于中等大小规模表现良好，对规模非常大的数据排序不是最优选择。 希尔排序实现简单，几乎任何排序工作在开始时都可以用希尔排序，若在实际使用中证明它不够快，再改成快速排序这样更高级的排序算法。 实现12345678910111213141516171819public class Shell &#123; public static void sort(Comparable[] a) &#123; int n = a.length; // 3x+1 increment sequence: 1, 4, 13, 40, 121, 364, 1093, ... int h = 1; while (h &lt; n/3) h = 3*h + 1; while (h &gt;= 1) &#123; // h-sort the array for (int i = h; i &lt; n; i++) &#123; for (int j = i; j &gt;= h &amp;&amp; less(a[j], a[j-h]); j -= h) &#123; exch(a, j, j-h); &#125; &#125; h /= 3; &#125; &#125;&#125; 参考资料 Wikipedia Algorithms (Fourth Edition) 十大经典排序算法]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ATR-CKN算法的研究与实现]]></title>
    <url>%2F2019%2F01%2F28%2FATR-CKN%E7%AE%97%E6%B3%95%E7%9A%84%E7%A0%94%E7%A9%B6%E4%B8%8E%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[前言最近在学校做了无线传感器网络（WSN）睡眠调度算法方面的一些研究，本篇文章主要对其中的CKN、EC-CKN算法的学习做个总结，并给出基于这两种算法而改进后的ATR-CKN算法的核心实现以及在Nettopo上的运行结果。 CKN与EC-CKN算法K-邻居节点连通算法（CKN）是一个有效的分布式睡眠/工作时序安排算法。该算法可以在有效的减少网络中处于工作状态的节点个数的同时保证整个网络处于连通状态和需求的路径延迟。执行CKN算法时对WSN中的每个节点u主要进行以下几步： 针对CKN算法在能量消耗方面存在的问题，基于能量消耗的睡眠/工作时序安排算法（EC-CKN）可以延长网络的寿命。EC-CKN算法利用节点当前的剩余能量信息作为参数来决定节点是否进入睡眠状态。EC-CKN算法不仅可以保证整个网络处于K邻居节点连通状态，同时还可以保证每个节点处于工作状态的K个邻居节点当前的剩余能量在所有邻居节点当前剩余能量排序中为最大的K个。 存在的问题EC-CKN对CKN有了一定的改进，但在某些场景下仍然会存在一些问题，例如下文将介绍的死亡加速与网络隔离。 死亡加速在下图的场景中，节点B有很多个邻居节点，按理是可以进入睡眠状态的，但是由于它的其中一个邻居节点A只有它一个邻居节点，因此节点A和B永远得不到睡眠机会，这导致的后果就是：节点B的能量很快就被消耗完了，而节点B周围原本刚好满足睡眠条件的节点由于少了一个醒着的邻居节点，睡眠的几率也因此下降，从而加速了整个网络的死亡。 网络隔离类似于死亡加速，在下面的场景中节点A和B永远也得不到睡眠机会，因此会更快的消耗完能量，导致相连的两个网络被隔离开了。 ATR-CKN算法ATR-CKN算法优于原始的基于CKN的睡眠调度算法，它的优势在于可以在物理上调整传感器节点的传输半径，从而执行CKN使部分节点进入睡眠状态。ATR-CKN算法在继承了EC-CKN算法的所有主要属性的同时，通过提高节点的睡眠率为延长网络生命周期做出了重要贡献。 相较于EC-CKN，ATR-CKN只用在之前加入一个判断逻辑即可： 核心实现下面给出在Nettopo上对于ATR-CKN算法的实现，其关键在于执行EC-CKN之前加入下面一段判断逻辑： 123456789101112131415161718192021private void ATRCKN_Function() &#123;//... boolean flag = false; Integer[] neighbors1 = neighbors.get(currentID); if(neighbors1.length &lt; k) &#123; while(!isUsingMaxTR(currentID)) &#123; increaseTR(currentID); neighbors1 = neighbors.get(currentID); if(neighbors1.length &gt;= k) &#123; for(int j = 0; j &lt; neighbors1.length; j++) &#123; int tr = ((SensorNode)wsn.getNodeByID(currentID)).getMaxTR(); ((SensorNode)wsn.getNodeByID(neighbors1[j])).setMaxTR(tr); &#125; flag = true; break; &#125; &#125; if(!flag) setDefaultTR(currentID); &#125; //...&#125; 运行结果下面将在Nettopo上简单的演示一遍ATR-CKN算法对于死亡加速问题的解决。 k = 2，round = 1的时候： k = 2，round = 10的时候： k = 2，round = 30的时候 k = 2，round = 43的时候： 由于增大了传感器节点的物理传输半径，可以看到两个关键节点都可以进入睡眠状态，以此延长了网络的整体寿命。虽然增大传输半径的同时也增加了能量消耗，但在进行了大量实验并对统计数据进行详细分析后，我们可以发现ATR-CKN的生命周期相比EC-CKN平均增加了19％，最大增加了41%，因此可以得出其更优于EC-CKN的结论。]]></content>
      <categories>
        <category>项目</category>
      </categories>
      <tags>
        <tag>WSN</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM-垃圾收集与内存分配]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM-%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E4%B8%8E%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%2F</url>
    <content type="text"><![CDATA[对象存活判断判断对象是否存活一般有引用计数法和可达性分析两种方式。 引用计数算法为每个对象添加一个引用计数器，新增一个引用时计数器加1，引用释放时计数器减1，计数器为0时该对象可以被回收。 引用计数法实现简单且高效，但无法解决对象之间相互循环引用的问题。 可达性分析算法通过一系列GC Roots作为起始点向下搜索，搜索所走过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可引用的。 可作为GC Roots的对象包括下面几种： 虚拟机栈中引用的对象。 方法区中类静态属性引用的对象。 方法区中常量引用的对象。 本地方法栈中JNI引用的对象。 finalize如果对象在进行可达性分析后发现没有与GC Roots相连接的引用链，那它将会被第一次标记。如果没有覆盖finalize()方法或者该方法已经被虚拟机调用过，那么它将被回收；否则，会将这个对象放置在一个叫做F-Queue的队列中，要想不被回收，就要在finalize()中重新与引用链上的任何一个对象建立关联。 引用类型对象的引用类型分为强引用、软引用、弱引用、虚引用，这四种引用强度依次减弱。 强引用：类似Object obj = new Object()这类的引用，强引用关联的对象永远不会被回收。 软引用：软引用是用来描述一些还有用但并非必需的对象。在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中进行第二次回收，如果这次回收还没有足够的内存才会抛出内存溢出异常。简单的说，被软引用关联的对象只有在内存不够的情况下才会被回收。 弱引用：强度比软引用更弱一些，无论当前内存是否足够，被弱引用关联的对象一定会被回收。 虚引用：一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用取得一个对象。为一个对象设置虚引用关联的唯一目的就是能在这个对象被回收时收到一个系统通知。 垃圾收集算法最基础的垃圾收集算法有三种：标记-清除算法、复制算法、标记-整理算法，我们常用的垃圾回收器一般都采用分代收集算法。 标记-清除算法首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。 不足：标记和清除的两个过程的效率都不高；会产生大量不连续的内存碎片，导致无法给大对象分配内存。 复制算法将内存划分为大小相等的两块，每次只使用其中一块，当这一块内存用完了就将还存活的对象复制到另一块上面，然后再把使用过的内存空间进行一次清理。 现在的商业虚拟机都采用这种收集算法来回收新生代，但并不需要按照1：1的比例来划分内存空间，而是将内存分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中一块Survivor。当回收时，将Eden和Survivor中还活着的对象一次性地复制到另外一块Survivor空间上，最后清理掉Eden和刚才用过的Survivor空间。 如果每次回收有多于 10% 的对象存活，那么一块 Survivor 空间就不够用了，此时需要依赖于老年代进行分配担保，也就是借用老年代的空间存储放不下的对象。 标记-整理算法复制算法在对象存活率较高时要进行较多的复制操作，也有可能需要额外的空间进行分配担保，所以在老年代一般不能直接选用这种算法。 标记-整理算法的标记过程仍与标记-清除算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。 分代收集算法现在的商业虚拟机采用分代收集算法，它根据对象存活周期将内存划分为新生代和老年代，新生代使用复制算法，老年代使用标记-清除或者标记-整理算法。 垃圾收集器如果说收集算法是内存回收的方法论，垃圾收集器就是内存回收的具体实现。 Serial收集器串行收集器是最古老，最稳定以及效率高的收集器，可能会产生较长的停顿，只使用一个线程去回收。 ParNew收集器ParNew收集器其实就是Serial收集器的多线程版本。 Parallel Scavenge收集器Parallel是一个多线程收集器。其它收集器关注点是尽可能缩短垃圾收集时用户线程的停顿时间，而Parallel Scavenge收集器的目标是达到一个可控制的吞吐量，它被称为“吞吐量优先”收集器。这里的吞吐量指 CPU 用于运行用户代码的时间占总时间的比值。 停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验。而高吞吐量则可以高效率地利用 CPU 时间，尽快完成程序的运算任务，适合在后台运算而不需要太多交互的任务。缩短停顿时间是以牺牲吞吐量和新生代空间来换取的：新生代空间变小，收集时间缩短，但同时垃圾回收也变得频繁，导致吞吐量下降。 可以通过一个开关参数打开GC自适应的调节策略（GC Ergonomics），就不需要手工指定新生代的大小、Eden和Survivor区的比例、晋升老年代对象年龄等细节参数了。虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量。 Serial Old收集器Seriol Old是Serial收集器的老年代版本，同样是一个单线程收集器。 Parallel Old收集器Parallel Old是Parallel Scavenge收集器的老年代版本，同样是一个多线程收集器。 CMS收集器CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。目前很大一部分的Java应用都集中在互联网站或B/S系统的服务端上，这类应用尤其重视服务的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。 从名字（包含“Mark Sweep”）上就可以看出CMS收集器是基于“标记-清除”算法实现的，它的运作过程相对于前面几种收集器来说要更复杂一些，整个过程分为4个步骤，包括： 初始标记 并发标记 重新标记 并发清除 其中初始标记、重新标记这两个步骤仍然需要“Stop The World”。初始标记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，并发标记阶段就是进行GC Roots Tracing的过程，而重新标记阶段则是为了修正并发标记期间，因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。 由于整个过程中耗时最长的并发标记和并发清除过程中，收集器线程都可以与用户线程一起工作，所以总体上来说，CMS收集器的内存回收过程是与用户线程一起并发地执行。 CMS收集器具有以下三个缺点： 在并发阶段，CMS虽然不会导致用户线程停顿，但是会因为占用了一部分线程（或者说CPU资源）而导致应用程序变慢，总吞吐量会降低。 CMS无法处理浮动垃圾。 需要预留一部分空间提供并发收集时的程序运作使用，因此不能等到老年代完全被填满再进行收集，要是CMS运行期间预留的内存无法满足程序需要，就会出现“Concurrent Mode Failure”失败，这时将会启用Serial Old收集器重新进行老年代的垃圾收集，停顿时间就很长了。 CMS是基于“标记-清除”算法实现的收集器，会产生大量空间碎片。 浮动垃圾：由于CMS并发清理阶段用户线程还在运行着，伴随程序运行自然就还会有新的垃圾不断产生，这一部分垃圾出现在标记过程之后，CMS无法在当次收集中处理掉它们，只好留待下一次GC时再清理掉，这一部分垃圾就称为“浮动垃圾”。 G1收集器G1（Garbage-First）收集器是一款面向服务端应用的垃圾收集器，在多CPU和大内存的场景下有很好的性能。HotSpot开发团队赋予它的使命是未来可以替换掉 CMS 收集器。G1收集器具有以下几个特点： 并行与并发。 分代收集：不需要其它收集器配合就能独立管理整个GC堆，采用不同的方式去收集 新生代和老年代。 空间整合：整体来看是基于“标记 - 整理”算法实现的收集器，从局部（两个Region之间）上来看是基于“复制”算法实现的，这意味着运行期间不会产生内存空间碎片。 可预测的停顿：能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在GC上的时间不得超过N毫秒。 G1收集器的范围不再是整个新生代或者整个老年代，它将整个Java堆划分为多个大小相等的独立区域Region，虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔离的了，它们都是一部分不需要连续的Region的集合。 G1跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region，这保证了G1收集器在有限的时间内可以获取尽可能高的收集效率。 每个Region都有一个Remembered Set，用来记录该Region对象的引用对象所在的Region。通过使用Remembered Set，在做可达性分析的时候就可以避免全堆扫描。 G1收集器的运作大致可划分为以下几个步骤： 初始标记 并发标记 最终标记 筛选回收 前三个步骤与CMS收集器相似，最后的筛选回收阶段对各个Region的回收价值和成本进行排序，根据用户所期望的GC停顿时间来制定回收计划。 内存分配策略 对象优先分配在Eden区：如果Eden区没有足够的空间时，虚拟机执行一次Minor GC。 大对象直接进入老年代：大对象是指需要大量连续内存空间的对象，这样做的目的是避免在Eden区和两个Survivor区之间发生大量的内存拷贝（新生代采用复制算法收集内存）。 长期存活的对象进入老年代：为对象定义年龄计数器，对象在Eden区出生并经过Minor GC依然存活，将被移动到Survivor区中，年龄增加1岁，增加到年龄阈值则移动到老年代中。 动态判断对象的年龄：如果在Survivor区中相同年龄所有对象大小的总和大于Survivor空间的一半，则年龄大于或等于该年龄的对象可以直接进入老年代而无需达到年龄阈值。 空间分配担保：在发生Minor GC之前，虚拟机先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果这个条件成立的话，那么Minor GC可以确保是安全的。如果不成立的话虚拟机会查看HandlePromotionFailure设置值是否允许担保失败，如果允许那么就会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试着进行一次Minor GC，尽管这次Minor GC是有风险的；如果小于，或者 HandlePromotionFailure设置不允许冒险，那么就改为进行一次Full GC。 方法区的回收垃圾收集主要针对于Java堆进行，方法区虽然也有垃圾收集，但性价比很低，主要回收两部分内容：废弃常量和无用的类。 无用的类需要满足下面三个条件： 该类所有的实例都已经被回收，也就是堆中不存在该类的任何实例。 加载该类的ClassLoader已经被回收。 该类对应的Class对象没有在任何地方被引用，也就无法在任何地方通过反射访问该类方法。 参考资料 周志明. 深入理解 Java 虚拟机 [M]. 机械工业出版社, 2011.]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>垃圾收集</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM-类加载机制]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM-%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[类的生命周期 类加载过程类加载的过程包括了加载、验证、准备、解析、初始化五个阶段。 在这五个阶段中，加载、验证、准备和初始化这四个阶段发生的顺序是确定的，而解析阶段则不一定，它在某些情况下可以在初始化阶段之后开始，这是为了支持Java语言的运行时绑定（也称为动态绑定或晚期绑定）。另外注意这里的几个阶段是按顺序开始，而不是按顺序进行或完成，因为这些阶段通常都是互相交叉地混合进行的，通常在一个阶段执行的过程中调用或激活另一个阶段。 加载在加载阶段，虚拟机需要完成以下三件事情： 通过一个类的全限定名来获取其定义的二进制字节流。 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。 在Java堆中生成一个代表这个类的java.lang.Class对象，作为对方法区中这些数据的访问入口。 相对于类加载的其他阶段而言，加载阶段（准确地说，是加载阶段获取类的二进制字节流的动作）是可控性最强的阶段，因为开发人员既可以使用系统提供的类加载器来完成加载，也可以自定义自己的类加载器来完成加载。 加载阶段完成后，虚拟机外部的二进制字节流就按照虚拟机所需的格式存储在方法区之中，而且在Java堆中也创建一个java.lang.Class类的对象，这样便可以通过该对象访问方法区中的这些数据。 二进制字节流不一定要从一个Class文件中获取，还可以通过以下几种方式获取： 从ZIP包读取，成为JAR、EAR、WAR格式的基础。 从网络中获取，最典型的应用是Applet。 运行时计算生成，例如动态代理技术，在java.lang.reflect.Proxy中使用ProxyGenerator.generateProxyClass来为特定接口生成代理类的二进制字节流。 由其他文件生成，例如由JSP文件生成对应的Class类。 验证确保 Class 文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。验证阶段大致会完成4个阶段的检验动作： 文件格式验证：验证字节流是否符合Class文件格式的规范。 元数据验证：对类的元数据信息进行语义校验，保证不存在不符合Java语言规范的元数据信息。（例如：这个类是否有父类）。 字节码验证：通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的，保证被校验类的方法在运行时不会做出危害虚拟机安全的事件。 符号引用验证：确保解析动作能正确执行。 验证阶段是非常重要的，但不是必须的，它对程序运行期没有影响，如果所引用的类经过反复验证，那么可以考虑采用-Xverifynone参数来关闭大部分的类验证措施，以缩短虚拟机类加载的时间。 准备准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些变量所使用的内存都将在方法区中进行分配。 注意： 这时候进行内存分配的仅包括类变量（被static修饰的变量），实例变量将会在对象实例化时（实例化不是类加载的一个过程）随着对象一起分配在Java堆中。 初始值通常情况下是数据类型的零值，但如果类字段同时被final和static修饰（即为常量），那么在准备阶段就会被初始化为所指定的值。 解析解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。 符号引用：符号引用以一组符号来描述所引用的目标，可以是任何形式的字面量，与虚拟机实现的内存布局无关，引用的目标不一定已经加载到内存中。 直接引用：直接引用可以是直接指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄。直接引用是和虚拟机实现的内存布局相关的，引用的目标必定已经在内存中存在。 其中解析过程在某些情况下可以在初始化阶段之后再开始，这是为了支持Java的动态绑定。 初始化初始化阶段才真正开始执行类中定义的Java程序代码。初始化阶段即虚拟机执行类构造器&lt;clinit&gt;()方法的过程。 &lt;clinit&gt;()方法是由编译器自动收集类中所有类变量的赋值动作和静态语句块中的语句合并产生的，编译器收集的顺序由语句在源文件中出现的顺序决定。特别注意的是，静态语句块只能访问到定义在它之前的类变量，定义在它之后的类变量只能赋值，不能访问。 与类的构造函数（或者说实例构造器&lt;init&gt;()）不同，不需要显式的调用父类的构造器。虚拟机会自动保证在子类的&lt;clinit&gt;()方法运行之前，父类的&lt;clinit&gt;()方法已经执行结束。因此虚拟机中第一个执行&lt;clinit&gt;()方法的类肯定为java.lang.Object。 由于父类的&lt;clinit&gt;()方法先执行，也就意味着父类中定义的静态语句块的执行要优先于子类。 &lt;clinit&gt;()方法对于类或接口不是必须的，如果一个类中不包含静态语句块，也没有对类变量的赋值操作，编译器可以不为该类生成&lt;clinit&gt;()方法。 接口中不可以使用静态语句块，但仍然有类变量初始化的赋值操作，因此接口与类一样都会生成&lt;clinit&gt;()方法。但接口与类不同的是，执行接口的&lt;clinit&gt;()方法不需要先执行父接口的&lt;clinit&gt;()方法。只有当父接口中定义的变量使用时，父接口才会初始化。另外，接口的实现类在初始化时也一样不会执行接口的&lt;clinit&gt;()方法。 虚拟机会保证一个类的&lt;clinit&gt;()方法在多线程环境下被正确的加锁和同步，如果多个线程同时初始化一个类，只会有一个线程执行这个类的&lt;clinit&gt;()方法，其它线程都会阻塞等待，直到活动线程执行&lt;clinit&gt;()方法完毕。如果在一个类的&lt;clinit&gt;()方法中有耗时的操作，就可能造成多个线程阻塞，在实际过程中此种阻塞很隐蔽。 在准备阶段，类变量已经赋过一次系统要求的初始值，而在初始化阶段，根据程序员通过程序制定的主观计划去初始化类变量和其它资源。在Java中对类变量进行初始值设定有两种方式： 声明类变量时指定初始值。 使用静态代码块为类变量指定初始值。 只有当对类主动引用的时候才会导致类的初始化，主动引用有以下几种： 创建类的实例，也就是new的方式。 访问某个类或接口的静态变量，或者对该静态变量赋值。 调用类的静态方法。 使用java.lang.reflect包的方法对类进行反射调用的时候。 当初始化一个类的时候，如果其父类还没有进行过初始化，则需要先触发其父类的初始化。 当虚拟机启动时，用户需要指定一个要执行的主类（包含 main() 方法的那个类），虚拟机会先初始化这个主类。 除主动引用外的所有引用类的方式都不会触发初始化，被称为被动引用，常见有以下几个例子: 通过子类引用父类的静态字段，不会导致子类初始化。 通过数组定义来引用类，不会触发此类的初始化。该过程会对数组类进行初始化，数组类是一个由虚拟机自动生成的、直接继承自Object的子类，其中包含了数组的属性和方法。 类加载器两个类相等需要类本身相等，并且使用同一个类加载器进行加载。这是因为每一个类加载器都拥有一个独立的类名称空间。 从 Java 虚拟机的角度来讲，只存在以下两种不同的类加载器： 启动类加载器（Bootstrap ClassLoader），这个类加载器用C++实现，是虚拟机自身的一部分。 所有其他类的加载器，这些类由Java实现，独立于虚拟机外部，并且全都继承自抽象类java.lang.ClassLoader，这些类加载器需要由启动类加载器加载到内存中之后才能去加载其他的类。 站在Java开发人员的角度来看，类加载器可以大致划分为以下三类： 启动类加载器（Bootstrap ClassLoader）：此类加载器负责将存放在 &lt;JRE_HOME&gt;\lib目录中的，或者被-Xbootclasspath参数所指定的路径中的，并且是虚拟机识别的（仅按照文件名识别，如rt.jar，名字不符合的类库即使放在lib目录中也不会被加载）类库加载到虚拟机内存中。启动类加载器无法被Java程序直接引用，用户在编写自定义类加载器时，如果需要把加载请求委派给启动类加载器，直接使用null代替即可。 扩展类加载器（Extension ClassLoader）：此类加载器是由ExtClassLoader（sun.misc.Launcher$ExtClassLoader）实现的。它负责将&lt;JAVA_HOME&gt;/lib/ext或者被java.ext.dir系统变量所指定路径中的所有类库加载到内存中，开发者可以直接使用扩展类加载器。 应用程序类加载器（Application ClassLoader）：此类加载器是由AppClassLoader（sun.misc.Launcher$AppClassLoader）实现的。由于这个类加载器是ClassLoader中的getSystemClassLoader()方法的返回值，因此一般称为系统类加载器。它负责加载用户类路径（ClassPath）上所指定的类库，开发者可以直接使用这个类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。 双亲委派模型双亲委派模型的工作流程是：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把请求委托给父加载器去完成，依次向上，因此，所有的类加载请求最终都应该被传递到顶层的启动类加载器中，只有当父加载器在它的搜索范围中没有找到所需的类时，即无法完成该加载，子加载器才会尝试自己去加载该类。 该模型要求除了顶层的启动类加载器外，其余的类加载器都应有自己的父类加载器。这里类加载器之间的父子关系一般通过组合关系来实现，而不是通过继承的关系实现。 具体过程 当AppClassLoader加载一个class时，它首先不会自己去尝试加载这个类，而是把类加载请求委派给父类加载器ExtClassLoader去完成。 当ExtClassLoader加载一个class时，它首先也不会自己去尝试加载这个类，而是把类加载请求委派给BootStrapClassLoader去完成。 如果BootStrapClassLoader加载失败（例如在&lt;JRE_HOME&gt;\lib里未查找到该class），会使用ExtClassLoader来尝试加载。 若ExtClassLoader也加载失败，则会使用AppClassLoader来加载，如果AppClassLoader也加载失败，则会报出异常ClassNotFoundException。 优点使得Java类随着它的类加载器一起具有一种带有优先级的层次关系，从而使得基础类得到统一。 例如java.lang.Object存放在rt.jar中，如果编写另外一个java.lang.Object的类并放到ClassPath中，程序可以编译通过。由于双亲委派模型的存在，所以在rt.jar中的Object比在ClassPath中的Object优先级更高，这是因为rt.jar中的Object使用的是启动类加载器，而ClassPath中的Object使用的是应用程序类加载器。rt.jar中的Object优先级更高，那么程序中所有的Object都是这个Object。 自定义类加载器通常情况下，我们都是直接使用系统类加载器，但是有的时候，我们也需要自定义类加载器。 自定义类加载器一般都是继承自ClassLoader类，而java.lang.ClassLoader的loadClass()实现了双亲委派模型的逻辑，因此自定义类加载器最好不要去重写它。 参考资料 周志明. 深入理解 Java 虚拟机 [M]. 机械工业出版社, 2011.]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM-内存模型]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM-%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[Java内存模型由于计算机上的内存模型涉及到物理的主内存、高速缓存和寄存器等。这些不同的计算机不同的操场系统可能会存在差异，Java虚拟机规范中试图定义一种Java内存模型，来屏蔽掉各种硬件和操作系统的内存访问差异，让Java程序在各个平台下都能达到一致的访问效果。 主内存与工作内存 Java内存模型规定了所有变量都存储在主内存内（主内存包括方法区和堆），此处主内存隶属于Java虚拟机内存的一部分，而虚拟机内存是操作系统分配的。每条Java线程还有自己的工作内存，工作内存中保存了被该线程使用到的变量的主内存的副本，线程对变量的所有操作都在工作内存中进行，Java线程之间的变量值传递都通过主内存来完成。 内存间的交互关于主内存和工作内存间的交互协议，即一个变量如何从工作内存拷贝到工作内存、又是如何从工作内存同步回主内存之类的实现细节，Java内存模型中定义了8种操作，这8种操作实现时必须保证每一种操作都是原子的、不可再分的，其中前4条是作用于主内存，后4条作用于工作内存： lock锁定：将一个变量标识为线程独占状态 unlock解锁：将锁定状态的变量解除锁定，释放后的变量才可以被其他变量锁定 read读取：将变量从主内存传输到线程的工作内存中，待之后的load加载 write写入：把store操作从工作内存中得到的变量值写入主内存的变量中 load加载：将read后从主内存得到的变量值加载到工作内存的变量副本中 use使用：把工作内存中的一个变量值传递给字节码执行引擎，等待字节码指令使用 assign赋值：把一个从执行引擎接收到的值赋值给工作内存的变量 store存储：把工作内存中一个变量的值传送到主内存中，以便随后的write使用 volatile关键字volatile关键字具有以下两种特性： 保证此变量对所有变量的可见性 禁止指令重排序优化 对于第一种特性，即volatile关键字保证了新值能立即同步到主内存，以及每个线程在每次使用volatile变量前都立即从主内存刷新。因此我们可以说volatile保证了多线程操作时变量的可见性，而普通变量则不能保证这一点。 而对于第二种特性，volatile关键字本身就包含了禁止指令重排序的语义。 运行时数据区域Java虚拟机在执行Java程序的过程中会把它所管理的内存划分为若干个不同的数据区域。其中程序计数器、JVM栈、本地方法栈是线程私有的，而方法区和堆是所有线程共享的。 程序计数器一块较小的内存空间，可以看作当前线程所执行的字节码的行号指示器：如果线程正在执行一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行Native方法，这个计数器值则为空。 Java虚拟机栈Java虚拟机栈描述的是Java方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。 局部变量表：存放了编译器可知的各种基本数据类型、对象引用和returnAddress类型（指向了一条字节码指令的地址）。局部变量表所需的内存空间在编译期间完成分配。 动态链接：动态链接是指编译系统在链接阶段并不把目标文件和函数库文件链接在一起，是等到程序在运行过程中需要使用时才链接函数库。 操作数：参与运算的常量或者变量称为操作数。 该区域可能抛出以下异常： 当线程请求的栈深度超过最大值，会抛出StackOverflowError异常。 栈进行动态扩展时如果无法申请到足够内存，会抛出OutOfMemoryError异常。 本地方法栈本地方法栈与Java虚拟机栈类似，它们的区别只不过是虚拟机栈为虚拟机执行Java方法服务，而本地方法栈为本地方法服务。该区域可能抛出的异常与Java虚拟机栈一样。 Java堆Java堆是Java虚拟机所管理的内存中最大的一块，是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。 Java堆是垃圾收集器管理的主要区域，还可以细分为新生代和老年代。 一般情况下，新创建的对象都会存放到新生代中。 在新生代每进行一次垃圾收集后，就会给存活的对象“加1岁”，当年龄达到一定数量的时候就会进入老年代，另外，比较大的对象也会进入老年代。 Java堆不需要物理上连续的内存空间，逻辑上连续即可。如果堆中没有内存完成实例分配且堆也无法再扩展时，将抛出OutOfMemoryError异常。 方法区方法区常被称为“永久代”，也是各个线程共享的内存区域，用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。 和堆一样不需要连续的内存，并且可以动态扩展，动态扩展失败将抛出OutOfMemoryError异常。 运行时常量池运行时常量池是方法区的一部分，用于存放编译期生成的各种字面量和符号引用。 相较于Class文件常量池，运行时常量池更具动态性，在运行期间也可以将新的变量放入常量池中，而不是一定要在编译时确定的常量才能放入，这种特性用的比较多的便是String类的intern()方法。 控制参数汇总可以通过如下参数来控制各区域的内存大小：12345678910111213-Xms设置堆的最小空间大小-Xmx设置堆的最大空间大小-XX:NewSize设置新生代最小空间大小-XX:MaxNewSize设置新生代最大空间大小-XX:PermSize设置永久代最小空间大小-XX:MaxPermSize设置永久代最大空间大小-Xss设置每个线程的堆栈大小 参考资料 周志明. 深入理解 Java 虚拟机 [M]. 机械工业出版社, 2011.]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>内存模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统原理-死锁]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86-%E6%AD%BB%E9%94%81%2F</url>
    <content type="text"><![CDATA[死锁的定义一组进程中，每个进程都无限等待被该组进程中另一进程所占有的资源，因而永远无法得到的资源，这种现象称为进程死锁，这一组进程就称为死锁进程。 死锁与活锁的区别活锁指的是一组进程既无进展也没有阻塞 ，由于某些条件没有满足，导致一直重复尝试并失败。例如错误地使用Pertonson算法： 产生死锁的必要条件 互斥使用（资源独占）：一个资源每次只能给一个进程使用。 占有且等待（请求和保持）：进程在申请新的资源的同时保持对原有资源的占有。 不可抢占：资源申请者不能强行的从资源占有者手中夺取资源，资源只能由占有者自愿释放。 循环等待：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。 资源分配图系统由若干类资源构成，一类资源称为一个资源类；每个资源类中包含若干个同种资源，称为资源实例。用方框表示资源类，用方框中的黑圆点表示资源实例，用圆圈中加进程名表示进程。如果资源分配图中没有环路，则系统中没有死锁， 如果图中存在环路则系统中可能存在死锁。 资源分配图化简 找一个非孤立、且只有分配边的进程结点，去掉分配边，将其变为孤立结点。 再把相应的资源分配给一个等待该资源的进程，即将该进程的申请边变为分配边。 如果一个图可完全化简（所有的资源和进程都变成孤立的点），则不会产生死锁；如果一个图不可完全化简（即图中还有边存在），则会产生死锁。 死锁预防防止产生死锁的四个必要条件中任何一个条件发生，以此排除发生死锁的可能性。 破坏“互斥使用”条件把独占资源变为共享资源。例如在SPOOLing系统中，实际上并没有为任何进程分配这台打印机，而只是在输入井和输出井中，为进程分配一存储区和建立一章I/O请求表。这样，便把独占设备改造为共享设备。 破坏“占有且等待”条件实现方案一：要求每个进程在运行前必须一次性申请它所要求的所有资源，且仅当该进程所要资源均可满足时才给予一次性分配。 实现方案二：在允许进程动态申请资源前提下规定，一个进程在申请新的资源不能立即得到满足而变为等待状态之前，必须释放已占有的全部资 源，若需要再重新申请。 破坏“不可抢占”条件当一个进程申请的资源被其他进程占用时，可以通过操作系统抢占这一资源(两个进程优先级不同) 。 破坏“循环等待”条件通过定义资源类型的线性顺序实现。 把系统中所有资源编号，进程在申请资源时必须严格按资源编号的递增次序进行，否则操作系统不予分配。 死锁避免在系统运行过程中，对进程发出的每一个系统能够满足的资源申请进行动态检查，并根据检查结果决定是否分配资源，若分配后系统发生死锁或可能发生死锁，则不予分配，否则予以分配。 安全状态如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也仍然存在某种调度次序能够使得每一个进程运行完毕，则称该状态是安全的。 例如，图a的第二列Has表示已拥有的资源数，第三列Max表示总共需要的资源数，Free表示还有可以使用的资源数。从图a开始出发，先让B拥有所需的所有资源（图b），运行结束后释放B，此时Free变为5（图c）；接着以同样的方式运行C和A，使得所有进程都能成功运行，因此可以称图a所示的状态时安全的。 单个资源的银行家算法一个小城镇的银行家，他向一群客户分别承诺了一定的贷款额度，算法要做的是判断对请求的满足是否会进入不安全状态，如果是，就拒绝请求；否则予以分配。 由图可知，状态b进入状态c是进入了一个不安全的状态，因此恢复原来状态，避免了进入不安全状态。 多个资源的银行家算法上图中有五个进程，四个资源。左边的图表示已经分配的资源，右边的图表示还需要分配的资源。最右边的E、P以及A分别表示：总资源、已分配资源以及可用资源。 检查一个状态是否安全的算法如下： 查找右边的矩阵是否存在一行小于等于向量A。如果不存在这样的行，那么系统将会发生死锁，状态是不安全的。 假若找到这样一行，将该进程标记为终止，并将其已分配资源加到A 中。 重复以上两步，直到所有进程都标记为终止，则状态是安全的。 如果一个状态不是安全的，需要拒绝进入这个状态。 死锁检测与解除允许死锁发生，但是操作系统会不断监视系统进展情况，判断死锁是否真的发生，一旦死锁发生则采取专门的措施，解除死锁并以最小的代价恢复操作系统运行。 死锁的检测死锁的检测与银行家算法几乎一样，此处不再阐述。 死锁的解除 利用抢占恢复 利用回滚恢复 通过杀死进程恢复 鸵鸟算法把头埋在沙子里，假装根本没发生问题。 因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。 哲学家就餐问题五个哲学家围着一张圆桌，每个哲学家面前放着食物。哲学家的生活有两种交替活动：吃饭以及思考。当一个哲学家吃饭时，需要先拿起自己左右两边的两根筷子，并且一次只能拿起一根筷子。 下面是一种错误的解法，考虑到如果所有哲学家同时拿起左手边的筷子，那么就无法拿起右手边的筷子，造成死锁。 123456789101112#define N 5void philosopher(int i) &#123; while(true) &#123; think(); take(i); // 拿起左边的筷子 take((i+1)%N); // 拿起右边的筷子 eat(); put(i); put((i+1)%N); &#125;&#125; 为了防止死锁的发生，有以下几种解法： 仅当一个哲学家左右两边的筷子都可用时，才允许他拿筷子。 最多允许4个哲学家同时坐在桌子周围。 规定奇数号哲学家先拿左筷子再拿右筷子，而偶数号哲学家相反。 参考资料 Tanenbaum A S, Bos H. Modern operating systems[M]. Prentice Hall Press, 2014. 北京大学操作系统原理（Operating Systems） 计算机操作系统]]></content>
      <tags>
        <tag>操作系统</tag>
        <tag>死锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统原理-文件系统]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[文件的分类 普通文件：包含了用户的信息，一般为ASCII或二进制文件 目录文件：管理文件系统的系统文件 特殊文件（设备文件） 文件的逻辑结构逻辑结构是从用户观点出发看到的文件的组织形式。分为以下两类： 流式文件：无结构，对文件内信息不再划分单位，它是依次的一串字符流构成的文件。 记录式文件：有结构，文件由若干个记录组成，可以按记 录进行读、写、查找等操作。 存储介质与物理块典型的存储介质磁盘(包括固态盘SSD)、磁带、光盘、U盘等等，以下为典型的磁盘结构： 物理块 信息存储、传输、分配的独立单位 存储设备划分为大小相等的物理块，统一编号 磁盘访问 寻道：磁头移动定位到指定磁道 旋转延迟：等待指定扇区从磁头下旋转经过 数据传输：数据在磁盘与内存之间的实际传输 文件控制块（FCB）为管理文件而设置的数据结构，保存管理文件所需的所有有关信息（文件属性或元数据）。 文件控制块一般包含下列常用属性： 文件名 文件号 文件大小 文件地址 创建时间 最后修改时间 最后访问时间 各种标志(只读、隐藏、系统、归档等) … 文件目录 文件目录：文件目录由目录项构成，统一管理每个文件的元数据，以支持文件名到文件物理地址的转换。 目录文件：将文件目录以文件的形式存放在磁盘上。 目录项：可以看成是FCB。 文件的物理结构文件的物理结构指的是文件在存储介质上的存放方式。 连续结构文件的信息存放在若干连续的物理块中。 连续结构实现简单，且所需的磁盘寻道次数和寻道时间最少，支持顺序存取和随机存取，但文件不能动态增长，且会产生许多外部碎片。 链接结构一个文件的信息存放在若干不连续的物理块中，各块之间通过指针连接，前一个物理块指向下一 个物理块。 使用链接结构不存在外部碎片的问题，提高了磁盘空间利用率，有利于文件的动态扩充，但是比起连续结构需要更多的寻道次数和寻道时间，且存取速度慢，不适于随机存取。 索引结构一个文件的信息存放在若干不连续物理块中，系统为每个文件建立一个专用数据结构索引表，并将这些物理块的块号存放在该索引表中。 索引结构保持了链接结构的优点，也解决了其缺点：既能顺序存取又能随机存取，满足了文件动态增长的要求，能充分利用磁盘空间。但是索引结构依然有较多的寻道次数和寻道时间，而索引表本身也带来了额外系统开销。 多级索引结构（综合模式） UNIX文件系统采用的便是这种多级索引结构（综合模式）：每个文件的索引表有15个索引项，每项2个字节，前12项直接存放文件的物理块号，如果文件大于12块，则利用第13项指向一个物理块作为一级索引表。假设扇区大小为512字节，物理块等于扇区块大小，那么一级索引表可以存放256个物理块号。对于更大的文件还可利用第14和第15项作为二级和三级索引表。 文件目录检索用户给出文件名，按文件名查找到目录项/FCB，根据目录项/FCB中文件物理地址等信息，计算出文件中任意记录或字符在存储介质上的地址。 目录项分解法通过目录项分解法可以加快文件目录的检索速度。 目录项分解法即把FCB分解成两部分：符号目录项（文件名，文件号）、基本目录项（除文件名外的所有字段）。目录文件改进后减少了访盘次数，提高了文件检索速度。 磁盘调度算法当有多个访盘请求等待时，采用一定的策略，对这些请求的服务顺序调整安排，以降低平均磁盘服务时间，达到公平、高效。 先来先服务（FCFS）按访问请求到达的先后次序服务。 优点是简单公平，但效率不高，相临两次请求可能会造成最内到最外的柱面寻道，使磁头反复移动，增加了服务时间，对机械也不利。 最短寻道时间优先（Shortest Seek Time First）优先选择距当前磁头最近的访问请求进行服务。 虽然改善了磁盘平均服务时间，但是造成某些访问请求长期等待得不到服务，也就是饥饿现象。 扫描算法（SCAN）扫描算法又称为电梯算法，当设备无访问请求时，磁头不动；当有访问请求时，磁头按一个方向移动，在移动过程中对遇到的访问请求进行服务，然后判断该方向上是否还有访问请求，如果有则继续扫描；否则改变移动方向，并为经过的访问请求服务，如此反复。 单向扫描算法（CSCAN）扫描调度算法（SCAN）存在这样的问题：当磁头刚从里向外移动过某一磁道时，恰有一进程请求访问此磁道，这时该进程必须等待，待磁头从里向外，然后再从外向里扫描完所有要访问的磁道后，才处理该进程的请求，致使该进程的请求被严重地推迟。 为了减少这种延迟，CSCAN算法规定磁头只做单向移动。例如，磁头只自里向外移动，当磁头移到最外的被访问磁道时，磁头立即返回到最里的欲访磁道，即将最小磁道号紧接着最大磁道号构成循环，进行扫描。 旋转调度算法旋转调度算法根据延迟时间来决定执行次序的调度，请求访问分为以下三种情况： 若干等待访问者请求访问同一磁头上的不同扇区 若干等待访问者请求访问不同磁头上的不同编号的扇区 若干等待访问者请求访问不同磁头上具有相同的扇区 对于前两种情况总是让首先到达读写磁头位置下的扇区先进行传送操作，而对于第三种情况，这些扇区同时到达读写磁头位置下，可任意选择一个读写磁头进行传送操作。 参考资料 Tanenbaum A S, Bos H. Modern operating systems[M]. Prentice Hall Press, 2014. 北京大学操作系统原理（Operating Systems） 计算机操作系统]]></content>
      <categories>
        <category>操作系统原理</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统原理-存储模型]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86-%E5%AD%98%E5%82%A8%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[地址重定位为了保证CPU执行指令时可正确访问内存单元，需要将用户程序中的逻辑地址转换为运行时可由机器直接寻址的物理地址，这一过程称为地址重定位（又称地址转换、地址变换、地址翻译、地址映射）。 逻辑地址（相对地址，虚拟地址）：目标代码通常采用相对地址的形式，其首地址为0， 其余地址都相对于首地址而编址。不能用逻辑地址在内存中读取信息。 物理地址（绝对地址，实地址）：内存中存储单元的地址，可直接寻址。 地址重定位分为静态重定位和动态重定位： 静态重定位：当用户程序加载到内存时，一次性实现逻辑地址到物理地址的转换。 动态重定位：在进程执行过程中进行地址变换，即逐条指令执行时完成地址转换。 伙伴系统Linux底层内存管理采用伙伴系统这一种经典的内存分配方案。 主要思想：将内存按2的幂进行划分，组成若干空闲块链表；查找该链表找到能满足进程需求的最佳匹配块。 过程： 首先将整个可用空间看作一块： 2^u 假设进程申请的空间大小为 s，如果满足 2^u-1 &lt; s &lt;= 2^u，则分配整个块；否则，将块划分为两个大小相等的伙伴，大小为2^u-1 一直划分下去直到产生大于或等于 s 的最小块 基本内存管理方案一整个进程进入内存中一片连续区域。 单一连续区内存在此方式下分为系统区和用户区，系统区仅提供给操作系统使用，用户区是为用户提供的、除系统区之外的内存空间。一段时间内只有一个进程在内存，简单但内存利用率低。 固定分区把内存空间分割成若干区域，称为分区，每个分区的大小可以相同也可以不同，但分区大小固定不变，每个分区装一个且只能装一个进程。 这种方式会产生两个问题：一是程序太大而放不进任何一个分区中；二是容易产生内部碎片。 可变分区可变分区是一种动态划分内存的分区方法。这种分区方法不预先将内存划分，而是在进程装入内存时，根据进程的大小动态地建立分区，并使分区的大小正好适合进程的需要。因此系统中分区的大小和数目是可变的。 可变分区虽然不会产生内部碎片，但容易产生外部碎片，导致内存利用率下降。 在进程装入或换入主存时，如果内存中有多个足够大的空闲块，操作系统必须确定分配哪个内存块给进程使用，考虑以下几种分配算法： 首次适配（first fit）：在空闲区表中找到第一个满足进程要求的空闲区。该算法优先使用低址部分空闲区，在低址空间造成许多小的空闲区，在高地址空间保留大的空闲区。 下次适配（next fit）：从上次找到的空闲区处接着查找。 最佳适配（best fit）：查找整个空闲区表，找到能够满足进程要求的最小空闲区。该算法保留大的空闲区，但造成许多小的空闲区。 最差适配（worst fit ）：总是分配满足进程要求的最大空闲区。该算法保留小的空闲区，尽量减少小的碎片产生。 基本内存管理方案二一个进程进入内存中若干片不连续的区域。 页式存储管理方案用户进程地址空间被划分为大小相等的部分，称为页（page）或页面，从0开始编号。内存空间按同样大小划分为大小相等的区域，称为页框（page frame）或物理页面或内存块，从0开始编号。 内存分配规则：以页为单位进行分配，并按进程需要的页数来分配；逻辑上相邻的页，物理上不一定相邻。 每个进程一个页表，存放在内存。 地址转换CPU取到逻辑地址，自动划分为页号和页内地址；用页号查页表，得到页框号，再与页内偏移拼接成为物理地址。 段式存储管理方案将用户进程地址空间按程序自身的逻辑关系划分为若干个程序段，每个程序段都有一个段号。内存空间被动态划分为若干长度不相同的区域， 称为物理段，每个物理段由起始地址和长度确定。 内存分配规则：以段为单位进行分配，每段在内存中占据连续空间，但各段之间可以不相邻。 地址转换CPU取到逻辑地址，自动划分为段号和段内地址；用段号查段表，得到该段在内存的起始地址，与段内偏移地址计算出物理地址。 覆盖技术把一个程序划分为一系列功能相对独立的程序段，让执行时不要求同时装入内存的程序段组成一组（称为覆盖段），共享同一块内存区域 ，这种内存扩充技术就是覆盖技术。 程序段先保存在磁盘上，当有关程序段的前一部分执行结束，把后续程序段调入内存，覆盖前面的程序段。 一般要求作业各模块之间有明确的调用结构，程序员要向系统指明覆盖结构，然后由操作系统完成自动覆盖。 交换技术内存空间紧张时，系统将内存中某些进程暂时移到外存，把外存中某些进程换进内存，占据前者所占用的区域（进程在内存与磁盘之间的动态调度）。 虚拟存储技术所谓虚拟存储技术是指：当进程运行时，先将其一部分装入内存，另一部分暂留在磁盘，当要执行的指令或访问的数据不在内存时，由操作系统自动完成将它们从磁盘调入内存的工作。 虚拟地址空间：分配给进程的虚拟内存 虚拟地址：在虚拟内存中指令或数据的位置， 该位置可以被访问，仿佛它是内存的一部分 虚拟内存：把内存与磁盘有机地结合起来使用，从而得到一个容量很大的“内存” 虚拟页式存储管理系统虚拟页式即将虚拟存储技术和页式存储管理方案结合起来，以CPU时间和磁盘空间换取昂贵内存空间。 基本思想：进程开始运行之前，不是装入全部页面， 而是装入一个或零个页面，之后，根据进程运行的需要，动态装入其他页面。当内存空间已满，而又需要装入新的页面时，则根据某种算法置换内存中的某个页面，以便装入新的页面。 内存管理单元（MMU）内存管理单元（MMU）管理着地址空间和物理内存的转换，其中的页表（Page table）存储着页（程序地址空间）和页框（物理内存空间）的映射表。 上图为一级页表结构的地址转换，下图为二级页表结构的地址转换及MMU的位置。 二级页表结构及地址映射页目录表共有2^10 = 1K个表项，每个表项是4B，因此页目录大小为4K，存储在一个4K字节的页面中。同理，一个页表也存储在一个4K字节的页面中。 为什么要使用多级页表系统分配给每个进程的虚拟地址都是4G，那么采用一级页表需要4G／4K = 2^20个表项，如果每个页表项是4B，那么需要4MB的内存空间。但是大多数程序根本用不到4G的虚拟内存空间，比如hello world程序，这样一个几kb的程序却需要4MB的内存空间是很浪费的。如果采用二级页表，那么一级页表只需要4KB的空间用来索引二级页表的地址，像hello world这样的程序可能只需要一个物理页，那么只需要一条记录就可以了，故对于二级页表也只要4KB就足够了，所以这样只需要8KB就能解决问题。 TLB（快表）页表一般都很大，并且存放在内存中，所以处理器引入MMU后，读取指令、数据需要访问两次内存：首先通过查询页表得到物理地址，然后访问该物理地址读取指令、数据。由于CPU的指令处理速度与内存指令的访问速度差异大，CPU的速度得不到充分利用，为了减少因为MMU导致的处理器性能下降，引入了TLB。 TLB(Translation Lookaside Buffer)转换检测缓冲区相当于页表的缓存，利用程序访问的局部性原理改进虚拟地址到物理地址的转换速度。TLB保存正在运行进程的页表的子集(部分页表项)，只有在TLB无法完成地址转换任务时，才会到内存中查询页表，这样就减少了页表查询导致的处理器性能下降。 缺页异常缺页异常是一种Page Fault（页错误）。在地址映射过程中，硬件检查页表时发现所要访问的页面不在内存，则产生缺页异常，操作系统执行缺页异常处理程序：获得磁盘地址，启动磁盘，将该页调入内存。此时分为两种情况： 如果内存中有空闲页框，则分配一个页框， 将新调入页装入，并修改页表中相应页表项的有效位及相应的页框号。 若内存中没有空闲页框，则要置换内存中某一页框；若该页框内容被修改过，则要将其写回磁盘。 页面置换算法最佳页面置换算法（OPT，Optimal）置换以后不再需要的或最远的将来才会用到的页面。 这是一种理论上的算法，因为无法知道一个页面多长时间不再被访问，它作为一种标准来衡量其他算法的性能。 先进先出算法（FIFO）选择在内存中驻留时间最长的页并置换它。 该算法会将那些经常被访问的页面也被换出，从而使缺页率升高。 第二次机会算法（SCR，Second Chance）当页面被访问 (读或写) 时设置该页面的R位为1。需要替换的时候，检查最老页面的R位。如果R位是0，那么这个页面既老又没有被使用，可以立刻置换掉；如果是1，就将R位清0，并把该页面放到链表的尾端，修改它的装入时间使它就像刚装入的一样，然后继续从链表的头部开始搜索。 这个算法是对FIFO算法的改进，不会像FIFO一样把经常使用的页面置换出去。 时钟算法（CLOCK）第二次机会算法需要在链表中移动页面，降低了效率。时钟算法使用环形链表将页面连接起来，再使用一个指针指向最老的页面。 最近未使用算法（NRU，Not Recently Used）选择在最近一段时间内未使用过的一页并置换。 每个页面都有两个状态位：R与M，当页面被访问时设置页面的R=1，当页面被修改时设置M=1。其中R位会定时被清零。可以将页面分成以下四类： R=0，M=0 R=0，M=1 R=1，M=0 R=1，M=1 当发生缺页中断时，NRU算法随机地从类编号最小的非空类中挑选一个页面将它换出。 NRU算法优先换出已经被修改的脏页面（R=0，M=1），而不是被频繁使用的干净页面（R=1，M=0）。 最近最久未使用算法（LRU，Least Recently Used ）虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。LRU算法选择最后一次访问时间距离当前时间最长的一页并置换，即置换未使用时间最长的一页。 为了实现LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最长时间未访问的。 LRU的性能接近OPT，但因为每次访问都需要更新链表，因此这种方式实现的LRU代价很高。 最不经常使用算法（NFU，Not Frequently Used）NFU算法选择访问次数最少的页面置换。 因为LRU算法的实现比较麻烦而且开销很大，所以提出了用软件来模拟LRU算法的NFU算法，该算法为每一页设置一个软件计数器，初值为0，每次时钟中断的时候就将计数器加R，发生缺页中断时选择计数器值最小的一页置换。 老化算法（AGING）在NFU算法中存在一个问题：在第一次时钟中断的时候其中一页可能被访问了很多次，之后再未被访问过，然而在以后的时钟中断这一页计数器的值仍然高于其它页，因此其虽然长时间未被访问也不会被置换出去。 为了更好地模拟LRU算法，老化算法对NFU进行了改进，计数器在加R前先右移一位，R位加到计数器的最左端。 工作集算法基本思想：根据程序的局部性原理，一般情况下，进程在一段时间内总是集中访问一些页面，这些页面称为活跃页面，如果分配给一个进程的物理页面数太少了，使该进程所需的活跃页面不能全部装入内存，则进程在运行过程中将频繁发生中断 。如果能为进程提供与活跃页面数相等的物理页 面数，则可减少缺页中断次数。 工作集W(t, Δ) = 该进程在过去的Δ个虚拟时间单位中访问到的页面的集合 工作集算法就是找出一个不在工作集中的页面并置换它。具体过程为：扫描所有页表项，如果一个页面的R位是1，则将该页面的最后一次访问时间设为当前时间，将R位清零；如果一个页面的R位是0，则检查该页面的访问 时间是否在“当前时间-T”之前，如果是，则该页面为被置换的页面；如果不是，记录当前所有被扫描过页面的最后访问时间里面的最小值，扫描下一个页面并重复上述过程。 参考资料 Tanenbaum A S, Bos H. Modern operating systems[M]. Prentice Hall Press, 2014. 北京大学操作系统原理（Operating Systems） 计算机操作系统 内存连续分配方式的几种算法及优劣 多级页表]]></content>
      <categories>
        <category>操作系统原理</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统原理-同步机制]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86-%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[进程互斥由于各进程要求使用共享资源（变量、文件等），而这些资源需要排他性使用，各进程之间竞争使用这些资源，这一关系称为进程互斥。 临界资源与临界区系统中某些资源一次只允许一个进程使用，称这样的资源为临界资源或互斥资源或共享变量。 而各个进程中对某个临界资源（共享变量）实施操作的程序片段称为临界区或互斥区。 临界区的使用原则 没有进程在临界区时，想进入临界区的进程可进入 不允许两个进程同时处于其临界区中 临界区外运行的进程不得阻塞其他进程进入临界区 不得使进程无限期等待进入临界区 进程互斥的软件解决方案错误解法考虑两个进程p和q，pturn与qturn表示哪个进程要进入临界区，P进入临界区的条件为pturn &amp;&amp; not qturn，而Q进入临界区的条件为not pturn &amp;&amp; qturn: 12345//进程p：pturn = true; while (qturn) ; visit(); //访问临界区pturn = false; 12345//进程q：qturn = true; while (pturn) ; visit(); //访问临界区qturn = false; 如果由于CPU调度使得两个进程都执行完了第一行语句，也就是pturn和qturn都为true了，那么就都会在下一行while语句上死循环，互相都在谦让对方执行，也就不满足了临界区的使用原则—不得使进程无限期等待进入临界区。 Dekker算法Dekker互斥算法是由荷兰数学家Dekker提出的一种解决并发进程互斥与同步的软件实现方法。假设有p和q两个进程，变量pturn、qturn表示p和q进程是否想要资源（可以想象为举手示意想要），变量turn表示安排资源给谁： 123456789101112//进程P：pturn = true; //进程p举手示意想要访问while (qturn) &#123; //如果进程q也举手了 if (turn == 2) &#123; //资源被安排给了q pturn = false; //进程p把手放下 while (turn == 2); //资源安排给q的时候一直等待 pturn = true; //此时资源安排给了自己，进程p再举手 &#125;&#125;visit(); //访问临界区turn = 2; //进程p使用完了，安排资源给qpturn = false; //进程p把手放下 123456789101112//进程q：qturn = true; while (pturn) &#123; if (turn == 1) &#123; qturn = false; while (turn == 1); qturn = true; &#125;&#125;visit(); //访问临界区turn = 1;qturn = false; 如果两个进程都执行完了第一行语句，也就是pturn和qturn都为true了，那么会根据变量turn进一步查看究竟是把资源安排给了谁，如果安排给了另一个进程，那么自己就先把手放下，等待安排资源给自己。 与之前的错误解法相比，可以发现Dekker算法就是在原本的while死循环上做了进一步的判断，引入的turn变量总是会安排一个进程访问临界区。 Peterson算法Peterson算法是另一种解决并发进程互斥与同步的软件实现方法，而且克服了强制轮流法的缺点。其使用十分方便，只需要向如下这样调用即可: 123enter_region(i);visit(); //访问临界区leave_region(i); 其中的enter_region方法实现如下： 1234567891011121314#define FALSE 0#define TRUE 1#define N 2 //进程的个数int turn; //轮到谁int interested[N]; //兴趣数组，初始值均为FALSE void enter_region(int process) // process = 0 或 1&#123; int other; // 另外一个进程的进程号 other = 1 - process; interested[process] = TRUE; // 表明本进程感兴趣 turn = process; // 设置标志位 while(turn == process &amp;&amp; interested[other] == TRUE); &#125; 如果有两个进程都要执行的话，turn会被设置成后一个进程的进程号，这时候因为要按照先来后到的规矩，后一个进程在判断while条件的时候turn == process成立，也就进行循环等待，而先进入的进程可以访问临界区。当先进入的进程离开了临界区，就调用leave_region方法，将自己的兴趣设为FALSE，后一个进程判断interested[other] == TRUE不成立时就可以跳出while循环进入临界区了。 123void leave_region(int process)&#123; interested[process] = FALSE; // 本进程已离开临界区&#125; 进程互斥的硬件解决方案“测试并加锁”指令 “交换”指令 进程同步进程同步指系统中多个进程中发生的事件存在某种时序关系，需要相互合作，共同完成一项任务。具体地说，一个进程运行到某一点时， 要求另一伙伴进程为它提供消息，在未获得消息之前，该进程进入阻塞态，获得消息后被唤醒进入就绪态。 信号量及PV操作信号量是一个特殊变量，用于进程间传递信息的一个整数值，定义如下： 12345struct semaphore&#123; int count; queueType queue;&#125; 可以对其执行down和up操作，也就是常见的P和V操作（PV操作均为原语操作），定义如下： 12345678910111213141516171819P(semaphore s) &#123; s.count--; if (s.count &lt; 0) &#123; //该进程状态置为阻塞状态； //将该进程插入相应的等待队列s.queue末尾; //重新调度； &#125;&#125;V(semaphore s) &#123; s.count++; if (s.count &lt;= 0) &#123; //唤醒相应等待队列s.queue中等待的一个进程； //改变其状态为就绪态，并将其插入就绪队列； &#125; &#125; 用PV操作解决进程间互斥问题 分析并发进程的关键活动，划定临界区 设置信号量 mutex，初值为1 在临界区前实施 P(mutex) 在临界区之后实施 V(mutex) 用信号量解决生产者-消费者问题问题描述：使用一个缓冲区来保存物品，只有缓冲区没有满，生产者才可以放入物品；只有缓冲区不为空，消费者才可以拿走物品。 这里使用三个信号量，其中mutex用于解决互斥问题，empty和full用于解决同步问题。 123456789101112131415161718192021222324252627#define N 100 //缓冲区个数typedef int semaphore; //信号量是一种特殊的整型数据semaphore mutex = 1; //互斥信号量：控制对临界区的访问semaphore empty = N; //空缓冲区个数，初始为Nsemaphore full = 0; //满缓冲区个数，初始为0void producer() &#123; while(TRUE) &#123; int item = produce_item(); p(&amp;empty); p(&amp;mutex); insert_item(item); v(&amp;mutex); v(&amp;full); &#125;&#125;void consumer() &#123; while(TRUE) &#123; p(&amp;full); p(&amp;mutex); int item = remove_item(); v(&amp;mutex); v(&amp;empty); consume_item(item); &#125;&#125; 注意：不能交换p(&amp;empty);和p(&amp;mutex);的顺序，否则会导致死锁。 用信号量解决读者-写者问题问题描述：多个进程共享一个数据区，这些进程分为只读数据区中的数据的读者进程和只往数据区中写数据的写者进程。允许多个读者同时执行读操作，不允许多个写者同时操作，不允许读者、写者同时操作。 1234567891011121314151617181920212223242526typedef int semaphore;semaphore count_mutex = 1; //对count加锁semaphore data_mutex = 1; //对读写的数据加锁int count = 0; //对数据进行读操作的进程数量void reader() &#123; while(TRUE) &#123; p(&amp;count_mutex); count = count + 1; if(count == 1) p(&amp;data_mutex); // 第一个读者需要对数据进行加锁，防止写进程访问 v(&amp;count_mutex); read(); p(&amp;count_mutex); count = count - 1; if(count == 0) v(&amp;data_mutex); v(&amp;count_mutex); &#125;&#125;void writer() &#123; while(TRUE) &#123; p(&amp;data_mutex); write(); v(&amp;data_mutex); &#125;&#125; 管程由于信号量机制程序编写困难、易出错，所以在程序设计语言中引入管程。 管程是一个抽象数据类型，由关于共享资源的数据结构及在其上操作的一组过程组成，进程只能通过调用管程中的过程来间接地访问管程中的数据结构。 互斥/同步互斥：管程是互斥进入的，管程的互斥性是由编译器负责保证的。 同步：管程中设置条件变量及等待/唤醒操作以解决同步问题，可以让一个进程或线程在条件变量上等待（此时，应先释放管程的使用权），也可以通过发送信号将等待在条件变量上的进程或线程唤醒。 Hoare管程因为管程是互斥进入的，所以当一个进程试图进入一个已被占用的管程时，应当在管程的入口处等待，为此，管程的入口处设置一个进程等待队列，称作入口等待队列。 如果进程P唤醒进程Q，则P等待Q执行；如果进程Q执行中又唤醒进程R，则Q等待R执行；如此， 在管程内部可能会出现多个等待进程。在管程内需要设置一个进程等待队列，称为紧急等待队列，紧急等待队列的优先级高于入口等待队列的优先级。 条件变量条件变量是在管程内部说明和使用的一种特殊类型的变量，对于条件变量，可以执行wait和signal操作： wait(c)：如果紧急等待队列非空，则唤醒第一个等待者；否则释放管程的互斥权，执行此操作的进程进入c链末尾。 signal(c)：如果c链为空，则相当于空操作，执行此操作的进程继续执行；否则唤醒第一个等待者，执行此操作的进程进入紧急等待队列的末尾。 用管程解决生产者-消费者问题12345678910111213141516171819202122232425262728293031323334353637383940//管程monitor ProducerConsumer condition full, empty; //条件变量 integer count; procedure insert (item: integer); begin if count == N then wait(full); insert_item(item); count++; if count ==1 then signal(empty); end; function remove: integer; begin if count==0 then wait(empty); remove = remove_item; count--; if count==N-1 then signal(full); end; count:=0; end monitor; //生产者procedure producer; begin while true do begin item = produce_item; ProducerConsumer.insert(item); end end; //消费者procedure consumer; begin while true do begin item=ProducerConsumer.remove; consume_item(item); end end; MESA管程Hoare管程有个缺点就是会有两次额外的进程切换，因此MESA管程将原本的signal操作变为notify操作：当一个正在管程中的进程执行notify(x)时，它使得x条件队列得到通知，发信号的进程继续执行，而位于条件队列头的进程在将来合适的时候且当处理器可用时恢复执行。 由于收到通知时并未执行，且对等待进程在notify之后何时运行没有任何限制，所以当进程真正被调度时，条件不一定成立，因而这个进程必须重新检查条件，也就是用while循环取代if语句。 IPC（进程间通信）进程间通信（IPC，InterProcess Communication）是指在不同进程之间传播或交换信息。 进程通信是一种手段，而进程同步是一种目的。也可以说，为了能够达到进程同步的目的，需要让进程进行通信，传输一些进程同步所需要的信息。 进程通信的方式通常有管道（包括无名管道和命名管道）、消息队列、信号量、共享存储、Socket、Streams等。其中 Socket和Streams支持不同主机上的两个进程IPC。 管道管道，通常指无名管道，是 UNIX 系统IPC最古老的形式。 管道是通过调用 pipe 函数创建的，当一个管道建立时，它会创建两个文件描述符：fd[0]为读而打开，fd[1]为写而打开，要关闭管道只需将这两个文件描述符关闭即可。 单个进程中的管道几乎没有任何用处。所以，通常调用 pipe 的进程接着调用 fork，这样就创建了父进程与子进程之间的 IPC 通道。若要数据流从父进程流向子进程，则关闭父进程的读端（fd[0]）与子进程的写端（fd[1]）；反之，则可以使数据流从子进程流向父进程。 特点: 它是半双工的（即数据只能在一个方向上流动），具有固定的读端和写端。 它只能用于具有亲缘关系的进程之间的通信（也是父子进程或者兄弟进程之间）。 FIFOFIFO也称为命名管道，它是一种文件类型，可以在无关的进程之间交换数据，与无名管道不同。 FIFO 常用于客户-服务器应用程序中，FIFO 用作汇聚点，在客户进程和服务器进程之间传递数据。 消息队列消息队列，是消息的链接表，存放在内核中。一个消息队列由一个标识符（即队列ID）来标识。 消息队列是面向记录的，其中的消息具有特定的格式以及特定的优先级。 消息队列独立于发送与接收进程。进程终止时，消息队列及其内容并不会被删除。 消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取。 信号量信号量是一个计数器。信号量用于实现进程间的互斥与同步，而不是用于存储进程间通信数据。 共享内存共享内存指两个或多个进程共享一个给定的存储区，因为数据不需要在进程之间复制，所以这是最快的一种 IPC。由于多个进程可以同时操作，所以信号量与共享内存通常结合在一起使用，信号量用来同步对共享内存的访问。 套接字与其它通信机制不同的是，它可用于不同机器间的进程通信。 参考资料 Tanenbaum A S, Bos H. Modern operating systems[M]. Prentice Hall Press, 2014. 北京大学操作系统原理（Operating Systems） 计算机操作系统 进程间的五种通信方式介绍]]></content>
      <categories>
        <category>操作系统原理</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>同步</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统原理-进程线程模型]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86-%E8%BF%9B%E7%A8%8B%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[进程的定义进程是具有独立功能的程序关于某个数据集合上的一次运行活动，是系统进行资源分配和调度的独立单位。 进程控制块PCBPCB：Process Control Block，又称进程描述符、进程属性，是操作系统用于管理控制进程的一个专门数据结构，是系统感知进程存在的唯一标志。 PCB的内容包括： 进程描述信息 进程控制信息 所拥有的资源和使用情况 CPU现场信息 进程状态及状态转换进程的三种基本状态 运行态（Running）：占有CPU，并在CPU上运行 就绪态（Ready）：已经具备运行条件，但由于没有空闲CPU，而暂时不能运行 等待态（Waiting/Blocked）：因等待某一事件而暂时不能运行（如等待读盘结果，又称为阻塞态、睡眠态） 三状态模型及状态转换 其中，只有就绪态和运行态可以相互转换，其它的都是单向转换。 进程的其它状态 创建：已完成创建一进程所必要的工作，但因为资源有限尚未同意执行该进程 终止：终止执行后，进程进入该状态，回收资源 挂起：用于调节负载，进程不占用内存空间，其进程映像交换到磁盘上 进程的五状态模型 进程队列操作系统为每一类进程建立一个或多个队列，队列元素为PCB，伴随进程状态的改变，其PCB从一个队列进入另一个队列。以下为五状态进程模型的队列模型： 进程控制进程控制操作完成进程各状态之间的转换，由具有特定功能的原语完成： 进程创建原语 进程撤消原语 阻塞原语 唤醒原语 挂起原语… 原语：完成某种特定功能的一段程序，具有不可分割性或不可中断性，即原语的执行必须是连续的，在执行过程中不允许被中断 进程的创建 给新进程分配一个唯一标识以及进程控制块 为进程分配地址空间 初始化进程控制块 设置相应的队列指针（如: 把新进程加到就绪队列链表中） 进程的撤销 收回进程所占有的资源（如：关闭打开的文件、断开网络连接、回收分配的内存） 撤消该进程的PCB 进程阻塞处于运行状态的进程，在其运行过程中期待某一事件发生，如等待键盘输入、等待磁盘数据传输完成、等待其它进程发送消息，当被等待的事件未发生时，由进程自己执行阻塞原语，使自己由运行态变为阻塞态。 上下文切换将CPU硬件状态从一个进程换到另一个进程的过程称为上下文切换。 进程运行时，其硬件状态保存在CPU上的寄存器中；进程不运行时，这些寄存器的值保存在进程控制块PCB中；当操作系统要运行一个新的进程时，将PCB中的相关值送到对应的寄存器中。 线程的定义进程中的一个运行实体，是CPU的调度单位，有时将线程称为轻量级进程。 线程共享所在进程的地址空间和其他资源。 线程机制的实现用户级线程在用户空间建立线程库：提供一组管理线程的过程。运行时系统完成线程的管理工作，内核管理的还是进程，不知道线程的存在，线程切换不需要内核态特权。 优点： 线程切换快 调度算法是应用程序特定的 用户级线程可运行在任何操作系统上（只需要实现线程库） 缺点： 大多数系统调用是阻塞的，因此，由于内核阻塞进程，故进程中所有线程也被阻塞 核心级线程内核管理所有线程管理，并向应用程序提供API接口。内核维护进程和线程的上下文，且线程的切换需要内核支持。 混合模型线程创建在用户空间完成，线程调度等在核心态完成。 线程与进程的区别 拥有资源：进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。 调度：线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。 系统开销：由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。 通信方面：线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC。 参考资料 Tanenbaum A S, Bos H. Modern operating systems[M]. Prentice Hall Press, 2014. 北京大学操作系统原理（Operating Systems） 计算机操作系统]]></content>
      <categories>
        <category>操作系统原理</category>
      </categories>
      <tags>
        <tag>操作系统 </tag>
        <tag>进程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统原理-处理器调度]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86%E2%80%94%2F</url>
    <content type="text"><![CDATA[CPU调度即按一定的调度算法从就绪队列中选择一个进程， 把CPU的使用权交给被选中的进程，其任务是控制、协调进程对CPU的竞争。 调度算法衡量指标吞吐量：每单位时间完成的进程数目 周转时间：每个进程从提出请求到运行完成的时间 响应时间：从提出请求到第一次回应的时间 进程调度算法批处理系统目标：吞吐量，周转时间，cpu利用率，包含以下四种调度算法： 先来先服务（FCFS） 短作业优先（SJF） 最短剩余时间优先（SRTN） 最高响应比优先（HRRN） 先来先服务（FCFS） First Come First Serve 按照进程就绪的先后顺序使用CPU 非抢占 长进程后面的短进程需要等很长时间，不利于用户体验。 短作业优先（SJF） Shortest Job First 具有最短完成时间的进程优先执行 非抢占式 最短剩余时间优先（SRTN） Shortest Remaining Time Next SJF的抢占式版本，即当一个新就绪的进程比当前运行进程具有更短的完成时间时，系统抢占当前进程， 选择新就绪的进程执行 短作业优先的调度算法可以得到最短的平均周转时间，但随着源源不断的短任务到来，可能使长的任务长时间得不到运行，即产生 “饥饿”现象。 最高响应比优先（HRRN） Highest Response Ratio Next 调度时，首先计算每个进程的响应比R；之后，总是选择R最高的进程执行 响应比R = 周转时间 / 处理时间 =（处理时间 + 等待时间）/ 处理时间 = 1 +（等待时间 / 处理时间） 交互式系统目标：响应时间，包含以下三种调度算法： 时间片轮转（RR） 最高优先级（HPF） 多级反馈队列（Multiple feedback queue） 时间片轮转 Round Robin 将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。 时间片轮转算法中选择合适的时间片很重要： 如果太长，会降级为先来先服务算法，延长短进程的响应时间 如果太短，进程切换会浪费CPU时间 最高优先级 Highest Priority First 选择优先级最高的进程投入运行 优先级可以是静态不变的，也可以是动态调整的 不公平 会导致优先级翻转问题，解决方案：1、优先级天花板；2、优先级继承 优先级翻转是当一个高优先级任务通过信号量机制访问共享资源时，该信号量已被一低优先级任务占有，因此造成高优先级任务被许多具有较低优先级任务阻塞，实时性难以得到保证。 例如：有优先级为A、B和C三个任务，优先级A&gt;B&gt;C，任务A，B处于挂起状态，等待某一事件发生，任务C正在运行，此时任务C开始使用某一共享资源S。在使用中，任务A等待事件到来，任务A转为就绪态，因为它比任务C优先级高，所以立即执行。当任务A要使用共享资源S时，由于其正在被任务C使用，因此任务A被挂起，任务C开始运行。如果此时任务B等待事件到来，则任务B转为就绪态。由于任务B优先级比任务C高，因此任务B开始运行，直到其运行完毕，任务C才开始运行。直到任务C释放共享资源S后，任务A才得以执行。在这种情况下，优先级发生了翻转，任务B先于任务A运行。 解决优先级翻转问题有优先级天花板(priority ceiling)和优先级继承(priority inheritance)两种办法。 优先级天花板是当任务申请某资源时， 把该任务的优先级提升到可访问这个资源的所有任务中的最高优先级， 这个优先级称为该资源的优先级天花板。这种方法简单易行， 不必进行复杂的判断， 不管任务是否阻塞了高优先级任务的运行， 只要任务访问共享资源都会提升任务的优先级。 优先级继承是当任务A 申请共享资源S 时， 如果S正在被任务C 使用，通过比较任务C 与自身的优先级，如发现任务C 的优先级小于自身的优先级， 则将任务C的优先级提升到自身的优先级， 任务C 释放资源S 后，再恢复任务C 的原优先级。这种方法只在占有资源的低优先级任务阻塞了高优先级任务时才动态的改变任务的优先级，如果过程较复杂， 则需要进行判断。 多级反馈队列设置多个就绪队列，第一级队列优先级最高，给不同就绪队列中的进程分配长度不同的时间片，第一级队列时间片最小；随着队列优先级别的降低，时间片增大。当第一级队列为空时，在第二级队列调度，以此类推。当一个新创建进程就绪后，进入第一级队列，进程用完时间片而放弃CPU，进入下一级就绪队列。由于阻塞而放弃CPU的进程进入相应的等待队列，一旦等待的事件发生，该进程回到原来一级就绪队列。 调度算法总结 调度算法 占用CPU方式 吞吐量 响应时间 开销 对进程的影响 饥饿问题 FCFS 非抢占式 不强调 可能很慢，特别是当进程的执行时间差别很大时 最小 对短进程不利；对I/O型的进程不利 无 RR 抢占式(时间片用完时) 若时间片小，吞吐量会很低 为短进程提供好的响应时间 较大 公平对待 无 SJF 非抢占式 高 为短进程提供好的响应时间 可能较大 对长进程不利 可能 SRTN 抢占式(到达时) 高 提供好的响应时间 可能较大 对长进程不利 可能 HRRN 非抢占式 高 提供好的响应时间 可能较大 很好的平衡性 无 Feedback 抢占式(时间片用完时) 不强调 不强调 可能较大 对I/O型进程有利 可能 参考资料 Tanenbaum A S, Bos H. Modern operating systems[M]. Prentice Hall Press, 2014. 北京大学操作系统原理（Operating Systems） 计算机操作系统 优先级翻转]]></content>
      <categories>
        <category>操作系统原理</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LinkedList源码分析]]></title>
    <url>%2F2018%2F09%2F11%2FLinkedList%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[LinkedList简介（jdk1.8)LinkedList是基于双向链表实现的。如下为LinkedList的继承体系结构： 123public class LinkedList&lt;E&gt; extends AbstractSequentialList&lt;E&gt; implements List&lt;E&gt;, Deque&lt;E&gt;, Cloneable, java.io.Serializable 可以看到，LinkedList实现了Deque接口，Deque表示双端队列，即在两端都可以进行插入和删除的队列。Deque是一个比Stack和Queue功能更强大的接口，它同时实现了栈和队列的功能。Deque接口的部分方法如下：1234567891011// *** Queue methods *** boolean add(E e); boolean offer(E e); E remove(); E poll(); E element(); E peek(); // *** Stack methods *** void push(E e); E pop(); 从代码可以看出，Deque既可以用作后进先出的栈，也可以用作先进先出的队列。 与ArrayList一样，LinkedList也不是线程安全的，因此只能在单线程环境下使用。 属性LinkedList有size、first、last三个属性： 12345678//LinkedList中元素的数量transient int size = 0;//指向第一个元素transient Node&lt;E&gt; first;//指向最后一个元素transient Node&lt;E&gt; last; Node既然LinkedList是基于链表实现的，那就必须要介绍一下它的内部类Node：1234567891011private static class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; next; Node&lt;E&gt; prev; Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element; this.next = next; this.prev = prev; &#125;&#125; 因为是双向链表，所以每个节点都包含前一个节点的指向与后一个节点的指向。 构造函数 无参构造函数 12public LinkedList() &#123;&#125; 有参构造函数 1234public LinkedList(Collection&lt;? extends E&gt; c) &#123; this(); addAll(c);&#125; 此方法先调用一个无参构造函数构造一个空列表，然后再将集合内的所有元素添加进去。 addAll将集合内的所有元素加入到LinkedLiist中。 123public boolean addAll(Collection&lt;? extends E&gt; c) &#123; return addAll(size, c);&#125; 123456789101112131415161718192021222324252627282930313233343536373839 public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123;//判断是否满足index &gt;= 0 &amp;&amp; index &lt;= size，若不满足，则抛出异常 checkPositionIndex(index); Object[] a = c.toArray(); int numNew = a.length; if (numNew == 0) return false; Node&lt;E&gt; pred, succ; if (index == size) &#123; succ = null; pred = last; &#125; else &#123; succ = node(index); pred = succ.prev; &#125; for (Object o : a) &#123; @SuppressWarnings("unchecked") E e = (E) o; Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, null); if (pred == null) first = newNode; else pred.next = newNode; pred = newNode; &#125; if (succ == null) &#123; last = pred; &#125; else &#123; pred.next = succ; succ.prev = pred; &#125; size += numNew; modCount++; return true; &#125; 此段代码中，succ表示后节点，pred表示前节点。 在进行了下标检查与长度检查后，首先判断要加入的元素是加入在末尾还是中间，如果在末尾，则succ应指向null，而pred应指向last，否则，succ应指向下标为index的节点，而pred指向该节点的前一个节点。这样，要插入的节点的前后节点就都有了，接下来就可以将要插入的节点的前后节点都连接好，从而完成插入操作。 这里有必要介绍一下取出指定位置的节点的方法：123456789101112131415Node&lt;E&gt; node(int index) &#123; // assert isElementIndex(index); if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125;&#125; 与数组不同，链表无法直接通过下标找到指定的元素，而需要依次遍历。由于LinkedList是通过双向链表实现的，所以既可以从头也可以从尾开始遍历。为了提高效率，该方法先判断指定的位置index在链表的前半段还是后半段，从而决定从头还是从尾开始遍历。 linkFirst，linkLast，linkBefore在介绍add方法与其它相关方法前，有必要先介绍一下这三个辅助方法：123456789101112131415161718192021222324252627282930313233343536private void linkFirst(E e) &#123; final Node&lt;E&gt; f = first; final Node&lt;E&gt; newNode = new Node&lt;&gt;(null, e, f); first = newNode; if (f == null) last = newNode; else f.prev = newNode; size++; modCount++;&#125;void linkLast(E e) &#123; final Node&lt;E&gt; l = last; final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); last = newNode; if (l == null) first = newNode; else l.next = newNode; size++; modCount++;&#125;void linkBefore(E e, Node&lt;E&gt; succ) &#123; // assert succ != null; final Node&lt;E&gt; pred = succ.prev; final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ); succ.prev = newNode; if (pred == null) first = newNode; else pred.next = newNode; size++; modCount++;&#125; linkFirst、linkLast、linkBefore方法分别将元素加入到链表头部、链表尾部与链表中指定节点之前。 以linkFirst为例，先创建一个新的节点，并将first指向该节点。然后判断以前的first节点是否为null，如果为null，则说明之前链表中没有元素，应将last指向新节点，否则，将原first节点的prev指向新节点。 add，addFirst，addLast介绍完上面三个辅助方法后，我们再来看看add相关的方法。 123456789101112131415161718192021public boolean add(E e) &#123; linkLast(e); return true;&#125;public void add(int index, E element) &#123; checkPositionIndex(index); if (index == size) linkLast(element); else linkBefore(element, node(index));&#125;public void addFirst(E e) &#123; linkFirst(e);&#125;public void addLast(E e) &#123; linkLast(e);&#125; 由源码可以看到，add相关的代码都是直接调用上面介绍的辅助方法，十分简单。 unlink，unlinkFirst，unlinkLast同样，在介绍remove及相关方法时，先介绍这三个辅助方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657E unlink(Node&lt;E&gt; x) &#123; // assert x != null; final E element = x.item; final Node&lt;E&gt; next = x.next; final Node&lt;E&gt; prev = x.prev; if (prev == null) &#123; first = next; &#125; else &#123; prev.next = next; x.prev = null; &#125; if (next == null) &#123; last = prev; &#125; else &#123; next.prev = prev; x.next = null; &#125; x.item = null; size--; modCount++; return element;&#125;private E unlinkFirst(Node&lt;E&gt; f) &#123; // assert f == first &amp;&amp; f != null; final E element = f.item; final Node&lt;E&gt; next = f.next; f.item = null; f.next = null; // help GC first = next; if (next == null) last = null; else next.prev = null; size--; modCount++; return element;&#125;private E unlinkLast(Node&lt;E&gt; l) &#123; // assert l == last &amp;&amp; l != null; final E element = l.item; final Node&lt;E&gt; prev = l.prev; l.item = null; l.prev = null; // help GC last = prev; if (prev == null) first = null; else prev.next = null; size--; modCount++; return element;&#125; 这三个方法也很好理解。以unlink方法为例，将要删除的元素的前后节点相连接，并且把要删除的节点的属性设为null以帮助垃圾回收机制回收，从而达到移除该节点的目的。最后，将要删除的节点的值返回。 remove，removeFirst，removeLast接下来介绍移除链表中元素的几个方法。 123456789101112131415161718192021222324252627public E remove() &#123; return removeFirst();&#125;public E remove(int index) &#123; checkElementIndex(index); return unlink(node(index));&#125;public boolean remove(Object o) &#123; if (o == null) &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (x.item == null) &#123; unlink(x); return true; &#125; &#125; &#125; else &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) &#123; unlink(x); return true; &#125; &#125; &#125; return false;&#125; 前两个方法比较简单，而对于remove(Object o)方法，要先判断对象是否为null，如果为null，则遍历链表找到值为null的节点，并调用unlink方法移除该节点，否则，同样遍历链表并用equals方法根据内容进行等值比较，如果找到值相等的节点，调用unlink方法将其移除。 12345678910111213public E removeFirst() &#123; final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return unlinkFirst(f);&#125; public E removeLast() &#123; final Node&lt;E&gt; l = last; if (l == null) throw new NoSuchElementException(); return unlinkLast(l);&#125; 这两个方法先判断链表中是否有元素，如果没有，则抛出异常，否则就调用辅助方法将其移除。 get，getFirst，getLast123456789101112131415161718public E get(int index) &#123; checkElementIndex(index); return node(index).item;&#125;public E getFirst() &#123; final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return f.item;&#125;public E getLast() &#123; final Node&lt;E&gt; l = last; if (l == null) throw new NoSuchElementException(); return l.item;&#125; get(int index)方法在进行了下标检查后，直接通过node方法找到该节点并返回节点的值。而getFirst和getLast先判断first和last是否为null，如果不为null则返回节点的值，否则抛出异常。 setset方法将替换链表中指定位置的节点的值。 1234567public E set(int index, E element) &#123; checkElementIndex(index); Node&lt;E&gt; x = node(index); E oldVal = x.item; x.item = element; return oldVal;&#125; 该方法先判断index是否合法，然后获取到该下标的节点，并将该节点的值重新设置即可。 linkedList总结 linkedList是通过双向链表实现的，因此删除效率很高，而查找效率很低，且不存在扩容问题。 linkedList实现了Deque接口，因此既可以当作栈，也可以当作队列。 与ArrayList一样，linkedList也是非线程安全的，只能在单线程环境下使用。]]></content>
      <categories>
        <category>JDK源码阅读</category>
      </categories>
      <tags>
        <tag>JDK</tag>
        <tag>LinkedList</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ArrayList源码分析]]></title>
    <url>%2F2018%2F09%2F06%2FArrayList%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[ArrayList简介（jdk1.8）ArrayList就是动态数组，其容量能够自动增长。如下为ArrayList的继承体系结构： 12public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable ArrayList实现了List, RandomAccess, Cloneable, java.io.Serializable接口，且不是线程安全的，因此只能用在单线程环境下。 属性ArrayList主要有elementData和size两个属性：12transient Object[] elementData; private int size; elementData数组是用来存储元素的，而size表示ArrayList中已有的元素数量（不等于elementData.length）。 构造方法ArrayList共有三种构造方法： 指定容量的构造函数 123456789public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException("Illegal Capacity: " + initialCapacity); &#125;&#125; 此方法接受一个初始化容量来初始化底层数组elementData，如果初始化容量值为0则将其初始化为一个空的常量数组：private static final Object[] EMPTY_ELEMENTDATA = {}; ，如果值小于零，则抛出异常。 无参构造函数 12345private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;; public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; &#125; 此方法中的DEFAULTCAPACITY_EMPTY_ELEMENTDATA区别于EMPTY_ELEMENTDATA，通过将数组设为前者，在添加元素的时候会将容量设置为默认值10。 Collection作为参数的构造函数 1234567891011public ArrayList(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); if ((size = elementData.length) != 0) &#123; // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // replace with empty array. this.elementData = EMPTY_ELEMENTDATA; &#125;&#125; 此方法接受一个Collection，并且将其转换为数组赋给elementData，如果被赋值后的elementData长度为0，则将空的常量数组赋值给它。相反，则再判断Collection是否转化为了Object数组，如果没有则将其进行转化。 这里用到了Arrays.copyof()方法：123456789public static &lt;T,U&gt; T[] copyOf(U[] original, int newLength, Class&lt;? extends T[]&gt; newType) &#123; @SuppressWarnings("unchecked") T[] copy = ((Object)newType == (Object)Object[].class) ? (T[]) new Object[newLength] : (T[]) Array.newInstance(newType.getComponentType(), newLength); System.arraycopy(original, 0, copy, 0, Math.min(original.length, newLength)); return copy;&#125; 可以看出，该方法构造了一个新的长度为newLength的Object类型数组，并且将原数组复制到新的数组中 。而此处的复制用了System.arraycopy()方法，该方法被标记了native，调用了系统的C/C++代码，可以在openJDK中查看到源码。 get123456789public E get(int index) &#123; rangeCheck(index); return elementData(index);&#125;E elementData(int index) &#123; return (E) elementData[index];&#125; 此方法可以得到指定下标的元素，先对下标进行越界检查，然后再通过一个间接方法获取到elementData的index下标的元素。 set1234567public E set(int index, E element) &#123; rangeCheck(index); E oldValue = elementData(index); elementData[index] = element; return oldValue;&#125; 此方法用于设置指定下标的元素，并将该下标原有的元素返回。 addadd方法比较复杂，也是ArrayList核心所在，有下面两种形式： 将元素加入到列表末尾 12345public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true;&#125; 12345678910private void ensureCapacityInternal(int minCapacity) &#123; ensureExplicitCapacity(calculateCapacity(elementData, minCapacity));&#125;private static int calculateCapacity(Object[] elementData, int minCapacity) &#123; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; return Math.max(DEFAULT_CAPACITY, minCapacity); &#125; return minCapacity;&#125; 此处的calculateCapacity正是与上文DEFAULTCAPACITY_EMPTY_ELEMENTDATA常量相照应的方法。如果ArrayList是默认构造函数构造的话，在添加元素的时候此方法将返回DEFAULT_CAPACITY也就是10。而size已经大于10的情况，该方法便也失去了意义。12345678910111213141516171819202122232425262728private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // overflow-conscious code if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125;private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity);&#125;private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE;&#125; 从源码可以看出，当需要的容量大于elementData数组的长度时，就需要对其进行扩张。而扩张的大小则根据if条件判断。一般情况下，会将长度扩张为原来的1.5倍，但是当1.5倍仍小于所需的容量时，会将长度直接设为所需容量。而新容量如果大于最大数组长度MAX_ARRAY_SIZE ，则根据所需容量分配Integer.MAX_VALUE或者MAX_ARRAY_SIZE。 ensureExplicitCapacity方法的第一行语句modCount++;的作用是记录修改次数。我们知道，ArrayList不是线程安全的，因此在迭代ArrayList的时候如果有其它线程修改了内容，那么就会导致modCount与迭代器初始化时的modCount不同，从而抛出异常ConcurrentModificationException。说白了，就是防止一个线程正在迭代遍历，另一个线程修改了这个列表的结构。 将元素添加到指定位置上 123456789public void add(int index, E element) &#123; rangeCheckForAdd(index); ensureCapacityInternal(size + 1); // Increments modCount!! System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++;&#125; 在此方法中，先对index进行越界检查，然后再进行扩容。这里用了System.arraycopy方法，j将包括index在内的之后的所有元素均向右移动一位，再将要添加的元素放置在elementData的index下标下。 addAll 将集合中的元素全部添加到ArrayList末尾 12345678public boolean addAll(Collection&lt;? extends E&gt; c) &#123; Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); // Increments modCount System.arraycopy(a, 0, elementData, size, numNew); size += numNew; return numNew != 0;&#125; 将Collection对象转化为Object数组后，先根据其长度进行扩容，再同样利用System.arraycopy函数把数组中的所有元素添加到elementData数组末尾。 将集合中的元素全部添加到ArrayList指定位置 12345678910111213141516public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; rangeCheckForAdd(index); Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); // Increments modCount int numMoved = size - index; if (numMoved &gt; 0) System.arraycopy(elementData, index, elementData, index + numNew, numMoved); System.arraycopy(a, 0, elementData, index, numNew); size += numNew; return numNew != 0;&#125; 原理与add(int index, E element)类似，都是通过将已有元素右移实现，此处将不再阐述。 remove 移除指定下标上的元素 1234567891011121314public E remove(int index) &#123; rangeCheck(index); modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work return oldValue;&#125; 在这里，移除操作是将要移除的元素后面的所有元素均向左移动一位，并将size数减小实现的。此方法将返回要移除的元素。 移除指定的元素 12345678910111213141516171819202122232425public boolean remove(Object o) &#123; if (o == null) &#123; for (int index = 0; index &lt; size; index++) if (elementData[index] == null) &#123; fastRemove(index); return true; &#125; &#125; else &#123; for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) &#123; fastRemove(index); return true; &#125; &#125; return false;&#125;private void fastRemove(int index) &#123; modCount++; int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work&#125; 先找到指定元素的下标，再根据下标进行移除。指定的元素有可能为null，而不为null的情况下将根据元素内容进行比较，因此将分为两种情况遍历数组。fastRemove的实现与remove(int index)基本一致，区别在于fastRemove不需要对下标进行检查，也不返回被移除的元素。 indexOf1234567891011121314151617181920212223242526272829public int indexOf(Object o) &#123; if (o == null) &#123; for (int i = 0; i &lt; size; i++) if (elementData[i]==null) return i; &#125; else &#123; for (int i = 0; i &lt; size; i++) if (o.equals(elementData[i])) return i; &#125; return -1;&#125;public int lastIndexOf(Object o) &#123; if (o == null) &#123; for (int i = size-1; i &gt;= 0; i--) if (elementData[i]==null) return i; &#125; else &#123; for (int i = size-1; i &gt;= 0; i--) if (o.equals(elementData[i])) return i; &#125; return -1;&#125;public boolean contains(Object o) &#123; return indexOf(o) &gt;= 0;&#125; 由源码可以看出，indexOf和lastIndexOf与remove(Object o)方法类似，并且找到元素时返回下标，没找到时返回-1，而contains方法正是通过indexOf判断是否找到元素实现的。 ArrayList总结 ArrayList底层是通过数组实现的，随机访问速度快，但插入和移除由于要移动大量的元素，所以性能较差。 ArrayList不是线程安全的，在多线程环境下，通过modCount域检测是否出现问题。 ArrayList每次扩容为原本的1.5倍，若依然不够，则会直接设置为所需容量大小。]]></content>
      <categories>
        <category>JDK源码阅读</category>
      </categories>
      <tags>
        <tag>JDK</tag>
        <tag>ArrayList</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈对尾递归的理解]]></title>
    <url>%2F2018%2F08%2F22%2F%E6%B5%85%E8%B0%88%E5%AF%B9%E5%B0%BE%E9%80%92%E5%BD%92%E7%9A%84%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[今天在做《剑指Offer》第十题时，发现了一个用尾递归的解法，由于之前对于尾递归并没有太多了解，于是查阅了一些资料，在此对其进行一个简单的总结。关于其它题目的题解与笔记，感兴趣的朋友可以到我的Github或个人博客上看看：剑指Offer笔记 Cenjie’s Blog ， 以下是正文。 递归本质递归的本质是自己调用自己，因为是嵌套调用，所以栈帧无法回收，在递归调用的层级太多时，往往会引发调用栈溢出，也就是内存溢出。 尾递归概述尾递归本质与递归并无区别，只不过是递归的一种特殊写法。尾递归要求递归调用是整个函数体中最后执行的语句且它的返回值不属于表达式的一部分，例如 return 3f(n)或者return f(n)+f(n-1) 都是不允许的。 由于尾递归也是一种递归，因此这种写法本身并不会有任何的优化效果，内存依旧会溢出，只不过一些编译器中会加入对尾递归的优化机制，在编译代码时自动根据尾递归的特性对其进行优化。 如何优化尾递归因为在递归调用自身的时候，这一层函数已经没有要做的事情了，虽然被递归调用的函数是在当前的函数里，但是他们之间的关系已经在传参的时候了断了，也就是这一层函数的所有变量什么的都不会再被用到了，所以当前函数虽然没有执行完，不能弹出栈，但它确实已经可以出栈了，这是一方面。 另一方面，正因为调用的是自身，所以需要的存储空间是一模一样的，那干脆重新刷新这些空间给下一层利用就好了，不用销毁再另开空间。 因此，为尾递归进行优化主要分两个步骤：1、写成尾递归的形式。2、编译器遇到此形式时自动为其优化。 而在第十题：斐波那契数列中，由于Java没有对尾递归进行优化，因此与使用普通递归并无太大区别，依然会产生内存溢出的问题。 本文参考：https://www.cnblogs.com/bellkosmos/p/5280619.html]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[README文档的规范写法总结]]></title>
    <url>%2F2018%2F06%2F25%2FREADME%E6%96%87%E6%A1%A3%E7%9A%84%E8%A7%84%E8%8C%83%E5%86%99%E6%B3%95%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[俗话说的好：“一个好开源项目一定有一个好的 README”。 要想自己放到github上的项目能吸引更多人的眼球，就必须写一个规范舒适的README.md，这么做不仅可以梳理自己对于项目的思路，也方便他人上手使用或学习。因此，此文根据Github上众多项目以及查阅相关资料对README做了一个小小的总结， 方便以后写README的时候可以直接套用该模板。 XXX系统（如果有Logo可以加上Logo）xxx系统是一个..系统，支持…，…（此处为简要描述） 官方网站 | 文档手册 | 别的东西 目前，此系统包含有以下功能： 功能1 功能2 功能3 准备 依赖1 依赖2 依赖3 搭建环境IntelliJ IDEA + MySQL 或者 eclipse + MySQL，… 快速开始 步骤1 步骤2 步骤3 相关截图截图1截图2 To Do List 功能1 功能2 功能3 CHANGE LOG此处填写版本更新记录 至此，我们可以看到一个相对规范的README.md模板，在开源项目时可以直接套用该模板，而不必每次都采用不同的零零散散的格式去书写README。Markdown代码在下方给出，当然，大家也可以根据项目具体情况进行修改而使用。 12345678910111213141516171819202122232425262728293031323334## XXX系统（如果有Logo可以加上Logo）xxx系统是一个..系统，支持...，...（此处为简要描述）[官方网站](http://example.com) | [文档手册](http://example.com) | [别的东西](http://example.com) 目前，此系统包含有以下功能：* 功能1* 功能2* 功能3### 准备* 依赖1* 依赖2* 依赖3### 搭建环境IntelliJ IDEA + MySQL 或者 eclipse + MySQL，...### 快速开始* 步骤1* 步骤2* 步骤3### 相关截图截图1截图2### To Do List* 功能1* 功能2* 功能3### CHANGE LOG此处填写版本更新记录 ContactIf you have some questions after you see this article, you can just find some info by clicking these links. Cenjie’s CSDN Cenjie’s Github Cenjie’s Gmail Cenjie’s Weibo]]></content>
      <categories>
        <category>Github</category>
      </categories>
      <tags>
        <tag>README</tag>
        <tag>markdown</tag>
        <tag>Github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Welcome To My Blog]]></title>
    <url>%2F2018%2F06%2F22%2FWelcome-To-My-Blog%2F</url>
    <content type="text"><![CDATA[写在前面的话大家好！我是就读于南京某高校的一名大二学生，在昨天搭建了这个个人博客网站用于记录自己在学习以及项目过程中的技术积累，希望通过这个平台能与大家分享自己的经验与教训，同时也欢迎大家随时可以联系我，期待与大家共同进步。 关于我我在学校的专业是电子信息科学与技术，曾利用课余时间学习过C、C++、Python等多门语言(仅限于皮毛)，经过两年的不断试错，终于在大二下学期确定了自己以后的发展方向—Java后台研发工程师。于是从基础语法到各大框架，这半年里接触到了许多新技术，看似学了许多东西却仍浮于水面终无所获，逐渐了解到自己要走的路还很长，而自己目前对于基础方面知识也尤为欠缺。因此需记住，沉下心，耐下性子，Coding the World。 铭记Work hard in silence, let success make the noise. ContactIf you have some questions after you see this article, you can just find some info by clicking these links. Cenjie’s CSDN Cenjie’s Github Cenjie’s Gmail]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>hello</tag>
        <tag>杂谈</tag>
      </tags>
  </entry>
</search>
