<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[僵尸进程与孤儿进程]]></title>
    <url>%2F2019%2F07%2F20%2F%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%AD%A4%E5%84%BF%E8%BF%9B%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[僵尸进程一个父进程利用fork创建子进程，如果子进程结束了，但是父进程没有等待（调用wait / waitpid）它，那么该子进程将变成一个僵尸进程。 僵尸进程对操作系统是有害的：在每个进程退出的时候，内核释放该进程所有的资源，包括打开的文件、占用的内存等，但是仍然为其保留一定的信息（包括进程号、退出状态、运行时间等），如果父进程一直不调用wait / waitpid，那么保留的这些信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果产生大量的僵尸进程，将因为没有可用的进程号而导致系统不能产生新的进程。 孤儿进程一个父进程退出，而它的一个或多个子进程仍然在运行，那么这些子进程就会变成孤儿进程。孤儿进程将被init进程（进程号为1）所收养，init进程将在这些孤儿进程结束时第一时间回收它们的信息，保证它们不会成为僵尸进程。 僵尸进程的避免 父进程通过wait / waitpid等待子进程，子进程工作完父进程再执行工作。 父进程fork一个子进程，然后继续工作，子进程fork一个孙进程后退出，那么孙进程将变为孤儿进程从而被init接管，并且由孙进程接受本应子进程接受的任务。当孙进程结束后，init会回收它的信息，不过子进程的回收还是需要自己做。 补充僵尸状态是每个子进程必经的状态，而之所以在进程结束后要进入僵尸状态是因为父进程可能要取得子进程的退出状态等信息。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于Java和Python的一些思考]]></title>
    <url>%2F2019%2F05%2F30%2F%E5%85%B3%E4%BA%8EJava%E5%92%8CPython%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[前言最近实习在做的一些项目都是用Python来写的，虽然在之前就有学习过Python的语法，但真正用到的机会很少，而这次通过项目刚好让我对Python有了更进一步的认识，并且在此总结一下Python与之前用的比较多的Java的一些区别。 动态类型Python与Java很大的一个区别在于Java必须在第一次声明变量时指定其类型，也就是所谓的静态类型，而Python则不一样，Python可以动态改变变量的类型。虽然Python的这个特性显得十分灵活，并且某些场景下可能开发效率更高一些，但稍不注意的话就有可能出错，在写代码时要更加注意。 缩进Python不像很多语言使用花括号定义函数或类，而是使用的缩进将代码分割成块，使得代码可读性更高一些。 GIL因为在项目中有许多要异步执行的任务，如果不了解Python的话，可能就会想到用多线程来解决问题，但实际上，Python中并不存在真正意义上的多线程，原因就是GIL的存在。GIL即全局解释器锁，Python的每个线程运行时首先要获得该锁，这也就意味着任何时刻仅有一个线程在执行，无法利用到多核的优势，使得多线程的效率甚至还不如单线程。但这也并非绝对的，在I/O操作或别的一些情况下，线程会主动释放GIL，这样别的线程就可以继续工作了，而如果是想完成一些CPU密集的任务的话，就只能通过进程或协程来解决了。 垃圾收集不像Java使用的可达性分析算法，Python中的垃圾收集是使用的引用计数法，这也就意味着会有循环引用的问题。比如说，在以下这个代码中：12345678def f2(): while True: c1=ClassA() c2=ClassA() c1.t=c2 c2.t=c1 del c1 del c2 在执行完上面的代码后，两个对象的引用计数都为1而非0，虽然它们都应该要被回收销毁的，但由于存在循环引用，所以不会被回收掉，也就导致了内存泄露。要解决这个问题，可以使用gc模块。]]></content>
  </entry>
  <entry>
    <title><![CDATA[常见查找算法之跳跃表]]></title>
    <url>%2F2019%2F05%2F28%2F%E5%B8%B8%E8%A7%81%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95%E4%B9%8B%E8%B7%B3%E8%B7%83%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[前言跳跃表（skiplist）是一种有序数据结构，它通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。 跳跃表支持平均O(logN)和最坏O(N)复杂度的节点查找，还可以通过顺序性操作来批量处理节点。在大部分情况下，跳跃表的效率可以和平衡树相媲美，并且因为跳跃表的实现比平衡树要来得更为简单，所以有不少程序都使用跳跃表来代替平衡树。 跳跃表的实现Redis的跳跃表由zskiplistNode和zskiplist两个结构定义，其中zskiplistNode结构用于表示跳跃表节点，而zskiplist结构则用于保存跳跃表节点的相关信息，比如节点的数量，以及指向表头节点和表尾节点的指针等等。 图5-1展示了一个跳跃表示例，位于图片最左边的是zskiplist结构，该结构包含以下属性： header：指向跳跃表的表头节点。 tail：指向跳跃表的表尾节点。 level：记录目前跳跃表内，层数最大的那个节点的层数（表头节点的层数不计算在内）。 length：记录跳跃表的长度，也即是，跳跃表目前包含节点的数量（表头节点不计算在内）。 位于zskiplist结构右方的是四个zskiplistNode结构，该结构包含以下属性： 层（level）：节点中用 L1 、 L2 、 L3 等字样标记节点的各个层，L1 代表第一层， L2 代表第二层，以此类推。每个层都带有两个属性：前进指针和跨度。前进指针用于访问位于表尾方向的其他节点，而跨度则记录了前进指针所指向节点和当前节点的距离。每次创建一个新跳跃表节点的时候， 程序都根据幂次定律（power law，越大的数出现的概率越小）随机生成一个介于1和32之间的值作为层的高度。跨度是用来计算排位（rank）的，在查找某个节点的过程中，将沿途访问过的所有层的跨度累计起来，得到的结果就是目标节点在跳跃表中的排位。 后退（backward）指针：节点中用 BW 字样标记节点的后退指针，它指向位于当前节点的前一个节点。后退指针在程序从表尾向表头遍历时使用。跟可以一次跳过多个节点的前进指针不同，因为每个节点只有一个后退指针，所以每次只能后退至前一个节点。 分值（score）：各个节点中的 1.0 、 2.0 和 3.0 是节点所保存的分值。在跳跃表中，节点按各自所保存的分值从小到大排列。 成员对象（obj）：各个节点中的 o1、o2 和 o3 是节点所保存的成员对象。分值相同的节点将按照成员对象在字典序中的大小来进行排序，成员对象较小的节点会排在前面，而成员对象较大的节点则会排在后面。 注意表头节点和其他节点的构造是一样的：表头节点也有后退指针、分值和成员对象，不过表头节点的这些属性都不会被用到，所以图中省略了这些部分，只显示了表头节点的各个层。 虽然仅靠多个跳跃表节点就可以组成一个跳跃表，但通过使用一个zskiplist结构来持有这些节点，程序可以更方便地对整个跳跃表进行处理，比如快速访问跳跃表的表头节点和表尾节点，又或者快速地获取跳跃表节点的数量（也即是跳跃表的长度）等信息。 查找跳跃表的查找是从最上层的跳跃区间大的层开始的，从头结点开始和前进指针指向的节点进行比较，如果大于前进节点，则继续向前找，如果小于前进节点，则到下一层继续查找，直到找到为止。 插入跳跃表的插入操作和链表的插入操作十分相似，大致过程如下： 查找到需要插入的位置 申请新的结点 调整指针 因为找到插入点之后，新生成节点，新节点的层的高度是随机生成的，故需要保存所有层的后继指针。 删除删除和插入类似，大致过程如下： 查找到需要删除的结点 删除结点 调整指针 时间复杂度 最坏时间复杂度 О(n) 平均时间复杂度 O(logn) Redis中的应用Redis使用跳跃表作为有序集合键的底层实现之一：如果一个有序集合包含的元素数量比较多，又或者有序集合中元素的成员是比较长的字符串时，Redis就会使用跳跃表来作为有序集合键的底层实现。而之所以不使用红黑树，是因为在性能相差不大的情况下，跳跃表实现更为简单。 总结 跳跃表是有序集合的底层实现之一。 Redis的跳跃表实现由zskiplist和zskiplistNode两个结构组成，其中zskiplist用于保存跳跃表信息（比如表头节点、表尾节点、长度），而zskiplistNode则用于表示跳跃表节点。 每个跳跃表节点的层高都是1至32之间的随机数。 在同一个跳跃表中，多个节点可以包含相同的分值，但每个节点的成员对象必须是唯一的。 跳跃表中的节点按照分值大小进行排序，当分值相同时，节点按照成员对象的大小进行排序。 参考资料 Redis 设计与实现 查找——图文翔解SkipList（跳跃表）]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>跳跃表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Drools规则引擎原理简介]]></title>
    <url>%2F2019%2F05%2F28%2FDrools%E8%A7%84%E5%88%99%E5%BC%95%E6%93%8E%E5%8E%9F%E7%90%86%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[DRL解释执行流程Drools 规则是在 Java 应用程序上运行的，其要执行的步骤顺序由代码确定。为了实现这一点，Drools 规则引擎将业务规则转换成执行树，如下图所示：如上图所示，每个规则条件分为小块，在树结构中连接和重用。每次将数据添加到规则引擎中时，它将在与此类似的树中进行求值，并到达一个动作节点，在该节点处，它们将被标记为准备执行特定规则的数据。 规则引擎工作方式Drools规则引擎基于ReteOO算法（对面向对象系统的Rete算法进行了增强和优化的实现），它将事实（Fact）与规则进行匹配，以推断相应的规则结果，这个过程称之为模式匹配。 当我们到达一个事实（Fact）与规则相匹配的节点时，规则评估会将规则操作与触发数据添加到一个叫作议程（Agenda）的组件中，如果同一个事实（Fact）与多个规则相匹配，就认为这些规则是冲突的，议程（Agenda）使用冲突解决策略（Conflict Resolution strategy）管理这些冲突规则的执行顺序。整个生命周期中，规则评估与规则执行之间有着明确的分割。规则操作的执行可能会导致事实（Fact）的更新，从而与其它规则相匹配，导致它们的触发，称之为前向链接。 参考资料 Drools 简介 rete算法学习]]></content>
      <tags>
        <tag>Drools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[工厂模式与模板方法的一次实践]]></title>
    <url>%2F2019%2F05%2F28%2F%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%E4%B8%8E%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95%E7%9A%84%E4%B8%80%E6%AC%A1%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[前言最近做的一个项目是实现一个灰度发布的逻辑，具体来说就是当某个产品更新的时候，根据不同的用户决定是否对新版本可见。该功能本身是很容易实现的，但是考虑到可扩展性的问题，引入了Drools规则引擎，并且通过一些设计模式来进一步提高它的可扩展性，以应对之后可能不断发生变化的规则。 原始代码由于规则并不十分复杂，所以项目中将许多的校验与判断逻辑统一封装到了Fact对象中，而在.drl文件中仅仅是做一些初始化工作，例如这里的场景是给每个用户设置一个新版本可见的延迟天数，达到了这个天数才能获取新版本，那么在.drl中就是将用户与延迟天数的映射关系做初始化。因此，最开始只需要一个Fact就行了：在.drl文件中，初始化完成之后，仅仅需要调用这个Fact对象的releaseCheck()，然后就可以通过isRelease()方法决定是否发布新版本了。 可扩展性由上面的简单分析可以看到，判断是否发布新版本的逻辑都封装在了releaseCheck()方法中，但这个方法中的许多步骤其实是冗余的，比如说参数校验、安全校验等等，如果每次增加新的Fact时都去写一模一样的重复代码，就显得十分不简洁且不利于维护了，因此，我们将该方法抽象出来，并且将其中最关键的判断逻辑doReleaseCheck()交由子类去实现，这样不同的Fact子类只需要实现各自的核心判断逻辑即可。此时的UML如下：除此之外，对于调用方来说，是不需要关心Fact对象的创建过程的，尤其是当参数比较复杂的情况下。这时候就可以通过工厂方法模式，将创建对象的具体过程交给工厂类来完成：这样，对于调用方来说，只需要传入一个UserInfo对象即可，具体需要用到它的哪些属性以及属性的一些校验工作则交由工厂类来实现，调用方可以直接拿到想要的Fact对象。 总结通过模板方法，可以在抽象父类中先定义好整个方法的框架，并且让不同的子类去实现其中的某些核心步骤，这些核心步骤在父类中是抽象的；而通过工厂方法，使得调用者不再需要关心创建对象的具体过程，将许多繁琐的工作解耦了出去，由工厂类来负责实现。]]></content>
      <categories>
        <category>项目</category>
      </categories>
      <tags>
        <tag>项目</tag>
        <tag>工厂方法</tag>
        <tag>模板方法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL建索引的几大原则]]></title>
    <url>%2F2019%2F05%2F27%2F%E5%BB%BA%E7%B4%A2%E5%BC%95%E7%9A%84%E5%87%A0%E5%A4%A7%E5%8E%9F%E5%88%99%2F</url>
    <content type="text"><![CDATA[最左前缀匹配原则b+树的数据项是复合的数据结构，比如索引为(name, age, sex)的时候，b+数是按照从左到右的顺序来建立搜索树的，比如当(张三, 20, F)这样的数据来检索的时候，b+树会优先比较name来确定下一步的搜索方向，如果name相同再依次比较age和sex，最后得到检索的数据；但当(20, F)这样的没有name的数据来的时候，b+树就不知道下一步该查哪个节点，因为建立搜索树的时候name就是第一个比较因子，必须要先根据name来搜索才能知道下一步去哪里查询。比如当(张三, F)这样的数据来检索时，b+树可以用name来指定搜索方向，但下一个字段age的缺失，所以只能把名字等于张三的数据都找到，然后再匹配性别是F的数据了，这个是非常重要的性质，即索引的最左前缀匹配原则。 索引建议 根据最左前缀匹配原则，MySQL会一直向右匹配直到遇到范围查询（&gt;、&lt;、between、like）就停止匹配，比如a = 1 and b = 2 and c &gt; 3 and d = 4，如果建立(a, b, c, d)顺序的索引，d是用不到索引的，如果建立(a, b, d, c)的索引则都可以用到，a、b、d的顺序可以任意调整。 =和in可以乱序，比如a = 1 and b = 2 and c = 3建立(a, b, c)索引可以任意顺序，MySQL的查询优化器会帮你优化成索引可以识别的形式。 尽量选择区分度高的列作为索引，区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0。 索引列不能参与计算，否则将导致引擎放弃使用索引而进行全表扫描，比如select id from t where num/2=100;应优化成select id from t where num=100*2; 尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a, b)的索引，那么只需要修改原来的索引即可。 参考资料 MySQL索引原理及慢查询优化]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>索引</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[InnoDB的行锁与表锁]]></title>
    <url>%2F2019%2F05%2F27%2FInnoDB%E7%9A%84%E8%A1%8C%E9%94%81%E4%B8%8E%E8%A1%A8%E9%94%81%2F</url>
    <content type="text"><![CDATA[前言在数据库系统中，根据作用范围我们可以将锁分为行级锁与表级锁，下面结合InnoDB与MyISAM引擎分别介绍一下这两种锁。 表级锁表级锁是MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，但发出锁冲突的概率最高，并发度也是最低的。MyISAM就是使用的表级锁，并且因为MyISAM总是一次性获得所需的全部锁，要么全部满足，要么全部等待，所以是不会发生死锁的。 行级锁行级锁是MySQL中锁定粒度最小的一种锁，表示只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突，其加锁粒度最小，但加锁的开销也最大。行级锁分为共享锁和排他锁。 InnoDB中的行锁与表锁InnoDB行锁是通过给索引上的索引项加锁来实现的，这一点MySQL与Oracle不同，后者是通过在数据块中对相应数据行加锁来实现的。InnoDB这种行锁实现特点意味着只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表级锁。除此之外，虽然是访问不同行的记录，但是如果使用相同的索引键，是会出现锁冲突的。但如果MySQL认为全表扫描效率更高，比如对一些很小的表，它就不会使用索引，这种情况下InnoDB将使用表锁，而不是行锁。 在实际应用中，要特别注意InnoDB行锁的这一特性，不然的话，可能导致大量的锁冲突，从而影响并发性能。 行级锁与死锁InnoDB与MyISAM不同，它是遵循的两段锁协议，是逐步获取锁的，也就有可能出现死锁问题。前面说过，InnoDB不是锁记录，而是锁索引。索引分为主键索引和非主键索引两种，如果一条SQL语句操作了主键索引，MySQL就会锁定这条主键索引；如果一条语句操作了非主键索引，MySQL会先锁定该非主键索引，再锁定相关的主键索引。当两个事务同时执行，一个锁住了主键索引，在等待其他相关索引。另一个锁定了非主键索引，在等待主键索引。这样就会发生死锁。发生死锁后，InnoDB一般都可以检测到，并使一个事务释放锁回退，另一个获取锁完成事务。 参考资料 MySQL中的行级锁,表级锁,页级锁]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>InnoDB</tag>
        <tag>MySQL</tag>
        <tag>锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL主从复制与分库分表]]></title>
    <url>%2F2019%2F05%2F27%2FMySQL%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E4%B8%8E%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[主从复制主要涉及三个线程：binlog 线程、I/O 线程和 SQL 线程。 binlog线程：负责将主服务器上的数据更改写入二进制日志（Binary log）中。 I/O线程：负责从主服务器上读取二进制日志，并写入从服务器的中继日志（Relay log）。 SQL线程：负责读取中继日志，解析出主服务器已经执行的数据更改并在从服务器中重放（Replay）。 读写分离主服务器处理写操作以及实时性要求比较高的读操作，而从服务器处理读操作。 读写分离能提高性能的原因在于 主从服务器负责各自的读和写，极大程度缓解了锁的争用； 从服务器可以使用MyISAM，提升查询性能以及节约系统开销； 增加冗余，提高可用性。 分库分表当在主从复制、索引优化并且升级硬件后，数据库性能依然无法达到要求，此时就可以考虑数据库的切分，根据其切分类型，可以分为两种切分方式：垂直切分和水平切分。 垂直切分垂直切分又分为垂直分库和垂直分表。 垂直分库就是根据业务耦合性，将关联度低的不同表存储在不同的数据库。做法与大系统拆分为多个小系统类似，按业务分类进行独立划分。与”微服务治理”的做法相似，每个微服务使用单独的一个数据库。（例如用户User一个库，商品Producet一个库，订单Order一个库） 垂直分表是针对列进行的。如果某个表的字段较多，可以把不常用的字段或者长度较长的字段拆分到一张新的扩展表中。在字段较多的情况下，通过“大表拆小表”，更有利于维护与开发，也能避免跨页问题（一致性、排序等问题）。MySQL底层是通过数据页存储的，一条记录占用空间过大会导致跨页，造成额外的性能开销。另外数据库以行为单位将数据加载到内存中，这样表中字段长度较短且访问频率较高，内存能加载更多的数据，命中率更高，减少了磁盘IO，从而提升了数据库性能。 水平切分因为垂直切分并没有解决单表数据量过大的问题（1000W行切分后还是1000W行），所以当还是无法满足需求的时候，可以进行水平切分。水平切分有以下几种方式： 范围切分：比如按照时间区间或ID区间来切分，这可以使得冷热数据分离。由于是顺序存储，天然适合水平扩展，但是无法解决集中写入瓶颈的问题。 Hash切分：通过Hash取模解决了数据访问不均匀的问题，但是在集群扩容的时候，数据迁移量是很大的（使用一致性hash算法能较好的避免这个问题）。 参考资料 数据库分库分表思路 MySQL 分库分表策略 CS-NOTE]]></content>
  </entry>
  <entry>
    <title><![CDATA[GET和POST的区别]]></title>
    <url>%2F2019%2F05%2F26%2FPUT%E5%92%8CPOST%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[GET用于资源获取，是安全且幂等的，安全的意思是仅仅会获取资源而不会影响资源状态，幂等则是对同一URL的多次请求应该返回同样的结果；POST主要用来传输数据，多次调用会产生多个新的资源，因此是不安全且非幂等的。 GET请求的数据会包含在URL中，而POST请求则把数据放置在HTTP请求体中。 正因为GET请求是通过URL提交数据，所以GET请求可提交的数据量跟URL的长度有关系，而POST请求从理论上讲是没有大小限制，可传较大量的数据。]]></content>
  </entry>
  <entry>
    <title><![CDATA[TCP与UDP的区别]]></title>
    <url>%2F2019%2F05%2F26%2FTCP%E4%B8%8EUDP%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[OSI和TCP/IP模型在传输层定义了两种传输协议：TCP（传输控制协议）和 UDP（用户数据报协议）。它们的主要区别如下： 面向连接与无连接 TCP保证数据可靠性，错误重发；UDP不可靠，可能丢包 TCP保证数据顺序，UDP不保证 TCP主要提供完整性服务，UDP主要提供及时性服务]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
        <tag>TCP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@Autowired源码分析]]></title>
    <url>%2F2019%2F05%2F24%2FAutowired%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[AutowiredAnnotationBeanPostProcessor@Autowired注解的逻辑是由AutowiredAnnotationBeanPostProcessor实现的，AutowiredAnnotationBeanPostProcessor不是一个简单的BeanPostProcessor，而是一个实现了多重接口的BeanPostProcessor，它主要实现了以下两个接口： InstantiationAwareBeanPostProcessor：对应postProcessPropertyValues()方法 MergedBeanDefinitionPostProcessor：对应findAutowiringMetadata方法 下面我们分别来看看这两个接口的实现是如何完成@Autowired的逻辑的。 作为MergedBeanDefinitionPostProcessor的行为首先，我们从ApplicationContext体系最核心的refresh()方法说起： refresh()方法中registerBeanPostProcessors(beanFactory)这一行代码完成了对AutowiredAnnotationBeanPostProcessor的注册，当执行finishBeanFactoryInitialization(beanFactory)方法时，会实例化所有非懒加载的单例Bean，这个过程中会调用AbstractAutowireCapableBeanFactory类的doCreateBean()方法，其中在使用合适的实例化策略实例化完Bean之后，会有下面这么一段代码：123456789101112131415161718192021222324252627protected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final Object[] args) throws BeanCreationException &#123; // ... synchronized (mbd.postProcessingLock) &#123; if (!mbd.postProcessed) &#123; try &#123; applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName); // 重点关注这一行 &#125; catch (Throwable ex) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Post-processing of merged bean definition failed", ex); &#125; mbd.postProcessed = true; &#125; &#125; // ...&#125;protected void applyMergedBeanDefinitionPostProcessors(RootBeanDefinition mbd, Class&lt;?&gt; beanType, String beanName) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof MergedBeanDefinitionPostProcessor) &#123; MergedBeanDefinitionPostProcessor bdp = (MergedBeanDefinitionPostProcessor) bp; bdp.postProcessMergedBeanDefinition(mbd, beanType, beanName); &#125; &#125;&#125; 在applyMergedBeanDefinitionPostProcessors()方法中，会判断当前的BeanPostProcessor是否是MergedBeanDefinitionPostProcessor类型的，如果是的话则调用它的postProcessMergedBeanDefinition()方法（显然，这里会判断为真，因为AutowiredAnnotationBeanPostProcessor实现了MergedBeanDefinitionPostProcessor）。我们再来看看AutowiredAnnotationBeanPostProcessor对该方法的实现：1234567891011121314151617181920212223242526272829303132@Overridepublic void postProcessMergedBeanDefinition(RootBeanDefinition beanDefinition, Class&lt;?&gt; beanType, String beanName) &#123; if (beanType != null) &#123; InjectionMetadata metadata = findAutowiringMetadata(beanName, beanType, null); metadata.checkConfigMembers(beanDefinition); &#125;&#125;private InjectionMetadata findAutowiringMetadata(String beanName, Class&lt;?&gt; clazz, PropertyValues pvs) &#123; String cacheKey = (StringUtils.hasLength(beanName) ? beanName : clazz.getName()); InjectionMetadata metadata = this.injectionMetadataCache.get(cacheKey); // 先从缓存中找 InjectionMetadata，诸如 @Autowire，@Inject 等 if (InjectionMetadata.needsRefresh(metadata, clazz)) &#123; // 如果找不到，则从这里开始，通过分析 bean，去找到它的 InjectionMetadata synchronized (this.injectionMetadataCache) &#123; metadata = this.injectionMetadataCache.get(cacheKey); if (InjectionMetadata.needsRefresh(metadata, clazz)) &#123; if (metadata != null) &#123; metadata.clear(pvs); &#125; try &#123; metadata = buildAutowiringMetadata(clazz); // 重点关注：去找，并构建其 InjectionMetadata 对象 this.injectionMetadataCache.put(cacheKey, metadata); // 如果找到了，将其放入 injectionMetadataCache 中返回； &#125; catch (NoClassDefFoundError err) &#123; throw new IllegalStateException("Failed to introspect bean class [" + clazz.getName() + "] for autowiring metadata: could not find class that it depends on", err); &#125; &#125; &#125; &#125; return metadata;&#125; findAutowiringMetadata()方法先从缓存中判断否已经存在该InjectionMetadata了，如果存在，且无需进行刷新，则返回；如果缓存中不存在（或者存在但需要刷新），那么就需要去构建一个InjectionMetadata。 接下来就是比较核心的部分了，通过buildAutowiringMetadata()方法构建InjectionMetadata对象：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061private InjectionMetadata buildAutowiringMetadata(final Class&lt;?&gt; clazz) &#123; LinkedList&lt;InjectionMetadata.InjectedElement&gt; elements = new LinkedList&lt;InjectionMetadata.InjectedElement&gt;(); Class&lt;?&gt; targetClass = clazz; do &#123; final LinkedList&lt;InjectionMetadata.InjectedElement&gt; currElements = new LinkedList&lt;InjectionMetadata.InjectedElement&gt;(); // 1. 通过反射从 targetClass 的 field 中去找注解 ReflectionUtils.doWithLocalFields(targetClass, new ReflectionUtils.FieldCallback() &#123; @Override public void doWith(Field field) throws IllegalArgumentException, IllegalAccessException &#123; AnnotationAttributes ann = findAutowiredAnnotation(field); // 是否存在 @Autowired if (ann != null) &#123; if (Modifier.isStatic(field.getModifiers())) &#123; if (logger.isWarnEnabled()) &#123; logger.warn("Autowired annotation is not supported on static fields: " + field); &#125; return; // 如果当前处理的属性是静态属性，则直接返回 &#125; boolean required = determineRequiredStatus(ann); currElements.add(new AutowiredFieldElement(field, required)); &#125; &#125; &#125;); // 2. 通过反射从 targetClass 的 method 中去找注解 ReflectionUtils.doWithLocalMethods(targetClass, new ReflectionUtils.MethodCallback() &#123; @Override public void doWith(Method method) throws IllegalArgumentException, IllegalAccessException &#123; Method bridgedMethod = BridgeMethodResolver.findBridgedMethod(method); if (!BridgeMethodResolver.isVisibilityBridgeMethodPair(method, bridgedMethod)) &#123; return; &#125; // 上述代码处理 bridged method 相关情况；可忽略； AnnotationAttributes ann = findAutowiredAnnotation(bridgedMethod); // 是否存在 @Autowired if (ann != null &amp;&amp; method.equals(ClassUtils.getMostSpecificMethod(method, clazz))) &#123; if (Modifier.isStatic(method.getModifiers())) &#123; if (logger.isWarnEnabled()) &#123; logger.warn("Autowired annotation is not supported on static methods: " + method); &#125; return; // 如果方法是静态的，则直接返回； &#125; if (method.getParameterTypes().length == 0) &#123; if (logger.isWarnEnabled()) &#123; logger.warn("Autowired annotation should only be used on methods with parameters: " + method); // 警告，方法参数长度为 0 &#125; &#125; boolean required = determineRequiredStatus(ann); PropertyDescriptor pd = BeanUtils.findPropertyForMethod(bridgedMethod, clazz); currElements.add(new AutowiredMethodElement(method, required, pd)); &#125; &#125; &#125;); elements.addAll(0, currElements); targetClass = targetClass.getSuperclass(); &#125; while (targetClass != null &amp;&amp; targetClass != Object.class); return new InjectionMetadata(clazz, elements);&#125; 该方法分为两部分，通过工具类ReflectionUtils分别从当前Bean实例的fields和methods中去查找@Autowired注解： 从fields找@Autowired注解，若找到，则创建AutowiredFieldElement实例，并放入currElements队列中 从methods中找@Autowired注解，若找到，则创建AutowiredMethodElement实例，并放入currElements队列中 最后，通过Bean的Class对象和curreElements构建InjectionMetadata实例并返回 此时，将构建好的InjectionMetadata加入缓存injectionMetadataCache中并返回。 作为InstantiationAwareBeanPostProcessor的行为同样，在doCreateBean()方法中执行populateBean()方法填充属性时，populateBean()方法中有如下一段代码：1234567891011121314151617if (hasInstAwareBpps || needsDepCheck) &#123; if (pvs == null) &#123; pvs = mbd.getPropertyValues(); &#125; PropertyDescriptor[] filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching); if (hasInstAwareBpps) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; pvs = ibp.postProcessPropertyValues(pvs, filteredPds, bw.getWrappedInstance(), beanName); // 重点关注这一行 if (pvs == null) &#123; return; &#125; &#125; &#125; &#125; 其中，pvs = ibp.postProcessPropertyValues()这行代码调用了InstantiationAwareBeanPostProcessor的接口方法，继续跟进去看。 12345678910111213public PropertyValues postProcessPropertyValues(PropertyValues pvs, PropertyDescriptor[] pds, Object bean, String beanName) throws BeanCreationException &#123; // &lt;1&gt; InjectionMetadata metadata = findAutowiringMetadata(beanName, bean.getClass(), pvs); try &#123; // &lt;2&gt; metadata.inject(bean, beanName, pvs); &#125; catch (BeanCreationException ex) &#123; throw ex; &#125; catch (Throwable ex) &#123; // ... &#125; return pvs;&#125; 在刚实例化完Bean之后，作为MergedBeanDefinitionPostProcessor，已经调用过findAutowiringMetadata()方法，即从当前Bean对象中的属性和方法中找到了@Autowired注解，并将它们封装成了InjectionMetadata放入了缓存当中，因此，此处直接从缓存中就可以获取到该Bean对应的InjectMetadata。接下来就是通过InjectMetadata进行注入： 12345678910111213141516171819202122232425262728293031323334public void inject(Object target, @Nullable String beanName, @Nullable PropertyValues pvs) throws Throwable &#123; Collection&lt;InjectedElement&gt; checkedElements = this.checkedElements; Collection&lt;InjectedElement&gt; elementsToIterate = (checkedElements != null ? checkedElements : this.injectedElements); if (!elementsToIterate.isEmpty()) &#123; for (InjectedElement element : elementsToIterate) &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Processing injected element of bean '" + beanName + "': " + element); &#125; element.inject(target, beanName, pvs); // 重点关注 &#125; &#125;&#125; protected void inject(Object target, @Nullable String requestingBeanName, @Nullable PropertyValues pvs) throws Throwable &#123; if (this.isField) &#123; Field field = (Field) this.member; ReflectionUtils.makeAccessible(field); field.set(target, getResourceToInject(target, requestingBeanName)); // 重点关注 &#125; else &#123; if (checkPropertySkipping(pvs)) &#123; return; &#125; try &#123; Method method = (Method) this.member; ReflectionUtils.makeAccessible(method); method.invoke(target, getResourceToInject(target, requestingBeanName)); // 重点关注 &#125; catch (InvocationTargetException ex) &#123; throw ex.getTargetException(); &#125; &#125; &#125; 由于InjectionMetadata对象本身包含了一系列的AutowiredFieldElement和AutowiredMethodElement，所以这里迭代InjectedElement并依次处理它们，而处理的逻辑都在inject()这一关键方法中，可以看到最终就是根据是属性还是方法来分别使用反射注入，并且对于方法而言，该方法会被调用。 参考资料 Spring Core Container 源码分析五：@Autowired 深入理解Spring系列之十四：@Autowired是如何工作的]]></content>
  </entry>
  <entry>
    <title><![CDATA[破坏双亲委派模型]]></title>
    <url>%2F2019%2F05%2F24%2F%E7%A0%B4%E5%9D%8F%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[如何破坏双亲委派模型双亲委派模型不是一个强制性的约束模型，而是一个建议型的类加载器实现方式。考虑这么一个问题，如果基础类需要调用用户的代码该怎么办，因为根据双亲委派模型，越基础的类由越上层的加载器进行加载，但是上层的加载器并不认识用户的代码。 一个典型的例子就是JNDI服务，JNDI现在已经是Java的标准服务，它的代码由启动类加载器去加载（在JDK1.3时就放进rt.jar）,但它需要调用由独立厂商实现并部署在应用程序的ClassPath下的JNDI接口提供者（SPI， Service Provider Interface）的代码，但启动类加载器不可能“认识“这些代码啊。因为这些类不在rt.jar中，但是启动类加载器又需要加载。怎么办呢？ 为了解决这个问题，Java设计团队只好引入了一个不太优雅的设计：线程上下文类加载器（Thread Context ClassLoader）。这个类加载器可以通过java.lang.Thread类的setContextClassLoader()方法进行设置。如果创建线程时未设置，它将会从父线程中继承一个，如果在应用程序的全局范围内都没有设置过的话，那这个类加载器默认即是应用程序类加载器。 有了线程上下文加载器，JNDI服务使用这个线程上下文加载器去加载所需要的SPI代码，也就是父类加载器请求子类加载器去完成类加载的动作，这种行为实际上就是打通了双亲委派模型的层次结构来逆向使用类加载器，实际上已经违背了双亲委派模型的一般性原则。 JDBC如果破坏双亲委派模型JDBC之所以要破坏双亲委派模型，是因为原生的JDBC中Driver驱动本身只是一个接口，并没有具体的实现，具体的实现是由不同的数据库去实现的，例如，可以由MySQL的mysql-connector-.jar中的Driver类具体实现。由于原生的JDBC中的类是放在rt.jar包的，是由启动类加载器进行类加载的，且需要动态去加载不同数据库类型的Driver类，而mysql-connector-.jar中的Driver类是用户自己写的代码，所以启动类加载器是不能进行加载的，需要由应用程序类加载器进行加载。此时，通过线程上下文类加载器获得应用程序类加载器，通过应用程序类加载器去加载这个Driver类，从而避开了双亲委派模型的局限性。 Tomcat的类加载器是怎么设计的？前面3个类加载器和默认的一致，CommonClassLoader、CatalinaClassLoader、SharedClassLoader和WebappClassLoader则是Tomcat自己定义的类加载器，它们分别加载/common/*、/server/*、/shared/*（在tomcat 6之后已经合并到根目录下的lib目录下）和/WebApp/WEB-INF/*中的Java类库。其中WebApp类加载器和Jsp类加载器通常会存在多个实例，每一个Web应用程序对应一个WebApp类加载器，每一个JSP文件对应一个Jsp类加载器。 commonLoader：Tomcat最基本的类加载器，加载路径中的class可以被Tomcat容器本身以及各个Webapp访问。 catalinaLoader：Tomcat容器私有的类加载器，加载路径中的class对于Webapp不可见。 sharedLoader：各个Webapp共享的类加载器，加载路径中的class对于所有Webapp可见，但是对于Tomcat容器不可见。 WebappClassLoader：各个Webapp私有的类加载器，加载路径中的class只对当前Webapp可见。 Common ClassLoader能加载的类都可以被Catalina ClassLoader和Shared ClassLoader使用，从而实现了公有类库的共用，而Catalina ClassLoader和Shared ClassLoader自己能加载的类则与对方相互隔离，从而保证了安全性。WebApp ClassLoader可以使用Shared ClassLoader加载到的类，但各个WebApp ClassLoader实例之间相互隔离。JasperLoader的加载范围仅仅是这个JSP文件所编译出来的那一个.Class文件，它出现的目的就是为了被丢弃：当Web容器检测到JSP文件被修改时，会替换掉目前的JasperLoader的实例，并通过再建立一个新的Jsp类加载器来实现JSP文件的HotSwap功能，否则如果类名还是一样，旧的类加载器会直接取方法区中已经存在的，修改后的JSP是不会重新加载的。 可以看出，Tomcat没有遵循双亲委派模型，每个Webapp ClassLoader加载自己的目录下的class文件，不会传递给父类加载器。 参考资料 深入理解 Tomcat（四）Tomcat 类加载器之为何违背双亲委派模型]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>双亲委派模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ApplicationContext体系分析]]></title>
    <url>%2F2019%2F05%2F23%2FApplicationContext%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[前言ApplicationContext实现了除基本容器外的多个接口，提供了比BeanFactory更为丰富的功能，比如说自动识别BeanPostProcessor以及其它特殊类型Bean、容器启动时自动加载Bean、国际化支持、容器内事件发布等。因此，我们在实际应用中一般会使用ApplicationContext而不是BeanFactory。 继承体系 从上图可以看出，ApplicationContext继承了BeanFactory，因此拥有BeanFactory的全部功能，实际上，它是将容器的功能委派给DefaultListableBeanFactory来实现。除此之外，ApplicationContext还继承了ResourceLoader、EnvironmentCable、ApplicationEventPublisher、MessageSource等接口，提供了十分丰富的功能。 源码分析创建一个常用的ApplicationContext：1ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext("classpath:application.xml"); ClassPathXmlApplicationContext的构造函数在设置完配置文件的位置后，紧接着调用refresh()方法，这个方法是整个ApplicationContext体系的核心，是在AbstractApplicationContext中实现的，并且是个典型的模板方法，也就是说其中的一些步骤是交由具体子类来实现的。以下是这个方法的代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // 1. 准备刷新时的上下文环境 prepareRefresh(); // 2. 刷新并初始化 BeanFactory ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // 3. 配置 BeanFactory 中的一些其它信息 prepareBeanFactory(beanFactory); try &#123; // 4. 提供子类覆盖的额外处理，即子类处理自定义的 BeanFactoryPostProcess postProcessBeanFactory(beanFactory); // 5. 调用各种 BeanFactoryPostProcessor invokeBeanFactoryPostProcessors(beanFactory); // 6. 注册 BeanPostProcessor 到 BeanFactory 中去 registerBeanPostProcessors(beanFactory); // 7. 初始化上下文中的资源文件，如国际化文件的处理等 initMessageSource(); // 8. 初始化上下文事件广播器 initApplicationEventMulticaster(); // 9. 初始化其它特殊 Bean onRefresh(); // 10. 检查 listener 类型的 Bean 并注册 registerListeners(); // 11. 实例化所有非懒加载的单例 Bean finishBeanFactoryInitialization(beanFactory); // 12. 发布相应的事件 finishRefresh(); &#125; catch (BeansException ex) &#123; // ... &#125; finally &#123; // Reset common introspection caches in Spring's core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); &#125; &#125;&#125; obtainFreshBeanFactoryobtainFreshBeanFactory()方法核心是内部调用refreshBeanFactory()方法并将容器内部的ConfigurableListableBeanFactory返回，从这也看到了ApplicationContext和BeanFactory的关系：ApplicationContext内部包含一个BeanFactory，ApplicationContext所有关于BeanFactory的功能将委派给此BeanFactory处理。 1234567891011121314151617181920212223protected final void refreshBeanFactory() throws BeansException &#123; // 清理之前的BeanFactory if (hasBeanFactory()) &#123; destroyBeans(); closeBeanFactory(); &#125; try &#123; // createBeanFactory方法直接新建一个DefaultListableBeanFactory，也就是说内部使用的是DefaultListableBeanFactory实例 DefaultListableBeanFactory beanFactory = createBeanFactory(); beanFactory.setSerializationId(getId()); // 自定义此上下文使用的内部bean工厂 customizeBeanFactory(beanFactory); // 将BeanDefinition加载到给定的bean工厂中，通常通过委托给一个或多个BeanDefinitionReader来实现 // 子类实现的方法，此处调用的是AbstractXmlApplicationContext的方法 loadBeanDefinitions(beanFactory); synchronized (this.beanFactoryMonitor) &#123; this.beanFactory = beanFactory; &#125; &#125; catch (IOException ex) &#123; throw new ApplicationContextException(...); &#125;&#125; 也就是说这一步是构建ApplicationContext内部的BeanFactory，以及根据配置将BeanDefinition加载到BeanFactory中（此时并没有实例化Bean）。 prepareBeanFactory配置内部BeanFactory的一些基础参数，比如ClassLoader等等。 postProcessBeanFactory对BeanFactory预处理，ClassPathXmlApplicationContext未重写，WebXmlApplicationContext有重写，这里不展开。 invokeBeanFactoryPostProcessors在任何Bean的实例化之前，实例化并调用所有已注册的BeanFactoryPostProcessorBean，如果实现了PriorityOrdered或者Ordered接口则按顺序调用。此时允许BeanFactoryPostProcessor在实例化BeanDefinition之前对当前的配置数据进行修改。 registerBeanPostProcessors将当前所有的BeanPostProcessor注册到BeanFactory中去，同样也是按照PriorityOrdered或者Ordered的顺序。这也是ApplicationContext与BeanFactory的一个不同，BeanFactory必须自己手动的调用addBeanPostProcessor()方法。 initMessageSource初始化MessageSource，如果没有定义则使用DelegatingMessageSource，实际是委派给父类的。 initApplicationEventMulticaster初始化ApplicationEventMulticaster，如果没有定义则使用SimpleApplicationEventMulticaster。 onRefresh模板方法，交给子类来实现，一般是用于在实例化单例Bean之前调用特定Bean的初始化。 registerListeners将所有ApplicationListener注册到ApplicationEventMulticaster中，然后将earlyApplicationEvents中定义的事件进行广播。 finishBeanFactoryInitialization实例化所有剩余的非懒加载的单例Bean，就是遍历所有的beanName，然后挨个调用getBean(beanName)。 finishRefresh完成此上下文的刷新，调用LifecycleProcessor的onRefresh()方法并发布ContextRefreshedEvent。主要是对于有生命周期的Bean，按照分组，调用其start()方法。 ApplicationContext使用1234567891011// beanFactoryUserService userService = context.getBean("userService", UserService.class);// 事件context.addApplicationListener(new WalkListener());context.publishEvent(new WalkEvent(new User("Jerry")));context.publishEvent(new WalkEvent(new User("Peter")));// localecontext.getMessage("menu.edit", null, "Edit", Locale.US);// ... 参考资料 Spring IOC ApplicationContext 源码分析 Spring ApplicationContext源码分析]]></content>
  </entry>
  <entry>
    <title><![CDATA[Simple IoC开发日志：加载Bean]]></title>
    <url>%2F2019%2F05%2F21%2FSimple-IoC%E5%BC%80%E5%8F%91%E6%97%A5%E5%BF%97%EF%BC%9AgetBean%2F</url>
    <content type="text"><![CDATA[Spring IoC实现在之前加载注册BeanDefinition完成后，Spring已经存在一组beanName - &gt;BeanDefinition的映射了，接下来我们就可以根据名称或类型实例化并获取我们想要的Bean，而和这个实例化Bean相关的则是整个BeanFactory体系。接下来我们从doGetBean()这个方法开始分析起，这个方法涵盖了实例化Bean的总流程，大致步骤如下： 将 alias name、FactoryBean name 转换为对应的beanName 尝试从缓存中获取单例Bean 如果缓存中不存在，则从父类容器中加载 合并父类的属性，获取RootBeanDefinition 加载所依赖的Bean 根据不同的scope实例化Bean 类型转换处理，如果传递的requiredType不为null，则需要检测所得到的Bean的类型是否与该requiredType一致。 首先，如果名称是以&amp;开头的，则去掉&amp;，并且根据别名获取到beanName，然后尝试从单例缓存中获取Bean，这也正是解决循环依赖的关键，第一次获取时是没有效果的，继续往下走。此时判断是否发生原型模式的循环依赖，如果发生了，则抛出异常。接下来根据beanName从映射中获取到BeanDefinition（其实是RootBeanDefinition），然后优先加载所依赖的Bean（depends-on标签），然后根据不同的scope分别实例化Bean，完成FactoryBean的相关处理，最后做类型转换即可，不过目前不会去关心这个类型转换。下面开始分析比较重要的几个步骤。 Bean实例化Bean会根据不同的scope采取不同的实例化策略，总共有五种scope：singleton、prototype、request、session、global session，其实比较常用的也就singleton和prototype，而prototype不需要解决循环依赖的问题，直接反射创建就好了，重点需要关注的是singleton的实例化过程。 接下来从getSingleton()这个方法进入Bean实例化的正戏。这个方法的开始可以看到用到了双重校验锁，因为多个线程可能在之前同时判断缓存中没有Bean，就都进入到了这里，但为了保证不重复实例化Bean（单例模式），在获取锁之后还会再判断一次是否能从缓存中获取，这里是要注意的。接下来通过ObjectFactory#getObject()方法开始实例化，里面会调用doCreateBean()方法，然后经历以下几个步骤： 使用合适的实例化策略来创建新的实例：工厂方法、构造函数自动注入、简单初始化。此时Bean已经被创建出来了，只是没有进行属性填充和初始化 如果为单例模式、允许循环依赖且当前单例Bean正在被创建，那么将其加入到三级缓存singletonFactories中 属性填充 调用初始化方法 4.1. 激活Aware方法，对特殊的Bean处理4.2. 调用postProcessBeforeInitialization()4.3. 如果实现了InitializingBean接口，调用其afterPropertiesSet()方法；如果指定了init-method，则调用指定的init-method4.4. 调用postProcessAfterInitialization() 注册Bean的销毁方法。与InitializingBean和init-method用于对象的自定义初始化工作相似，DisposableBean和destroy-method用于对象的自定义销毁工作。但这里并不是立刻执行，而是先注册，等到Spring容器关闭的时候才去调用，并且需要我们主动去告知Spring容器，对于BeanFactory容器需要调用destroySingletons()方法，对于ApplicationContext容器需要调用registerShutdownHook()方法。 到这里，我们就获取到一个Bean了，下面对其中的一些细节进行解释。 createBeanInstance在这个方法中，完成了Bean的实例化（注意，此时还没填充属性等等），Spring提供了四种实例化策略： Supplier回调：从BeanDefinition中获取Supplier对象，如果不为空，则调用obtainFromSupplier()方法完成Bean的初始化 工厂方法初始化 构造函数自动注入初始化 默认构造函数注入 工厂方法初始化的工厂分为静态工厂和实例工厂，静态工厂的配置如下：1&lt;bean id="eat" class="it.spring.liao.com.EatFactory" factory-method="getInstance" /&gt; 实例工厂的配置如下：12&lt;bean id="eatFactory" class="it.spring.liao.com.EatFactory "/&gt;&lt;bean id="eat" factory-bean="eatFactory" factory-method="getInstance"/&gt; 如果配置了构造函数的自动注入或者配置了构造函数参数，则调用带参的构造函数去实例化Bean。因为一个类有多个构造函数，每个构造函数都有不同的构造参数，需要根据参数个数和类型确定最精确匹配的构造函数，这部分的源码还是十分复杂的。 对于带参构造函数或默认构造函数，都会先判断是否有覆盖方法，如果有的话则使用CGLIB创建代理对象，否则通过反射来创建Bean（核心代码其实就是constructorToUse.newInstance()）。 而对于工厂方法，其实也就是通过该Method反射创建Bean（核心代码其实就是factoryMethod.invoke(factoryBean, args)）。 解决循环依赖先看一下Spring中关于这块的实现：12345678910111213boolean earlySingletonExposure = (mbd.isSingleton() // 如果为单例模式 &amp;&amp; this.allowCircularReferences // 允许循环依赖 &amp;&amp; isSingletonCurrentlyInCreation(beanName)); // 当前单例 Bean 正在被创建if (earlySingletonExposure) &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Eagerly caching bean '" + beanName + "' to allow for resolving potential circular references"); &#125; // 这个方法的调用发生在 createBeanInstance() 方法之后，也就是说这个 bean 其实已经创建出来了，但是没有进行属性填充和初始化， // 但是此时已经可以根据对象引用定位到堆中该对象了，所以将该对象提前曝光出来，加入到三级缓存 singletonFactories 中 // 这里是为了后期避免循环依赖 addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean));&#125; Spring IoC是通过三级缓存这么个机制解决循环依赖的问题的，每次在调用createBeanInstance()方法实例化一个Bean后，就将这个Bean加入到三级缓存singletonFactories中，而此时如果依赖的属性又依赖于自己，即发生循环依赖的话，那么就会直接从三级缓存中拿到这个Bean，并将其升级到二级缓存中去，如果后续还有循环依赖的话，直接从二级缓存就能获取到结果。需要注意的是，这时候的Bean仅仅只是实例化了出来，并没有进行属性填充等操作，只有当一切都完成后，才会将这个Bean升级到一级缓存中去。 populateBean上面已经实例化出了Bean，并且加入到三级缓存中了，但是这个Bean还有许多事没做完，接下来第一件事就是对其进行属性填充，也就是populateBean()这个方法，它的大体步骤如下： 获取Bean的属性值，也就是PropertyValues 根据名称或类型解析依赖（此时并未注入到Bean中，仅仅将属性放到了`pvs中） 调用applyPropertyValues()真正注入属性： 3.1. 检测属性值列表是否已经转换过，若转换过，则直接填充属性，无需再次转换3.2. 遍历属性值列表pvs，解析原始值originalValue，得到解析值resolvedValue3.3. 对解析后的属性值resolvedValue进行类型转换3.4. 将类型转换后的属性值设置到PropertyValue对象中，并将PropertyValue对象存入deepCopy集合中3.5. 将deepCopy中的属性信息注入到Bean对象中 首先讲讲根据名称或类型解析依赖。autowireByName()方法主要完成了以下几件事： 获取Bean对象中的非简单属性名，即类型为对象类型的属性，String、Enum、Date、URI/URL、Number的继承类如Integer/Long、byte/short/int等基本类型、Locale、以上所有类型的数组形式。 遍历那些非简单属性名，如果容器中包含该名称对应的Bean，则递归实例化该Bean（也就是调用getBean()方法） 将递归获取到的Bean存入到属性值列表PropertyValues中 注册依赖（就是建立映射关系） autowireByType()方法比autowireByName()方法复杂一些，因为相同类型的Bean可能有多个，它最核心的思路如下： 根据类型查找所有合适的候选Bean。比如说我们的成员变量是Dao类型的，那么此时MongoDao和MySQLDao这两个Bean可能都属于合适的候选项，因为它们都实现了Dao接口。 如果没有找到合适的候选Bean，并且autowire的require属性为true，则直接抛出异常 当候选者不唯一时，则依次根据Primary、Priority决定最终的候选Bean（此时拿到了autowiredBeanName和instanceCandidate） 当候选者唯一时，可以直接决定候选Bean（此时拿到了autowiredBeanName和instanceCandidate） 候选Bean可能并没有实例化，也就是instanceCandidate仅仅为Class类型，比如说是MySQLDao.class，此时根据beanFactory.getBean(autowiredBeanName)方法实例化该Bean 返回已实例化好的Bean 接下来就和autowireByName()方法一样了，将获取到的Bean存入到属性值列表PropertyValues中，并且注册这个依赖关系。此时，&lt;property&gt;标签表示的属性和自动注入的属性都已经解析到PropertyValues中了，调用applyPropertyValues()开始真正的属性注入，该方法核心步骤如下： 将ref（在之前解析标签时将其封装成了RuntimeBeanReference）解析为具体的对象，将&lt;list&gt;标签转换为List对象，还会解析&lt;set/&gt;、&lt;map/&gt;、&lt;array/&gt;等标签。 对属性值的类型进行转换，比如将String类型的属性值&quot;123&quot;转换为Integer类型的123 反射设置PropertyValues中的所有属性 至此，属性值已经注入到Bean中了。 initializeBean填充完属性，接下来就是调用初始化方法，该方法的步骤如下： 激活Aware方法：Bean可以实现Aware接口，从而对当前环境进行感知（就是实现了setXXX()方法）。在这里，会针对BeanNameAware、BeanClassLoaderAware、BeanFactoryAware三种Aware接口进行判断，将一些值设置到当前Bean中。 调用postProcessBeforeInitialization()方法 调用invokeInitMethods()方法： 3.1. 如果Bean实现了InitializingBean接口，那么会先调用该接口的afterPropertiesSet()方法3.2. 检查是否指定了init-method，如果指定了则通过反射机制调用init-method方法 调用postProcessAfterInitialization()方法 至此，几个核心步骤就都介绍完了。 Simple IoC实现Simple IoC的实现大体思路上与Spring IoC一致，但是尚不支持&lt;list/&gt;等一些集合标签，并且不像Spring实现了一套类型转换体系，这里直接使用了apache的BeanUtils完成类型转换相关的操作。除此之外，暂时还未实现initializeBean()相关的逻辑。 快速开始第一个测试是模拟登陆接口的场景，分为Controller、Service、Dao三层，XML配置文件如下：12345678910111213141516&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans-2.0.xsd"&gt; &lt;bean id="loginController" class="cn.hecenjie.simpleioc.tests.objects.login.LoginController"&gt; &lt;property name="loginService" ref="loginService" /&gt; &lt;/bean&gt; &lt;bean id="loginService" class="cn.hecenjie.simpleioc.tests.objects.login.LoginServiceImpl"&gt; &lt;property name="userDao" ref="userDao" /&gt; &lt;/bean&gt; &lt;bean id="userDao" class="cn.hecenjie.simpleioc.tests.objects.login.UserDao"/&gt; &lt;/beans&gt; 测试代码如下：12345678910@Testpublic void testGetBean() &#123; ResourceLoader resourceLoader = new FileSystemResourceLoader(); Resource resource = resourceLoader.getResource("C:\\Users\\canjie\\Desktop\\login.xml"); DefaultListableBeanFactory factory = new DefaultListableBeanFactory(); BeanDefinitionReader beanDefinitionReader = new XmlBeanDefinitionReader(factory); beanDefinitionReader.loadBeanDefinitions(resource); LoginController loginController = (LoginController) factory.getBean("loginController"); assertEquals(loginController.login("Lihua", "123456789"), true);&#125; 第二个测试是针对循环依赖问题的，XML配置文件如下：1234567891011121314151617&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans-2.0.xsd"&gt; &lt;bean id="person" class="cn.hecenjie.simpleioc.tests.objects.persons.Person"&gt; &lt;property name="name" value="Lihua" /&gt; &lt;property name="age" value="18" /&gt; &lt;property name="idCard" ref="idCard" /&gt; &lt;/bean&gt; &lt;bean id="idCard" class="cn.hecenjie.simpleioc.tests.objects.persons.IdCard"&gt; &lt;property name="id" value="441301188875468912" /&gt; &lt;property name="owner" ref="person" /&gt; &lt;/bean&gt; &lt;/beans&gt; 测试代码如下：123456789101112131415@Testpublic void testCyclicDependence()&#123; ResourceLoader resourceLoader = new FileSystemResourceLoader(); Resource resource = resourceLoader.getResource("C:\\Users\\canjie\\Desktop\\persons.xml"); DefaultListableBeanFactory factory = new DefaultListableBeanFactory(); BeanDefinitionReader beanDefinitionReader = new XmlBeanDefinitionReader(factory); beanDefinitionReader.loadBeanDefinitions(resource); Person person = (Person) factory.getBean("person"); IdCard idCard = (IdCard) factory.getBean("idCard"); assertEquals(person.getName(), "Lihua"); assertEquals(person.getAge(), 18); assertEquals(person.getIdCard(), idCard); assertEquals(idCard.getId(), 441301188875468912L); assertEquals(idCard.getOwner(), person);&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[Simple IoC开发日志：注册BeanDefinitions]]></title>
    <url>%2F2019%2F05%2F19%2FSimple-IoC%E5%BC%80%E5%8F%91%E6%97%A5%E5%BF%97%EF%BC%9ABeanDefinition%E5%8A%A0%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[Spring IoC实现在之前已经介绍过Spring IoC对资源的抽象了，也就是Resource接口。当我们加载了指定的资源后，接下来需要做的就是将资源（也就是XML文件）解析成Document实例，并解析成BeanDefinition然后注册。这个过程的整体流程如下： loadBeanDefinitions(Resource resource)作为方法入口。 doLoadBeanDefinitions(InputSource inputSource, Resource resource)方法实现了真正的加载逻辑，它首先根据XML获取Document实例，然后根据Document实例注册Bean信息。 2.1. doLoadDocument()方法根据XML获取Document实例，其中会牵扯到获取验证模式和错误处理等过程。 2.2. registerBeanDefinitions()遍历XML的每一个节点并注册它们的BeanDefinition。 接下来就上面获取Document实例和注册BeanDefinition进行分析。 获取Document解析XML有两种方式，一种是DOM解析，另一种则是SAX解析，关于这两个解析方式在网上也有比较充足的资料，就不在这赘述了。在这一个过程还有两个方面是需要关心的，一个是验证模式，另一个是错误处理（还有一个是Spring实现的EntityResolver，自定义了验证文件的获取方式，在本地建立了一个映射而不需要从网络中获取）。 首先，验证模式同样也有两种，一种是DTD验证模式，另一种是XSD验证模式。因此，在这里需要根据XML文件中的一些信息来探测决定具体使用哪种验证模式，比如说如果内容中包含DOCTYPE则肯定为DTD验证模式，而如果探测不出的话，最终会使用XSD验证模式。错误处理就是当加载Document发生错误时需要做出的反应，简单的实现就是输出错误日志。当以上两个都准备好了后，就先通过DocumentBuilderFactory创建一个DocumentBuilder，再调用DocumentBuilder的parse()方法直接解析并返回一个Document实例即可。 注册BeanDefinition注册BeanDefinition实际上就是通过上面获取到的Document的根节点开始逐个遍历子节点（要先判断根节点是否使用的默认命名空间），然后根据&lt;import/&gt;、&lt;alias/&gt;、&lt;bean/&gt;、&lt;beans/&gt;这四种标签分别进行解析，其中&lt;beans/&gt;标签的处理是一个递归的过程，而&lt;bean/&gt;标签的处理则是需要重点关注的，在这个过程中主要分为两步：解析出BeanDefinition并且完成注册。 Simple IoC实现获取Document目前仅支持XSD格式的验证，并且没有实现EntityResolver，也就是说无法根据自定义的策略从本地拿到验证文件，还是默认的从网络中获取。 注册BeanDefinition在目前的实现中，并没有像Spring IoC一样支持四种标签的解析，这里只解析了&lt;bean/&gt;标签。之后，需要重点关注的一个方法就是parseBeanDefinitionElement()，这是解析&lt;bean/&gt;标签的核心逻辑，主要完成了从&lt;bean/&gt;标签的id属性和name属性还有一些别的属性以及子元素中获取到值并组装成一个BeanDefinition（实际上还会包装一层BeanDefinitionHolder，其中保存了beanName和aliases），下面对这一部分的细节进行分析。 parseBeanDefinitionElement这个方法主要完成以下这些事： 解析出&lt;bean&gt;标签中的id属性和name属性，在Spring中是以,作为分隔符取得多个别名，但在这里的实现中只考虑一种别名的情况，也就是没有使用,进行分割。 优先使用id作为beanName，但如果并没有设置id属性的话，就使用第一个别名作为beanName，那么在这里就只有唯一的一个别名，当id没设置时它就是beanName。 检查beanName和别名的唯一性，如果不唯一，则抛出异常，唯一的话则加入到集合中去。（注意，别名也是需要唯一的） 解析别的属性以及子元素，开始构造AbstractBeanDefinition。上面几步只是对名称做一些解析，这一步的工作量则相对要大很多，下面是一些比较常见的属性： 4.1. 解析class属性，最重要的了4.2. 解析parent属性，未实现4.3. 解析scope属性4.4. 解析autowire属性4.5. 解析init-method属性4.6. 解析destroy-method属性4.7. 解析factory-bean属性4.8. 解析factory-method属性4.9. 解析&lt;lookup-method/&gt;子元素，未实现4.10. 解析&lt;replaced-method/&gt;子元素，未实现4.11. 解析&lt;property/&gt;子元素，这一步也很重要，它将属性名和属性值封装到了PropertyValue中，并且用PropertyValues封装所有属性（也就是每个BeanDefinition都有一个PropertyValues类型的成员变量）。4.12. 解析&lt;constructor-arg/&gt;子元素，未实现 此时已经构造出了一个相对完整的BeanDefinition了，这时候将其和beanName与别名一起封装成BeanDefinitionHolder对象。 注册beanName -&gt; BeanDefinition以及alias -&gt; beanName的映射关系（个人认为，这正是IoC的本质所在，通过一个映射表维护一个名称到BeanDefinition的关系，而这个BeanDefinition中封装了这个Bean的各种信息）。这里要注意的是，在注册alias -&gt; beanName的映射关系时，Spring考虑了别名循环指向的问题，它是通过递归来进行判断的。 此时，这个BeanDefinition已经注册成功，可以等待使用了 快速开始针对根据XML获取Document实例并注册BeanDefinition的过程做一些简单的测试：123456789101112@Testpublic void testLoadBeanDefinitions() &#123; ResourceLoader resourceLoader = new FileSystemResourceLoader(); Resource resource = resourceLoader.getResource("C:\\Users\\canjie\\Desktop\\simple.xml"); BeanDefinitionRegistry registry = new DefaultListableBeanFactory(); BeanDefinitionReader beanDefinitionReader = new XmlBeanDefinitionReader(registry); assertEquals(beanDefinitionReader.loadBeanDefinitions(resource), 2); assertEquals(((DefaultListableBeanFactory) registry).getBeanDefinition("first").getBeanClassName(), "beans.First"); assertEquals(((DefaultListableBeanFactory) registry).getBeanDefinition("second").getBeanClassName(), "beans.Second");&#125;]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>IoC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Simple IoC开发日志：资源加载]]></title>
    <url>%2F2019%2F05%2F19%2FSimple-IoC%E5%BC%80%E5%8F%91%E6%97%A5%E5%BF%97%EF%BC%9A%E8%B5%84%E6%BA%90%E5%8A%A0%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[Spring IoC实现Spring对资源文件和资源的加载都做了统一的抽象，以下是资源文件的继承体系： 其中，顶层接口InputStreamSource只包含一个getInputStream()方法用于返回指定资源的InputStream；而Resource是对资源的一个抽象，里面提供了判断资源是否存在、资源是否可读、资源大小等常见接口，并且大部分接口由抽象子类AbstractResource提供了默认实现，而一些方法则由具体的子类如FileSystemResource、ClassPathResource等覆写，以满足特定的场景需求。 接下来看看Spring对资源加载的统一抽象，同样从它的继承体系说起： 与AbstractResource相似，DefaultResourceLoader是ResourceLoader的默认实现。其中getResource()方法是其核心（两个子类都没覆盖该方法），它根据方法参数location的内容来决定到底是返回ClassPathResource还是FileSystemResource还是Resource其它的一些子类。由于在默认的实现策略中，凡是以/开头的都会返回ClassPathContextResource类型的资源，但对于/user/hecenjie/test.xml这样的路径我们更加希望是FileSystemResource类型的资源，因此在子类FileSystemResourceLoader中覆写了相关方法，使之可以从文件系统中获取资源；而另一个子类ClassRelativeResourceLoader则扩展了功能，可以根据给定的Class所在包或者所在包的子包下加载资源。 ResourceLoader的另一个重要实现是ResourcePatternResolver，与上面的ResourceLoader实现类不同的是，它支持根据指定的资源路径匹配模式每次返回多个Resource实例（也就是Resource数组），并且它也新增了一种新的协议前缀classpath*:，该前缀表示可以加载多个jar包中相同的资源文件，而classpath:只能加载找到的第一个文件。 PathMatchingResourcePatternResolver除了支持ResourceLoader和ResourcePatternResolver新增的classpath*:前缀外，还支持Ant风格的路径匹配模式（类似于**/*.xml）。 Simple IoC实现目前自己实现的IoC容器中，只实现了文件系统的资源与加载抽象，以下为它们各自的类图： 快速使用我们可以尝试写一些简单的单元测试从文件系统中加载指定的资源，并对该资源做一些基本操作。首先，准备一个test.xml文件，然后编写以下测试方法：1234567891011121314@Testpublic void testFileSystemResource() throws IOException &#123; Resource resource = new FileSystemResource("C:\\Users\\canjie\\Desktop\\test.xml"); assertTrue(resource.exists()); assertEquals(resource.contentLength(), 992);&#125;@Testpublic void testFileSystemResourceLoader() throws IOException &#123; ResourceLoader resourceLoader = new FileSystemResourceLoader(); Resource resource = resourceLoader.getResource("C:\\Users\\canjie\\Desktop\\test.xml"); assertTrue(resource.exists()); assertEquals(resource.contentLength(), 992);&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[Mybatis之Mapper接口]]></title>
    <url>%2F2019%2F05%2F19%2FMybatis%E4%B9%8BMapper%E6%8E%A5%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[前言MyBatis有两种方式能和数据库打交道，一种是直接调用SqlSession的select()、update()等方法，传入statementId参数即可；另一种则是通过Mapper接口，这种方式在实际应用中更加常见，因为它使我们可以使用面向接口编程的方式操作数据库。 XML映射文件Mybatis将所有XML配置信息都封装到Configuration内部，在XML映射文件中： &lt;parameterMap&gt;标签，会被解析为ParameterMap对象，其每个子元素会被解析为ParameterMapping对象 &lt;resultMap&gt;标签，会被解析为ResultMap对象，其每个子元素会被解析为ResultMapping对象 每一个&lt;select&gt;、&lt;insert&gt;、&lt;update&gt;、&lt;delete&gt;标签，均会被解析为一个MappedStatement对象，标签内的SQL会被解析为一个BoundSql对象 Mapper接口在MyBatis中，Mapper接口是与XML映射文件相对应的，它们之间的对应关系如下： 接口的全限名，就是映射文件中的namespace的值 接口的方法名，就是映射文件中MappedStatement的id值 接口方法内的参数，就是传递给SQL的参数 当调用接口方法时，通过接口全限名+方法名可唯一定位一个对应的MappedStatement，MyBatis会使用JDK动态代理自动为该Mapper接口生成代理对象，而这个代理对象会拦截接口的方法，从而调用对应的MappedStatement方法，最终执行SQL语句并返回执行结果。 也正因为是全限名+方法名的保存和寻找策略，所以Mapper接口里的方法是不能重载的。 参考资料 精尽 MyBatis 面试题]]></content>
      <categories>
        <category>MyBatis</category>
      </categories>
      <tags>
        <tag>MyBatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入分析Spring MVC：请求处理流程]]></title>
    <url>%2F2019%2F05%2F19%2FSpring-MVC%EF%BC%9A%E8%AF%B7%E6%B1%82%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[处理流程 FrameworkServlet虽然在上面的整体流程图中，我们看到请求首先是被DispatcherServlet所处理，但是实际上，FrameworkServlet才是真正的入口：12345678910111213@Overrideprotected void service(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; // &lt;1&gt; 获得请求方法 HttpMethod httpMethod = HttpMethod.resolve(request.getMethod()); // &lt;2.1&gt; 处理 PATCH 请求 if (httpMethod == HttpMethod.PATCH || httpMethod == null) &#123; processRequest(request, response); // &lt;2.2&gt; 调用父类，处理其它请求 &#125; else &#123; super.service(request, response); &#125;&#125; 当不是PATCH请求时，会调用父类HttpServlet的service()方法，在这个方法中调用由子类FrameworkServlet实现的doGet()、doPost()、doPut()、doDelete()等各种方法上，而这些方法最终会调用processRequest()方法，处理请求： 12345678910111213// FrameworkServlet.javaprotected final void processRequest(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; // ... try &#123; doService(request, response); // 执行真正的逻辑 &#125; //...&#125;// 抽象方法，交由子类 DispatcherServlet 实现protected abstract void doService(HttpServletRequest request, HttpServletResponse response) throws Exception; DispatcherServletDispatcherServlet实现了FrameworkServlet的doService()方法，这个方法中会调用到doDispatch()执行请求的分发，而这个过程正是处理请求的核心逻辑，也对应着本文最开始的流程图：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; boolean multipartRequestParsed = false; WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); try &#123; ModelAndView mv = null; Exception dispatchException = null; try &#123; processedRequest = checkMultipart(request); multipartRequestParsed = (processedRequest != request); // 检查是否是上传请求 // 1. 获取可处理当前请求的处理器 mappedHandler = getHandler(processedRequest); if (mappedHandler == null) &#123; // 如果获取不到，则调用 noHandlerFound 根据配置抛出异常或返回 404 noHandlerFound(processedRequest, response); return; &#125; // 2. 获取可执行处理器逻辑的适配器 HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler()); String method = request.getMethod(); // 处理 last-modified 消息头 boolean isGet = "GET".equals(method); if (isGet || "HEAD".equals(method)) &#123; long lastModified = ha.getLastModified(request, mappedHandler.getHandler()); if (logger.isDebugEnabled()) &#123; logger.debug("Last-Modified value for [" + getRequestUri(request) + "] is: " + lastModified); &#125; if (new ServletWebRequest(request, response).checkNotModified(lastModified) &amp;&amp; isGet) &#123; return; &#125; &#125; // 执行拦截器 preHandle 方法 if (!mappedHandler.applyPreHandle(processedRequest, response)) &#123; return; &#125; // 3. 真正调用处理器逻辑（一般就是在这里调用我们的 Controller 方法） mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); if (asyncManager.isConcurrentHandlingStarted()) &#123; return; &#125; // 如果 controller 未返回 view 名称，这里生成默认的 view 名称 applyDefaultViewName(processedRequest, mv); // 执行拦截器 postHandle 方法 mappedHandler.applyPostHandle(processedRequest, response, mv); &#125; catch (Exception ex) &#123; dispatchException = ex; &#125; catch (Throwable err) &#123; // As of 4.3, we're processing Errors thrown from handler methods as well, // making them available for @ExceptionHandler methods and other scenarios. dispatchException = new NestedServletException("Handler dispatch failed", err); &#125; // 4. 解析并渲染视图 processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException); &#125; catch (Exception ex) &#123; triggerAfterCompletion(processedRequest, response, mappedHandler, ex); &#125; catch (Throwable err) &#123; triggerAfterCompletion(processedRequest, response, mappedHandler, new NestedServletException("Handler processing failed", err)); &#125; finally &#123; if (asyncManager.isConcurrentHandlingStarted()) &#123; // Instead of postHandle and afterCompletion if (mappedHandler != null) &#123; mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response); &#125; &#125; else &#123; // Clean up any resources used by a multipart request. if (multipartRequestParsed) &#123; // 如果是上传请求，清理资源 cleanupMultipart(processedRequest); &#125; &#125; &#125;&#125; 整个过程涉及以下几个核心组件： DispatcherServlet：请求入口，负责协调各个组件工作 HandlerMapping：内部维护了一些&lt;访问路径，处理器&gt;映射，负责为请求找到合适的处理器 HandlerAdapter：处理器的适配器。Spring中的处理器的实现多变，比如用户处理器可以实现Controller接口，也可以用@RequestMapping注解将方法作为一个处理器等，这就导致 Spring 不止到怎么调用用户的处理器逻辑。所以这里需要一个处理器适配器，由处理器适配器去调用处理器的逻辑 ViewResolver：根据视图名查找获得视图对象View View：视图对象用于将模板渲染成html或其他类型的文件。比如InternalResourceView可将jsp渲染成 html。 完整流程虽然像上面那样，但在目前主流的架构中，前后端已经彻底分离了，所以也就将View移交给了前端，上面的视图解析与渲染步骤已不再需要，而是当Handler（Controller）执行完后，判断方法是否有@ResponseBody注解，有的话则直接将结果写回给用户。但是由于HTTP是不支持返回Java POJO对象的，所以还需要将结果使用HttpMessageConverter进行转换后才能返回。 HandlerMapping根据请求获得相应的处理器和拦截器们（HandlerInterceptor数组 )，代码如下： 1234567891011121314151617// HandlerMapping.javapublic interface HandlerMapping &#123; String PATH_WITHIN_HANDLER_MAPPING_ATTRIBUTE = HandlerMapping.class.getName() + ".pathWithinHandlerMapping"; String BEST_MATCHING_PATTERN_ATTRIBUTE = HandlerMapping.class.getName() + ".bestMatchingPattern"; String INTROSPECT_TYPE_LEVEL_MAPPING = HandlerMapping.class.getName() + ".introspectTypeLevelMapping"; String URI_TEMPLATE_VARIABLES_ATTRIBUTE = HandlerMapping.class.getName() + ".uriTemplateVariables"; String MATRIX_VARIABLES_ATTRIBUTE = HandlerMapping.class.getName() + ".matrixVariables"; String PRODUCIBLE_MEDIA_TYPES_ATTRIBUTE = HandlerMapping.class.getName() + ".producibleMediaTypes"; /** * 获得请求对应的处理器和拦截器们 */ @Nullable HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception;&#125; 返回的对象类型是HandlerExecutionChain，它包含处理器（handler）和拦截器们（HandlerInterceptor数组），简单代码如下：12345678// HandlerExecutionChain.java/** 处理器 */private final Object handler;/** 拦截器数组 */@Nullableprivate HandlerInterceptor[] interceptors; 这里要注意的是处理器的类型是Object。 HandlerAdapter因为处理器handler的类型是Object类型，需要有一个调用者来实现handler是怎么被使用，怎么被执行，而HandlerAdapter的用途就在于此：12345678910111213public interface HandlerAdapter &#123; /** 是否支持该处理器 */ boolean supports(Object handler); /** 执行处理器，返回 ModelAndView 结果 */ @Nullable ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception; /** 返回请求的最新更新时间。如果不支持该操作，则返回 -1 即可 */ long getLastModified(HttpServletRequest request, Object handler);&#125; HandlerInterceptorHandlerInterceptor是Spring MVC中的拦截器接口，代码如下：123456789101112131415161718192021public interface HandlerInterceptor &#123; /** * 拦截处理器，在 &#123;@link HandlerAdapter#handle(HttpServletRequest, HttpServletResponse, Object)&#125; 执行之前 */ default boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; return true; &#125; /** * 拦截处理器，在 &#123;@link HandlerAdapter#handle(HttpServletRequest, HttpServletResponse, Object)&#125; 执行成功之后 */ default void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, @Nullable ModelAndView modelAndView) throws Exception &#123; &#125; /** * 拦截处理器，在 &#123;@link HandlerAdapter&#125; 执行完之后，无论成功还是失败， * 并且，只有 &#123;@link #preHandle(HttpServletRequest, HttpServletResponse, Object)&#125; 执行成功之后，才会被执行 */ default void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, @Nullable Exception ex) throws Exception &#123; &#125;&#125; 总结来说： preHandle()方法，按拦截器定义顺序调用，若任一拦截器返回false，则后面的拦截器不再执行，且Controller方法不再调用，处理请求流程结束 postHandle()方法，按拦截器定义逆序调用，在调用Controller方法成功之后执行 afterCompletion()方法，按拦截器定义逆序调用，只有该拦截器在preHandle()方法返回true，Controller方法执行完后才能够被调用（不管是否执行成功），且一定会被调用（过程中出现的异常仅会记录到日志中，不会打断下一个拦截器的afterCompletion()执行）。 HttpMessageConverter在Spring MVC中，可以使用@RequestBody和@ResponseBody两个注解，分别完成请求报文到对象和对象到响应报文的转换，底层这种灵活的消息转换机制就是通过HttpMessageConverter完成的。 我们知道，在Servlet标准中，可以用javax.servlet.ServletRequest接口中的以下方法：1public ServletInputStream getInputStream() throws IOException; 来得到一个ServletInputStream，从这个ServletInputStream中，可以读取到一个原始请求报文的所有内容。同样的，在javax.servlet.ServletResponse接口中，可以用以下方法：1public ServletOutputStream getOutputStream() throws IOException; 来得到一个ServletOutputStream，从这个ServletOutputSteam中，可以输出Http的响应报文内容。 当请求报文来到Java世界，它会被封装成为一个ServletInputStream的输入流，供我们读取报文，而响应报文则是通过一个ServletOutputStream的输出流，来输出响应报文。由于从输入流中只能读取到原始的字符串报文，同样，往输出流中也只能写原始的字符，但在处理业务逻辑时更多都是以一个个对象作为处理维度的，因此在SpringMVC中，由HttpMessageConverter完成这中间的一个转换工作： 123456789101112131415public interface HttpMessageConverter&lt;T&gt; &#123; boolean canRead(Class&lt;?&gt; clazz, MediaType mediaType); boolean canWrite(Class&lt;?&gt; clazz, MediaType mediaType); List&lt;MediaType&gt; getSupportedMediaTypes(); T read(Class&lt;? extends T&gt; clazz, HttpInputMessage inputMessage) throws IOException, HttpMessageNotReadableException; void write(T t, MediaType contentType, HttpOutputMessage outputMessage) throws IOException, HttpMessageNotWritableException;&#125; HttpMessageConverter接口的定义出现了成对的canRead()+read() 和canWrite()+write() 方法，而参数中的HttpInputMessage和HttpOutputMessage则分别是Spring MVC内部对Http请求报文和响应报文的抽象。下面通过一个例子解释消息转换的过程：1234@RequestMapping(value = "/string", method = RequestMethod.POST)public @ResponseBody String readString(@RequestBody String string) &#123; return "Read string '" + string + "'";&#125; 在SpringMVC进入readString(@RequestBody String string)方法前，会根据@RequestBody注解选择适当的HttpMessageConverter实现类来将请求参数解析到string变量中，具体来说是使用了StringHttpMessageConverter类，它的canRead()方法返回true，然后它的read()方法会从请求中读出请求参数，绑定到readString(@RequestBody String string)方法的string变量中。 当Spring MVC执行readString(@RequestBody String string)方法后，由于返回值标识了@ResponseBody注解，Spring MVC将使用StringHttpMessageConverter的write()方法，将结果作为String值写入响应报文，当然，此时canWrite()方法返回true。 RequestResponseBodyMethodProcessorRequestResponseBodyMethodProcessor同时实现了HandlerMethodArgumentResolver和HandlerMethodReturnValueHandler两个接口，前者是将请求报文绑定到处理方法形参的策略接口，后者则是对处理方法返回值进行处理的策略接口。 对HandlerMethodArgumentResolver接口的实现：12345678910111213141516171819202122// RequestResponseBodyMethodProcessor.javapublic boolean supportsParameter(MethodParameter parameter) &#123; return parameter.hasParameterAnnotation(RequestBody.class);&#125;public Object resolveArgument(MethodParameter parameter, ModelAndViewContainer mavContainer, NativeWebRequest webRequest, WebDataBinderFactory binderFactory) throws Exception &#123; Object argument = readWithMessageConverters(webRequest, parameter, parameter.getGenericParameterType()); String name = Conventions.getVariableNameForParameter(parameter); WebDataBinder binder = binderFactory.createBinder(webRequest, argument, name); if (argument != null) &#123; validate(binder, parameter); &#125; mavContainer.addAttribute(BindingResult.MODEL_KEY_PREFIX + name, binder.getBindingResult()); return argument;&#125; 对HandlerMethodReturnValueHandler接口的实现：123456789101112131415// RequestResponseBodyMethodProcessor.javapublic boolean supportsReturnType(MethodParameter returnType) &#123; return returnType.getMethodAnnotation(ResponseBody.class) != null;&#125;public void handleReturnValue(Object returnValue, MethodParameter returnType, ModelAndViewContainer mavContainer, NativeWebRequest webRequest) throws IOException, HttpMediaTypeNotAcceptableException &#123; mavContainer.setRequestHandled(true); if (returnValue != null) &#123; writeWithMessageConverters(returnValue, returnType, webRequest); &#125;&#125; 两个接口的实现，分别是以是否有@RequestBody和@ResponseBody为条件，然后分别调用HttpMessageConverter来进行消息的读写。 HandlerExceptionResolverSpring MVC提供了异常解析器HandlerExceptionResolver接口，将处理器执行时发生的异常，转换成对应的ModelAndView结果。代码如下：123456789public interface HandlerExceptionResolver &#123; /** * 解析异常，转换成对应的 ModelAndView 结果 */ @Nullable ModelAndView resolveException(HttpServletRequest request, HttpServletResponse response, @Nullable Object handler, Exception ex);&#125; 也就是说，如果异常被解析成功，则会返回ModelAndView对象。 参考资料 Spring MVC 原理探秘 - 一个请求的旅行过程 精尽 Spring MVC 源码分析 —— 请求处理一览]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring MVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入分析Spring MVC：WebApplicationContext容器初始化]]></title>
    <url>%2F2019%2F05%2F19%2FWebApplicationContext%E5%AE%B9%E5%99%A8%E5%88%9D%E5%A7%8B%E5%8C%96%2F</url>
    <content type="text"><![CDATA[web.xml123456789101112131415161718192021222324252627282930&lt;!-- 省略非关键的配置 --&gt;&lt;!-- [1] Spring配置 --&gt;&lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;&lt;/listener&gt;&lt;!-- 指定Spring Bean的配置文件所在目录，默认配置在WEB-INF目录下。该 &lt;context-param&gt; 标签会被设置到 ServletContext 中--&gt;&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:config/applicationContext.xml&lt;/param-value&gt;&lt;/context-param&gt;&lt;!-- ====================================== --&gt;&lt;!-- [2] Spring MVC配置 --&gt;&lt;servlet&gt; &lt;servlet-name&gt;spring&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!-- 可以自定义servlet.xml配置文件的位置和名称，默认为WEB-INF目录下，名称为[&lt;servlet-name&gt;]-servlet.xml，如spring-servlet.xml &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;/WEB-INF/spring-servlet.xml&lt;/param-value&gt; // 默认 &lt;/init-param&gt; --&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;spring&lt;/servlet-name&gt; &lt;url-pattern&gt;*.do&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; [1]处配置了org.springframework.web.context.ContextLoaderListener对象，它实现了javax.servlet.ServletContextListener接口，会初始化一个Root WebApplicationContext容器； [2]处配置了org.springframework.web.servlet.DispatcherServlet对象，它实现了javax.servlet.http.HttpServlet，除了拦截我们制定的*.do请求外，也会初始化一个属于它的 Servlet WebApplicationContext 容器，并且这个容器是以 [1] 处的 Root 容器作为父容器。 下面就以上两个容器进行分析，一个是业务容器，一个是Web容器。 Root WebApplicationContextRoot WebApplicationContext也就是业务容器，用于加载业务逻辑相关的类，比如service、dao层的一些类。它的初始化是通过ContextLoaderListener来实现，在Servlet容器启动时，例如Tomcat、Jetty启动，则会被ContextLoaderListener监听到，从而调用contextInitialized(ServletContextEvent event)方法，初始化Root WebApplicationContext容器。它的核心配置如下： 123456789&lt;!-- [1] Spring配置 --&gt;&lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;&lt;/listener&gt;&lt;!-- 指定Spring Bean的配置文件所在目录。默认配置在WEB-INF目录下 --&gt;&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:config/applicationContext.xml&lt;/param-value&gt;&lt;/context-param&gt; 如上，ContextLoaderListener可通过ServletContext获取到contextConfigLocation配置。这样，业务容器就可以加载application.xml配置文件了。 ContextLoaderListenerorg.springframework.web.context.ContextLoaderListener，实现ServletContextListener接口，继承ContextLoader类，上面说过，它实现了Servlet容器启动和关闭时，分别初始化和销毁WebApplicationContext容器。 对于ContextLoaderListener，它的初始化和销毁的真正逻辑其实是由父类ContextLoader实现的。 初始化WebApplicationContext容器： 1234567// ContextLoaderListener.java@Overridepublic void contextInitialized(ServletContextEvent event) &#123; // 初始化 WebApplicationContext，调用父类实现的方法 initWebApplicationContext(event.getServletContext());&#125; 销毁WebApplicationContext容器： 1234567// ContextLoaderListener.java@Overridepublic void contextDestroyed(ServletContextEvent event) &#123; closeWebApplicationContext(event.getServletContext()); ContextCleanupListener.cleanupAttributes(event.getServletContext());&#125; Servlet WebApplicationContextServlet WebApplicationContext也就是Web容器，它的初始化是在DispatcherServlet初始化的过程中执行，并且会将业务容器作为父容器，之所以这样是因为Web容器中的一些Bean会依赖于业务容器中的Bean，比如我们的controller层接口通常会依赖service层的业务逻辑类。 以下是这个继承体系中各个类负责的任务，结构还是比较清晰的： HttpServletBean：覆写了父类HttpServlet中的init()方法，是创建Web容器的入口，负责将ServletConfig设置到HttpServletBean的子类对象中（比如DispatcherServlet）。类上的简单注释如下： 1234567// HttpServletBean.java/** * Simple extension of &#123;@link javax.servlet.http.HttpServlet&#125; which treats * its config parameters (&#123;@code init-param&#125; entries within the * &#123;@code servlet&#125; tag in &#123;@code web.xml&#125;) as bean properties. */ FrameworkServlet：覆写了父类HttpServletBean中的initServletBean()方法，负责初始化Servlet WebApplicationContext容器。类上的简单注释如下： 123456// FrameworkServlet.java/** * Base servlet for Spring's web framework. Provides integration with * a Spring application context, in a JavaBean-based overall solution. */ DispatcherServlet：负责初始化Spring MVC的各个组件，以及处理客户端的请求。类上的简单注释如下： 1234567// DispatcherServlet.java/** * Central dispatcher for HTTP request handlers/controllers, e.g. for web UI controllers * or HTTP-based remote service exporters. Dispatches to registered handlers for processing * a web request, providing convenient mapping and exception handling facilities. */ 参考资料 精尽 Spring MVC 源码分析 —— 容器的初始化（一）之 Root WebApplicationContext 容器 精尽 Spring MVC 源码分析 —— 容器的初始化（二）之 Servlet WebApplicationContext 容器 Spring MVC 原理探秘 - 容器的创建过程)]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring MVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MyBatis插件机制]]></title>
    <url>%2F2019%2F05%2F17%2FMyBatis%E6%8F%92%E4%BB%B6%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[前言插件增加了框架的灵活性，使得我们可以根据需要自行对功能进行拓展。在MyBatis中，插件就类似于拦截器，通过拦截相应的方法从而执行插件逻辑。MyBatis所允许拦截的接口与方法如下： Executor ParameterHandler ResultSetHandler StatementHandler 插件配置如果我们要实现一个插件，比如我们想要拦截Executor的query方法，那么可以这样定义插件：123456789101112@Intercepts(&#123; @Signature( type = Executor.class, method = "query", args =&#123;MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class&#125; ), @Signature(...), @Signature(...)&#125;)public class ExamplePlugin implements Interceptor &#123; // 省略逻辑&#125; 这里的注解是必须的，@Intercepts注解装载一个@Signature列表，一个@Signature其实就是一个需要拦截的方法封装。那么，当一个拦截器要拦截多个方法，自然就是一个@Signature列表。 除此之外，我们还需将插件配置到相关文件中，这样MyBatis在启动时可以加载插件，并保存插件实例到拦截器链InterceptorChain中。待准备工作做完后，MyBatis处于就绪状态。我们在执行SQL时，需要先通过DefaultSqlSessionFactory创建SqlSession。Executor实例会在创建SqlSession的过程中被创建，Executor实例创建完毕后，MyBatis会通过JDK动态代理为实例生成代理类。这样，插件逻辑即可在Executor相关方法被调用前执行。配置示例如下：123456789&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN" "http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;&lt;configuration&gt; &lt;plugins&gt; &lt;plugin interceptor="com.mybatis3.interceptor.ExamplePlugin"&gt; // ... &lt;/plugin&gt; &lt;/plugins&gt;&lt;/configuration&gt; 注册插件Executor实例是在开启SqlSession时被创建的，Executor的创建过程封装在Configuration中，注册插件也正是这个时候：12345678910111213141516171819public Executor newExecutor(Transaction transaction, ExecutorType executorType) &#123; executorType = executorType == null ? defaultExecutorType : executorType; executorType = executorType == null ? ExecutorType.SIMPLE : executorType; Executor executor; // 根据 executorType 创建相应的 Executor 实例 if (ExecutorType.BATCH == executorType) &#123;...&#125; else if (ExecutorType.REUSE == executorType) &#123;...&#125; else &#123; executor = new SimpleExecutor(this, transaction); &#125; if (cacheEnabled) &#123; executor = new CachingExecutor(executor); &#125; // 注册插件 executor = (Executor) interceptorChain.pluginAll(executor); return executor;&#125; 在上面创建好Executor后，紧接着通过拦截器链interceptorChain为Executor实例注册代理逻辑（注意是注册而非执行）：123456789101112131415public class InterceptorChain &#123; private final List&lt;Interceptor&gt; interceptors = new ArrayList&lt;&gt;(); public Object pluginAll(Object target) &#123; // 遍历拦截器集合 for (Interceptor interceptor : interceptors) &#123; // 调用拦截器的 plugin 方法植入相应的插件逻辑 target = interceptor.plugin(target); &#125; return target; &#125; // ... &#125; 它的pluginAll()方法会调用具体插件的plugin()方法注册相应的插件逻辑。如果有多个插件，则会多次调用plugin()方法，最终生成一个层层嵌套的代理类。plugin()方法是由具体的插件类实现，以下是一个示例：12345678910111213141516171819202122232425262728293031323334353637@Intercepts(&#123;&#125;)public class ExamplePlugin implements Interceptor &#123; private Properties properties; @Override public Object intercept(Invocation invocation) throws Throwable &#123; return invocation.proceed(); &#125; @Override public Object plugin(Object target) &#123; return Plugin.wrap(target, this); &#125; // ...&#125;public class Plugin implements InvocationHandler &#123; public static Object wrap(Object target, Interceptor interceptor) &#123; // 获取插件类 @Signature 注解内容 Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; signatureMap = getSignatureMap(interceptor); Class&lt;?&gt; type = target.getClass(); // 获取目标类实现的接口 Class&lt;?&gt;[] interfaces = getAllInterfaces(type, signatureMap); if (interfaces.length &gt; 0) &#123; // 通过 JDK 动态代理为目标类生成代理类 return Proxy.newProxyInstance( type.getClassLoader(), interfaces, new Plugin(target, interceptor, signatureMap)); &#125; return target; &#125; // ...&#125; 如上，plugin方法在内部调用了Plugin类的wrap()方法，用于为目标对象生成代理。Plugin类实现了InvocationHandler接口，因此它可以作为参数传给Proxy的newProxyInstance()方法。 执行插件在上面注册插件的过程中，我们在wrap()方法中看到了如下代码，它传入了一个Plugin对象作为参数：12345// 通过 JDK 动态代理为目标类生成代理类return Proxy.newProxyInstance( type.getClassLoader(), interfaces, new Plugin(target, interceptor, signatureMap)); Plugin实现了InvocationHandler接口，因此它的invoke()方法会拦截所有的方法调用。invoke()方法会对所拦截的方法进行检测，以决定是否执行插件逻辑。该方法的逻辑如下：12345678910111213141516171819202122232425262728public class Plugin implements InvocationHandler &#123; private final Object target; private final Interceptor interceptor; private final Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; signatureMap; // ... @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; try &#123; // 获取被拦截方法列表 Set&lt;Method&gt; methods = signatureMap.get(method.getDeclaringClass()); // 检测方法列表是否包含当前被拦截的方法 if (methods != null &amp;&amp; methods.contains(method)) &#123; // 执行插件逻辑，在 ExamplePlugin 实现中仅仅为执行被拦截的方法 return interceptor.intercept(new Invocation(target, method, args)); &#125; // 执行被拦截的方法 return method.invoke(target, args); &#125; catch (Exception e) &#123; throw ExceptionUtil.unwrapThrowable(e); &#125; &#125; // ... &#125; 参考资料 MyBatis 源码分析 - 插件机制 Mybatis3.4.x技术内幕（十九）：Mybatis之plugin插件设计原理]]></content>
      <categories>
        <category>MyBatis</category>
      </categories>
      <tags>
        <tag>MyBatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MyBatis缓存机制]]></title>
    <url>%2F2019%2F05%2F17%2FMyBatis%E7%BC%93%E5%AD%98%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[前言缓存机制是MyBatis的一大特性，它分为一级和二级缓存，其中一级缓存是SqlSession级别的缓存，其实现较为简单，而二级缓存是mapper级别的缓存，并且多个SqlSession之间可以共享。 一级缓存每当我们使用MyBatis开启一次和数据库的会话，MyBatis会创建出一个SqlSession对象表示一次数据库会话，对于这种会话级别的数据缓存，我们就称之为一级缓存。通过一级缓存，每次查询时都将结果缓存起来，当下次查询的时候，如果判断先前有个完全一样的查询，会从缓存中直接将结果取出，返回给用户，不需要再进行一次数据库查询了。 我们知道，SqlSession只是一个MyBatis对外的接口，SqlSession将它的工作交给了Executor执行器这个角色来完成，负责完成对数据库的各种操作。当创建了一个SqlSession对象时，MyBatis会为这个SqlSession对象创建一个新的Executor执行器，而缓存信息就被维护在这个Executor执行器中，MyBatis将缓存和对缓存相关的操作封装到了Cache接口中。 PerpetualCacheExecutor接口的实现类BaseExecutor中拥有一个Cache接口的实现类PerpetualCache，则对于BaseExecutor对象而言，它将使用PerpetualCache对象维护缓存，下面看一下它的源码：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class PerpetualCache implements Cache &#123; private String id; private Map&lt;Object, Object&gt; cache = new HashMap&lt;Object, Object&gt;(); public PerpetualCache(String id) &#123; this.id = id; &#125; public String getId() &#123; return id; &#125; public int getSize() &#123; return cache.size(); &#125; public void putObject(Object key, Object value) &#123; cache.put(key, value); &#125; public Object getObject(Object key) &#123; return cache.get(key); &#125; public Object removeObject(Object key) &#123; return cache.remove(key); &#125; public void clear() &#123; cache.clear(); &#125; public ReadWriteLock getReadWriteLock() &#123; return null; &#125; public boolean equals(Object o) &#123; if (getId() == null) throw new CacheException("Cache instances require an ID."); if (this == o) return true; if (!(o instanceof Cache)) return false; Cache otherCache = (Cache) o; return getId().equals(otherCache.getId()); &#125; public int hashCode() &#123; if (getId() == null) throw new CacheException("Cache instances require an ID."); return getId().hashCode(); &#125; &#125; 可以看出，PerpetualCache实现原理其实很简单，其内部就是通过一个简单的HashMap来实现的，没有其他的任何限制。 生命周期关于一级缓存的生命周期，有以下几条规则： MyBatis在开启一个数据库会话时，会创建一个新的SqlSession对象，SqlSession对象中会有一个新的Executor对象，Executor对象中持有一个新的PerpetualCache对象；当会话结束时，SqlSession对象及其内部的Executor对象还有PerpetualCache对象也一并释放掉。 如果SqlSession调用了close()方法，会释放掉一级缓存PerpetualCache对象，一级缓存将不可用； 如果SqlSession调用了clearCache()，会清空PerpetualCache对象中的数据，但是该对象仍可使用； SqlSession中执行了任何一个update操作(update()、delete()、insert()) ，都会清空PerpetualCache对象的数据，但是该对象可以继续使用； 工作流程 对于某个查询，会构建一个key值，根据这个key值去缓存Cache中取出对应的缓存结果 判断从Cache中根据特定的key值取的数据是否为空，即是否命中 如果命中，则直接将缓存结果返回 如果没命中： 4.1 去数据库中查询数据，得到查询结果 4.2 将key和查询到的结果分别作为key-value对存储到Cache中 4.3. 将查询结果返回 结束 CacheKey在上面的工作流程中已经看到，Cache中的Map是根据一个key来查询缓存的，这个key的决定因素具体如下： 传入的statementId （比如为com.xxx.mapper.selectUserName） 查询时要求的结果集中的结果范围 （结果的范围通过rowBounds.offset和rowBounds.limit表示） 这次查询所产生的最终要传递给JDBC Preparedstatement的SQL语句（boundSql.getSql()） 要设置的参数值（只用这个SQL语句所需要的参数） 因此，CacheKey其实就是由statementId + rowBounds + 传递给JDBC的SQL + 传递给JDBC的参数值这四个条件并生成哈希构建而成的。MyBatis认为，对于两次查询，只要构建出的CacheKey一样，就认为它们是完全相同的查询，也就可以根据这个CacheKey去缓存中查找已有的缓存结果。 注意事项MyBatis的一级缓存就是简单的使用了HashMap，MyBatis只负责将查询数据库的结果存储到缓存中去，不会去判断缓存存放的时间是否过长、是否过期，并且也没有对缓存的大小进行限制，因此对于准确性要求比较高的数据来说，要控制好SqlSession的生存时间，其生存时间越长，它缓存的数据有可能就越旧，从而造成与真实数据库的误差较大。 二级缓存当开一个会话时，一个SqlSession对象会使用一个Executor对象来完成会话操作，MyBatis的二级缓存机制的关键就是对这个Executor对象做文章。如果用户配置了cacheEnabled=true，那么MyBatis在为SqlSession对象创建Executor对象时，会对Executor对象加上一个装饰者：CachingExecutor，这时SqlSession使用CachingExecutor对象来完成操作请求。CachingExecutor对于查询请求，会先判断该查询请求在二级缓存中是否有缓存结果，如果有缓存结果，则直接返回该结果；如果缓存中没有，再交给真正的Executor对象来完成查询操作，之后CachingExecutor会将真正Executor返回的查询结果放置到缓存中，然后在返回给用户。 缓存粒度MyBatis并不是简单地对整个Application就只有一个Cache缓存对象，它将缓存划分的更细，即是Mapper级别的，每一个Mapper都可以拥有一个Cache对象，具体如下： 为每一个Mapper分配一个Cache缓存对象（使用&lt;cache&gt;节点配置） 多个Mapper共用一个Cache缓存对象（使用&lt;cache-ref&gt;节点配置） 使用条件虽然在Mapper中配置了&lt;cache&gt;，并且为此Mapper分配了Cache对象，这并不表示我们使用Mapper中定义的查询语句查到的结果都会放置到Cache对象之中，我们必须指定Mapper中的某条选择语句是否支持缓存，即在&lt;select&gt;节点中配置useCache=&quot;true&quot;，如 &lt;select id=&quot;selectByMinSalary&quot; resultMap=&quot;BaseResultMap&quot; parameterType=&quot;java.util.Map&quot; useCache=&quot;true&quot;&gt; ，Mapper才会对此Select的查询支持缓存特性。 总结来说，要想使某条select查询支持二级缓存，需要保证： MyBatis支持二级缓存的总开关：全局配置变量参数cacheEnabled=true 该select语句所在的Mapper，配置了&lt;cache&gt;或&lt;cached-ref&gt;节点，并且有效 该select语句的参数useCache=true 二级缓存实现的选择MyBatis对二级缓存的设计非常灵活，它自己内部实现了一系列的Cache缓存实现类，有大量的Cache的装饰器来增强Cache缓存的功能。另外，MyBatis还允许用户自定义Cache接口实现，用户只需要实现org.apache.ibatis.cache.Cache接口，然后将Cache实现类配置在&lt;cache type=&quot;&quot;&gt;节点的type属性上即可。除此之外，MyBatis还支持跟第三方内存缓存库如Memecached的集成。总之，使用MyBatis的二级缓存有三个选择: MyBatis自身提供的缓存实现 用户自定义的Cache接口实现 跟第三方内存缓存库的集成 参考资料 《深入理解mybatis原理》 MyBatis的一级缓存实现详解 及使用注意事项 《深入理解mybatis原理》 MyBatis的二级缓存的设计原理]]></content>
      <categories>
        <category>MyBatis</category>
      </categories>
      <tags>
        <tag>MyBatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MyBatis之#{}和${}的区别]]></title>
    <url>%2F2019%2F05%2F16%2FMyBatis%E4%B9%8B-%E5%92%8C-%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[前言动态SQL是MyBatis的强大特性之一，我们在使用MyBatis作为持久层框架时，经常需要动态传递参数，例如我们需要根据用户的姓名来筛选用户时，SQL如下：1select * from user where name = "Lihua"; 上述SQL中，我们希望name是动态可变的，即不同的时刻根据不同的姓名来查询用户，那么在MyBatis的xml中可以如下配置：1select * from user where name = #&#123;name&#125;; 或者1select * from user where name = '$&#123;name&#125;'; 这两种方式的本质是不同的，如果不了解其原理，在某些场景下会导致意想不到的后果。 区别MyBatis在对SQL语句进行预编译之前，会对SQL进行动态解析，解析为一个BoundSql对象，也正是在这个阶段#{}和${}会有不同的表现。 #{}在动态SQL解析阶段，#{}解析为一个JDBC预编译（PreparedStatement）的参数标记符。例如，如下的SQL语句：1select * from user where name = #&#123;name&#125;; 会被解析为：1select * from user where name = ?; 也就是说，一个#{}被解析为一个参数占位符?。 ${}在动态SQL解析阶段，${}仅仅为一个纯粹的字符串替换。例如，如下的SQL语句：1select * from user where name = '$&#123;name&#125;'; 当我们传递的参数为Lihua时，上述SQL解析为：1select * from user where name = "Lihua"; 也就是说，预编译前的SQL语句已经不包含变量name了。 总结对于#{}，它其实就对应着JDBC中的PreparedStatement的?，因此一旦MySQL服务器对SQL模板进行了编译，并且存储了函数，PreparedStatement做的就是把参数进行转义后直接传入参数到数据库，然后让函数执行，也就避免了SQL注入的问题；而${}的变量替换是在动态SQL解析阶段，也就是预编译之前，相当于这个SQL语句已经是个常量了，因此会产生SQL注入的问题。 参考资料 mybatis深入理解(一)之 # 与 $ 区别以及 sql 预编译]]></content>
      <categories>
        <category>MyBatis</category>
      </categories>
      <tags>
        <tag>MyBatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MyBatis架构设计]]></title>
    <url>%2F2019%2F05%2F16%2FMyBatis%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[整体架构 MyBatis和数据库交互有两种方式： 使用传统的MyBatis提供的API：传递Statement Id和查询参数给SqlSession对象，使用SqlSession对象完成和数据库的交互： 使用Mapper接口：MyBatis将配置文件中的每一个&lt;mapper&gt;节点抽象为一个Mapper接口，而这个接口中声明的方法和&lt;mapper&gt;节点中的&lt;select | update | delete | insert&gt;节点项对应，即select | update | delete | insert节点的id值为Mapper接口中的方法名称，parameterType值表示Mapper对应方法的入参类型，而resultMap值则对应了Mapper接口表示的返回值类型： 使用Mapper接口的方式并配置好相关信息后，通过SqlSession.getMapper(XXXMapper.class)方法，MyBatis会根据相应的接口声明的方法信息，通过动态代理机制生成一个Mapper实例，我们使用Mapper接口的某一个方法时，MyBatis会根据这个方法的方法名，确定Statement Id，底层还是通过SqlSession.select(&quot;statementId&quot;,parameterObject);或者SqlSession.update(&quot;statementId&quot;,parameterObject);等等来实现对数据库的操作。 主要构件从MyBatis代码实现的角度来看，MyBatis的主要的核心部件有以下几个： SqlSession：作为MyBatis工作的主要顶层API，表示和数据库交互的会话，完成必要数据库增删改查功能 Executor：MyBatis执行器，是MyBatis调度的核心，负责SQL语句的生成和查询缓存的维护 StatementHandler：封装了JDBC Statement操作，负责对JDBC Statement的操作，如设置参数、将Statement结果集转换成List集合 ParameterHandler：负责对用户传递的参数转换成JDBC Statement所需要的参数 ResultSetHandler：负责将JDBC返回的ResultSet结果集对象转换成List类型的集合 TypeHandler：负责java数据类型和jdbc数据类型之间的映射和转换 MappedStatement：MappedStatement维护了一条&lt;select | update | delete | insert&gt;节点的封装 SqlSource：负责根据用户传递的parameterObject，动态地生成SQL语句，将信息封装到BoundSql对象中，并返回 BoundSql：表示动态生成的SQL语句以及相应的参数信息 Configuration：MyBatis所有的配置信息都维持在Configuration对象之中。 它们的关系如下图所示： 参考资料 《深入理解mybatis原理》 MyBatis的架构设计以及实例分析]]></content>
      <categories>
        <category>MyBatis</category>
      </categories>
      <tags>
        <tag>MyBatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDBC：PreparedStatement和Statement]]></title>
    <url>%2F2019%2F05%2F16%2FJDBC%EF%BC%9APreparedStatement%E5%92%8CStatement%2F</url>
    <content type="text"><![CDATA[MySQL支持预编译在不使用预编译时，客户端每发送一条sql语句给服务器后，服务器总是需要校验sql语句的语法格式是否正确，然后把sql语句编译成可执行函数，最后才是执行sql语句。其中，校验语法和编译所花的时间可能比执行sql语句花的时间还要多。因此，如果我们需要执行多次insert语句，但每次只是插入的值不同，MySQL都要校验语法和编译，会浪费许多时间，而如果使用预编译功能，那么就只用对sql语句进行一次语法校验和编译，所以效率要高。 MySQL本身是支持预编译的，MySQL执行预编译分为如下三步： 执行预编译语句，例如：prepare myFunc from &#39;select * from user where username like ?&#39; 设置变量，例如：set @username=&#39;%小明%&#39; 执行语句，例如：execute myFunc using @username 如果需要再次执行myFunc，那就不再需要第一步，即不需要再编译语句了： 设置变量，例如：set @username=&#39;%小宋%&#39; 执行语句，例如：execute myFunc using @username PreparedStatement使用预编译JDBC的PreparedStatement接口是有预编译功能的，但是在JDBC MySQL驱动5.0.5以后的版本默认是关闭预编译功能的，因此如果我们不手动开启的话，其实并没有使用到预编译，只是用到了防止sql注入的功能。要开启预编译功能，我们需要设置MySQL连接URL参数：useServerPrepStmts=true，这样才能保证MySQL驱动会先把sql语句发送给服务器进行预编译，然后在执行executeQuery()时只是把参数发送给服务器。 注意：通过设置MySQL连接参数，目的是告诉MySQLPreparedStatement使用预编译功能，但不管我们是否使用预编译功能，MySQL Server4.1版本以后都是支持预编译功能的。 当使用不同的PreparedStatement对象来执行相同的sql语句时，还是会出现编译两次的现象，这是因为驱动没有缓存编译后的函数key，导致二次编译。但在实际的应用场景中，我们不可能保持同一个PreparedStatement，此时如果希望缓存编译后的函数的key，那么就要设置MySQL连接参数cachePrepStmts=true。 在持久层框架中存在的问题很多主流持久层框架其实都没有真正的用上预编译，预编译是要我们自己在连接参数上配置的。 总结 MySQL主流版本是支持预编译的，但PremaredStatement在JDBC MySQL驱动5.0.5以后需要手动配置连接参数才可以使用预编译功能，如果同时也开启了缓存，那么MySQL服务器是会缓存编译后的函数，而编译后的函数key缓存在PreparedStatement中，此时不同的PreparedStatement执行相同的sql语句时不会重复编译，也就提高了效率。 Statement对于MySQL数据库是不会对编译后的函数进行缓存的，数据库不会缓存函数，Statement也不会缓存函数的key，所以多次执行相同的sql语句时，还是会先检查sql语句语法是否正确，然后编译sql语句成函数，最后执行函数。 因为PreparedStatement已经对sql模板进行了编译，并且存储了函数，所以PreparedStatement做的就是把参数进行转义后直接传入参数到数据库，然后让函数执行，这也就是为什么PreparedStatement能够防止sql注入攻击的原因。 PreparedStatement还有一点要注意的是，在数据库端存储的函数和PreparedStatement中存储的函数key，都是建立在数据库连接的基础上的，如果当前数据库连接断开了，数据库端的函数会清空，建立在连接上的PreparedStatement里面的函数key也会被清空。 参考资料 JDBC：深入理解PreparedStatement和Statement 探究mysql预编译]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>PreparedStatement</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java线程池源码分析]]></title>
    <url>%2F2019%2F05%2F12%2FJava%E7%BA%BF%E7%A8%8B%E6%B1%A0%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[前言在Java中实现异步任务的处理，我们通常会使用Executor框架，而它的子类ThreadPoolExecutor则提供了线程池的实现，避免了线程频繁创建与销毁所带来的性能开销，为线程做了统一的管理与监控。因此，本文将从Executor接口开始逐层向下分析，重点关注ThreadPoolExecutor，这也是我们平时使用最多的一个类，深入理解它的原理还是很重要的。 继承体系Executor接口位于整个体系的最顶层，它只包含一个execute()方法；ExecutorService也是接口，它在Executor接口的基础上添加了很多的接口方法，所以一般我们会使用这个接口；AbstractExecutorService是抽象类，实现了部分的方法，而把其它一些核心方法交给了子类去实现；ThreadPoolExecutor是最核心的一个类，它真正的实现了线程池的相关功能，是重点需要分析的一个类；ScheduledExecutorService是定时任务相关的接口，本文不会去分析该类。 除此之外，该体系还涉及一个Executors工具类，它提供了很多创建线程池的静态方法，为我们省去了创建线程池时需要关心的参数细节。 Executor接口123public interface Executor &#123; void execute(Runnable command);&#125; Executor接口非常简单，只有一个execute()方法，用来提交一个任务去执行。注意参数是Runnable类型的，表示一个任务。 ExecutorService由于Executor接口只有提交任务的功能，我们更多使用的是ExecutorService，它定义的方法比较丰富，大部分情况下已经能满足我们的需求了。例如 ：12ExecutorService executor = Executors.newFixedThreadPool(args...);ExecutorService executor = Executors.newCachedThreadPool(args...); 下面看看它的源码：1234567891011121314151617181920212223242526272829public interface ExecutorService extends Executor &#123; // 关闭线程池：停止接受外部提交的新任务，而等到正在执行的任务以及队列中等待的任务执行完才真正关闭 void shutdown(); // 关闭线程池：停止接受外部提交的新任务，忽略队列里等待的任务，尝试将正在跑的任务中断，然后返回未执行的任务列表 List&lt;Runnable&gt; shutdownNow(); // 线程池是否关闭 boolean isShutdown(); // 如果调用了 shutdown() 或 shutdownNow() 方法后，所有任务结束了，那么返回 true // 这个方法必须在调用 shutdown() 或 shutdownNow() 方法之后调用才会返回 true boolean isTerminated(); // 关闭线程池后等待所有任务完成，并设置超时时间：调用 shutdown() 或 shutdownNow() 方法后，调用该方法阻塞直到所有任务执行完毕或发生了超时，返回 false 表示发生了超时 boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; // 提交一个 Callable 任务，返回一个 Future &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); // 提交一个 Runnable 任务，返回一个 Future，第二个参数会放到 Future 中作为返回值 &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); // 提交一个 Runnable 任务 Future&lt;?&gt; submit(Runnable task); // ...&#125; 可以看出，这个接口提供了大部分我们需要的功能，一些不太常用的如invokeAll()、invokeAny()等上面将其省略了，不进行分析。 AbstractExecutorServiceAbstractExecutorService抽象类实现了几个实用的方法：1234567891011121314151617181920212223242526272829303132333435public abstract class AbstractExecutorService implements ExecutorService &#123; protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) &#123; // 将 Runnable 包装成 FutureTask，内部其实会通过 Executors#callable 方法将这个 Runnable 转换成 Callable return new FutureTask&lt;T&gt;(runnable, value); &#125; protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Callable&lt;T&gt; callable) &#123; return new FutureTask&lt;T&gt;(callable); &#125; // 提交任务，和 execute() 不同的是这个会返回一个 Future public Future&lt;?&gt; submit(Runnable task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null); // 将 Runnable 包装成 FutureTask execute(ftask); // 执行这个任务，execute() 方法交由子类实现，FutureTask 间接实现了 Runnable 接口 return ftask; &#125; public &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task, result); // 将 Runnable 包装成 FutureTask execute(ftask); // 执行这个任务，execute() 方法交由子类实现，FutureTask 间接实现了 Runnable 接口 return ftask; &#125; public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task); // 将Callable 包装成 FutureTask execute(ftask); // 执行这个任务，execute() 方法交由子类实现，FutureTask 间接实现了 Runnable 接口 return ftask; &#125; // ...&#125; 这个抽象类封装了一些基本的方法如submit()，但是都没有真正开启线程来执行任务，它们都只是在方法内部调用了execute()方法，而将该方法交由子类去实现。 ThreadPoolExecutorThreadPoolExecutor是JDK中的线程池实现，这个类实现了一个线程池需要的各个方法，比如任务提交、线程管理、监控等等。关于这个方法内容比较多，因此将会拆开来分析。 核心参数我们先看看该类的构造函数： 123456789public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; // ...&#125; 核心参数的作用分别如下： corePoolSize：核心线程数，当线程数小于该值时，线程池会创建新线程来执行新任务 maximumPoolSize：线程池允许创建的最大线程数 keepAliveTime：空闲线程的存活时间，但要注意这个值不会对所有线程起作用，如果线程池中的线程数少于等于核心线程数corePoolSize，那么这些线程不会因为空闲太长时间而被关闭，但也可以通过调用allowCoreThreadTimeOut(true)使核心线程数内的线程也可以被回收。 workQueue：任务队列，用来存储未执行的任务，是BlockingQueue接口的某个实现 threadFactory：线程工厂，可通过工厂为新建的线程设置更有意义的名字 handler：拒绝策略，当线程池和任务队列均处于饱和状态时该使用的处理方式，默认为抛出异常 线程池状态ThreadPoolExecutor采用一个32位的整数来存放线程池的状态和当前池中的线程数，其中高3位用于存放线程池状态，低29位表示线程数。123456789101112131415161718192021/** 状态控制变量，该变量用于表示线程池的状态和线程数 */private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));/** 该方法用于组合线程池的状态和线程数，通过按位或的方式 */private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125;/** 就是29 */private static final int COUNT_BITS = Integer.SIZE - 3;/** 线程池的最大线程数，也就是（2^29-1）：000 11111111111111111111111111111 */private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1;// 线程池的状态存放在高3位中private static final int RUNNING = -1 &lt;&lt; COUNT_BITS; // 111 0000...private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS; // 000 0000...，对应 shutdown()private static final int STOP = 1 &lt;&lt; COUNT_BITS; // 001 0000...，对应 shutdownNow()private static final int TIDYING = 2 &lt;&lt; COUNT_BITS; // 010 0000...private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; // 011 0000...// 获取线程池的运行状态，~运算符i会将0、1取反private static int runStateOf(int c) &#123; return c &amp; ~CAPACITY; &#125;// 获取线程池中的线程数private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; &#125; 这里面的状态还是比较清晰的，并且状态值是顺序递增的。RUNNING表示线程池的初始状态，而SHUTDOWN和STOP分别是调用了shutdown()和shutdownNow()方法后进入的状态，其中在tryTerminate()方法中转换成TIDYING状态，表示在SHUTDOWN / STOP后任务队列和线程池都清空了，此时执行钩子方法terminated()，而当terminated()方法结束后，线程池的状态就会变为TERMINATED。 WorkerWorker是ThreadPoolExecutor的内部类，用于封装线程池中的工作线程，也就是用来执行任务的，而任务是Runnable（内部变量名叫task或command）。要注意的是，该类继承了AQS，用于实现一个简单的互斥锁。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960private final class Worker extends AbstractQueuedSynchronizer implements Runnable &#123; // 工作线程，用来执行任务的 final Thread thread; // 初始任务 Runnable firstTask; // 存放此线程完成的任务数 volatile long completedTasks; Worker(Runnable firstTask) &#123; setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); // 通过构造线程池时传入的线程工厂来创建一个新线程 &#125; public void run() &#123; // 调用了外部的 runWorker() 方法 runWorker(this); &#125; // 以下为AQS相关的方法： // 0 表示解锁状态 // 1 表示加锁状态 protected boolean isHeldExclusively() &#123; return getState() != 0; &#125; protected boolean tryAcquire(int unused) &#123; if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; protected boolean tryRelease(int unused) &#123; setExclusiveOwnerThread(null); setState(0); return true; &#125; public void lock() &#123; acquire(1); &#125; public boolean tryLock() &#123; return tryAcquire(1); &#125; public void unlock() &#123; release(1); &#125; public boolean isLocked() &#123; return isHeldExclusively(); &#125; void interruptIfStarted() &#123; Thread t; if (getState() &gt;= 0 &amp;&amp; (t = thread) != null &amp;&amp; !t.isInterrupted()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; &#125; &#125;&#125; runWorkerWorker实现了Runnable接口，并将run()方法的实现委托给了外部类ThreadPoolExecutor的runWorker()方法，这个方法就是不断的从任务队列中拿取任务运行：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; // help GC w.unlock(); // allow interrupts boolean completedAbruptly = true; // 用于标记完成任务时是否有异常 try &#123; // 循环：初始任务（首次）或者从阻塞队列中拿一个（后续） // 这也体现了线程池的意义，工作线程在执行完一个任务后，会再次到任务队列中获取新的任务，实现了”线程复用“ while (task != null || (task = getTask()) != null) &#123; // 获取互斥锁，在获取互斥锁时，调用 shutdown() 方法不会中断线程，但是 shutdownNow() 方法无视互斥锁，会中断所有线程 w.lock(); // 判断是否需要中断当前线程。如果线程池的状态 &gt;= STOP ，当前线程未中断，则中断当前线程，否则清除线程中断位 if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; // 交由子类实现的前置处理钩子 beforeExecute(wt, task); Throwable thrown = null; try &#123; // 真正的执行任务 task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; // 交由子类实现的后置处理钩子 afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; w.completedTasks++; // 该 Worker 完成的任务数加一 w.unlock(); &#125; &#125; // while 循环之外 completedAbruptly = false; &#125; finally &#123; processWorkerExit(w, completedAbruptly); // 处理工作线程退出 &#125;&#125; getTask在runWorker()方法中，会尝试通过阻塞队列获取任务来执行，而这个获取任务的逻辑则封装到了getTask()这个核心方法中。在以下几种情况会返回null从而接下来线程退出（runWorker()方法中的循环结束）： 当前工作线程数超过了maximumPoolSize（由于maximumPoolSize可以动态调整，这是可能的） 线程池状态为STOP（因为STOP状态不处理阻塞队列中的任务了） 线程池状态为SHUTDOWN，但阻塞队列为空 线程数量大于corePoolSize或allowCoreThreadTimeOut设置为true，当线程空闲时间超过keepAliveTime（这里说的空闲时间其实就是poll()方法阻塞在队列上的时间） 1234567891011121314151617181920212223242526272829303132333435363738394041424344private Runnable getTask() &#123; // 上次从阻塞队列 poll 任务时是否超时 boolean timedOut = false; // Did the last poll() time out? for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // if 条件等价于 rs &gt;= STOP || (rs == SHUTDOWN &amp;&amp; workQueue.isEmpty()) // 此时将工作线程数减一 if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; decrementWorkerCount(); return null; &#125; int wc = workerCountOf(c); // allowCoreThreadTimeOut 是用于设置核心线程是否受 keepAliveTime 影响， // 在 allowCoreThreadTimeOut 为 true 或工作线程数 &gt; corePoolSize的情况下， // 当前的工作线程会受 keepAliveTime 影响 boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; // 1. 工作线程数 &gt; maximumPoolSize，当前工作线程需要退出 // 2. timed &amp;&amp; timedOut == true 说明当前线程受 keepAliveTime 影响并且上次获取任务超时。这种情况下，如果当前线程不是最后一个线程或者队列为空，则可以退出 if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; if (compareAndDecrementWorkerCount(c)) return null; continue; &#125; try &#123; // 根据 timed 变量的值决定是限时阻塞获取还是一直阻塞获取队列中的任务 Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : // 超时退出 workQueue.take(); // 一直阻塞 if (r != null) return r; timedOut = true; // 走到这说明 poll 超时了 &#125; catch (InterruptedException retry) &#123; timedOut = false; &#125; &#125;&#125; 执行任务execute有了上面的一些概念后，接下来我们看看最核心的execute()方法，它包含了提交任务时的几大过程： 12345678910111213141516171819202122232425public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); // 获取线程池的状态控制变量 // 1. 如果线程数少于核心线程池的大小，则添加一个 Worker 来执行任务 if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; // 2. 到这里说明当前线程数大于等于核心线程池大小（或者 addWorker() 失败），如果线程池处于 RUNNING 状态，则将这个任务添加到阻塞队列 workQueue 中 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); // 2.1 线程池已经关闭了，则移除队列中刚提交的任务 if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); // 2.2 没有工作线程了，则添加一个空任务工作线程用于执行提交的任务 else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; // 3. 如果阻塞队列满了，那么以 maximumPoolSize 为界创建新的 Worker， // 如果失败，说明当前线程数已经达到 maximumPoolSize，此时执行拒绝策略 else if (!addWorker(command, false)) reject(command);&#125; 这里先对上面的三大步骤做个抽象层面的梳理： 如果当前运行的线程数少于corePoolSize，则创建新线程来执行任务 如果运行的线程数大于或等于corePoolSize，则将任务加入阻塞队列 如果阻塞队列也满了，则以maximumPoolSize为界创建新线程，如果线程数比maximumPoolSize还大，则执行拒绝策略 addWorker下面开始更细的去分析上述三大流程中涉及的一些方法，首先是addWorker()： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778/** * @param firstTask 准备提交给这个线程执行的任务，可以为 null * @param core 如果为 true，表示使用核心线程数 corePoolSize 作为创建线程的界限；如果为 false，表示使用最大线程数 maximumPoolSize 作为创建线程的界限 */private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); // 获取线程池的状态控制变量 int rs = runStateOf(c); // 获取线程池的状态 // 当线程池状态小于 SHUTDOWN 时，直接往下继续执行 // 当线程池状态等于 SHUTDOWN 时，如果 firstTask 为 null，且 workQueue 不为空，是允许创建新的 Worker 的，因为此时要把 workQueue 中的任务执行完；否则，当其中一个条件不满足时，不会继续往下执行 // 当线程池状态大于 SHUTDOWN 时，不允许创建新的 Worker 提交任务，不会继续往下执行 if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; int wc = workerCountOf(c); // 获取线程数 if (wc &gt;= CAPACITY || // 如果超过了 2^29-1 这个上限，或者超过了 corePoolSize 或 maximumPoolSize（由传入参数决定使用哪个），一样不会继续往下执行 wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; // 如果成功 CAS 新增 Worker 的数目，跳出循环往下走 if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl // 重读状态控制变量，如果线程池状态变了，则重试整个大循环 if (runStateOf(c) != rs) continue retry; // 否则，仅仅是 workerCount 变了，也就是 CAS 新增 workerCount 失败，重试内层循环 &#125; &#125; // 运行到此处时，线程池线程数已经成功+1，下面进行实质操作 boolean workerStarted = false; // Worker 是否已经启动 boolean workerAdded = false; // Worker 是否已经添加到 workers 中 Worker w = null; try &#123; w = new Worker(firstTask); // 在这个 Worker 的构造函数中，会通过线程工厂 new 一个新线程 final Thread t = w.thread; // 获取在构造 Worker 时线程工厂 new 出的新线程 if (t != null) &#123; final ReentrantLock mainLock = this.mainLock; // 整个线程池的全局锁，因为关闭线程池是需要这个锁的，这能保证持有锁的期间，线程池不会关闭 mainLock.lock(); try &#123; // 由于获取锁之前线程池状态可能发生了变化，这里需要重新读一次状态 int rs = runStateOf(ctl.get()); // 如果小于 SHUTDOWN 或者等于 SHUTDOWN 但 firstTask == null（不接受新任务但会继续执行阻塞队列中的任务） if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // worker 中的 thread 不能是已经启动了的，不然要抛出异常 throw new IllegalThreadStateException(); workers.add(w); // 将新创建的 Worker 加入到 workers 这个 HashSet 中 int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; // 记录线程池的历史最大值 workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; if (workerAdded) &#123; // Worker 添加成功，启动线程 t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; // 如果 Worker 线程启动失败，则做一些回滚操作 if (! workerStarted) addWorkerFailed(w); &#125; // 返回线程是否启动成功 return workerStarted;&#125; 这里笔者刚开始很疑惑的一点是，为什么t.start();会执行到Worker中的run()方法，它不是Worker中的属性吗，它自己本身并没有传入一个Runnable吧。但实际上，在通过线程工厂创建这个线程的时候，是传入了一个Runnable的，它就是Worker本身：12345Worker(Runnable firstTask) &#123; setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); // 注意这里的 this&#125; 因此，当我们使用t.start()开启这个Thread的时候，这个Thread中的target是为Worker本身的，所以才会执行它的run()方法：1234567// Thread.java public void run() &#123; if (target != null) &#123; target.run(); &#125; &#125; 此时就与之前分析Worker时候的方法串起来了，Worker的run()方法的执行逻辑其实是委托给外部类的runWorker()方法来完成，而runWorker()方法最终调用的就是传入的firstTask或者从阻塞队列中取到的某个任务，执行它的run()方法。 addWorkerFailed线程成功启动后的逻辑已经分析完了，接下来看看线程如果启动失败时会发生什么： 123456789101112private void addWorkerFailed(Worker w) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; if (w != null) workers.remove(w); decrementWorkerCount(); tryTerminate(); &#125; finally &#123; mainLock.unlock(); &#125;&#125; 其实就是回滚后尝试终止线程池： 从workers中删除失败的Worker workerCount减一 调用tryTerminate()尝试终止线程池 线程池的关闭shutdownshutdown()方法关闭线程池比较优雅，线程池进入SHUTDOWN后不会再接受新任务，并且中断所有空闲线程（阻塞在队列上的线程），但是任务队列中已有的任务将会继续处理。 12345678910111213141516171819202122232425262728293031323334353637public void shutdown() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; checkShutdownAccess(); // 检查是否有 shutdown 的权限，非重点 advanceRunState(SHUTDOWN); // 状态切换到 SHUTDOWN interruptIdleWorkers(); // 中断所有空闲线程，或者说在任务队列上阻塞的线程 onShutdown(); // hook for ScheduledThreadPoolExecutor &#125; finally &#123; mainLock.unlock(); &#125; // 尝试终止线程池（状态流转至 TERMINATED） tryTerminate();&#125;private void interruptIdleWorkers(boolean onlyOne) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; for (Worker w : workers) &#123; Thread t = w.thread; // 工作线程在处理任务阶段是被互斥锁保护着的，所以 tryLock() 会返回 false，不会中断到 if (!t.isInterrupted() &amp;&amp; w.tryLock()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; finally &#123; w.unlock(); &#125; &#125; if (onlyOne) break; &#125; &#125; finally &#123; mainLock.unlock(); &#125;&#125; shutdownNowshutdownNow()方法关闭线程池相比shutdown()暴力了一些，会中断所有线程，哪怕线程正在执行任务。线程池进入STOP状态后既不会接受新任务，也不会处理任务队列中已有的任务。需要注意的是，即便shutdownNow()会中断正在执行任务的线程，但不代表任务一定会挂，因为如果提交的任务里面的代码没有对线程中断敏感的逻辑的话，线程中断是不会有任何效果的。 1234567891011121314151617181920212223242526272829303132333435363738public List&lt;Runnable&gt; shutdownNow() &#123; List&lt;Runnable&gt; tasks; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; checkShutdownAccess(); // 检查是否有 shutdown 的权限，非重点 advanceRunState(STOP); // 状态切换到 STOP interruptWorkers(); // 与 SHUTDOWN 不同的是，直接中断所有线程 tasks = drainQueue(); // 将任务队列中的任务收集到 tasks &#125; finally &#123; mainLock.unlock(); &#125; // 尝试终止线程池（状态流转至 TERMINATED） tryTerminate(); return tasks;&#125;private void interruptWorkers() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; for (Worker w : workers) w.interruptIfStarted(); &#125; finally &#123; mainLock.unlock(); &#125;&#125; // 此方法在 Worker 类中 void interruptIfStarted() &#123; Thread t; if (getState() &gt;= 0 &amp;&amp; (t = thread) != null &amp;&amp; !t.isInterrupted()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; &#125; &#125; 拒绝策略在execute()方法中我们可以看到，有两种情况会调用reject()拒绝策略来处理任务，一个是当任务加入阻塞队列后的短暂空窗期线程池已经关闭了，此时再次查看线程池的状态不为RUNNING就会将任务移出队列并执行拒绝策略，另一个是当线程数超过了maximumPoolSize，无法再创建新线程了。 12345private volatile RejectedExecutionHandler handler;final void reject(Runnable command) &#123; handler.rejectedExecution(command, this);&#125; RejectedExecutionHandler在ThreadPoolExecutor中有四个已经定义好的实现类可供我们直接使用，当然，我们也可以实现自己的策略，不过一般也没有必要。 123456789101112131415161718192021222324252627282930313233343536373839404142// 如果线程池没有被关闭，那么由提交任务的线程自己来执行这个任务public static class CallerRunsPolicy implements RejectedExecutionHandler &#123; public CallerRunsPolicy() &#123; &#125; public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; if (!e.isShutdown()) &#123; r.run(); &#125; &#125;&#125; // 不管怎样，直接抛出 RejectedExecutionException 异常// 这个是默认的策略，如果在构造线程池时不传相应的 handler 的话，那就会使用这个public static class AbortPolicy implements RejectedExecutionHandler &#123; public AbortPolicy() &#123; &#125; public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; throw new RejectedExecutionException("Task " + r.toString() + " rejected from " + e.toString()); &#125;&#125; // 不做任何处理，直接忽略掉这个任务public static class DiscardPolicy implements RejectedExecutionHandler &#123; public DiscardPolicy() &#123; &#125; public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; &#125;&#125; // 如果线程池没有被关闭，那么丢弃任务队列中首部的任务，然后提交该任务public static class DiscardOldestPolicy implements RejectedExecutionHandler &#123; public DiscardOldestPolicy() &#123; &#125; public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; if (!e.isShutdown()) &#123; e.getQueue().poll(); e.execute(r); &#125; &#125;&#125; ExecutorsExecutors是一个工具类，所有的方法都是static的，它为我们创建线程池提供了很大的便利。 newFixedThreadPool生成一个固定大小的线程池，最大线程数设置为与核心线程数相等，此时keepAliveTime设置为0（因为这里它是没用的，即使不为0，线程池默认也不会回收corePoolSize内的线程），阻塞队列采用LinkedBlockingQueue无界队列。 12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; newSingleThreadExecutor生成只有一个线程的线程池，与newFixedThreadPool唯一的不同在于核心线程和最大线程数都为1，不需要指定。 123456public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125; newCachedThreadPool生成一个需要的时候就创建新线程的线程池。这种线程池对于任务可以比较快速地完成的情况下有比较好的性能，如果线程空闲了60秒都没有任务，那么将关闭此线程并从线程池中移除。所以如果线程池空闲了很长时间也不会有问题，因为随着所有线程的关闭，整个线程池不会占用任何的系统资源。 12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; 总结本文从Executor顶层接口逐层向下分析，重点讲解了ThreadPoolExecutor的源码实现，包括核心参数、线程创建过程、执行任务、拒绝策略和线程池的关闭等，由于Executor体系本身内容还是比较多的，因此有些地方依然没有关注到，例如定时相关的ScheduledExecutorService接口和同时实现了ThreadPoolExecutor与ScheduledExecutorService的ScheduledThreadPoolExecutor，并且关于ThreadPoolExecutor的线程池关闭这一块，也还有几个方法没有深入分析，将来有时间一定补上。 参考资料 ThreadPoolExecutor源码解读 深度解读 java 线程池设计思想及源码实现 Java 线程池原理分析]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
        <tag>Executor</tag>
        <tag>线程池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ThreadLocal源码分析]]></title>
    <url>%2F2019%2F05%2F11%2FThreadLocal%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[实现原理每个线程读写ThreadLocal是线程隔离的，互相之间不会影响。其原因就是在于Thread类有一个ThreadLocal.ThreadLocalMap类型的属性，也就是说每个线程有一个自己的ThreadLocalMap，读写某个ThreadLocal时都会获取当前线程以及当前线程的ThreadLocalMap属性，对其进行读写，以此实现线程隔离。以下是ThreadLocal的几个关键方法：12345678910111213141516171819202122public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); // 将自己作为 key else createMap(t, value);&#125;public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); // 将自己作为 key if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125; 可以看出，ThreadLocal本身并没有太多东西，它只是作为ThreadLocalMap的key，核心源码其实都在ThreadLocalMap中。 弱引用在开始源码分析之前，需要先了解弱引用这个概念，因为在ThreadLocalMap中ThreadLocal并不是直接作为key的，而是使用的弱引用对象Entry。在Java中存在四种引用，分别是强引用、软引用、弱引用和虚引用，它们的区别如下： 强引用：通常我们通过new来创建一个新对象时返回的引用就是一个强引用，若一个对象通过一系列强引用可到达，它就是强可达的，那么它就不被回收 软引用：软引用和弱引用的区别在于，若一个对象是弱引用可达，无论当前内存是否充足它都会被回收，而软引用可达的对象在内存不充足时才会被回收，因此软引用要比弱引用“强”一些 虚引用：虚引用是Java中最弱的引用，通过虚引用甚至无法获取到被引用的对象，虚引用存在的唯一作用就是当它指向的对象被回收后，虚引用本身会被加入到引用队列中，用作记录它指向的对象已被回收 之所以需要弱引用，是因为在类似HashMap的结构中，如果存放了一个key为Product对象且value为1的节点，此时我们有一个变量product指向了这个Product对象，当我们不再需要这个对象时，如果直接将product设为null，Product对象其实并不会被回收，因为通过HashMap它还存在一条强引用链，如果我们想让它被垃圾收集器回收，就必须将其彻底从HashMap中移除，让它不再存在任何强引用。如果上述过程我们不想自己手动去实现，而是想告诉垃圾收集器在只有HashMap中的key引用着Product对象的情况下，就可以回收相应的Product对象了，那么就可以使用弱引用。 Java中的弱引用具体指的是java.lang.ref.WeakReference&lt;T&gt;类，我们使用一个指向Product对象的弱引用对象来作为HashMap的key，只需这样定义这个弱引用对象：12Product product = new Product(...);WeakReference&lt;Product&gt; weakProduct = new WeakReference&lt;&gt;(product); 而如果要通过weakProduct获取它所指向的Product对象，我们只需要通过这行代码：Product product = weakProductA.get();即可。WeakReference的构造函数如下：1234//创建一个指向给定对象的弱引用WeakReference(T referent)//创建一个指向给定对象并且登记到给定引用队列的弱引用WeakReference(T referent, ReferenceQueue&lt;? super T&gt; q) 通过将原始对象包装成弱引用对象，当变量product设为null时，指向这个Product对象的就只剩弱引用对象weakProduct了，显然这时候相应的Product对象是弱可达的，所以指向它的弱引用会被清除，这个Product对象随即会被回收，指向它的弱引用对象会进入引用队列中，在引用队列中可以对这些被清除的弱引用对象进行统一管理。 源码分析Entry节点上面说过，ThreadLocalMap并不是简单的使用ThreadLocal作为key的，其实它内部存储着一个Entry节点数组，而Entry继承了弱引用类WeakReference：123456789static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125;&#125; 当构造一个Entry节点时，会先调用父类WeakReference的构造函数将ThreadLocal传入，并设置了一个类型为Object的value，用于存放ThreadLocal对应的值。 这里之所以要使用弱引用Entry节点而不是简单的key-value形式的节点，是因为如果简单的使用key-value形式会造成节点的生命周期与线程强绑定，只要线程存在，那么作为属性的ThreadLocalMap也就存在，在不显式移除的情况下，key对象就依然被强引用着，没办法被回收。在这里通过使用弱引用节点，当我们将某个ThreadLocal对象的强引用设为null后，这个ThreadLocal对象就只剩下弱引用了，之后会被GC回收掉，有效的避免了内存泄漏的问题。 成员变量1234567891011 // 初始容量默认为16 private static final int INITIAL_CAPACITY = 16; // Entry 数组，大小必须为2的幂private Entry[] table; // 数组中 Entry 的实际个数private int size = 0; // 扩容时的阈值private int threshold; ThreadLocalMap与HashMap不同，它是使用的线性探测法而非拉链法解决碰撞冲突的，所以实际上Entry[]数组在逻辑上是作为一个环形存在的。 123456789// 环形意义的下一个索引下标private static int nextIndex(int i, int len) &#123; return ((i + 1 &lt; len) ? i + 1 : 0);&#125;// 环形意义的前一个索引下标private static int prevIndex(int i, int len) &#123; return ((i - 1 &gt;= 0) ? i - 1 : len - 1);&#125; 构造函数123456789101112ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) &#123; // 初始化 table 数组 table = new Entry[INITIAL_CAPACITY]; // 用位运算而非取模得到下标，这也是为什么容量需要为偶数的原因 int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); // 构造并设置该节点 table[i] = new Entry(firstKey, firstValue); // 更新表（数组）的大小 size = 1; // 设置扩容阈值 setThreshold(INITIAL_CAPACITY);&#125; 这个构造函数我们重点需要关注其中的threadLocalHashCode，这是传入的ThreadLocal对象的哈希值：123456789 private static AtomicInteger nextHashCode = new AtomicInteger();private final int threadLocalHashCode = nextHashCode(); private static int nextHashCode() &#123; return nextHashCode.getAndAdd(HASH_INCREMENT); &#125;private static final int HASH_INCREMENT = 0x61c88647; 这个哈希值在对象创建时就会生成，每次都会累加0x61c88647，通过这种方式使得与2的幂取模（实际是位运算）后均匀分布，也就提高了线性探测时的效率。 getEntrygetEntry()方法会被ThreadLocal的get()方法直接调用，上面也说过，get()方法内部就是先拿到当前线程的ThreadLocalMap，然后将自己this作为参数调用其getEntry()方法。这里要提前说明一点的是，每个索引（slot）上的状态有三种：有效（ThreadLocal未回收），失效（ThreadLocal已回收），空（null）： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; // 获取这个 key 的索引下标 int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; // 对应的 entry 不为空且未失效，且弱引用指向的 ThreadLocal 就是传入的 key，则命中返回 if (e != null &amp;&amp; e.get() == key) return e; else // 因为用的是线性探测，所以往后还是有可能找到目标 Entry 的 return getEntryAfterMiss(key, i, e);&#125;/** * 调用 getEntry() 未直接命中时调用此方法 */private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123; Entry[] tab = table; int len = tab.length; // 基于线性探测法不断向后探测直到遇到 null while (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) return e; if (k == null) // 如果该 entry 对应的 ThreadLocal 已经被回收（失效），调用 expungeStaleEntry() 来清理无效的 entry expungeStaleEntry(i); else // 如果该 entry 对应的 ThreadLocal 未被回收，但与传入的 key 不等，则继续向后探测 i = nextIndex(i, len); // 环形意义下往后面走，线性探测 e = tab[i]; &#125; // 没找到指定的 key return null;&#125;/** * ThreadLocal 的核心清理函数，从 staleSlot 下标开始遍历，将无效的的 entry 清理， * 即将 entry 中的 value 置为 null，指向这个 entry 的 table[i] 置为 null，直到遍历到空 entry。 * 另外，在这个过程中还会对非空的 entry 作 rehash。 */private int expungeStaleEntry(int staleSlot) &#123; Entry[] tab = table; int len = tab.length; // 因为 entry 对应的 ThreadLocal 已经被回收，此时为了垃圾回收： // 将 entry 中的 value 置为 null，显示断开强引用 tab[staleSlot].value = null; // 将指向这个 entry 的 table[i] 置为 null tab[staleSlot] = null; // 将实际 entry 数减一 size--; Entry e; int i; // 从 staleSlot 的下一个索引开始，不断向后遍历，直到遇到 null for (i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123; ThreadLocal&lt;?&gt; k = e.get(); // 如果当前 entry 中的 ThreadLocal 已经被回收，则做一次清理 if (k == null) &#123; e.value = null; tab[i] = null; size--; &#125; else &#123; // 如果 entry 对应的 ThreadLocal 还没被回收，需要做一次 rehash // 如果 ThreadLocal 计算出的 hash 对应的索引h与当前位置不同， // 则从 h 开始向后线性探测直到第一个空的 slot，把当前的 entry 给挪过去 int h = k.threadLocalHashCode &amp; (len - 1); if (h != i) &#123; tab[i] = null; // 先将当前索引置 null while (tab[h] != null) // 遍历找到从索引h开始的第一个空 slot h = nextIndex(h, len); tab[h] = e; // 将 entry 挪到这个空 slot 上 &#125; &#125; &#125; // 返回 staleSlot 之后第一个 entry 为 null 的索引下标 return i;&#125; 总的来说，getEntry()会经历以下几步： 根据传入的ThreadLocal的哈希值定位到某个索引下标 如果该下标对应的entry存在，且其中的ThreadLocal和方法传入的ThreadLocal相同，则直接命中返回 否则，调用getEntryAfterMiss()进行线性探测，过程中每次碰到失效的 slot，就调用expungeStaleEntry进行段清理（清理并rehash，直到遇到null） 遍历直到 null 都未命中 key，直接返回 null set123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); // 获取该键对应的索引下标 // 线性探测 for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); // 找到 key 相同的 entry，覆盖 value if (k == key) &#123; e.value = value; return; &#125; // 如果当前 entry 失效，则替换失效的 entry if (k == null) &#123; replaceStaleEntry(key, value, i); return; &#125; &#125; // 线性探测过程中没有遇到 key 相同的 entry，也没遇到失效的 entry，当遇到 null 时跳出循环 // 在 null 的位置上建立新的 entry tab[i] = new Entry(key, value); int sz = ++size; if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash();&#125;/** * 替换失效的 entry */private void replaceStaleEntry(ThreadLocal&lt;?&gt; key, Object value, int staleSlot) &#123; Entry[] tab = table; int len = tab.length; Entry e; // 从 staleSlot 向前遍历，查找最前的一个无效的 slot int slotToExpunge = staleSlot; for (int i = prevIndex(staleSlot, len); (e = tab[i]) != null; i = prevIndex(i, len)) if (e.get() == null) slotToExpunge = i; // 从 staleSlot 向后遍历，看能不能找到相同的 key，如果找到了则和无效的 staleSlot 交换 for (int i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123; ThreadLocal&lt;?&gt; k = e.get(); // 找到了 key，将其与无效的slot交换 if (k == key) &#123; e.value = value; tab[i] = tab[staleSlot]; tab[staleSlot] = e; if (slotToExpunge == staleSlot) slotToExpunge = i; // 从 slotToExpunge 开始做一次连续段的清理，再做一次启发式清理 cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); return; &#125; // 如果当前的 slot 已经无效，并且向前扫描过程中没有无效 slot，则更新 slotToExpunge 为当前位置 if (k == null &amp;&amp; slotToExpunge == staleSlot) slotToExpunge = i; &#125; // 如果找不到相同的 key，则直接设置在失效的 staleSlot 下标上 tab[staleSlot].value = null; tab[staleSlot] = new Entry(key, value); // 在探测过程中如果发现任何无效 slot，则做一次清理（连续段清理+启发式清理） if (slotToExpunge != staleSlot) cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);&#125;/** * 做一次全量清理，并且调低阈值决定是否扩容 */private void rehash() &#123; // 做一次全量清理 expungeStaleEntries(); // 因为做了一次清理，所以 size 很可能会变小 // 这里是调低阈值判断是否需要扩容，下面一行相当于 if(size &gt;= len / 2) if (size &gt;= threshold - threshold / 4) resize();&#125;/** * 全量清理 */private void expungeStaleEntries() &#123; Entry[] tab = table; int len = tab.length; for (int j = 0; j &lt; len; j++) &#123; Entry e = tab[j]; if (e != null &amp;&amp; e.get() == null) // 这里其实可以将 j 设为返回值，j 之前的 entry 其实已经被清理过了，肯定为 null expungeStaleEntry(j); &#125;&#125;/** * 扩容为原来的两倍 */private void resize() &#123; Entry[] oldTab = table; int oldLen = oldTab.length; int newLen = oldLen * 2; Entry[] newTab = new Entry[newLen]; int count = 0; for (int j = 0; j &lt; oldLen; ++j) &#123; Entry e = oldTab[j]; if (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == null) &#123; e.value = null; // Help the GC &#125; else &#123; int h = k.threadLocalHashCode &amp; (newLen - 1); // 计算新容量时哈希值对应的索引下标 while (newTab[h] != null) // 线性探测解决碰撞冲突 h = nextIndex(h, newLen); newTab[h] = e; count++; &#125; &#125; &#125; // 设置新阈值 setThreshold(newLen); size = count; table = newTab;&#125; set()方法总体过程如下： 在遍历（也就是线性探测）遇到null之前，如果遇到了相同的key，则直接覆盖；如果遇到了失效的entry，则调用replaceStaleEntry，效果是最终一定会把key和value放在这个slot上，并且会尽可能地清理无效entry 遍历过程既没遇到相同的key，也没遇到失效的entry，也就是当前索引上为null，则直接将key和value插在这个空slot上 如果插入后的size大于阈值，那么做一次全量清理，再根据调低的阈值决定是否需要扩容，扩容两倍（因为容量必须为2的幂） removeremove()方法相对比较简单，只需要找到对应的key，然后将弱引用显式的断开，并做一次段清理即可。 123456789101112private void remove(ThreadLocal&lt;?&gt; key) &#123; Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; if (e.get() == key) &#123; e.clear(); // 显式断开弱引用 expungeStaleEntry(i); // 进行段清理 return; &#125; &#125;&#125; 这里光做e.clear();其实是不够的，因为value此时还被强引用着，所以才需要进行段清理，将table[i] = null;彻底断开强引用。 内存泄露经过上面的分析我们已经清楚在每个Thread中有一个ThreadLocalMap，每个线程在对某个ThreadLocal对象操作时都会先获取当前线程的ThreadLocalMap，然后对ThreadLocalMap进行操作，并且，ThreadLocal不是简单的作为key的，而是将key和value包装成继承自弱引用WeakReference的Entry类。但这里要注意的是，弱引用只是针对key（Entry中的ThreadLocal），当没有任何强引用指向ThreadLocal的时候，它就只剩下弱引用了，GC时将会被回收，但是value却不会被回收，因为它存在一条当前Thread-&gt;ThreadLocalMap-&gt;Entry数组-&gt;Entry-&gt;value的强引用，所以除非线程销毁，否则它将与线程的生命周期绑定，尤其是在有线程复用比如线程池的场景中，一个线程的寿命很长，大对象长期不被回收会影响系统运行效率与安全，也就造成了人们常说的内存泄露。 但是在源码中我们也会发现，ThreadLocalMap实现中是有一套自我清理的机制的，当我们调用get()或者set()方法时会有很高的概率顺便清理掉失效的Entry，防止出现内存泄露。当然，显示地进行remove()是个良好的编程习惯，它可以确保不会发生内存泄露。 参考资料 ThreadLocal源码解读 十分钟理解Java中的弱引用 Java中的强引用，软引用，弱引用，虚引用有什么用？]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
        <tag>ThreadLocal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ：流控与镜像队列]]></title>
    <url>%2F2019%2F05%2F08%2FRabbitMQ%EF%BC%9A%E9%95%9C%E5%83%8F%E9%98%9F%E5%88%97%E3%80%81%2F</url>
    <content type="text"><![CDATA[队列的结构通常队列由rabbit_amqqueue_process和backing_queue两部分组成，前者负责协议相关的消息处理，即接受生产者发布的消息、向消费者交付消息、处理消息的确认（包括生产端的confirm和消费端的ack）等。backing_queue是消息存储的具体形式和引擎，并向rabbit_amqqueue_process提供相关的接口以供调用。 四种状态如果消息投递的目的队列是空的，并且有消费者订阅了这个队列，那么该消息会直接发送给消费者，不会经过队列这一步。而当消息无法直接投递给消费者时，需要暂时将消息存入队列，以便重新投递。消息存入队列后，不是固定不变的，它会随着系统的负载在队列中不断地流动，消息的状态会不断发生变化。RabbitMQ中的队列消息可能会处于以下四种状态： alpha：消息内容（包括消息体、属性和headers）和消息索引都存储在内存中 beta：消息内容保存在磁盘中，消息索引保存在内存中 gamma：消息内容保存在磁盘中，消息索引在磁盘和内存中都有 delta：消息内容和索引都在磁盘中 其中，gamma状态的消息是只有持久化的消息才会有的状态。 RabbitMQ在运行时会根据统计的消息传送速率定期计算一个当前内存中能够保存的最大消息数量，如果alpha状态的消息数量大于此值时，就会引起消息的状态转换，多余的消息可能会转换到beta、gamma或者delta状态。其中，delta状态需要执行两次I/O操作才能读取到消息，一次是读消息索引，一次是读消息内容；而对于beta和gamma状态都只需要一次I/O操作就可以读取到消息。 对于普通的没有设置优先级和镜像的队列来说，backing_queue内部通过5个子队列Q1、Q2、Delta、Q3和Q4来体现消息的各个状态，其中Q1、Q4只包含alpha状态的消息，Q2、Q3包含beta和gamma状态的消息，Delta只包含delta状态的消息，一般情况下，消息按照Q1-&gt;Q2-&gt;Delta-&gt;Q3-&gt;Q4这样的顺序步骤进行流动。如图： 从Q1到Q4基本经历了内存到磁盘，再从磁盘到内存的过程，如此可以在队列负载很高的情况下，能够通过将一部分消息由磁盘保存来节省内存空间，而在负载降低的时候，这部分消息又渐渐回到内存被消费者获取，使得整个队列具有很好的弹性。 通常在负载正常时，如果消息被消费的速度不小于接受新消息的速度，对于非持久化的消息，通常只会处于alpha状态，而对于持久化的消息，一定会进入gamma状态，并且在开启生产端确认机制时，只有到了gamma状态时才会确认该消息已被接收，若消息消费速度足够快、内存也充足，这些消息也不会继续走到下一个状态。 在系统负载较高时，这些消息若不能很快的被消费掉，就会进入到很深的队列中去，这样会增加处理每个消息的平均开销，因为要花更多的时间和资源处理堆积的消息，如此用来处理新流入的消息的能力就会降低，导致恶性循环。应对这一问题，RabbitMQ有一套流控机制，在下文会介绍。 惰性队列队列具有两种模式，一个是default，一个是lazy。默认情况下，当生产者将消息发送到RabbitMQ中的时候，队列中的消息会尽可能地存储在内存之中，这样可以更加快速地将消息发送给消费者。当RabbitMQ需要释放内存时，将消息换入磁盘会耗费较长时间，也会阻塞队列的操作，进而无法接受新的消息。 RabbitMQ从3.6.0版本开始引入了惰性队列的概念，即将接受到的消息直接存入文件系统中，而在消费者消费到相应的消息时才会被加载到内存中，它的一个重要的设计目标是能够支持更长的队列，即支持更多的消息存储。惰性队列虽然减少了内存的消耗，但是增加了I/O的使用，因此对于持久化的消息，本身就不可避免磁盘I/O，使用惰性队列是较佳的选择。要注意的是，如果惰性队列中存储的是非持久化的消息，重启之后消息一样会丢失。 内存及磁盘告警当内存使用超过配置的阈值或者磁盘剩余空间低于配置的阈值时，RabbitMQ会暂时阻塞客户端的连接并停止接收从客户端发来的消息。被阻塞的Connection的状态要么是blocking，要么是blocked，前者对应于并不试图发送消息的Connection，后者对应于一直有消息发送的Connection，这种状态下的Connection会被停止发送消息。注意在一个集群中，如果一个Broker节点的内存或者磁盘受限，都会引起整个集群中所有的Connection被阻塞。 内存告警默认情况下内存阈值为0.4，表示当RabbitMQ使用的内存超过40%时，会产生内存告警并阻塞所有生产者的连接。一旦告警被解除（有消息被消费或者从内存转储到磁盘等情况的发生），一切都会恢复正常。 在某个Broker快达到内存阈值时，会先尝试将队列中的消息换页到磁盘以释放内存空间。默认情况下，在内存到达内存阈值的50%时会进行换页动作。 磁盘告警当剩余磁盘空间低于确定的阈值时，RabbitMQ同样会阻塞生产者，这样可以避免因非持久化的消息持续换页而耗尽磁盘空间导致服务崩溃。默认情况下，磁盘阈值为50MB。RabbitMQ会定期检测磁盘剩余空间，检测的频率与上一次执行检测到的磁盘剩余空间大小有关，随着磁盘剩余空间与磁盘阈值的接近，检测频率会有所增加。 流控当RabbitMQ出现内存或者磁盘资源达到阈值时，会触发流控机制，阻塞生产者的Connection，让生产者不能继续发送消息，直到内存或者磁盘资源得到释放。RabbitMQ基于Erlang开发，一个消息的生命周期中，会涉及多个进程间的转发，这些Erlang进程之间不共享内存，每个进程都有自己独立的内存空间，如果没有合适的流控机制，可能会导致某个进程占用内存过大，导致OOM。因此，要保证各个进程占用的内存在一个合理的范围。 RabbitMQ的流控机制的原理实质上就是通过监控各进程的mailbox，当某个进程负载过高来不及接收消息时，这个进程的mailbox就会开始堆积消息，当堆积到一定量时，就会阻塞住上游进程让其不得接收新消息，从而慢慢上游进程的mailbox也会开始积压消息，到了一定的量也会阻塞上游的上游的进程，最后就会使得负责网络数据包接收的进程阻塞掉，暂停接收数据。 从Connection到Channel到队列再到消息持久化存储形成了一个完整的流控链： 其中的各个进程如下所述： rabbit_reader：Connection的处理进程，负责接收、解析AMQP协议数据包等 rabbit_channel：Channel的处理进程，负责处理AMQP协议的各种方法、进行路由解析等 rabbit_amqqueue_process：队列的处理进程，负责实现队列的所有逻辑 rabbit_msg_store：负责实现消息的持久化 对于处于整个流控链中的任意进程，只要该进程阻塞，上游的进程必定全部被阻塞。也就是说，如果某个进程达到性能瓶颈，必然会导致上游所有的进程被阻塞。所以我们可以利用流控机制的这个特点找出瓶颈所在。 一个Connection触发流控时会处于flow的状态，也就意味着这个Connection的状态每秒在blocked和unblocked之间来回切换数次，这样可以将消息发送的速率控制在服务器能够支撑的范围之内。 镜像队列RabbitMQ的集群在默认模式下，队列实例只存在于一个节点上，既不能保证该节点崩溃的情况下队列还可以继续运行，也不能线性扩展该队列的吞吐量。虽然RabbitMQ的队列实际只会在一个节点上，但元数据可以存在于各个节点上。举个例子来说，当创建一个新的交换器时，RabbitMQ会把该信息同步到所有节点上，这个时候客户端不管连接到哪个RabbitMQ节点，都可以访问到这个新的交换器，也就能找到交换器下的队列： RabbitMQ内部的元数据主要有： 队列元数据：队列名称和属性 交换器元数据：交换器名称，类型和属性 绑定元数据：路由信息 尽管交换器和绑定关系能够在单点故障问题上幸免于难，但是队列和其上存储的消息却不行，它们仅存在于单个节点上。引入镜像队列的机制，可以将队列镜像到集群中的其它Broker节点之上，如果集群中的一个节点失效了，队列能够自动地切换到镜像中的另一个节点上以保证服务的可用性。通常情况下，针对每一个配置镜像的队列都包含一个主拷贝和若干个从拷贝，相应架构如下： 除了发送消息外的所有动作都只会向主拷贝发送，然后再由主拷贝将命令执行的结果广播给各个从拷贝，从拷贝实际只是个冷备（默认的情况下所有RabbitMQ节点上都会有镜像队列的拷贝），如果使用消息确认模式，RabbitMQ会在主拷贝和从拷贝都安全的接受到消息时才通知生产者。从这个结构上来看，如果从拷贝的节点挂了，实际没有任何影响，如果主拷贝挂了，那么会有一个重新选举的过程，这也是镜像队列的优点，除非所有节点都挂了，才会导致消息丢失。重新选举后，RabbitMQ会给消费者一个消费者取消通知（Consumer Cancellation），让消费者重连新的主拷贝。 实现原理不同于普通的非镜像队列，镜像队列的实现结构如下： 所有对镜像队列主拷贝的操作，都会通过GM同步到各个slave节点，Coodinator负责组播结果的确认。GM是一种可靠的组播通信协议，该协议能够保证组播消息的原子性，即保证组内的存活节点要么都收到消息要么都收不到。 GM的组播并不是由master来负责通知所有slave的（目的是为了避免master压力过大，同时避免master失效导致消息无法最终ack)，RabbitMQ把所有节点组成一个链表，每个节点都会监控位于自己左右两边的节点，当有节点新增时，相邻的节点保证当前广播的消息会复制到新节点上；当有节点失效时，相邻的节点会接管以保证本次广播的消息会复制到所有的节点。操作命令由master发起，也由master最终确认通知到了所有的slave，而中间过程则由slave接力的方式进行消息传播。 参考资料 RabbitMQ实战指南. 朱忠华 深入理解：RabbitMQ的前世今生 通过流控机制分析rabbitmq性能（持久化）瓶颈]]></content>
  </entry>
  <entry>
    <title><![CDATA[Java8新特性]]></title>
    <url>%2F2019%2F05%2F06%2FJava-8%E6%96%B0%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[前言Java 8是Java开发的一个主要版本，也是一个有着重大改变的版本，在此对Java 8的部分新特性进行总结，主要总结以下几个部分： Lambda表达式 函数式接口 默认方法 Stream Lambda表达式Lambda表达式能够让我们把函数作为方法参数，或者把代码作为数据对待，使用Lambda表达式可以使代码变得更加简洁紧凑。语法如下： 方法体为表达式，该表达式的值作为返回值返回：(parameters) -&gt; expression 方法体为代码块，必须用{}包裹起来，且需要有一个return返回值：(parameters) -&gt; { statements; } Lambda表达式还有以下几个特征： 可选类型声明：不需要声明参数类型，编译器可以统一识别参数值 可选的参数圆括号：一个参数无需定义圆括号，但多个参数需要定义圆括号 Lambda表达式的简单例子：123456789101112131415// 1. 不需要参数,返回值为 5 () -&gt; 5 // 2. 接收一个参数(数字类型),返回其2倍的值 x -&gt; 2 * x // 3. 接受2个参数(数字),并返回他们的差值 (x, y) -&gt; x – y // 4. 接收2个int型整数,返回他们的和 (int x, int y) -&gt; x + y // 5. 接受一个 string 对象,并在控制台打印,不返回任何值(看起来像是返回void) (String s) -&gt; System.out.print(s) Lambda表达式的原理： 在类编译时，会生成一个私有静态方法 + 一个内部类 在内部类中实现了函数式接口，在实现接口的方法中，会调用编译器生成的静态方法 在使用lambda表达式的地方，通过传递内部类实例，来调用函数式接口方法 函数式接口函数式接口就是一个有且仅有一个抽象方法，但是可以有多个非抽象方法的接口。函数式接口的重要特点是，我们能够使用Lambda实例化它们，如定义了一个函数式接口如下：12345@FunctionalInterfaceinterface GreetingService &#123; void sayMessage(String message);&#125; 那么就可以使用Lambda表达式来表示该接口的一个实现（Java 8之前一般是用匿名类实现）：1GreetingService greetService1 = message -&gt; System.out.println("Hello " + message); 注意该函数式接口上有一个新的注解@FunctionalInterface，该接口不是必须的，用来标记该接口为只允许有一个抽象方法的函数式接口，当接口不符合函数式接口定义的时候，编译器会报错。 默认方法接口的默认方法就是接口可以有实现方法，而且不需要实现类去实现其方法，我们只需要在方法名前面加个default关键字即可实现默认方法。 为什么要有这个特性呢？首先，之前的接口是个双刃剑，好处是面向抽象而不是面向具体编程，缺陷是当需要修改接口的时候，需要修改全部实现了该接口的类，但是如果我们想给接口添加新方法的同时不影响已有的实现，就可以使用默认方法这个特性，解决接口的修改与现有的实现不兼容的问题。 如果一个类实现了多个接口，并且这些接口有相同的默认方法，此时可以覆盖接口的默认方法，也可以使用super来调用指定接口的默认方法：123456789101112131415161718public class DefaultMethodTest implements A, B &#123; @Override public void print() &#123; A.super.print(); &#125;&#125;interface A&#123; default void print()&#123; System.out.println("a"); &#125;&#125;interface B&#123; default void print()&#123; System.out.println("b"); &#125;&#125; Java 8还可以在接口中提供静态方法的实现，例如：12345interface C&#123; static void hello()&#123; System.out.println("hello"); &#125;&#125; Stream流式操作分为中间操作和最终操作两种，最终操作返回一特定类型的结果，而中间操作返回流本身，这样就可以将多个操作依次串联起来。 生成流在Java 8中，集合接口有两个方法来生成流： stream()：为集合创建串行流 parallelStream()：为集合创建并行流 forEachStream 提供了新的方法forEach来迭代流中的每个数据。以下代码片段使用forEach输出了10个随机数：12Random random = new Random(); random.ints().limit(10).forEach(System.out::println); 需要注意的是，forEach是一个终止操作，也就是说该操作必须是流的最后一个操作，一旦被调用，Stream就不能再使用了。 filterfilter方法用于通过设置的条件过滤出元素。以下代码片段使用filter方法过滤出空字符串：12List&lt;String&gt;strings = Arrays.asList("abc", "", "bc", "efg", "abcd","", "jkl"); // 获取空字符串的数量int count = strings.stream().filter(string -&gt; string.isEmpty()).count(); limitlimit方法用于获取指定数量的流。 以下代码片段使用limit方法打印出10条数据：12Random random = new Random();random.ints().limit(10).forEach(System.out::println); sortedsorted方法用于对流进行排序。以下代码片段使用sorted方法对输出的10个随机数进行排序：12Random random = new Random(); random.ints().limit(10).sorted().forEach(System.out::println); 并行程序parallelStream是流并行处理程序的代替方法。以下实例我们使用parallelStream来输出空字符串的数量：12List&lt;String&gt; strings = Arrays.asList("abc", "", "bc", "efg", "abcd","", "jkl"); // 获取空字符串的数量 int count = strings.parallelStream().filter(string -&gt; string.isEmpty()).count(); 我们可以很容易的在顺序运行和并行直接切换。 参考资料 Java 8 新特性概述 Java 8 新特性 Java Lambda表达式 实现原理分析]]></content>
      <categories>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java中的装箱与拆箱]]></title>
    <url>%2F2019%2F05%2F06%2FJava%E4%B8%AD%E7%9A%84%E8%A3%85%E7%AE%B1%E4%B8%8E%E6%8B%86%E7%AE%B1%2F</url>
    <content type="text"><![CDATA[前言自动装箱和拆箱从Java 1.5开始引入，目的是让原始类型值与对应的包装对象之间可以自动的相互转换，比如将int类型值转换成Integer对象称为装箱，反之将Integer对象转换成int类型值称为拆箱。因为这里的装箱和拆箱是自动进行的而非人为转换，所以就称为自动装箱和拆箱。 在Java中，原始类型byte、short、char、int、long、float、double、boolean分别对应的包装类为Byte、Short、Character、Integer、Long、Float、Double、Boolean。 实现原理自动装箱与拆箱其实是编译器自动为我们调用了相关方法，自动装箱是通过调用包装类的valueOf()方法实现的，而自动拆箱是通过调用包装类的xxxValue()方法实现的（xxx代表对应的基本数据类型）。 何时发生自动装箱和拆箱自动装箱和拆箱主要发生在两种情况，一种是赋值时，另一种是在方法调用时。 赋值时这是最常见的一种情况，在Java 1.5以前我们需要手动地进行转换才行，而现在所有的转换都是由编译器来完成。 1234567//before autoboxingInteger iObject = Integer.valueOf(3);int iPrimitive = iObject.intValue()//after java5Integer iObject = 3; //autobxing - primitive to wrapper conversionint iPrimitive = iObject; //unboxing - object to primitive conversion 方法调用时这是另一个常用的情况，当我们在方法调用时，我们可以传入原始数据值或者对象，同样编译器会帮我们进行转换。 12345678public static Integer show(Integer iParam)&#123; System.out.println("autoboxing example - method invocation i: " + iParam); return iParam;&#125;//autoboxing and unboxing in method invocationshow(3); //autoboxingint result = show(3); //unboxing because return type of method is Integer show方法接受Integer对象作为参数，当调用show(3)时，会将int值转换成对应的Integer对象，这就是所谓的自动装箱，show方法返回Integer对象，而int result = show(3);中result为int类型，所以这时候发生自动拆箱操作，将show方法的返回的Integer对象转换成int值。 需要注意的问题自动装箱与拆箱虽然为我们省下了很多不必要的工作，使代码更加简洁清晰，但是如果使用不当，则会引起性能问题。 循环中的自动装箱自动装箱有一个问题，那就是在一个循环中进行自动装箱操作的情况，如下面的例子就会创建多余的对象，影响程序的性能： 1234Integer sum = 0; for(int i=1000; i&lt;5000; i++)&#123; sum+=i;&#125; 上面的代码sum+=i可以看成sum = sum + i，但是+这个操作符不适用于Integer对象，首先sum进行自动拆箱操作，进行数值相加操作，最后发生自动装箱操作转换成Integer对象。其内部变化如下：12int result = sum.intValue() + i;Integer sum = Integer.valueOf(result); 由于我们这里声明的sum为Integer类型，在上面的循环中会创建将近4000个无用的Integer对象，在这样庞大的循环中，会降低程序的性能并且加重了垃圾回收的工作量。因此在我们编程时，需要注意到这一点，正确地声明变量类型，避免因为自动装箱引起的性能问题。 对象和原始类型值的比较包装类对象和原始类型值的比较是很容易出错的一个地方，需要注意的是，==可以用于原始值的比较，也可以用于对象的比较，但是用于对象之间的比较时，比较的不是对象代表的值，而是检查两个对象是否是同一对象。而当其中一个操作数是原始类型值或算术运算时，则比较的是数值（触发自动拆箱）。以下几个例子基本可以涵盖所有情况：123456789101112131415161718192021public class Main &#123; public static void main(String[] args) &#123; Integer a = 1; Integer b = 2; Integer c = 3; Integer d = 3; Integer e = 321; Integer f = 321; Long g = 3L; Long h = 2L; System.out.println(c==d); // 比较对象是否为同一个，因为 Integer 会缓存-128~127之间的对象 System.out.println(e==f); // 比较对象是否为同一个，数值在缓存之外 System.out.println(c==(a+b)); // a+b运算触发自动拆箱，之后数值比较 System.out.println(c.equals(a+b)); // a+b运算触发自动拆箱，之后自动装箱 System.out.println(g==(a+b)); // a+b运算触发自动拆箱，之后数值比较 System.out.println(g.equals(a+b)); // a+b运算触发自动拆箱，之后自动装箱，由于不是同一类型，equals() 返回 false System.out.println(g.equals(a+h)); // a+h运算触发自动拆箱，int类型晋升为long，之后自动装箱为Long，equals() 返回 true &#125;&#125; 其运行结果如下：1234567truefalsetruetruetruefalsetrue 参考资料 Java中的自动装箱与拆箱 深入剖析Java中的装箱和拆箱]]></content>
      <categories>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[InnoDB的MVCC实现原理]]></title>
    <url>%2F2019%2F05%2F05%2FInnoDB%E7%9A%84MVCC%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[锁的种类在数据库中经常能听到各种各样的锁，比如说悲观锁、乐观锁、行锁、表锁等等，但实际上前两者是从思想上进行划分的，而后两者是从锁粒度上进行划分的，真正的锁有共享锁和排他锁，也就是常说的读锁（S锁）和写锁（X锁）。 封锁协议在运用X锁和S锁对数据对象进行加锁时，还需要约定一些规则，例如何时申请X锁或S锁、持锁时间、何时释放等，这些规则称为封锁协议，对封锁方式规定不同的规则，就形成了各种不同的封锁协议。 一级封锁协议一级封锁协议即事务在修改某行数据时必须先对其加X锁，直到事务结束才释放，事务结束包括正常结束（COMMIT）和非正常结束（ROLLBACK）。一级封锁协议可以防止丢失修改，因为此时别的事务要想修改该数据将会阻塞到对方释放X锁，但如果仅仅是读数据不对其进行修改，是不需要加锁的，也就不能保证可重复读和脏读问题。 二级封锁协议二级封锁协议即在一级封锁协议的基础上，事务读取某数据之前必须先对其加S锁，读完后即可释放S锁。二级封锁协议除了防止丢失修改，还可以进一步防止脏读问题，但在二级封锁协议中，由于读完数据后即可释放S锁，所以它不能保证可重复读。 三级封锁协议三级封锁协议即在一级封锁协议的基础上，事务读取某数据之前必须先对其加S锁，直到事务结束才释放。三级封锁协议除了防止丢失修改和脏读问题以外，还进一步防止了不可重复读。 两段锁协议一次性锁协议指的是在事务开始时，一次性申请所有的锁，之后不会再申请任何锁，如果其中某个锁不可用，则整个申请就不成功，事务就不会执行，一次性释放所有的锁。一次性锁协议不会产生死锁的问题，但事务的并发度不高。 InnoDB遵循的是两段锁协议，将事务分成两个阶段，加锁阶段和解锁阶段（所以叫两段锁）： 加锁阶段：事务只能加锁，也可以操作数据，但不能解锁，直到事务释放第一个锁，就进入解锁阶段 解锁阶段：事务只能解锁，也可以操作数据，但不能加锁 两段锁协议使得事务具有较高的并发度，但是没有解决死锁的问题，因为它在加锁阶段没有顺序要求，如两个事务分别申请了A、B锁，接着又申请了对方的锁，此时进入死锁状态。 多版本并发控制（MVCC）为了提高并发性能，让读写之间能不用相互阻塞，InnoDB实现了MVCC，不再单纯的使用行锁来进行数据库的并发控制，取而代之的是把数据库的行锁与行的多个版本结合起来，只需要很小的开销，就可以实现非锁定读，从而大大提高数据库系统的并发性能。 redo/undo log为了支持事务，InnoDB实现了redo log与undo log： redo log：保存执行的sql语句到一个指定的log文件，当MySQL执行recovery时重新执行redo log记录的sql操作即可，当客户端执行每条sql时，redo log首先会被写入log buffer，当客户端执行COMMIT时，log buffer中的内容会被视情况刷新到磁盘。redo log在磁盘上作为一个独立的文件存在，即InnoDB的log文件。 undo log：与redo log相反，undo log是为回滚而用，把该行修改前的值copy到undo buffer，在适合的时间把undo buffer中的内容刷新到磁盘。与redo log不同的是，磁盘上不存在单独的undo log文件，所有的undo log均存放在.ibd数据文件中。 隐藏字段在MySQL中，InnoDB为每行记录都实现了三个隐藏字段： 6字节的DB_TRX_ID：事务ID，每处理一个事务，其值自动+1 7字节的DATA_ROLL_PTR：回滚指针，指向该行修改前的上一个历史版本 6字节的DB_ROW_ID：如果表中没有显示定义主键或者没有唯一非空索引时InnoDB会自动创建 当插入一条新数据时，记录上对应的回滚指针为null： 更新记录时，原记录将被放入到undo log中，并通过DATA_ROLL_PT指向该记录： MySQL就是根据记录上的回滚指针及事务ID判断记录是否可见，如果不可见则按照DATA_ROLL_PT继续回溯查找。 通过read view判断行记录是否可见) 相关源码如下：1234567891011121314151617181920bool changes_visible(trx_id_t id,const table_name_t&amp; name) constMY_ATTRIBUTE((warn_unused_result))&#123;ut_ad(id &gt; 0);//如果ID小于Read View中最小的, 则这条记录是可以看到。说明这条记录是在select这个事务开始之前就结束的if (id &lt; m_up_limit_id || id == m_creator_trx_id) &#123;return(true);&#125;check_trx_id_sanity(id, name);//如果比Read View中最大的还要大，则说明这条记录是在事务开始之后进行修改的，所以此条记录不应查看到if (id &gt;= m_low_limit_id) &#123;return(false);&#125; else if (m_ids.empty()) &#123;return(true);&#125;const ids_t::value_type* p = m_ids.data();return(!std::binary_search(p, p + m_ids.size(), id)); //判断是否在Read View中， 如果在说明在创建Read View时 此条记录还处于活跃状态则不应该查询到，否则说明创建Read View是此条记录已经是不活跃状态则可以查询到&#125; 这里需要注意的是，InnoDB的MVCC仅针对RR和RC这两种隔离级别而言。对于Read Uncommitted，由于读取到的总是最新的数据，不管该记录是否已经提交，因此不会遍历版本链，也就不需要MVCC；对于Serializable级别，从MVCC并发控制退化为基于锁的并发控制，读加共享锁，写加排他锁，读写相互阻塞。而对于RR和RC级别，它们对于MVCC的可见性实现也是不同的： RC：事务内的每个查询语句都会重新创建read view，这样就会产生不可重复读的现象发生 RR：事务开始时创建read view，直到事务结束的这段时间内每一次查询都不会重建read view，从而实现了可重复读 总结MVCC是一种用来解决读-写冲突的无锁并发控制机制，它所支持的RR和RC两种隔离级别，读写之间不会被阻塞，大大提高了并发性能。InnoDB实现的四种隔离级别，总体就是通过MVCC+2PL实现的。 参考资料 MVCC原理探究及MySQL源码实现分析 【mysql】关于innodb中MVCC的一些理解 Innodb中的事务隔离级别和锁的关系 乐观锁和 MVCC 的区别？ MySQL 是如何实现四大隔离级别的？ 两阶段锁协议]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>InnoDB</tag>
        <tag>MVCC</tag>
        <tag>封锁协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java序列化与反序列化机制]]></title>
    <url>%2F2019%2F05%2F04%2FJava%E5%BA%8F%E5%88%97%E5%8C%96%E4%B8%8E%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[前言序列化是一种对象持久化的手段，使用Java对象序列化，保存对象时会将其状态保存为一组字节，在之后可以再将这些字节组装成对象。简单来说，要实现Java对象的序列化，我们只需要让被序列化类实现Serializable接口，并且使用ObjectInputStream和ObjectOutputStream进行对象的读写即可。但是，关于Java序列化和反序列化其实还有一些更深层次的特性需要了解。 如何实现对象的序列化首先，先介绍一下如何将对象序列化并反序列化。在Java中，被序列化的类必须实现Serializable接口，然后通过ObjectInputStream和ObjectOutputStream进行对象的读写即可实现对象的序列化与反序列化：1234567891011121314151617181920212223242526272829303132333435public class Person implements Serializable &#123; String name; Integer age; public Person(String name, Integer age) &#123; this.name = name; this.age = age; &#125; @Override public String toString() &#123; return "Person&#123;" + "name='" + name + '\'' + ", age=" + age + '&#125;'; &#125;&#125;public class Test &#123; public static void main(String[] args) throws IOException, ClassNotFoundException &#123; Person person = new Person("LiHua", 19); ObjectOutputStream oo = new ObjectOutputStream(new FileOutputStream("test.txt")); oo.writeObject(person); oo.close(); ObjectInputStream oi = new ObjectInputStream(new FileInputStream("test.txt")); Person anotherPerson = (Person) oi.readObject(); oi.close(); System.out.println(person); System.out.println(anotherPerson); System.out.println(person == anotherPerson); &#125;&#125; 控制台输出如下：123Person&#123;name=&apos;LiHua&apos;, age=19&#125;Person&#123;name=&apos;LiHua&apos;, age=19&#125;false 可以看出，对象在序列化到文件后，可以再通过反序列化重新加载进内存，不过虽然这两个对象的属性值都相同，可是它们并不是同一个对象，它们的内存地址并不相同。 这里需要注意的是，被序列化类虽然实现了Serializable接口，但这个接口并不包含任何方法，仅仅起到标识的作用，那么它是在什么地方起到作用的呢？这里就要从ObjectOutputStream的writeObject方法的调用栈去寻找：writeObject-&gt;writeObject0-&gt;writeOrdinaryObject-&gt;writeSerialData-&gt;invokeWriteObject，在writeObject0这个方法中有这么一段代码：12345678910111213141516if (obj instanceof String) &#123; writeString((String) obj, unshared);&#125; else if (cl.isArray()) &#123; writeArray(obj, desc, unshared);&#125; else if (obj instanceof Enum) &#123; writeEnum((Enum&lt;?&gt;) obj, desc, unshared);&#125; else if (obj instanceof Serializable) &#123; writeOrdinaryObject(obj, desc, unshared);&#125; else &#123; if (extendedDebugInfo) &#123; throw new NotSerializableException( cl.getName() + "\n" + debugInfoStack.toString()); &#125; else &#123; throw new NotSerializableException(cl.getName()); &#125;&#125; 也就是说，在序列化时该方法会先判断被序列化的类是否是String、Array、Enum或Serializable类型，如果不是则直接抛出NotSerializableException异常。 serialVersionUID虚拟机是否允许反序列化，不仅取决于类路径和功能代码是否一致，还有一个非常重要的一点是两个类的序列化ID是否一致，也就是我们可以在被序列化的类中加上private static final long serialVersionUID = 1L;来控制该类的序列化版本号，如果序列化与反序列化的该属性不同，则会抛出异常。这个序列化ID可以是随机的一个不重复的long型数值，但是如果没有特殊需求的话，使用默认的1L就可以了。 transient关键字transient关键字的作用是控制变量的序列化，在变量声明前加上该关键字，可以阻止该变量被序列化到文件中，在被反序列化后，transient变量的值被设为初始值，如int型的是0，对象型的是null。但是，其实我们也可以使用自定义的序列化和反序列化策略，将transient修饰过的变量序列化到文件中，在ArrayList中就有这样的应用：1transient Object[] elementData; 我们知道，ArrayList的本质其实就是通过数组存储元素，但是查看源码会发现这个存储元素的数组elementData被transient修饰了，这并不意味着它就无法被序列化了，相反，ArrayList通过writeObject和readObject方法以自定义的方式将其序列化并反序列化：123456789101112131415161718192021222324252627282930313233343536373839404142private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException&#123; // Write out element count, and any hidden stuff int expectedModCount = modCount; s.defaultWriteObject(); // Write out size as capacity for behavioural compatibility with clone() s.writeInt(size); // Write out all elements in the proper order. for (int i=0; i&lt;size; i++) &#123; s.writeObject(elementData[i]); &#125; if (modCount != expectedModCount) &#123; throw new ConcurrentModificationException(); &#125;&#125; private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; elementData = EMPTY_ELEMENTDATA; // Read in size, and any hidden stuff s.defaultReadObject(); // Read in capacity s.readInt(); // ignored if (size &gt; 0) &#123; // be like clone(), allocate array based upon size not capacity int capacity = calculateCapacity(elementData, size); SharedSecrets.getJavaOISAccess().checkArray(s, Object[].class, capacity); ensureCapacityInternal(size); Object[] a = elementData; // Read in all elements in the proper order. for (int i=0; i&lt;size; i++) &#123; a[i] = s.readObject(); &#125; &#125;&#125; 在序列化的过程中，如果被序列化的类定义了writeObject和readObject方法，虚拟机会试图调用这两个方法进行用户自定义的序列化和反序列化，如果没有这两个方法，则默认调用是ObjectOutputStream的defaultWriteObject方法以及ObjectInputStream的defaultReadObject方法。 因此，如果我们想在序列化的过程中动态改变序列化的数值，就可以定义这两个方法。典型的应用场景就是在序列化对象数据时，有一些数据是敏感的，我们想在序列化时进行加密，而在反序列化时进行解密，那么此时就可以通过这两个方法来实现。 那么在上面的ArrayList中，又为什么要用这种方式实现序列化呢？原因是因为ArrayList实际上是动态数组，每次放满元素后都会自动扩容，此时如果实际的元素个数小于容量大小时，会将null元素也序列化到文件中。为了保证只序列化实际存在的元素，ArrayList把elementData用transient关键字修饰，并自定义了序列化反序列化的策略。 那么这个自定义的序列化反序列化策略又是在哪调用的？还是上面的调用栈writeObject-&gt;writeObject0-&gt;writeOrdinaryObject-&gt;writeSerialData-&gt;invokeWriteObject，在writeSerialData方法中我们可以看到这样一段逻辑：12345678910111213141516if (slotDesc.hasWriteObjectMethod()) &#123; // ... try &#123; curContext = new SerialCallbackContext(obj, slotDesc); bout.setBlockDataMode(true); slotDesc.invokeWriteObject(obj, this); bout.setBlockDataMode(false); bout.writeByte(TC_ENDBLOCKDATA); &#125; finally &#123; // ... &#125; curPut = oldPut;&#125; else &#123; defaultWriteFields(obj, slotDesc);&#125; 它会先通过hasWriteObjectMethod判断存在用户自定义的writeObject方法后，调用invokeWriteObject方法：12345678910111213141516171819202122void invokeWriteObject(Object obj, ObjectOutputStream out) throws IOException, UnsupportedOperationException&#123; requireInitialized(); if (writeObjectMethod != null) &#123; try &#123; writeObjectMethod.invoke(obj, new Object[]&#123; out &#125;); &#125; catch (InvocationTargetException ex) &#123; Throwable th = ex.getTargetException(); if (th instanceof IOException) &#123; throw (IOException) th; &#125; else &#123; throwMiscException(th); &#125; &#125; catch (IllegalAccessException ex) &#123; // should not occur, as access checks have been suppressed throw new InternalError(ex); &#125; &#125; else &#123; throw new UnsupportedOperationException(); &#125;&#125; 其中writeObjectMethod.invoke(obj, new Object[]{ out });是关键，正是在这里通过反射的方式调用自定义的writeObject方法的。 父类与静态变量序列化关于序列化反序列化机制还有几点需要注意的是，静态变量是无法被序列化的，原因在于序列化保存的是对象的状态，而静态变量属于类的状态。除此之外，如果被序列化的类的父类没有实现Serializable接口时，虚拟机是不会序列化父对象的，要想将父类对象也序列化，就需要让父类也实现Serializable接口。因此，如果我们想要让某些字段不被序列化，可以将这些字段抽取出来放到父类中，且让子类实现Serialzable接口，父类不实现。 总结 在Java中，只要一个类实现了Serializable接口，那么就可以通过ObjectInputStream和ObjectOutputStream将其对象进行序列化与反序列化。 如果两个类的serialVersionUID不同，则无法被反序列化，此时会抛出异常。 序列化不保存静态变量。 要想将父类对象也序列化，就需要让父类也实现Serializable接口。 将被序列化的类的字段用transient关键字修饰，可以阻止该字段被序列化，在被反序列化时，该变量的值会被设为初始值。 可以通过定义writeObject和readObject方法实现自定义的序列化反序列化策略，如对敏感数据进行加密与解密。 参考资料 Java 序列化的高级认识 深入分析Java的序列化与反序列化]]></content>
      <categories>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java中的深拷贝与浅拷贝]]></title>
    <url>%2F2019%2F05%2F04%2FJava%E4%B8%AD%E7%9A%84%E6%B7%B1%E6%8B%B7%E8%B4%9D%E4%B8%8E%E6%B5%85%E6%8B%B7%E8%B4%9D%2F</url>
    <content type="text"><![CDATA[简介 浅拷贝：对基本数据类型进行值传递，对引用数据类型进行引用传递的拷贝。 深拷贝：对基本数据类型进行值传递，对引用数据类型，创建一个新的对象并复制其内容，做到了真正完全的拷贝。 浅拷贝实现以下场景中有两个类，一个是Parent，一个是Child：12345678910111213141516171819202122public class Parent implements Cloneable &#123; String parentName; Child child; public Parent(String parentName, Child child) &#123; this.parentName = parentName; this.child = child; &#125; @Override protected Object clone() throws CloneNotSupportedException &#123; return super.clone(); &#125;&#125;public class Child &#123; String childName; public Child(String childName) &#123; this.childName = childName; &#125;&#125; 要实现浅拷贝，只需要让Parent实现Cloneable接口，并覆盖Object的clone()方法即可。以下为测试代码：12345678910111213public class Test &#123; public static void main(String[] args) throws CloneNotSupportedException &#123; Parent parent1 = new Parent("parent name", new Child("child name")); Parent parent2 = (Parent) parent1.clone(); System.out.println(parent1 == parent2); System.out.println(parent1.parentName); System.out.println(parent2.parentName); System.out.println("=================="); System.out.println(parent1.child == parent2.child); System.out.println(parent1.child.childName); System.out.println(parent2.child.childName); &#125;&#125; 控制台输出：1234567falseparent nameparent name==================truechild namechild name 可以看出，浅拷贝确实创建了一个新的Parent对象，并且属性parentName的值也一模一样，但是对于为引用类型的属性child，实际上与之前引用的是同一个对象。 深拷贝实现要实现深拷贝，常用的方案有以下两种： 序列化这个对象，再反序列化回来，就可以得到新的对象。 让属性也实现Cloneable。 属性实现Cloneable1234567891011121314151617181920212223242526272829public class Parent implements Cloneable &#123; String parentName; Child child; public Parent(String parentName, Child child) &#123; this.parentName = parentName; this.child = child; &#125; @Override protected Object clone() throws CloneNotSupportedException &#123; Parent parentClone = (Parent) super.clone(); parentClone.child = (Child) this.child.clone(); return parentClone; &#125;&#125;public class Child implements Cloneable &#123; String childName; public Child(String childName) &#123; this.childName = childName; &#125; @Override protected Object clone() throws CloneNotSupportedException &#123; return super.clone(); &#125;&#125; 和之前的浅拷贝不同之处在于这里Child也实现了Cloneable，并覆盖了clone()方法，而Parent的clone()方法也有略微不同，在调用了clone()方法后还调用了属性child的clone()方法重新设置属性，从而实现完完全全的拷贝。 此时控制台输出如下：1234567falseparent nameparent name==================falsechild namechild name 注意到此时原始对象和拷贝对象的child属性所引用的不再是同一个对象了。 序列化方式123456789101112131415161718192021222324252627282930public class Parent implements Serializable &#123; String parentName; Child child; public Parent(String parentName, Child child) &#123; this.parentName = parentName; this.child = child; &#125; public Object deepClone() throws Exception &#123; // 将对象写到流里 OutputStream bo = new ByteArrayOutputStream(); //OutputStream op = new ObjectOutputStream(); ObjectOutputStream oo = new ObjectOutputStream(bo); oo.writeObject(this); // 从流里读对象出来 InputStream bi = new ByteArrayInputStream(((ByteArrayOutputStream) bo).toByteArray()); ObjectInputStream oi = new ObjectInputStream(bi); return (oi.readObject()); &#125;&#125;public class Child implements Serializable &#123; String childName; public Child(String childName) &#123; this.childName = childName; &#125;&#125; 此时两个类都不需要再实现Cloneable接口并覆盖clone()方法了，但是它们都需要实现Serializable接口，并且在Parent的克隆方法中要实现序列化反序列化的逻辑，此时控制台输出如下：1234567falseparent nameparent name==================falsechild namechild name]]></content>
      <categories>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[StringBuilder与StringBuffer源码分析]]></title>
    <url>%2F2019%2F05%2F03%2FStringBuilder%E4%B8%8EStringBuffer%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[前言StringBuilder与StringBuffer是两个常用的字符串操作类，与String的不同之处在于他们是可变的，不像String的value数组被final修饰的严严实实的，而StringBuilder和StringBuffer的value数组没有被final修饰过，并且这两个类的实现几乎一样，主要的区别在于StringBuffer的方法由synchronized关键字修饰过，所以是线程安全的。这里先贴出整个体系的UML类图： AbstractStringBuilder从上面的类图也能看到，StringBuilder和StringBuffer均继承自抽象类AbstractStringBuilder，AbstractStringBuilder为子类提供了大部分的实现，因此，我们有必要先分析一下AbstractStringBuilder的源码。 成员变量AbstractStringBuilder主要有以下两个成员变量，值得注意的是value并没有被final修饰，意味着它是可变的。 1234// 与 String 一样维护一个字符数组char[] value;// 字符的个数 int count; 在这里顺便将构造函数的源码也分析了：123456AbstractStringBuilder() &#123;&#125;AbstractStringBuilder(int capacity) &#123; value = new char[capacity]; // 初始化为指定容量&#125; 扩容在分析关键的append()方法前，我们先分析一下数组的扩容操作：12345678910111213141516171819202122232425262728293031323334public void ensureCapacity(int minimumCapacity) &#123; if (minimumCapacity &gt; 0) ensureCapacityInternal(minimumCapacity);&#125;private void ensureCapacityInternal(int minimumCapacity) &#123; // overflow-conscious code if (minimumCapacity - value.length &gt; 0) &#123; // 如果所需容量大于当前容量，则进行扩容 value = Arrays.copyOf(value, newCapacity(minimumCapacity)); &#125;&#125;private int newCapacity(int minCapacity) &#123; // overflow-conscious code int newCapacity = (value.length &lt;&lt; 1) + 2; // 计算新容量为原来容量的两倍加2 if (newCapacity - minCapacity &lt; 0) &#123; // 如果计算出的新容量不够大 newCapacity = minCapacity; // 直接将新容量设为所需容量 &#125; return (newCapacity &lt;= 0 || MAX_ARRAY_SIZE - newCapacity &lt; 0) ? hugeCapacity(minCapacity) // 如果新容量大于 MAX_ARRAY_SIZE，还要做进一步判断 : newCapacity; // 否则，返回新容量即可&#125;private int hugeCapacity(int minCapacity) &#123; // 如果所需容量大于整型最大值，则直接抛出 OutOfMemoryError if (Integer.MAX_VALUE - minCapacity &lt; 0) &#123; // overflow throw new OutOfMemoryError(); &#125; // 如果所需容量大于 MAX_ARRAY_SIZE 且小于整型最大值时，返回所需容量 // 如果所需容量小于 MAX_ARRAY_SIZE，返回 MAX_ARRAY_SIZE return (minCapacity &gt; MAX_ARRAY_SIZE) ? minCapacity : MAX_ARRAY_SIZE;&#125; 上面的扩容操作逻辑有点复杂，这里先总结下流程： 默认的新容量大小为原容量大小的两倍加2，如果还不够，就直接设为所需要的容量大小 如果新容量大小比MAX_ARRAY_SIZE小，那么直接返回该新容量大小 否则，检查需要的容量大小是否超过整型最大值，如果超过则抛出异常 如果需要的容量大小比MAX_ARRAY_SIZE大，则直接返回需要的容量大小；否则，返回MAX_ARRAY_SIZE 其实这个扩容操作和ArrayList的扩容操作逻辑基本一致，这里的MAX_ARRAY_SIZE的值为Integer.MAX_VALUE - 8也就是整型的最大值减8，那么为什么要设置成这个值呢？其实在注释中也有说明，一些虚拟机的实现可能会在数组中存储header words，因此如果分配比这个值更大的容量的话，有可能会导致OutOfMemoryError。 append()接下来看看append()方法，append()方法是整个类的核心，我们在实际中也经常使用。实际上它有很多个重载方法，这里就只分析参数为String类型的方法。 123456789101112131415161718192021public AbstractStringBuilder append(String str) &#123; if (str == null) // 如果参数为 null return appendNull(); // 实际上是添加 'n' 、'u'、'l' 、'l' 四个字符到 value 数组中 int len = str.length(); ensureCapacityInternal(count + len); // 扩容 str.getChars(0, len, value, count); // 调用 String 的 getChars() 方法将 str 追加到 value 末尾 count += len; // 更新字符长度 return this; // 返回自身，支持链式调用&#125;private AbstractStringBuilder appendNull() &#123; int c = count; ensureCapacityInternal(c + 4); final char[] value = this.value; value[c++] = 'n'; value[c++] = 'u'; value[c++] = 'l'; value[c++] = 'l'; count = c; return this;&#125; 可以看到append()方法其实逻辑挺简单的，但有两点是需要注意到的，一个是追加字符串的操作是通过String的getChars()完成的，但最后还是调用的System.arraycopy()这个native方法；另一个是该方法返回的是自身this，通过这种方式，我们可以实现append()方法的链式调用。 StringBuilder上面分析的AbstractStringBuilder已经实现了大部分需要的方法了，接下来开始分析第一个子类StringBuilder，先看看构造函数：1234567891011121314151617public StringBuilder() &#123; super(16);&#125; public StringBuilder(int capacity) &#123; super(capacity);&#125; public StringBuilder(String str) &#123; super(str.length() + 16); append(str);&#125; public StringBuilder(CharSequence seq) &#123; this(seq.length() + 16); append(seq);&#125; StringBuilder有四个重载的构造函数，并且默认的初始化容量为16，当然我们也可以指定初始化容量，或者直接传入一个已有的字符序列。 append()StringBuilder的append()方法有非常多的重载，但其实都是调用父类AbstractStringBuilder的方法，在上面已经分析过了，所以这里就简单看一个：12345@Overridepublic StringBuilder append(String str) &#123; super.append(str); return this;&#125; StringBufferStringBuffer和StringBuilder的实现基本一样，只不过方法被synchronized关键字修饰了，因此是线程安全的，比如下面的append()方法：123456@Overridepublic synchronized StringBuffer append(String str) &#123; toStringCache = null; super.append(str); return this;&#125; 可以看到方法中有个toStringCache变量，这个变量是最近一次toString()方法的缓存，任何写操作都会将该缓存重设为null，我们看下这个toString()方法：1234567@Overridepublic synchronized String toString() &#123; if (toStringCache == null) &#123; toStringCache = Arrays.copyOfRange(value, 0, count); &#125; return new String(toStringCache, true);&#125; 可以看到，如果缓存为空的话，那么就会先填充缓存，否则直接使用缓存new一个新的String对象并返回，但要注意的是，这里并不会有复制操作，而是直接将String对象中的value指向这个缓存数组：1234String(char[] value, boolean share) &#123; // assert share : "unshared not supported"; this.value = value;&#125; 总结 与String不同，StringBuilder和StringBuffer都是可变字符串，底层value数组没有使用final关键字修饰 StringBuilder和StringBuffer均继承自抽象类AbstractStringBuilder，它完成了大部分方法的实现，因此子类只需要调用父类的方法即可 StringBuilder和StringBuffer的默认容量都为16，并且默认的扩容大小是原来的两倍加2 StringBuilder不是线程安全的，而StringBuffer通过synchronized关键字保证了线程安全]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
        <tag>JDK</tag>
        <tag>StringBuilder</tag>
        <tag>StringBuffer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CountDownLatch与CyclicBarrier源码分析]]></title>
    <url>%2F2019%2F05%2F03%2FCountDownLatch%E4%B8%8ECyclicBarrier%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[CountDownLatchCountDownLatch是基于AQS实现的，它使用AQS中的state成员变量作为计数器，在state不为0的情况下，凡是调用await()方法的线程将会被阻塞，并放入AQS维护的同步队列中，而当state减至0时，队列中的节点会被唤醒，被阻塞的线程即可恢复运行。先来看看它的构造函数： 1234public CountDownLatch(int count) &#123; if (count &lt; 0) throw new IllegalArgumentException("count &lt; 0"); this.sync = new Sync(count);&#125; 可以看出，它创建了一个Sync对象，并将参数传入，这个参数就是计数器的值。因此，关于CountDownLatch的分析将从这个Sync类开始。 SyncCountDownLatch中有个Sync内部类，它实现了AQS中的几个重要方法：1234567891011121314151617181920212223242526272829303132private static final class Sync extends AbstractQueuedSynchronizer &#123; Sync(int count) &#123; setState(count); // 设置 AQS 的 state 变量，也就是计数器的值 &#125; int getCount() &#123; return getState(); // 获取 AQS 的 state 变量值，也就是计数器的值 &#125; // 该方法主要是在 await() 中用到 protected int tryAcquireShared(int acquires) &#123; // 调用 getState() 方法获取 state 变量的值， // 如果等于0，则返回正数，后续将不会阻塞线程 // 如果不等于0，则返回负数，后续将会阻塞线程 return (getState() == 0) ? 1 : -1; &#125; // 该方法主要是在 countDown() 中用到 protected boolean tryReleaseShared(int releases) &#123; // 因为可能有多个线程同时调用该方法 // 所以这里使用 CAS + 循环的方式保证线程安全 for (;;) &#123; int c = getState(); if (c == 0) return false; int nextc = c-1; if (compareAndSetState(c, nextc)) // CAS 将 state 的值减一 return nextc == 0; // 如果减到0了，就返回true &#125; &#125;&#125; await()使用CountDownLatch同步组件时，基本都会使用到await()方法，当计数器不为0时，这可以阻塞调用该方法的线程。同时，通过这个方法我们也将知道上面介绍的tryAcquireShared()是在何处被调用的：12345678910111213141516171819202122232425262728293031323334353637383940public void await() throws InterruptedException &#123; // 调用 AQS 的 acquireSharedInterruptibly() 方法 sync.acquireSharedInterruptibly(1);&#125;// 此方法在AQS中实现public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) // 响应中断 throw new InterruptedException(); if (tryAcquireShared(arg) &lt; 0) // 该方法由子类 Sync 实现，如果返回值大于0，那么将直接返回 doAcquireSharedInterruptibly(arg); // 否则，将会放入同步队列中被阻塞&#125;// 此方法在AQS中实现private void doAcquireSharedInterruptibly(int arg) throws InterruptedException &#123; final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head) &#123; int r = tryAcquireShared(arg); // 由 CountDownLatch 的 Sync 具体实现 if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; countDown()这个方法也是使用CountDownLatch组件时必不可少的一个方法，当一个线程调用上面的await()方法而被阻塞时，通过countDown()方法能将计数器的值（也就是变量state的值）减一，当计数器的值减为0时，阻塞在await()上的线程也就可以正常返回了。 1234567891011121314151617181920212223242526272829303132public void countDown() &#123; // 就像 await() 调用 AQS 的 acquireSharedInterruptibly() 方法一样 // 这里调用 AQS 的 releaseShared() 方法 sync.releaseShared(1);&#125;public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; // 该方法由子类 Sync 实现，会将 state--，如果 state 为0了，就返回 true doReleaseShared(); // 唤醒同步队列中的线程 return true; &#125; return false;&#125;private void doReleaseShared() &#123; for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h); &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; if (h == head) // loop if head changed break; &#125;&#125; CyclicBarrierCyclicBarrier的作用和CountDownLatch类似，它是在计数器（等待线程数）达到指定数量后，再唤醒等待线程。它的实现和CountDownLatch不同，并没有直接通过AQS实现同步功能，而是在重入锁ReentrantLock的基础上实现的。先来了解一下它的几个成员变量：12345678910111213141516171819 private final ReentrantLock lock = new ReentrantLock();private final Condition trip = lock.newCondition(); // 当 parties 个线程到达屏障后，屏障才会放行private final int parties; // 还剩下没到达屏障的线程数，会在新一轮开启或者当前屏障被破坏时重置为 partiesprivate int count; // 当第 parties 个线程到达时回调private final Runnable barrierCommand; // 代表每一轮的运行状况，仅有一个成员变量 broken 表示屏障是否被破坏private Generation generation = new Generation();private static class Generation &#123; boolean broken = false; &#125; 接下来看看它的构造函数，与CountDownLatch一样需要传入一个计数器的初始值，除此之外，还可以传入一个回调对象，当最后一个线程到达屏障时会执行该回调逻辑： 12345678910public CyclicBarrier(int parties) &#123; this(parties, null);&#125; public CyclicBarrier(int parties, Runnable barrierAction) &#123; if (parties &lt;= 0) throw new IllegalArgumentException(); this.parties = parties; this.count = parties; // 初始时有 parties 个线程未到达屏障 this.barrierCommand = barrierAction;&#125; await()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103public int await() throws InterruptedException, BrokenBarrierException &#123; try &#123; return dowait(false, 0L); &#125; catch (TimeoutException toe) &#123; throw new Error(toe); // cannot happen &#125;&#125;private int dowait(boolean timed, long nanos) throws InterruptedException, BrokenBarrierException, TimeoutException &#123; final ReentrantLock lock = this.lock; lock.lock(); // 加锁 try &#123; final Generation g = generation; // 如果 g.broken = true，表示屏障被破坏了，这里直接抛出异常 if (g.broken) throw new BrokenBarrierException(); // 如果线程中断，则调用 breakBarrier() 破坏屏障 if (Thread.interrupted()) &#123; breakBarrier(); throw new InterruptedException(); &#125; // index 表示线程到达屏障的顺序，如果为 parties-1 表明当前是第一个到达屏障的 // 如果 index 为0，表示当前线程是最后一个到达屏障的 int index = --count; if (index == 0) &#123; // 如果 index 为0，唤醒所有处于等待状态的线程 boolean ranAction = false; try &#123; final Runnable command = barrierCommand; if (command != null) command.run(); ranAction = true; nextGeneration(); // 重置屏障状态，使其进入新一轮的运行过程中 return 0; // 返回 &#125; finally &#123; if (!ranAction) // 若执行过程中发生异常，则调用 breakBarrier() 破坏屏障 breakBarrier(); &#125; &#125; // 运行到此处的线程都会被屏障挡住，并进入等待状态 for (;;) &#123; try &#123; if (!timed) // timed 一般传入 false，因此这里条件成立 trip.await(); // 阻塞在 Condition 上 else if (nanos &gt; 0L) nanos = trip.awaitNanos(nanos); &#125; catch (InterruptedException ie) &#123; if (g == generation &amp;&amp; ! g.broken) &#123; breakBarrier(); throw ie; &#125; else &#123; // We're about to finish waiting even if we had not // been interrupted, so this interrupt is deemed to // "belong" to subsequent execution. Thread.currentThread().interrupt(); &#125; &#125; // 屏障被破坏，抛出 BrokenBarrierException 异常 if (g.broken) throw new BrokenBarrierException(); // 屏障进入新的运行轮次，此时返回线程在上一轮次到达屏障的顺序 if (g != generation) return index; // 超时判断 if (timed &amp;&amp; nanos &lt;= 0L) &#123; breakBarrier(); throw new TimeoutException(); &#125; &#125; &#125; finally &#123; lock.unlock(); &#125;&#125;/** * 开启新的一轮运行过程 */private void nextGeneration() &#123; // 唤醒所有处于等待状态中的线程 trip.signalAll(); // 重置 count count = parties; // 重新创建 Generation generation = new Generation();&#125;/** * 破坏屏障 */private void breakBarrier() &#123; // 设置屏障被破坏的标志 generation.broken = true; // 重置 count count = parties; // 唤醒所有处于等待状态中的线程 trip.signalAll();&#125; reset()CyclicBarrier的计数器可以在正常结束一轮后自动重置，当然我们也可以使用reset()方法强制重置，代码如下：12345678910public void reset() &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; breakBarrier(); // 破坏屏障 nextGeneration(); // 开启新一轮的运行过程 &#125; finally &#123; lock.unlock(); &#125;&#125; 两者区别总的来说，CountDownLatch和CyclicBarrier能够实现的功能差不多，但是CyclicBarrier可以循环使用，并且可以设置回调，因此对于复杂的业务场景，使用CyclicBarrier更合适一些。关于具体的使用场景可以参考之前的一篇文章：Java中的并发工具类 。 参考资料 Java 线程同步组件 CountDownLatch 与 CyclicBarrier 原理分析]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
        <tag>JUC</tag>
        <tag>CountDownLatch</tag>
        <tag>CyclicBarrier</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ReentrantLock源码分析]]></title>
    <url>%2F2019%2F05%2F03%2FReentrantLock%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[前言ReentrantLock可重入锁功能与synchronized类似，用于协调多线程间的同步，并且提供比synchronized更为丰富的功能，比如可响应中断、锁超时等。ReentrantLock本身的实现其实较为简单，因为大部分的复杂逻辑方法已经由AQS实现了，它只需要实现少部分的关键方法即可，所以在学习ReentrantLock之前，个人认为有必要先去了解AQS。 本文将先说明重入锁的含义、公平锁与非公平锁的对比，然后进入ReentrantLock源码的分析，最后再将其与synchronized关键字进行对比。 重入锁可重入指的是同一个线程可以对同一把锁进行重复加锁，比如线程A获取到了锁并进入了临界区，然后调用另一个同样需要该锁的方法时，它可以成功的再次获取该锁，而不会被阻塞住。那么如果锁不可重入会发生什么问题呢？很简单，还是以上面的这个例子，此时线程A再次尝试获取锁时会被阻塞，此时就发生了死锁。 ReentrantLock和synchronized关键字一样是可重入的，它的内部通过AQS的state变量记录同步状态，每当一个线程进行加锁时state++，而释放锁时state--。因此，当同一个线程重入该锁时，state就表示着该线程重入的次数。 公平与非公平ReentrantLock是可以设置公平或非公平模式的，事实上，JDK中的许多锁实现都默认为非公平模式。在这里先简单对比一下两种模式的区别： 公平锁：公平锁保障了多线程获取锁时的顺序，先到的线程先获取到锁，正常情况下每个线程都能获取到锁 非公平锁：非公平锁不保障多线程获取锁时的顺序，也就是后来的线程有可能抢占了前面先来的线程获取锁的机会 公平锁保证了每个线程都能按顺序的获取到锁，而非公平锁则有可能导致前面等待许久的线程不停被后来的线程抢占，从而出现“饥饿”问题。但是从效率上来说，非公平锁会比公平锁高出许多，原因在于唤醒一个线程是需要一定时间的，此时后来的线程可以利用这段时间获取锁并执行代码逻辑，当后来的线程释放完锁后，前面的线程可能正好完全苏醒并成功获取到锁，这就有一个充分的优势：原本因为苏醒而浪费的时间被后来的线程充分利用了，而后来的线程也不会因为进入阻塞而导致线程切换的开销。因此，非公平锁的效率其实是高于公平锁的。 源码分析了解了重入锁和公平与非公平锁后，接下来进入正式的源码分析阶段。 前面说过，ReentrantLock其实是基于AQS实现的，那么具体是怎么实现的呢？先来看看它的UML类图： 可以看出，ReentrantLock的抽象内部类Sync实现了AQS，而Sync有两个具体的子类FairSync和NonfairSync，从名字就可以看出它们分别表示公平模式和非公平模式。通过构造函数的参数可以决定选择哪种模式，如果不传入参数，则默认为非公平模式：1234567public ReentrantLock() &#123; sync = new NonfairSync();&#125;public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125; Sync先看下实现了AQS的抽象内部类，相关方法在下面会介绍，这里先省略： 123456789abstract static class Sync extends AbstractQueuedSynchronizer &#123; // 交由子类去实现，也就是 FairSync 和 NonfairSync abstract void lock(); final boolean nonfairTryAcquire(int acquires) &#123; // ... &#125; protected final boolean tryRelease(int releases) &#123; // ... &#125; // ...&#125; FairSyncFairSync继承自Sync，实现了公平模式的ReentrantLock的相关逻辑。 123456789101112131415161718192021222324252627282930313233343536373839404142 final void lock() &#123; // 直接调用 AQS 的 acquire() 方法获取锁 acquire(1); &#125; // 此方法在 AQS 中 public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; // 在 AQS 中并未实现该方法，而交由这里的 FairSync 实现 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125; protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); // 获取当前线程 int c = getState(); // 获取同步状态 if (c == 0) &#123; // 如果同步状态为0，表示没有任何一个线程持有锁 if (!hasQueuedPredecessors() &amp;&amp; // 判断前面是否有等待更长时间的线程 compareAndSetState(0, acquires)) &#123; // 如果没有，通过CAS设置同步状态 setExclusiveOwnerThread(current); // 如果设置成功了，则将当前线程设置为锁持有者 return true; &#125; &#125; // 如果同步状态不为0，并且当前线程就是锁的持有者，那么进行锁的重入操作 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; // 计算重入后的同步状态 if (nextc &lt; 0) throw new Error("Maximum lock count exceeded"); setState(nextc); // 设置重入后的同步状态 return true; &#125; // 获取锁失败，会执行AQS的加入同步队列的逻辑 return false; &#125;&#125;public final boolean hasQueuedPredecessors() &#123; Node t = tail; Node h = head; Node s; return h != t &amp;&amp; // 如果头节点的后继节点不是当前线程，说明有等待时间更长的线程，返回true ((s = h.next) == null || s.thread != Thread.currentThread());&#125; 上过过程总结如下： 执行AQS的acquire()方法 调用FairSync实现的tryAcquire()方法，如果同步状态为0，则判断有没等待时间更长的线程，如果没有的话就成功获取；若同步状态不为0，且当前线程为持锁线程，则重入该锁 其它情况，一律返回false并将当前线程加入到同步队列，该过程由AQS实现 NonfairSyncNonfairSync同样继承自Sync，实现了非公平模式的ReentrantLock的相关逻辑。 123456789101112131415161718192021222324252627282930313233final void lock() &#123; // 这里先直接CAS设置同步状态，如果设置成功，则加锁成功，不需要管同步队列前面是否有等待时间更长的线程 if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); // CAS失败了，则调用此方法进入 tryAcquire() 的逻辑 else acquire(1);&#125;protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires);&#125;final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; // 与公平模式的唯一不同，不会检查前面是否有等待时间更长的线程，直接CAS // CAS 成功就获取锁成功，失败则加入到AQS的同步队列中 if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false;&#125; 对比公平模式的FairSync和非公平模式的NonfairSync可以发现，它们的差别其实并不大，主要体现在非公平模式在获取锁时不会先检查前面有没有其它等待的线程，而是直接野蛮式CAS，成则获取锁，败则加入同步队列。 释放锁释放锁的逻辑比较简单，并且没有公平和非公平之分。 1234567891011121314151617181920212223242526272829public void unlock() &#123; sync.release(1);&#125;// 此方法在 AQS 中实现public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; // 交由子类 Sync 实现 Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); // 唤醒后继节点 return true; &#125; return false;&#125; protected final boolean tryRelease(int releases) &#123; // 计算释放锁后的同步状态 int c = getState() - releases; // 如果当前线程没有持有锁，调用该方法会抛出异常 if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; // 如果释放后的同步状态为0，表示该锁完全释放了 free = true; setExclusiveOwnerThread(null); // 将锁持有者设为 null &#125; setState(c); // 设置新的同步状态 return free; // 返回该锁是否被完全释放了&#125; 与synchronized的异同ReentrantLock和synchronized都是用于线程的同步控制，它们的共同点是都可重入，并且synchronized也是非公平锁（ReentrantLock默认为非公平）。而它们之间的不同主要在于以下几点： ReentrantLock响应中断，而synchronized不响应 ReentrantLock支持超时等待，而synchronized不支持 ReentrantLock可设置成公平锁，而synchronized不可以 发生异常时，synchronized会自动释放锁，而ReentrantLock需要手动释放锁 除此之外，ReentrantLock还提供了丰富的接口用于获取锁的状态，比如可以通过isLocked()查询ReentrantLock对象是否处于绑定状态，也可以通过getHoldCount()获取ReentrantLock的加锁次数，也就是重入次数，不过它们的本质都是调用AQS实现的getState()方法。 参考资料 Java 重入锁 ReentrantLock 原理分析]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
        <tag>JUC</tag>
        <tag>ReentrantLock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AQS源码分析：Condition]]></title>
    <url>%2F2019%2F05%2F02%2FAQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%9ACondition%2F</url>
    <content type="text"><![CDATA[前言Condition是一个与Object中的wait() / nofity() / notifyAll()功能相似的接口，AQS的内部类ConditionObject实现了该接口。它与Object提供的这些方法一样用来协调线程间的同步关系，而不同之处在于Object中的这些方法需要配合Synchronized关键字使用（否则会抛出异常），而Condition中的方法则要配合锁（独占锁）来使用（否则也会抛出异常）。 ConditionObject内部维护了一个条件队列，当线程不满足某些条件的时候就会通过await()方法将当前线程加入到条件队列中，而当条件队列上等待的线程被signal() / signalAll()后，又会被转移到AQS的同步队列中尝试获取锁。接下来就其中最核心的三个方法await()、signal()、signalAll()说起，它们也分别对标了Object中的那三个方法。 await()await()方法负责将当前线程包装成一个Node后加入到条件队列中，并且需要释放持有的独占锁进入阻塞状态。这里先总结一下它的大致流程： 将当前线程加入到条件队列中 完全释放互斥锁 如果当前线程未在同步队列中，就将其阻塞 否则，重新获取锁并根据是否发生中断而做出不同反应（抛出异常或重新中断） 12345678910111213141516171819202122232425262728public final void await() throws InterruptedException &#123; if (Thread.interrupted()) // 响应中断 throw new InterruptedException(); // &lt;1&gt; 将当前线程包装成 Node 并加入到条件队列中 Node node = addConditionWaiter(); // &lt;2&gt; 完全释放互斥锁（不论锁是否可以重入），如果没有持锁，会抛出异常 int savedState = fullyRelease(node); int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; // &lt;3&gt; 只要仍未转移到同步队列就阻塞，转移的情况如下： // 1. 其它线程调用 signal 将当前线程节点转移到同步队列并唤醒当前线程 // 2. 其它线程调用 signalAll // 3. 其它线程中断了当前线程，当前线程会自行尝试进入同步队列 LockSupport.park(this); // 获取中断模式。在线程从park中被唤醒的时候，需要判断此时是否被中断，若中断则尝试转移到同步队列 if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; // &lt;4&gt; 重新获取互斥锁过程中如果发生中断并且 interruptMode 不为 THROW_IE，则将 interruptMode 设置为 REINTERRUPT if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); // 如果线程发生过中断则根据 THROW_IE 或是 REINTERRUPT 分别抛出异常或者重新中断 if (interruptMode != 0) reportInterruptAfterWait(interruptMode);&#125; addConditionWaiter()首先看看第一个关键步骤，也就是将当前线程加入到条件队列中：123456789101112131415161718private Node addConditionWaiter() &#123; Node t = lastWaiter; // 如果条件队列中最后一个节点的状态是 CANCELLED if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) &#123; unlinkCancelledWaiters(); // 清理队列 t = lastWaiter; // 重读 lastWaiter &#125; // 将当前线程封装为一个 Node Node node = new Node(Thread.currentThread(), Node.CONDITION); if (t == null) // 如果当前队列没有节点 firstWaiter = node; else // 将当前队列的尾节点连接到新节点 t.nextWaiter = node; // 将新节点作为新尾节点 lastWaiter = node; // 返回新节点 return node;&#125; 这里会先判断条件队列中的最后一个节点是否为取消状态，如果是的话就调用unlinkCancelledWaiters()进行清理，清理的过程其实就是将条件队列中所有取消的节点都移除。之后将当前线程封装成Node后与当前队列最后一个节点的nextWaiter关联即可。 fullyRelease()此时已经将线程加入到条件队列中了，调用fullyRelease()方法完全释放同步状态。这里的“完全”指的是对于重入锁来说，每次加锁都会将AQS的整型成员变量state++，而每次解锁时会将state--，因此这里将state的数量完全释放掉。 123456789101112131415161718final int fullyRelease(Node node) &#123; boolean failed = true; try &#123; // 获取同步状态数值 int savedState = getState(); // 调用 release() 释放指定数量的同步状态 if (release(savedState)) &#123; failed = false; return savedState; // 返回释放的数量 &#125; else &#123; throw new IllegalMonitorStateException(); &#125; &#125; finally &#123; // 如果释放时出现异常，将该 Node 的等待状态设置为 CANCELLED if (failed) node.waitStatus = Node.CANCELLED; &#125;&#125; isOnSyncQueue()该方法用于判断某个节点是否转移到了同步队列上（因为别的线程有可能通过signal() / signalAll()将其转移了），如果没有就将其阻塞。 12345678910111213141516171819final boolean isOnSyncQueue(Node node) &#123; // 等待状态如果是 CONDITION 则一定是在条件队列，或者如果 prev 为 null 也一定是在条件队列 // （同步队列新入队的节点的 prev 值是不可能为 null 的，因为有dummy节点的存在） if (node.waitStatus == Node.CONDITION || node.prev == null) return false; // 不在同步队列中，直接返回 false // 条件队列的节点是通过 nextWaiter 来维护的，不用 next 和 prev，因此如果节点在条件队列中则 next 和 prev 应该都为 null // 如果 next 不为 null，则说明一定是在同步队列中 // 这里还要说明的是在 cancelAcquire() 方法中，一个节点取消的时候会把自己的 next 域指向自己，即 node.next = next; 而不是node.next = null; // 通过这种方式，在这里就可以将其和在同步队列上的情况归一化判断，都返回 true // 如果 cancelAcquire() 方法中写成 node.next = null; 的形式，这里的判断不满足条件，那么又要往底下进一步判断 if (node.next != null) return true; // 虽然 node.prev 为 null 可以说明此时节点不在同步队列中， // 但如果 node.next 为 null 并不能说明 node 就不在同步队列中，因为新节点入队时会先设置 prev 然后再设置 next // 此时由 tail 节点开始从后向前遍历一次，确定节点是否真的不在同步队列中 return findNodeFromTail(node);&#125; checkInterruptWhileWaiting()checkInterruptWhileWaiting()方法用于检测线程在等待期间是否发生了中断，注意该方法是在LockSupport.park(this);这一行之后，也就是说此时线程已经从阻塞中返回了，返回的原因有可能是因为中断，也有可能是因为signal() / signalAll()。 12345678910111213141516171819202122232425262728private int checkInterruptWhileWaiting(Node node) &#123; // 检测线程在等待期间是否发生了中断，如果未发生中断，直接返回0 return Thread.interrupted() ? (transferAfterCancelledWait(node) ? THROW_IE : REINTERRUPT) : 0;&#125;/** * 判断中断发生的时期，分为两种： * 1. 中断在节点被转移到同步队列前发生，此时返回 true * 2. 中断在节点被转移到同步队列后发生，此时返回 false */final boolean transferAfterCancelledWait(Node node) &#123; // 第一种情况，中断在节点被转移到同步队列前发生 // 此时自行将节点转移到同步队列上，并返回 true if (compareAndSetWaitStatus(node, Node.CONDITION, 0)) &#123; enq(node); return true; &#125; // 如果上面的CAS失败了，说明已经有线程调用 signal() / signalAll() 方法了， // 这两个方法都会先将节点等待状态由 CONDITION 设为0后，再调用 enq() 方法转移节点 // 此时有可能仅设置了等待状态而没来得及将节点转移到同步队列中就被切换走了， // 此时自旋等待节点成功进入同步队列 while (!isOnSyncQueue(node)) Thread.yield(); // 让出 CPU return false;&#125; 执行完上面几个方法，当从while (!isOnSyncQueue(node))循环中跳出时，说明节点已经转移到了同步队列中了，此时通过acquireQueued(node, savedState)方法重新获取锁，并且如果线程发生过中断则根据THROW_IE或是REINTERRUPT分别抛出异常或者重新中断。 signal() / signalAll()上面的await()方法中从while (!isOnSyncQueue(node))循环跳出可不是自己独立就能做到的，它是需要signal() / signalAll()配合的。signal() / signalAll()的工作就是负责将条件队列中的节点转移到同步队列中，两个方法的区别在于signal()只会转移首节点，而signalAll()会转移队列上的所有节点。 123456789101112131415161718192021222324252627282930313233343536public final void signal() &#123; // 检查线程是否获取了独占锁，未获取独占锁调用 signal 方法是不允许的 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) // 头节点不为 null doSignal(first); // 将头节点转移到同步队列中&#125;private void doSignal(Node first) &#123; do &#123; // 如果下面这个条件满足了，说明条件队列中只有一个节点，此时 lastWaiter 设为 null if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; first.nextWaiter = null; // 调用 transferForSignal() 将节点转移到同步队列中，如果失败，且 firstWaiter 不为null，则继续尝试，transferForSignal() 成功了或者队列中没节点了，while 循环就结束了 &#125; while (!transferForSignal(first) &amp;&amp; (first = firstWaiter) != null);&#125;// 这个方法用于将条件队列中的节点转移到同步队列中final boolean transferForSignal(Node node) &#123; // 如果将节点的等待状态由 CONDITION 设为0失败，则表明节点被取消 // 注意：因为 transferForSignal() 不存在竞争的问题，所以唯一的可能就是节点被取消 if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; // 调用 enq() 方法将 node 转移到同步队列中，并返回 node 的前驱节点（原尾节点）p Node p = enq(node); int ws = p.waitStatus; // 如果前驱结点状态为取消或者无法将状态CAS到SIGNAL， // 则需要唤醒参数node节点对应的线程，使其能开始尝试争锁 if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) LockSupport.unpark(node.thread); return true;&#125; 可以看出，signal()一定会转移条件队列中的一个节点，除非队列中彻底空了。 12345678910111213141516171819public final void signalAll() &#123; // // 检查线程是否获取了独占锁，未获取独占锁调用 signalAll() 方法是不允许的 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignalAll(first);&#125;private void doSignalAll(Node first) &#123; lastWaiter = firstWaiter = null; // 将条件队列中所有节点都转移到同步队列中，与 doSignal() 的主要区别在于 while 循环条件上 do &#123; Node next = first.nextWaiter; first.nextWaiter = null; transferForSignal(first); // 调用 transferForSignal() 将节点转移到同步队列中 first = next; &#125; while (first != null);&#125; signalAll()与signal()的主要不同在于循环条件中，因为它会将条件队列中的所有节点都转移，因此实现起来稍微简单一些。 JDK BUG这里再讲一下jdk在上面实现中的一个bug。对比上面await()和signal() / signalAll()的源码可以发现，await()方法并没有做同步控制，也就是signal() / signalAll()方法开头的if (!isHeldExclusively()) throw new IllegalMonitorStateException();。因此，如果没有获取锁就调用该方法，会产生线程竞争的情况，导致条件队列的结构被破坏。例如，以下添加节点到条件队列的方法： 123456789101112131415161718private Node addConditionWaiter() &#123; Node t = lastWaiter; // 如果条件队列中最后一个节点的状态是 CANCELLED if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) &#123; unlinkCancelledWaiters(); // 清理队列 t = lastWaiter; // 重读 lastWaiter &#125; // 将当前线程封装为一个 Node Node node = new Node(Thread.currentThread(), Node.CONDITION); if (t == null) // 如果当前队列没有节点 firstWaiter = node; else // 将当前队列的尾节点连接到新节点 t.nextWaiter = node; // 将新节点作为新尾节点 lastWaiter = node; // 返回新节点 return node;&#125; 如果有两个线程同时执行到if (t == null)时，可能会造成firstWaiter先指向其中一个，之后却被另一个给覆盖了，那么此时其中一个线程将会一直阻塞下去，因为这个线程的node并不在条件队列中，也就永远不会被signal() / signalAll()转移到同步队列上，唯一能从阻塞中返回的可能就是被中断。 参考资料 AbstractQueuedSynchronizer源码解读–续篇之Condition AbstractQueuedSynchronizer 原理分析 - Condition 实现原理]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>AQS</tag>
        <tag>源码分析</tag>
        <tag>JUC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AQS源码分析：独占与共享同步状态]]></title>
    <url>%2F2019%2F05%2F02%2FAQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%9A%E7%8B%AC%E5%8D%A0%E4%B8%8E%E5%85%B1%E4%BA%AB%E5%90%8C%E6%AD%A5%E7%8A%B6%E6%80%81%2F</url>
    <content type="text"><![CDATA[前言AQS就是java.util.concurrent.locks包下的AbstractQueuedSynchronizer类，这个类也是整个并发包的核心之一。并发包中像ReentrantLock、CountDownLatch等同步组件都有一个内部类Sync，而所有的Sync都是继承自AbstractQueuedSynchronizer，因此，可以看出AQS的重要性是十分高的。 AQS主要的工作是维护线程同步队列（CLH）并且负责线程的阻塞和唤醒，它的方法基本可以分为三类： 独占式获取与释放同步状态 共享式获取与释放同步状态 查询同步队列中的等待线程情况 所谓独占就是一次只有一个线程能够获取，其它线程必须等它释放，共享则可以有多个线程同时获取。 CLH队列AQS内部维护着一个FIFO双向队列，该队列就是CLH同步队列，AQS依赖它来完成同步状态的管理： 当前线程如果获取同步状态失败时，AQS会将当前线程以及等待状态等信息构成一个节点Node并将其加入到CLH同步队列，同时会阻塞当前线程。 当同步状态释放时，会把首节点唤醒，使其再次尝试获取同步状态。 CLH同步队列的结构图如下： NodeNode是AQS的静态内部类：1234567891011121314151617181920212223242526272829303132333435363738static final class Node &#123; // 共享式节点，标记节点在共享模式下等待 static final Node SHARED = new Node(); // 独占式节点，标记节点在独占模式下等待 static final Node EXCLUSIVE = null; // 因为超时或中断，节点会被设置为取消状态，不会参与到竞争当中 static final int CANCELLED = 1; // 表示当前节点的线程如果释放了同步状态或者被取消，将会通知后继节点，使后继节点的线程得以运行 static final int SIGNAL = -1; // 节点在条件队列中，节点线程等待在 Condition 上，当其它线程对 Condition 调用了 signal() / signalAll() 后，该节点会从条件队列转移到同步队列，加入到同步状态的获取中 static final int CONDITION = -2; // 下一次共享模式的同步状态获取会无条件地传播下去 static final int PROPAGATE = -3; // 等待状态，也就是上面这几个，不过初始值为0 volatile int waitStatus; // 前驱结点 volatile Node prev; // 后继节点 volatile Node next; // 此节点的线程 volatile Thread thread; // 见 ConditionObject Node nextWaiter; // ... &#125; 入队入队操作过程是很简单的，只需要将tail指向新节点、新节点的prev指向当前最后的节点、当前最后的节点的next指向当前节点即可。但是在CLH的实现中需要考虑并发的情况，它通过CAS的方式，来保证正确的添加Node：1234567891011121314151617181920212223242526272829303132333435private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // 新建节点 // 记录原尾节点 Node pred = tail; if (pred != null) &#123; // 设置新Node的前驱结点为原尾节点 node.prev = pred; // CAS设置新Node为新的尾节点 if (compareAndSetTail(pred, node)) &#123; pred.next = node; // 设置成功，将原尾节点的后继节点设为新节点 return node; // 返回新节点 &#125; &#125; enq(node); // 失败，多次尝试直到成功 return node; // 返回新节点&#125;private Node enq(final Node node) &#123; for (;;) &#123; // 多次尝试直到成功 Node t = tail; // 记录原尾节点 if (t == null) &#123; // 原尾节点不存在 // 创建首尾节点都为 new Node()，作为一个占位节点（空节点） if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; // 原尾节点存在 // 将原尾节点设置为新节点的前驱节点 node.prev = t; // CAS设置新Node为新的尾节点 if (compareAndSetTail(t, node)) &#123; t.next = node; // 设置成功，将原尾节点的后继节点设为新节点 return t; // 返回新节点 &#125; &#125; &#125;&#125; 总体来说就是使用CAS设置新节点为尾节点，如果设置成功则返回新节点，如果失败则继续不断自旋CAS设置新节点为尾节点直到成功。 出队首节点的线程释放同步状态后，会唤醒它的后继节点，后继节点在获取同步状态成功时将自己设置为首节点，因为只有一个线程能够成功获取到同步状态，所以该过程不需要CAS来保证：12345private void setHead(Node node) &#123; head = node; node.thread = null; // 将未使用的字段设为null以帮助GC node.prev = null;&#125; LockSupport在进入AQS的核心源码之前有必要先了解一下大量使用到的LockSupport类。 LockSupport也是基于UNSAFE的操作，提供park()用来阻塞线程和unpark()用来唤醒线程，LockSupport的机制是每次unpark()给线程一个“许可”，并且这个许可最多只能为1，如果当前线程有许可，那么park()方法会消耗一个并返回，否则会阻塞线程直到线程重新获得许可，在线程启动之前调用park() / unpark()没有任何效果。 这里简单的讲一下LockSupport.park() / unpark()与object.wait() / notify()的区别，他们主要的区别在于语义上的不同，阻塞和唤醒是对于线程来说的，LockSupport的park() / unpark()以线程作为方法的参数，更符合这个语义；而notify()只能随机唤醒一个线程，notifyAll()会唤醒所有线程，无法准确的控制某一个线程。 Thread.interruptAQS中大量用了中断，也就是Thread的interrupt()方法，但要注意的是该方法并不会中断一个正在运行的线程：当调用一个线程的该方法时，如果该线程处于被阻塞状态（如Object.wait()、Thread.join()、Thread.sleep()），那么线程将立即退出被阻塞状态，并抛出一个InterruptedException异常；而如果线程正在运行，那么会将该线程的中断标志设置为true，此时线程将继续正常运行。 LockSupport.park()也能响应中断信号，但它不会抛出InterruptedException异常，因此要想知道线程是被unpark()还是中断，就依赖于该线程的中断标志，可以通过Thread的interrupted()或isInterrupted()方法获取该值，两个方法的区别是interrupted()获取后会将标志位重置为false。 同步状态的获取与释放接下来进入AQS比较关键的部分：同步状态的获取与释放。这里主要分为以下两类进行分析： 独占式获取与释放同步状态 共享式获取与释放同步状态 独占式获取独占就是一次只有一个线程能够获取到同步状态。首先来看独占式同步状态获取的方法：12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 该方法是一个模板方法，其中tryAcquire(arg)方法需要自定义同步组件（子类）自己去实现，它尝试获取同步状态，获取成功则设置锁状态并返回true，此时该方法就可以直接返回了；否则获取失败返回false，调用addWaiter(Node mode)方法将当前线程包装成Node加入到CLH同步队列尾部（上面已经介绍过），并且mode参数为Node.EXCLUSIVE，表示独占模式。 接下来会调用boolean acquireQueued(final Node node, int arg)方法，每个线程包装成Node进入同步队列后都会在该方法中自旋，一旦条件满足，获取到同步状态后，就可以从这个自旋过程中退出，否则会一直执行下去：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; // 记录是否获取同步状态成功 try &#123; boolean interrupted = false; // 记录该过程中是否发生过线程中断 for (;;) &#123; // 开始自旋 final Node p = node.predecessor(); // 获取当前线程的前驱节点 if (p == head &amp;&amp; tryAcquire(arg)) &#123; // 当前线程的前驱节点是头节点，且获取同步状态成功 setHead(node); // 将当前线程设置为头节点 p.next = null; // help GC failed = false; return interrupted; &#125; // 如果获取同步状态失败，则根据条件判断是否应该阻塞自己 // 如果不阻塞，CPU 就会处于忙等状态，这样会浪费 CPU 资源 // 并且从阻塞中返回时，要判断是否是因为中断造成的 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; // 因为 parkAndCheckInterrupt 方法中会将中断标志清除，所以这里重新设为true &#125; &#125; finally &#123; if (failed) // 获取同步状态发生异常，取消获取 cancelAcquire(node); &#125;&#125;private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; // 获得前驱节点的等待状态 if (ws == Node.SIGNAL) // 表示pred的下一个节点也就是node的线程需要阻塞等待。在pred的线程释放同步状态时会对node的线程进行唤醒通知，所以这里返回true表示当前线程可以放心的被park return true; if (ws &gt; 0) &#123; // Node.CANCELLED // 等待状态为CANCELLED时，表示此时前驱结点已经等待超时或者被中断了，需要从CLH队列中将前驱节点删除，循环回溯，直到前一个节点状态 &lt;= 0 do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; // 0 或 Node.PROPAGATE // CAS将状态修改为Node.SIGNAL，但是会返回false，这一次不会park compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125;private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); // 上面的方法一旦返回true了，就会执行此方法将当前线程park return Thread.interrupted(); // 判断是否因为中断而醒的，并且将中断标志清除&#125;private void cancelAcquire(Node node) &#123; if (node == null) return; // 节点的等待线程置空 node.thread = null; // 跳过已经取消了的前驱结点 Node pred = node.prev; while (pred.waitStatus &gt; 0) node.prev = pred = pred.prev; // 记录非取消状态的前驱节点的后继节点，注意不是当前节点node Node predNext = pred.next; // 将当前节点等待状态设为 CANCELLED node.waitStatus = Node.CANCELLED; // 如果当前节点是尾节点，则通过CAS设置前驱节点pred为尾节点 // 以下两个CAS即使失败了也没关系，失败了说明pred此时已经是尾节点了 if (node == tail &amp;&amp; compareAndSetTail(node, pred)) &#123; // 如果设置成功，就通过CAS将pred的next置空，那么中间被取消的节点就“消失”了 compareAndSetNext(pred, predNext, null); &#125; else &#123; int ws; // 根据条件判断是唤醒后继节点，还是将前驱节点和后继节点连接到一起 if (pred != head &amp;&amp; ((ws = pred.waitStatus) == Node.SIGNAL || (ws &lt;= 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp; pred.thread != null) &#123; Node next = node.next; // 这里使用 CAS 设置 pred 的 next，表明多个线程同时在取消，这里存在竞争。 // 不过此处没针对 compareAndSetNext 方法失败后做一些处理，表明即使失败了也没关系。 // 实际上，多个线程同时设置 pred 的 next 引用时，只要有一个能设置成功即可 if (next != null &amp;&amp; next.waitStatus &lt;= 0) compareAndSetNext(pred, predNext, next); &#125; else &#123; /* * 唤醒后继节点对应的线程。这里简单讲一下为什么要唤醒后继线程，考虑下面一种情况： * head node1 node2 tail * ws=0 ws=1 ws=-1 ws=0 * +------+ prev +-----+ prev +-----+ prev +-----+ * | | &lt;---- | | &lt;---- | | &lt;---- | | * | | ----&gt; | | ----&gt; | | ----&gt; | | * +------+ next +-----+ next +-----+ next +-----+ * * 头结点初始状态为 0，node1、node2 和 tail 节点依次入队。node1 自旋过程中调用 * tryAcquire 出现异常，进入 cancelAcquire。head 节点此时等待状态仍然是 0，它 * 会认为后继节点还在运行中，所它在释放同步状态后，不会去唤醒后继等待状态为非取消的 * 节点 node2。如果 node1 再不唤醒 node2 的线程，该线程面临无法被唤醒的情况。此 * 时，整个同步队列就回全部阻塞住。 */ unparkSuccessor(node); &#125; node.next = node; // help GC &#125;&#125;private void unparkSuccessor(Node node) &#123; int ws = node.waitStatus; // 通过 CAS 将等待状态设为 0，让后继节点线程多一次尝试获取同步状态的机会 if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); // 当前节点的后继节点 Node s = node.next; // 后继节点为null或者其状态 &gt; 0（表示超时或者被中断了） if (s == null || s.waitStatus &gt; 0) &#123; s = null; // 从tail节点开始向前遍历找到最前面的可用节点 for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; // 唤醒后继节点 if (s != null) LockSupport.unpark(s.thread);&#125; 在上面的unparkSuccessor()方法中有一个地方很有意思，就是当判断当前节点的next引用为null的时候，还需要从tail节点向前遍历找到可用的节点，之所以要这么做的原因在于：在之前的addWaiter()方法将新节点入队时，有这么一段代码：1234567// 设置新Node的前驱结点为原尾节点node.prev = pred;// CAS设置新Node为新的尾节点if (compareAndSetTail(pred, node)) &#123; pred.next = node; // 设置成功，将原尾节点的后继节点设为新节点 return node; // 返回新节点&#125; 也就是此时可能已经将新节点的prev指向了原尾节点，但原尾节点的next还并未指向新节点，因此不能从前往后遍历，而应从后往前遍历。 以下是上述步骤的流程图总结： 可以看出，虽然获取同步状态的过程表面上是自旋的操作，但是为了避免CPU资源的浪费，在获取同步状态失败后大部分情况还是进入了阻塞，但由于从阻塞中醒来不一定代表就可以获得同步状态了（有可能因为中断），所以此时会通过这个自旋循环再一次的去尝试获取同步状态，看看能不能获取成功。 独占式获取（响应中断）上面的acquire(int arg)方法对中断不响应，也就是线程被中断后，仅仅会通过selfInterrupt()方法（其实就是Thread.currentThread().interrupt()）将该线程的中断标志设置为true，然后线程继续正常运行。为了响应中断，AQS提供了acquireInterruptibly(int arg)方法，该方法在线程等待获取同步状态时如果被中断了，会立刻响应中断，抛出InterruptedException异常：12345678910111213141516171819202122232425262728293031public final void acquireInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) // 首先判断线程是否已经中断了，如果是的话就直接抛出异常 throw new InterruptedException(); if (!tryAcquire(arg)) // 尝试获取同步状态 doAcquireInterruptibly(arg);&#125;private void doAcquireInterruptibly(int arg) throws InterruptedException &#123; // 方法声明抛出异常 final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return; // 不再返回是否发生过中断 &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) // 与之前不响应中断的acquireQueued()方法唯一的区别在于这里判断发生了中断后会直接抛出异常 throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 独占式获取（超时）AQS除了提供上面两个独占式获取的方法外，还提供了一个增强版的方法tryAcquireNanos()，该方法除了能响应中断外，还提供了超时控制，即如果当前线程没有在指定时间内获取同步状态，则会返回false，否则返回true：12345678910111213141516171819202122232425262728293031323334353637383940414243public final boolean tryAcquireNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (Thread.interrupted()) // 首先判断线程是否已经中断了，如果是的话就直接抛出异常 throw new InterruptedException(); return tryAcquire(arg) || // 尝试获取同步状态 doAcquireNanos(arg, nanosTimeout);&#125;private boolean doAcquireNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (nanosTimeout &lt;= 0L) return false; // 计算超时时间 final long deadline = System.nanoTime() + nanosTimeout; final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return true; &#125; // 走到这说明获取失败，重新计算需要休眠的时间（剩余时间） nanosTimeout = deadline - System.nanoTime(); // 如果已经超时了，那么返回false if (nanosTimeout &lt;= 0L) return false; // 如果没有超时，判断了可以被park，并且nanosTimeout大于一个阈值，那么就进入休眠 // 当nanosTimeout小于阈值的时候不需要休眠，直接快速自旋 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; nanosTimeout &gt; spinForTimeoutThreshold) LockSupport.parkNanos(this, nanosTimeout); if (Thread.interrupted()) throw new InterruptedException(); // 响应中断，抛出异常 &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 独占式释放当线程获取了同步状态，执行完相应逻辑后，就需要释放同步状态。AQS提供了release(int arg)方法，释放同步状态：123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; // 由自定义同步组件自己实现 Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) // 如果头节点不为null且状态不为0（等于0说明后继节点正在运行中，不需要唤醒） unparkSuccessor(h); // 将后继节点唤醒 return true; &#125; return false;&#125; 共享式获取与独占模式不同，共享模式下，同一时刻会有多个线程获取共享同步状态。共享模式是实现读写锁中的读锁、CountDownLatch和Semaphore等同步组件的基础。 共享式同步状态获取的方法是acquireShared()，对标独占式的acquire()方法：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) // 由自定义同步组件自己实现。返回负数表示获取失败；返回0表示成功，但是后继争用线程不会成功；返回正数表示获取成功，并且后继争用线程也可能成功。 doAcquireShared(arg);&#125;private void doAcquireShared(int arg) &#123; // 与之前独占式的参数不同，这里传入一个Node.SHARED final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); // 获取当前线程的前驱节点 if (p == head) &#123; int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; // 前驱节点是头节点并且获取同步状态成功 // 设置当前节点为头节点并且向后传播，不断唤醒下一个共享式节点，从而实现多个节点线程同时获取共享同步状态 setHeadAndPropagate(node, r); p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125;private void setHeadAndPropagate(Node node, int propagate) &#123; Node h = head; // 记录原首节点 setHead(node); // 设置当前节点为新首节点 // 这里除了使用条件 propagate &gt; 0 判断是否唤醒后继节点，还有其它的一些判断依据 // 比如 propagate 是 tryAcquireShared() 的返回值，也是这是决定是否传播唤醒的依据之一 // 更为详细的解释可以参考 https://www.cnblogs.com/micrari/p/6937995.html if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &#123; Node s = node.next; if (s == null || s.isShared()) doReleaseShared(); &#125;&#125;/** * 这是共享锁中的核心唤醒函数，主要做的事情就是唤醒下一个线程或者设置传播状态。 * 后继线程被唤醒后，会尝试获取共享锁，如果成功之后，则又会调用setHeadAndPropagate，将唤醒传播下去。 * 这个函数的作用是保障在 acquire 和 release 存在竞争的情况下，保证队列中处于等待状态的节点能够有办法被唤醒。 */private void doReleaseShared() &#123;/* * 以下的循环做的事情就是，在队列存在后继线程的情况下，唤醒后继线程； * 或者由于多线程同时释放共享锁由于处在中间过程，读到head节点等待状态为0的情况下， * 虽然不能unparkSuccessor，但为了保证唤醒能够正确稳固传递下去，设置节点状态为PROPAGATE。 * 这样的话获取锁的线程在执行setHeadAndPropagate时可以读到PROPAGATE，从而由获取锁的线程去释放后继等待线程。 */ for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h); &#125; /* * ws = 0 的情况下，这里要尝试将状态从 0 设为 PROPAGATE，保证唤醒向后 * 传播。setHeadAndPropagate 在读到 h.waitStatus &lt; 0 时，可以继续唤醒 * 后面的节点。 */ else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; if (h == head) // loop if head changed break; &#125;&#125; 共享式释放共享式释放同步状态的主要逻辑都在上面的doReleaseShared()方法中，共享节点线程在获取同步状态和释放同步状态时都会调用doReleaseShared()，所以doReleaseShared是多线程竞争集中的地方。 1234567public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false;&#125; 关于共享式同步状态的获取与释放，其实这里介绍的较为简单了，由于时间原因，很多细节没有解释清楚，更为详细的分析可以参考这篇优质博客：AbstractQueuedSynchronizer源码解读 参考资料 【死磕 Java 并发】—– J.U.C 之 AQS：同步状态的获取与释放 AbstractQueuedSynchronizer 原理分析 - 独占/共享模式 AbstractQueuedSynchronizer源码解读]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>AQS</tag>
        <tag>源码分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java异常机制总结]]></title>
    <url>%2F2019%2F04%2F30%2FJava%E5%BC%82%E5%B8%B8%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[Java错误和异常在Java中，所有的异常都有一个共同的祖先Throwable，它有两个重要的子类：Exception（异常）和Error（错误），二者都是Java异常处理的重要子类，各自都包含大量子类: ErrorError是程序无法处理的错误，表示代码运行时Java虚拟机出现的问题。例如，当Java虚拟机不再有继续执行操作所需的内存资源时，将出现OutOfMemoryError，而另外还有一个常见的错误是StackOverflowError。这些错误是不可查的，也不应试图去捕获它，当这些错误发生时，Java虚拟机一般会选择终止。 ExceptionException异常是程序本身可以处理的异常，它有一个重要的子类RuntimeException，表示JVM常用操作引发的异常。例如，若试图使用空值对象引用、除数为零或数组越界，则分别引发运行时异常NullPointerException、ArithmeticException和ArrayIndexOutOfBoundException。 运行时异常Exception这种异常分为运行时异常和非运行时异常（编译异常）两大类： 运行时异常：都是RuntimeException类及其子类异常，如NullPointerException（空指针异常）、IndexOutOfBoundsException（下标越界异常）等。这些异常是不检查异常，Java编译器不会检查它，即使没有用try-catch语句捕获它，也没有用throws子句声明抛出它，也会编译通过。 非运行时异常：是RuntimeException以外的异常，类型上都属于Exception类及其子类。从程序语法角度讲是必须进行处理的异常（try-catch捕捉或者方法上声明throws抛出），如果不处理，程序就不能编译通过，如IOException、SQLException等。 处理异常机制在Java应用程序中，异常处理机制为：抛出异常，捕捉异常。 抛出异常：当一个方法出现错误引发异常时，方法创建异常对象并交付运行时系统，异常对象中包含了异常类型和异常出现时的程序状态等异常信息，运行时系统负责寻找处置异常的代码并执行。 捕获异常：在方法抛出异常之后，运行时系统将转为寻找合适的异常处理器（exception handler）。潜在的异常处理器是异常发生时依次存留在调用栈中的方法的集合。当异常处理器所能处理的异常类型与方法抛出的异常类型相符时，即为合适的异常处理器。运行时系统从发生异常的方法开始，依次回查调用栈中的方法，直至找到含有合适异常处理器的方法并执行。当运行时系统遍历调用栈而未找到合适的异常处理器，则运行时系统终止，同时意味着Java程序的终止。 一旦某个catch捕获到匹配的异常类型，将进入异常处理代码。一经处理结束，就意味着整个try-catch语句结束，其他的catch子句不再有匹配和捕获异常类型的机会。 参考资料 深入理解java异常处理机制]]></content>
  </entry>
  <entry>
    <title><![CDATA[JDK与CGLIB动态代理]]></title>
    <url>%2F2019%2F04%2F30%2FJDK%E4%B8%8ECGLIB%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%2F</url>
    <content type="text"><![CDATA[前言前段时间看了Spring AOP的源码，其底层就是通过JDK与CGLIB动态代理实现的，因此在这里对两种代理方式进行实践和总结。 准备工作首先创建一个代理创建器ProxyCreator接口，我们将分别实现JdkProxyCreator与CglibProxyCreator，通过实现getProxy()方法返回一个代理对象：123public interface ProxyCreator &#123; Object getProxy();&#125; 创建一个UserService接口，提供登陆login()和退出logout()两个方法，并创建一个它的实现类UserServiceImpl：123456789101112131415public interface UserService &#123; void login(int userId); void logout(int userId);&#125;public class UserServiceImpl implements UserService &#123; public void login(int userId) &#123; System.out.println("用户" + userId + "登陆成功"); &#125; public void logout(int userId) &#123; System.out.println("用户" + userId + "退出成功"); &#125;&#125; 接下来，我们将分为JDK与CGLIB这两种动态代理方式，为上面的登陆与退出两个方法前后打印日志。 JDK动态代理首先，创建一个JdkProxyCreator并实现ProxyCreator和InvocationHandler接口：123456789101112131415161718192021222324252627282930313233343536public class JdkProxyCreator implements ProxyCreator, InvocationHandler &#123; private Object target; public JdkProxyCreator(Object target) &#123; Class&lt;?&gt;[] interfaces = target.getClass().getInterfaces(); if(interfaces.length == 0)&#123; throw new IllegalArgumentException("目标对象必须实现接口"); &#125; this.target = target; &#125; public Object getProxy() &#123; Class&lt;?&gt; clazz = target.getClass(); // 该类本身实现了 InvocationHandler 接口，所以将自身作为参数传入 return Proxy.newProxyInstance(clazz.getClassLoader(), clazz.getInterfaces(), this); &#125; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; if("login".equals(method.getName()))&#123; System.out.println("登陆前日志打印..."); &#125; else if("logout".equals(method.getName()))&#123; System.out.println("退出前日志打印..."); &#125; Object res = method.invoke(target, args); // 调用目标方法 if("login".equals(method.getName()))&#123; System.out.println("登陆后日志打印..."); &#125; else if("logout".equals(method.getName()))&#123; System.out.println("退出后日志打印..."); &#125; return res; &#125;&#125; 可以看出，创建代理对象的核心其实就是这一行代码：Proxy.newProxyInstance(clazz.getClassLoader(), clazz.getInterfaces(), this);，其中第一个参数是目标对象的类加载器，第二个参数是目标对象实现的接口，第三个参数则是一个InvocationHandler，因为该类已经实现了这个接口，且打印日志的逻辑都封装在了该接口的invoke方法中了，所以直接传入this即可。 测试代码：123456789public class JdkProxyTest &#123; public static void main(String[] args) &#123; ProxyCreator proxyCreator = new JdkProxyCreator(new UserServiceImpl()); UserService userServiceProxy = (UserService) proxyCreator.getProxy(); System.out.println("代理对象的类型：" + userServiceProxy.getClass()); userServiceProxy.login(1); userServiceProxy.logout(1); &#125;&#125; 控制台输出：1234567代理对象的类型：class com.sun.proxy.$Proxy0登陆前日志打印...用户1登陆成功登陆后日志打印...退出前日志打印...用户1退出成功退出后日志打印... CGLIB动态代理CGLIB是一款优秀的Java字节码生成框架，它可以生成并操纵Java字节码。因此，CGLIB的动态代理其实就是使用字节码技术为目标类创建子类，并且在子类中拦截父类方法的调用，并且顺势织入横切逻辑。 首先，在pom.xml中引入CGLIB的依赖：12345678&lt;dependencies&gt; &lt;!-- https://mvnrepository.com/artifact/cglib/cglib --&gt; &lt;dependency&gt; &lt;groupId&gt;cglib&lt;/groupId&gt; &lt;artifactId&gt;cglib&lt;/artifactId&gt; &lt;version&gt;2.2.2&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 然后创建一个MethodInterceptor接口的实现类，将打印日志的操作封装在intercept()方法中：1234567891011121314151617181920public class UserMethodInterceptor implements MethodInterceptor &#123; public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; if("login".equals(method.getName()))&#123; System.out.println("登陆前日志打印..."); &#125; else if("logout".equals(method.getName()))&#123; System.out.println("退出前日志打印..."); &#125; Object res = methodProxy.invokeSuper(o, objects); if("login".equals(method.getName()))&#123; System.out.println("登陆后日志打印..."); &#125; else if("logout".equals(method.getName()))&#123; System.out.println("退出后日志打印..."); &#125; return res; &#125;&#125; 其中，Object res = methodProxy.invokeSuper(o, objects);这一行将会调用父类的实现，也就是目标对象的原始方法。这里要注意的是一定不要写成了method.invoke(o, objects);，否则会造成死循环。 接着，创建一个CglibProxyCreator实现ProxyCreator接口：123456789101112131415161718public class CglibProxyCreator implements ProxyCreator &#123; private Object target; private MethodInterceptor methodInterceptor; public CglibProxyCreator(Object target, MethodInterceptor methodInterceptor) &#123; this.target = target; this.methodInterceptor = methodInterceptor; &#125; public Object getProxy() &#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(target.getClass()); enhancer.setCallback(methodInterceptor); return enhancer.create(); &#125;&#125; 不同于JDK动态代理使用Proxy.newProxyInstance(clazz.getClassLoader(), clazz.getInterfaces(), this);的方式，这里创建了一个Enhancer对象，并且设置了目标对象的类作为父类，还设置了之前的方法拦截器UserMethodInterceptor（其实这里也可以让该类本身实现MethodInterceptor接口），最后通过enhancer.create()方法返回代理对象。 测试代码：123456789public class CglibProxyTest &#123; public static void main(String[] args) &#123; ProxyCreator proxyCreator = new CglibProxyCreator(new UserServiceImpl(), new UserMethodInterceptor()); UserService userServiceProxy = (UserService) proxyCreator.getProxy(); System.out.println("代理对象的类型：" + userServiceProxy.getClass()); userServiceProxy.login(2); userServiceProxy.logout(2); &#125;&#125; 控制台输出：1234567代理对象的类型：class cn.hecenjie.UserServiceImpl$$EnhancerByCGLIB$$76be9bea登陆前日志打印...用户2登陆成功登陆后日志打印...退出前日志打印...用户2退出成功退出后日志打印... 从上面的输出可以看出，代理对象其实是目标对象的一个子类。 总结JDK代理要求目标对象有实现接口，而CGLIB则不需要。从性能上来说，CGLIB创建的动态代理对象比JDK创建的动态代理对象的性能更高，但是CGLIB创建代理对象时所花费的时间却比JDK多得多。所以对于单例的对象，因为无需频繁创建对象，用CGLIB合适，反之使用JDK方式要更为合适一些。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>动态代理</tag>
        <tag>CGLIB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring AOP源码笔记]]></title>
    <url>%2F2019%2F04%2F30%2FSpring-AOP%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[前言本文是看了田小波博主的Spring AOP源码分析系列后自己总结整理的笔记，内容会更偏向于流程上的总结，具体源码细节并未深入研究，并且关于AOP的相关术语这里也不会再说明。 大致流程本文将会从AOP的入口开始分析，主要涉及以下四个流程： 入口分析 筛选合适的通知器 创建代理对象 拦截器链的执行过程 入口分析Spring是通过后置处理器BeanPostProcessor接口在init-method的前后通过切点对bean类中的方法进行匹配后织入的，这个接口是Spring提供的一个扩展接口，通过实现该接口，用户可在Bean初始化前后做一些自定义的操作： 12345678910111213141516171819202122232425protected Object initializeBean(final String beanName, final Object bean, @Nullable RootBeanDefinition mbd) &#123; // 激活Aware相关的方法 // &lt;2&gt; 后处理器，before if (mbd == null || !mbd.isSynthetic()) &#123; wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); &#125; // &lt;3&gt; 激活用户自定义的 init 方法 // 对应 &lt;bean&gt; 标签中的 init-method 属性 try &#123; invokeInitMethods(beanName, wrappedBean, mbd); &#125; catch (Throwable ex) &#123; throw new BeanCreationException( (mbd != null ? mbd.getResourceDescription() : null), beanName, "Invocation of init method failed", ex); &#125; // &lt;2&gt; 后处理器，after if (mbd == null || !mbd.isSynthetic()) &#123; wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); &#125; return wrappedBean;&#125; Spring AOP抽象代理创建器AbstractAutoProxyCreator实现了BeanPostProcessor接口，并在Bean初始化后置处理过程中向Bean织入通知： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public abstract class AbstractAutoProxyCreator extends ProxyProcessorSupport implements SmartInstantiationAwareBeanPostProcessor, BeanFactoryAware &#123; @Override public Object postProcessBeforeInitialization(Object bean, String beanName) &#123; return bean; &#125; @Override public Object postProcessAfterInitialization(@Nullable Object bean, String beanName) throws BeansException &#123; if (bean != null) &#123; Object cacheKey = getCacheKey(bean.getClass(), beanName); if (this.earlyProxyReferences.remove(cacheKey) != bean) &#123; // 如果需要，为 Bean 生成代理对象 return wrapIfNecessary(bean, beanName, cacheKey); &#125; &#125; return bean; &#125; protected Object wrapIfNecessary(Object bean, String beanName, Object cacheKey) &#123; if (StringUtils.hasLength(beanName) &amp;&amp; this.targetSourcedBeans.contains(beanName)) &#123; return bean; &#125; // 之前已经判断过了不需要生成代理，直接返回 Bean if (Boolean.FALSE.equals(this.advisedBeans.get(cacheKey))) &#123; return bean; &#125; // &lt;1&gt; 如果是基础设施类（Pointcut、Advice、Advisor 等接口的实现类），或是应该跳过的类（默认为false，由子类覆盖）， // 则不应该生成代理，此时直接返回 Bean if (isInfrastructureClass(bean.getClass()) || shouldSkip(bean.getClass(), beanName)) &#123; // 将 &lt;cacheKey, FALSE&gt; 键值对放入缓存中，供上面的if使用 this.advisedBeans.put(cacheKey, Boolean.FALSE); return bean; &#125; // &lt;2&gt; 为目标 Bean 查找合适的通知器（通知器持有通知） // Create proxy if we have advice. Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null); // &lt;3&gt; 如果找到了合适的通知器，则为 Bean 生成代理对象，否则直接返回 Bean if (specificInterceptors != DO_NOT_PROXY) &#123; this.advisedBeans.put(cacheKey, Boolean.TRUE); // 创建代理 Object proxy = createProxy( bean.getClass(), beanName, specificInterceptors, new SingletonTargetSource(bean)); this.proxyTypes.put(cacheKey, proxy.getClass()); // 返回代理对象，此时IoC容器中 beanName 对应的 bean 是代理对象，而非原始的 bean return proxy; &#125; // 将 &lt;cacheKey, FALSE&gt; 键值对放入缓存中，供上面的if使用 this.advisedBeans.put(cacheKey, Boolean.FALSE); // &lt;4&gt; specificInterceptors == null，直接返回 bean return bean; &#125;&#125; 可以看出，postProcessAfterInitialization主要过程分为四步： 若Bean是AOP基础设施类型（Pointcut、Advice、Advisor 等接口的实现类），则直接返回 为目标Bean查找匹配的通知器（通知器持有通知） 如果找到了匹配的通知器，则为Bean生成代理对象，并返回该对象 否则，返回原始bean 筛选合适的通知器上文说过，在创建代理对象前，首先要查找合适的通知器Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null);，这一行代码对应着postProcessAfterInitialization的第二步，具体实现如下：1234567891011121314151617181920212223protected Object[] getAdvicesAndAdvisorsForBean( Class&lt;?&gt; beanClass, String beanName, @Nullable TargetSource targetSource) &#123; // 查找合适的通知器 List&lt;Advisor&gt; advisors = findEligibleAdvisors(beanClass, beanName); if (advisors.isEmpty()) &#123; // 如果没有找到 return DO_NOT_PROXY; // 则返回 null &#125; return advisors.toArray(); // 否则，返回找到的通知器&#125; protected List&lt;Advisor&gt; findEligibleAdvisors(Class&lt;?&gt; beanClass, String beanName) &#123; // 查找所有的通知器 List&lt;Advisor&gt; candidateAdvisors = findCandidateAdvisors(); // 筛选可应用在 beanClass 上的 Advisor，通过 ClassFilter 和 MethodMatcher // 对目标类和方法进行匹配 List&lt;Advisor&gt; eligibleAdvisors = findAdvisorsThatCanApply(candidateAdvisors, beanClass, beanName); // 拓展操作 extendAdvisors(eligibleAdvisors); if (!eligibleAdvisors.isEmpty()) &#123; eligibleAdvisors = sortAdvisors(eligibleAdvisors); &#125; return eligibleAdvisors;&#125; 该过程首先会查询出所有的通知器，然后再通过ClassFilter和MethodMatcher对目标类和方法进行匹配，筛选出可应用到当前bean的通知器。下面分析查询出所有的通知器的过程。 查找所有通知器这个方法在子类AnnotationAwareAspectJAutoProxyCreator中被覆写过，增加了对@Aspect注解的解析： 12345678910@Overrideprotected List&lt;Advisor&gt; findCandidateAdvisors() &#123; // 调用父类方法从容器中查找所有的通知器 List&lt;Advisor&gt; advisors = super.findCandidateAdvisors(); // 解析 @Aspect 注解，并构建通知器 if (this.aspectJAdvisorsBuilder != null) &#123; advisors.addAll(this.aspectJAdvisorsBuilder.buildAspectJAdvisors()); &#125; return advisors;&#125; 这两行代码分别做了两件事： 第一步从容器中获取所有类型为Advisor的bean 第二步获取容器中所有beanName以及每个beanName对应的bean类型，遍历判断当前bean是否是一个Aspect注解类，若是则调用advisorFactory.getAdvisors获取所有通知器列表，其中会为每个方法调用getAdvisor方法，这个方法会获取AspectJ表达式切点（也就是获取方法上的相关注解如@Before、@After等并创建一个AspectJExpressionPointcut对象），并且创建Advisor实现类（这其中会先根据注解类型创建相应的通知Advice实现类）。 创建代理对象当Bean实现了接口时，Spring会基于JDK动态代理为目标Bean创建代理对象，若未实现任何接口，Spring则会通过CGLIB创建代理，而当proxy-target-class属性设为true时，则会强制Spring通过CGLIB的方式创建代理对象，即使目标Bean实现了接口。 AopProxy为目标Bean创建代理对象前，需要先创建AopProxy对象，然后再调用该对象的getProxy方法创建实际的代理类：12345public interface AopProxy &#123; Object getProxy(); Object getProxy(@Nullable ClassLoader classLoader);&#125; 在Spring中，有两个类实现了AopProxy，一个是CglibAopProxy，另一个是JdkDynamicAopProxy。在postProcessAfterInitialization的第三步Object proxy = createProxy(bean.getClass(), beanName, specificInterceptors, new SingletonTargetSource(bean));会根据bean是否实现接口以及一些其它配置来决定使用AopProxy的哪一个实现类为目标bean创建代理对象。 拦截器链的执行过程在上面两个步骤中，Spring AOP已经为目标bean筛选出合适的通知器，创建好了代理对象，接下来就是要执行通知逻辑了。通知可能在目标方法前执行，也可能在目标方法后执行，当目标方法被多个通知匹配到时，Spring通过引入拦截器链来保证每个通知的正常执行。 JDK动态代理逻辑分析对于JDK动态代理，代理逻辑封装在InvocationHandler接口实现类的invoke中，而JdkDynamicAopProxy实现了InvocationHandler接口：123456789101112131415161718192021222324252627282930313233343536373839404142434445final class JdkDynamicAopProxy implements AopProxy, InvocationHandler, Serializable &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; MethodInvocation invocation; Object oldProxy = null; boolean setProxyContext = false; TargetSource targetSource = this.advised.targetSource; Object target = null; try &#123; // ... Object retVal; if (this.advised.exposeProxy) &#123; // Make invocation available if necessary. oldProxy = AopContext.setCurrentProxy(proxy); setProxyContext = true; &#125; // Get as late as possible to minimize the time we "own" the target, // in case it comes from a pool. target = targetSource.getTarget(); Class&lt;?&gt; targetClass = (target != null ? target.getClass() : null); // 获取适合当前方法的拦截器链 List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass); if (chain.isEmpty()) &#123; // 如果拦截器链为空，则直接执行目标方法 Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args); retVal = AopUtils.invokeJoinpointUsingReflection(target, method, argsToUse); // 通过反射执行目标方法 &#125; else &#123; // 创建一个方法调用器，并将拦截器链传入其中 invocation = new ReflectiveMethodInvocation(proxy, target, method, args, targetClass, chain); // 执行拦截器链 retVal = invocation.proceed(); &#125; // ... return retVal; &#125; finally &#123; // ... &#125; &#125;&#125; 该方法的主要流程如下： 获取适合当前方法的拦截器（将advisor中的advice转成相应的拦截器） 如果拦截器链为空，则直接通过反射执行目标方法 否则，创建方法调用器ReflectiveMethodInvocation对象，将拦截器链传入其中 调用ReflectiveMethodInvocation对象的proceed()方法启动拦截器链 处理返回值，并返回该值 其中，启动拦截器是核心步骤，ReflectiveMethodInvocation的proceed方法用于启动拦截器链，这里直接引用一副图很好的解释了拦截器链的执行过程： 由上图可以看出，方法调用器每次调用下一个拦截器的invoke方法时，都会将自己作为参数传给该方法，并且通过方法调用器不断调用下一个拦截器，直到拦截器链中的最后一个拦截器执行完后，通过反射的方式执行目标方法，然后再返回到后置拦截器的方法中执行后置拦截器的一些逻辑。]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
        <tag>Spring</tag>
        <tag>AOP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ高级特性]]></title>
    <url>%2F2019%2F04%2F26%2FRabbitMQ%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[消息返回mandatory和immediate是发布消息时的两个参数，它们都有当消息传递过程中不可达目的地时将消息返回给生产者的功能。mandatory参数告诉服务器该消息至少能路由到一个队列中，而immediate参数告诉服务器要投递的队列必须有消费者。 mandatory当mandatory参数设为true时，交换器无法根据自身的类型和路由键找到一个符合条件的队列，那么RabbitMQ会调用Basic.Return命令将消息返回给生产者；当mandatory参数设置为false时，出现上述情形，则消息直接被丢弃。 对于没有被正确路由而返回给生产者的消息，可以通过给channel添加监听器获取到那些消息。 immediate当immediate参数设为true时，如果交换器在将消息路由到队列时发现队列上并不存在任何消费者，那么这条消息将不会存入队列中。当与路由键匹配的所有队列都没有消费者时，该消息会通过Basic.Return命令返回给生产者。 RabbitMQ从3.0的版本开始去掉了对immediate参数的支持。 备份交换器生产者在发送消息的时候如果不设置mandatory参数，那么消息在未被路由的情况下将会丢失；如果设置了mandatory参数，那么需要添加监听器的编程逻辑，生产者的代码会很复杂。如果既不想丢失消息，也不想使代码复杂化，那么可以使用备份交换器，将未被路由的消息存储在RabbitMQ中，需要的时候再去处理。 备份交换器和普通的交换器没有什么太大的区别，声明一个备份交换器后，在声明普通交换器时添加alternate-exchange参数即可建立它们之间的联系。为了方便使用，备份交换器建议设置为fanout类型的。 过期时间（TTL）RabbitMQ可以对消息和队列设置TTL。 设置消息的TTL如果不设置TTL，则表示此消息不会过期，而如果将TTL设置为0，则表示除非此时可以直接将消息投递到消费者，否则该消息会被立即丢弃。设置消息的TTL有两种方式： 通过队列属性设置，此时队列中所有消息都有相同的过期时间。 对消息本身进行单独设置，每条消息的TTL可以不同。 如果两种方法一起使用，则消息的TTL以两者之间较小的那个数值为准，消息在队列中的生存时间一旦超过设置的TTL时，就会变成死信。 还要注意的是，对于第一种设置队列TTL属性的方法，一旦消息过期，就会从队列中抹去，因为队列中己过期的消息肯定在队列头部；而在第二种方法中，即使消息过期，也不会马上从队列中抹去，因为每条消息的过期时间不同，如果要删除所有过期消息势必要扫描整个队列，所以不如等到此消息即将被消费时再判定是否过期，如果过期再进行删除即可。 设置队列的TTL在声明队列时可以通过x-expires参数控制队列被自动删除前处于未使用状态的时间，未使用的意思是队列上没有任何消费者，队列也没有被重新声明，并且在过期时间段内也未调用过Basic.Get命令。队列的TTL不能像消息一样设置为0。 死信队列当消息在一个队列中变成死信之后，它能被重新被发送到另一个交换器中，这个交换器就是DLX（Dead-Letter-Exchange，死信交换器），绑定DLX的队列就称之为死信队列。消息变成死信一般是由于以下几种情况： 消息被拒绝（Basic.Reject / Basic.Nack），并且设置requeue参数为false 消息过期 队列达到最大长度值 DLX也是一个正常的交换器，和一般的交换器没有区别，它能在任何的队列上被指定，实际上就是设置某个队列的属性。当这个队列中存在死信时，RabbitMQ就会自动地将这个消息重新发布到设置的DLX上去，进而被路由到死信队列中。 延迟队列延迟队列存储的对象是对应的延迟消息，即当消息被发送以后，并不想让消费者立刻拿到消息，而是等待特定时间后，消费者才能拿到这个消息进行消费。RabbitMQ本身并没有直接支持延迟队列的功能，但是可以通过DLX和TTL模拟出延迟队列的功能。 生产者将消息发送到过期时间为n毫秒的队列中，这个队列并未有消费者来消费消息，当过期时间到达时，消息会通过死信交换器转发到死信队列中，而消费者从死信队列中消费消息。这个时候就达到了“生产者发布了消息，过了n毫秒后消费者消费了消息”的延迟队列的效果。 优先级队列可以将队列声明为优先级队列，即在创建队列的时候添加参数x-max-priority指定最大的优先级，值为0-255，此时的规则如下： 优先级高的消息具备优先被消费的特权 没有指定优先级的消息会将优先级以0对待 对于超过优先级队列所定最大优先级的消息，优先级以最大优先级对待 对于相同优先级的消息，后进的排在前面 如果在消费者的消费速度大于生产者的速度且Broker中没有消息堆积的情况下， 对发送的消息设置优先级也就没有什么实际意义。因为生产者刚发送完一条消息就被消费者消费了，那么就相当于Broker中至多只有一条消息，对于单条消息来说优先级是没有什么意义的。 持久化持久化用以解决因为服务器的异常崩溃导致的消息丢失。RabbitMQ的持久化分为交换器的持久化、队列的持久化和消息的持久化： 交换器持久化：交换器的持久化是通过在声明交换器时将durable参数置为true实现的。 队列持久化：队列的持久化是通过在声明队列时将durable参数置为true实现的。如果队列不设置持久化，那么在RabbitMQ服务重启之后，相关队列的元数据会丢失，此时数据也会丢失。但即使设置了该队列为持久化的，也不能保证内部存储的消息不会丢失。 消息持久化：要确保消息不会丢失，需要通过将消息的投递模式（BasicProperties中的deliveryMode属性）设置为2即可实现消息的持久化。 就算将交换器、队列、消息都设置了持久化之后也不能百分百保证数据不会丢失。比如说消费者在订阅消费队列时将autoAck参数设置为true，那么当消费者接受到相关消息之后，还没来得及处理就宕机了，这样数据就丢失了。要解决这个问题可以将autoAck参数设置为false，并进行手动确认。 其次，在持久化的消息正确存入RabbitMQ之后，RabbitMQ并不会为每条消息都进行同步存盘（调用内核的fsync方法），此时仅仅保存到操作系统缓存之中，如果这时候发生了宕机，那么消息将会丢失。要解决这个问题可以使用RabbitMQ的镜像队列机制。 生产者确认当消息的生产者将消息发送出去之后，如果不进行特殊配置，默认情况下发送消息的操作是不会返回任何信息给生产者的，这样生产者也就不知道消息有没有正确到达服务器。RabbitMQ针对这个问题，提供了两种解决方式： 通过事务机制实现 通过发送方确认（publisher confirm）机制实现 事务机制RabbitMQ客户端中与事务机制相关的方法有三个：channel.txSelect、channel.txCommit、channel.txRollback。其中channel.txSelect用于将当前的信道设置成事务模式，channel.txCommit用于提交事务，channel.txRollback用于事务回滚。 当开启事务并且提交成功，那么消息就一定到达了RabbitMQ中了，如果在事务提交之前由于RabbitMQ异常崩溃或者其它原因抛出异常，这个时候便可以将其捕获，进而通过执行channel.txRollback方法来实现事务回滚，与此同时可以进行消息重发。 发送方确认机制事务机制会严重降低RabbitMQ的消息吞吐量，而发送方确认机制则更加轻量级。 生产者通过Confirm.Select命令将信道设置成confirm（确认）模式，一旦信道进入confirm模式，所有在该信道上面发布的消息都会被指派一个唯一的ID（从1开始），当消息被投递到所有匹配的队列之后，RabbitMQ就会发送一个确认（Basic.ACK）给生产者（包含消息的唯一ID），生产者可以通过回调方法来处理该确认消息。如果消息和队列是可持久化的，那么确认消息会在消息写入磁盘之后发出。如果RabbitMQ因为内部错误导致消息丢失，就会发送一条Basic.Nack命令，生产者同样也可以在回调方法中处理该命令。 RabbitMQ回传给生产者的确认消息中的deliveryTag包含了确认消息的序号，此外RabbitMQ也可以设置channel.basicAck方法中的multiple参数（默认为true，也就是批量确认），表示到这个序号之前的所有消息都已经得到了处理。 事务机制在一条消息发送之后会使发送端阻塞，以等待RabbitMQ的回应，之后才能继续发送下一条消息。而发送方确认机制如果使用同步串行的编程方式实现，其实并没有比事务机制好多少，但是该机制的优势是在于并不一定需要同步确认，对此有以下两种改进方案： 批量confirm方法：每发送一批消息后，调用channel.waitForConfirms方法，等待服务器的确认返回（该方法会阻塞到最后一条消息得到确认或者得到nack才结束）。 异步confirm方法：提供一个回调方法，服务端确认了一条或者多条消息后客户端会回调这个方法进行处理。 对于批量confirm方法，客户端程序需要定期或者定量（达到多少条），亦或者两者结合起来调用channel.waitForConfirms来等待RabbitMQ的确认返回，但是如果出现返回Basic.Nack或者超时情况时，客户端需要将这一批次的消息全部重发。 而对于异步confirm方法，它的编程比较复杂一些，但因为不会被阻塞，所以性能也略好一些。 消费者确认上面的生产者确认是保证生产者的消息正确的到达了服务器，而为了保证消息从队列可靠地到达消费者，消费者在订阅队列时可以指定autoAck参数，当autoAck等于true时，RabbitMQ会自动把发送出去的消息设置为确认，然后从内存（或者磁盘）中删除，而不管消费者是否真正地消费了这些消息；当autoAck为false时，RabbitMQ会等待消费者显示地回复确认信号后才从内存（或者磁盘）中移除消息。RabbitMQ不会为未确认的消息设置过期时间，除非消费此消息的消费者已经断开连接，此时RabbitMQ会安排该消息重新进入队列，等待投递给下一个消费者。 消费者拒绝在消费者接受到消息后，如果想明确拒绝当前的消息而不是确认，那么可以使用Basic.Reject命令，其中如果将参数requeue设置为false，则RabbitMQ立即会把消息从队列中删除，否则，RabbitMQ会重新将这条消息存入队列，以便可以发送给下一个订阅的消费者。 Basic.Reject命令一次只能拒绝一条消息，如果想要批量拒绝消息，则可以使用Basic.Nack这个命令，将multiple设为true则表示拒绝deliveryTag编号之前所有未被当前消费者确认的信息。 注意：如果requeue设置为false，那么可以启用死信队列的功能。 Basic.Recover命令用来请求RabbitMQ重新发送还未被确认的消息，也具备可重入队列的特性。如果将其参数requeue设置为true，则未被确认的消息会被重新加入到队列中，这样对于同一条消息来说，可能会被分配给与之前不同的消费者。如果将requeue参数设置为false，那么同一条消息会被分配给与之前相同的消费者。 消息分发当RabbitMQ队列拥有多个消费者时，队列收到的消息将以轮询的分发方式发送给消费者，但轮询的分发机制在各台机器性能差异较大时效率很低，那么就可以使用Basic.Qos命令限制信道上的消费者所能保持的最大未确认消息的数量，此时RabbitMQ会保存一个消费者的列表，每发送一条消息都会为对应的消费者计数，如果达到了所设定的上限，那么RabbitMQ就不会向这个消费者再发送任何消息，直到消费者确认了某条消息后，RabbitMQ将相应的计数减一，之后消费者才可以继续接收消息。 可靠性总结为了提升数据的可靠性，从上文分析可以总结出以下几个途径： 设置mandatory参数或者备份交换器来处理未能正确路由到队列的消息。 设置事务机制或者publisher confirm机制保证生产者的消息正确的到达了RabbitMQ。 设置交换器、队列和消息为持久化。 设置消费端对应的autoAck参数为false，在消费完消息后手动确认。 参考资料 RabbitMQ实战指南. 朱忠华 玩转不同业务场景，这些RabbitMQ特性会是得力助攻]]></content>
      <categories>
        <category>RabbitMQ</category>
      </categories>
      <tags>
        <tag>RabbitMQ</tag>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ基本概念]]></title>
    <url>%2F2019%2F04%2F26%2FRabbitMQ%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[基本架构RabbitMQ整体上是一个生产者-消费者模型，主要负责接收、存储和转发消息。整体架构如下： 这里省略生产者、消费者等最基础的概念，主要介绍队列、交换器、路由键等。 队列队列（Queue）是RabbitMQ的内部对象，用于存储消息。多个消费者可以订阅同一个队列，这时队列中的消息会被分摊（轮询）给多个消费者进行处理，而不是每个消费者都收到所有的消息并处理。 交换器生产者不是直接将消息发送到队列中，而是发送给交换器（Exchange），由交换器将消息路由到一个或者多个队列中。交换器主要有fanout、direct、topic、headers四种类型： fanout：它会把所有发送到该交换器的消息路由到所有与该交换器绑定的队列中。 direct：它会把消息路由到那些BindingKey和RoutingKey完全匹配的队列中。 topic：对direct类型的扩展，允许BindingKey和RoutingKey不严格的匹配它约定： RoutingKey和BindingKey为一个点号.分隔的字符串，如com.rabbitmq.client BindingKey中可以存在两种特殊字符串*和#，用于做模糊匹配，其中*用于匹配一个单词，#用于匹配多规格单词（可以是零个）。 headers：headers类型的交换器不依赖于路由键的匹配规则来路由消息，而是根据发送的消息内容中的headers属性进行匹配。在绑定队列和交换器时指定一组键值对，当发送消息到交换器时，RabbitMQ会获取到该消息的headers（也是一个键值对的形式），对比其中的键值对是否完全匹配队列和交换器绑定时指定的键值对，如果完全匹配则消息会路由到该队列，否则不会路由到该队列。这个类型基本不会使用。 路由键生产者将消息发送给交换器的时候一般会指定一个RoutingKey，用来指定这个消息的路由规则，而这个RoutingKey需要与交换器类型和绑定键（BindingKey）联合使用才能最终生效。这里要注意BindingKey并不是所有情况下都生效，它依赖于交换器类型，比如fanout类型的交换器就会无视BindingKey，而是将信息路由到所有绑定到该交换器的队列中。 Connection与Channel无论是生产者还是消费者，都需要和RabbitMQ Broker建立连接，这个连接就是一条TCP连接，也就是Connection。一旦TCP连接建立起来，客户端紧接着可以创建一个AMQP信道（Channel），每个信道都会被指派一个唯一的ID，它是建立在Connection之上的虚拟连接，RabbitMQ处理的每条AMQP指令都是通过信道完成的。 因为操作系统建立和销毁TCP连接是非常昂贵的开销，所以RabbitMQ采用TCP连接复用的方式，减少性能开销。 参考资料 RabbitMQ实战指南. 朱忠华]]></content>
      <categories>
        <category>RabbitMQ</category>
      </categories>
      <tags>
        <tag>RabbitMQ</tag>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis入门：单线程及五大数据类型]]></title>
    <url>%2F2019%2F04%2F21%2FRedis%E4%BA%94%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF%2F</url>
    <content type="text"><![CDATA[为什么Redis是单线程的首先对于Redis的网络通信模块，它是基于I/O多路复用模型实现的，也就是说只使用一个线程就可以处理多个连接，避免了传统方案使用多线程处理多条连接时的上下文切换开销。而对于命令的执行，因为Redis是基于内存的操作，CPU不是Redis的瓶颈，单线程的处理效率就是最高的，使用多线程反而会增大切换开销，并且引入线程安全的问题，因此Redis使用单线程的方案。 那什么时候应该使用多线程呢？其实对于类似磁盘I/O读写的操作，如果使用单线程执行，当耗时较长时，后面的所有其它请求都会被阻塞在这，这时候就可以使用新的线程去异步的处理之后的一些请求，提高系统的性能。 为什么Redis这么快 Redis是基于内存的操作 Redis底层使用C语言实现，效率更高 Redis使用I/O多路复用，不像传统方案开多个线程处理多个I/O，大大降低了线程切换的开销 字符串字符串是最基础的类型，字符串长度不能超过512MB。常用的API有如下几个： get key：获取一个key的value set key value：设置一个key的value del key：删除一个key incr key：key自增1，如果key不存在，自增后key的value为1 decr key：key自减1，如果key不存在，自减后key的value为-1 incrby key k：key自增k，如果key不存在，自增后key的value为k set key value：不管key是否存在，都设置value setnx key value：当key不存在时才设置value mget key1 key2 key3...：批量获取key，原子操作 mset key1 value1 key2 value2 key3 value3：批量设置key的value 适用场景： 记录某个用户的页面访问量：incr userid:pageview 实现分布式锁 哈希哈希可以理解为Map中的Map，因为它每个key对应的value都是一个Map结构，每个field不能相同，但value可以相同。常用的API有如下几个： hget key field：获取key对应的field的value hgetall key：返回key对应所有的field和value hset key field value：设置key对应的field的value hdel key field：删除key对应的field的value hmget key field1 field2 ... fieldN：批量获取key的一批field对应的value hmset key field1 value1 field2 value2 ... fieldN valueN：批量设置key的一批field对应的value 要注意的是，哈希结构无法针对某个指定的field设置超时时间，TTL不好控制。 列表列表（list）用来存储多个有序（插入顺序）的字符串，每个字符串称为元素，并且元素是可以重复的。常用的API有如下几个： rpush key value1 value2 ... valuen：从列表右端插入元素 lpush key value1 value2 ... valuen：从列表左端插入元素 linsert key before|after value newValue：在某个key下的list指定的value前|后插入newValue lpop key：从列表左侧弹出一个元素 rpop key：从列表右侧弹出一个元素 lrem key count value：根据count的值，从列表中删除所有value相等的元素。当count &gt; 0时，从左到右删除最多count个value相等的元素；当count &lt; 0时，从右到左删除最多Math.abs(count)个value相等的元素；当count = 0时，删除所有value相等的元素。 ltrim key start end：按照索引范围修剪列表，即删除索引范围之外的元素 lrange key start end：获取列表索引范围内的所有元素，包含end blpop key timeout：lpop阻塞版本，timeout是阻塞超时时间，timeout为0表示永久阻塞 brpop key timeout：rpop阻塞版本，timeout是阻塞超时时间，timeout为0表示永不阻塞 适用场景： 用户动态的时间轴：当用户更新动态的时候可以使用lpush命令加入列表，使用lrange命令展示一定数量的动态，并且使用ltrim限制动态的数量。 使用lpush + lpop实现一个栈，使用lpush + rpop实现一个队列。 使用lpush + brpop实现一个消息队列。 集合集合（set）与列表类似，都是用来保存多个字符串，但集合中的元素是无序的，因此不能通过索引来操作元素，并且集合中的元素不能有重复。常用的API有如下几个： sadd key element：向key添加element，如果element已经存在，则添加失败 srem key element：将key中的element移除掉 sinter key1 key2：取交集 sdiff key1 key2：取差集 sunion key1 key2：取并集 scard key：返回集合中元素的数量 sismember key member：判断集合key中是否存在member spop key：从集合中随机弹出一个元素 适用场景： 使用sadd命令给用户添加标签，或者给标签添加用户，通过sinter命令实现共同关注等功能。 有序集合有序集合与集合一样，元素都不能重复，但有序集合中的元素是有顺序的，与列表使用索引下标作为排序依据不同，有序集合为每个元素设置一个分数（score）作为排序依据。常用的API有如下几个： zadd key score element：添加score和element，score是可以重复的，但element是不能重复的。 zrem key element：删除元素element zscore key element：返回元素element的分数score zincrby key increScore element：增加或减少元素element的分数score zcard key：返回元素的总个数 zrange key start end [WITHSCORES]：返回指定索引范围内的升序元素（相当于排名） zrangebyscore key minScore maxScore [WITHSCORES]：返回指定分数范围内的升序元素 zcount key minScore maxScore：返回有序集合内在指定分数范围内的个数 适用场景： 排行榜：可以将销售量、关注人数、时间戳作为score进行元素的排序]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis Pipeline]]></title>
    <url>%2F2019%2F04%2F21%2FRedis-%E7%AE%A1%E9%81%93%2F</url>
    <content type="text"><![CDATA[命令执行Redis客户端执行一条命令分为以下四个步骤: 发送命令 命令排队 命令执行 返回结果 其中，第一步加第四步称为Round Trip Time（RTT，往返时间）。 性能瓶颈Redis提供了批量操作命令（例如mget、mset等），有效的节约了RTT，但大部分命令是不支持批量操作的。由于Redis命令执行本身是很快的（微妙级别），而发送命令以及返回结果的网络耗时往往更大，所以说Redis的性能瓶颈其实是网络。 Pipeline机制Pipeline机制能改善上面这类问题，它能将一组Redis命令进行组装，通过一次RTT传输给Redis，再将这组Redis命令按照顺序执行并装填结果返回给客户端。 Pipeline虽然好用，但是每次Pipeline组装的命令个数不能没有节制，否则一次组装Pipeline数据量过大，一方面会增加客户端的等待时机，另一方面会造成一定的网络阻塞，可以将一次包含大量命令的Pipeline拆分成多次较小的Pipeline来完成。 对比原生批量命令 原生批量命令是原子性，Pipeline是非原子性的。 原生批量命令是一个命令对应多个key，Pipeline支持多个命令。 原生批量命令是Redis服务端支持实现的，而Pipeline需要服务端与客户端的共同实现。 参考资料 redis学习笔记 - Pipeline与事务]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis实现分布式锁]]></title>
    <url>%2F2019%2F04%2F21%2FRedis%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%2F</url>
    <content type="text"><![CDATA[普通实现下面的加锁操作直接使用一条原子命令即可，而解锁操作需要用到Lua脚本保证原子性，该实现只适用于在单节点上操作。 加锁加锁可以使用Redis提供的一条原子命令完成：SET key value NX PX 30000。 这里对其中的一些参数做一些解释： key：我们使用key来当锁，因为key是唯一的。 value：为保证可靠性，加锁和解锁要是同一个客户端，客户端自己不能把别人加的锁给解了。所以这里value可用于标识客户端，解锁时需要进行比较。 NX：当key不存在时才进行set操作，若key已经存在，则不做任何操作。这个参数保证了只有一个人能拿到锁。 PX：这里其实可以传入EX或PX，主要目的是设置一个过期时间，锁的持有者后续发生崩溃而没有解锁，锁也会因为到了过期时间而自动解锁（即key被删除），不会发生死锁。 解锁为确保原子性，这里使用Lua脚本实现Redis分布式锁的解锁操作：12345if redis.call(&quot;get&quot;, KEYS[1]) == ARGV[1] then return redis.call(&quot;del&quot;, KEYS[1])else return 0end 实现的关键在于一定要先比较value是否相等，这也是上面加锁时提到的客户端自己不能把别人加的锁给解了，如果是同一个客户端那么就直接将key删除即可。 存在的问题事实上，上面的分布式锁实现在Redis单机部署的场景下工作是没问题的。但是如果Redis有多个节点的话，加锁就只能作用在一个Redis节点上，即使使用了哨兵或者集群方案保证高可用，如果master节点由于某些原因发生了主从切换，依然会出现锁丢失的情况： 在Redis的master节点上获取到锁 这个锁的key还没来得及同步到slave节点 master故障，发生故障转移，slave节点升级为master节点 导致锁丢失 Redlock实现由于上述的分布式锁只适用于单机环境，Redis作者基于分布式环境提出了一种更高级的实现方式：Redlock。 在Redis的分布式环境中，我们假设有N个Redis master节点，这些节点完全互相独立，不存在主从复制或者其他集群协调机制。之前我们已经描述了在Redis单实例下怎么安全地获取和释放锁，我们确保将在每个实例上使用此方法获取和释放锁。这里假设有5个Redis master节点，并且运行在5台不同的服务器上以保证他们不会同时都宕掉。以下为加锁操作： 首先获取当前的本地时间 使用相同的key和value依次尝试在5个实例上申请锁。在获得锁的过程中，为每一个锁操作设置一个快速失败时间（如果想要获得一个10秒的锁，那么每一个锁操作的失败时间设为5-50ms）。这样可以避免客户端与一个已经故障的master节点通信占用太长时间，通过快速失败的方式尽快与集群中的其他节点完成锁操作。 客户端计算出与master获得锁操作过程中消耗的时间（即当前时间减去第一步记录的时间），当且仅当客户端获得锁的过程中消耗的时间小于锁的存活时间，并且在一半以上的master节点中都获得锁，才认为client成功的获得了锁。 如果已经获得了锁，客户端执行任务的有效时间是锁的存活时间减去获得锁的过程中所消耗的时间。 如果客户端获得锁的数量不足一半以上，或获得锁的时间超时，那么认为获得锁失败，客户端应尽快地释放（部分）已经成功取到的锁，这样其他的客户端就不必非得等到锁过完有效时间才能取到。 这个算法的核心思想其实在于只可能有一个客户端能获取到大部分master节点中的锁，也就避免了多个客户端都能获取到锁的情况。对于释放锁来说，过程就相对简单一些了：向所有的Redis实例发送释放锁命令即可，不用关心之前有没有从Redis实例成功获取到锁。 参考资料 Redis分布式锁 Redlock：Redis分布式锁最牛逼的实现]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>分布式锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[String源码分析]]></title>
    <url>%2F2019%2F04%2F20%2FString%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[String 简介String实例是常量，一旦创建后就不能再修改其值。以下为它的继承关系： 12public final class String implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence &#123; 可以看出String实现了Serializable、CharSequence、Comparable接口，其中CharSequence主要提供一些对字符序列的只读访问，许多类如StringBuilder、StringBuffer也都实现了此接口，里面就只有几个方法：123456public interface CharSequence &#123; int length(); char charAt(int index); CharSequence subSequence(int start, int end); public String toString();&#125; String类通过final修饰，不可被继承，同时String底层的字符数组也是被final修饰的，char属于基本数据类型，一旦被赋值之后也是不能被修改的，所以String是不可变的。这里对final做一个简单的总结： 修饰类：当用final修饰一个类时，表明这个类不能被继承。也就是说，String类是不能被继承的。 修饰方法：把方法锁定，以防任何继承类对其覆盖。 修饰变量：修饰基本数据类型变量，则其数值一旦在初始化之后便不能更改；修饰引用类型变量，则在对其初始化之后便不能再让其指向另一个对象。 成员变量1234private final char value[]; // String的核心，用final修饰，无法再被修改private int hash; // 哈希值，默认为0private static final ObjectStreamField[] serialPersistentFields = new ObjectStreamField[0]; 构造函数String有很多重载的构造方法，介绍如下： 空参数构造方法，初始化字符串实例，默认为空字符，理论上不需要用到这个构造方法，实际上定义一个空字符String = &quot;&quot;就会初始化一个空字符串的String对象，而此构造方法，也是把空字符的value[]拷贝一遍而已，源码实现如下： 123public String() &#123; this.value = "".value;&#125; 通过一个字符串参数构造String对象，实际上将形参的value和hash赋值给实例对象作为初始化，相当于深拷贝了一个形参String对象，源码如下： 1234public String(String original) &#123; this.value = original.value; this.hash = original.hash;&#125; 通过字符数组去构建一个新的String对象，这里使用Arrays.copyOf方法拷贝字符数组： 123public String(char value[]) &#123; this.value = Arrays.copyOf(value, value.length);&#125; 在源字符数组基础上，通过偏移量（起始位置）和字符数量，截取构建一个新的String对象： 123456789101112131415161718192021222324public String(char value[], int offset, int count) &#123; //如果偏移量小于0，则抛出越界异常 if (offset &lt; 0) &#123; throw new StringIndexOutOfBoundsException(offset); &#125; if (count &lt;= 0) &#123; //如果字符数量小于0，则抛出越界异常 if (count &lt; 0) &#123; throw new StringIndexOutOfBoundsException(count); &#125; //在截取的字符数量为0的情况下，偏移量在字符串长度范围内，则返回空字符 if (offset &lt;= value.length) &#123; this.value = "".value; return; &#125; &#125; // Note: offset or count might be near -1&gt;&gt;&gt;1. //如果偏移量大于字符总长度-截取的字符长度，则抛出越界异常 if (offset &gt; value.length - count) &#123; throw new StringIndexOutOfBoundsException(offset + count); &#125; //使用Arrays.copyOfRange静态方法，截取一定范围的字符数组，从offset开始，长度为offset+count，赋值给当前实例的字符数组 this.value = Arrays.copyOfRange(value, offset, offset+count);&#125; 通过源字节数组，按照一定范围，从offset开始截取length个长度，初始化String实例，同时可以指定字符编码： 12345678910public String(byte bytes[], int offset, int length, String charsetName) throws UnsupportedEncodingException &#123; //字符编码参数为空，抛出空指针异常 if (charsetName == null) throw new NullPointerException("charsetName"); //静态方法 检查字节数组的索引是否越界 checkBounds(bytes, offset, length); //使用 StringCoding.decode 将字节数组按照一定范围解码为字符串，从offset开始截取length个长度 this.value = StringCoding.decode(charsetName, bytes, offset, length);&#125; 将StringBuffer构建成一个新的String，比较特别的就是这个方法有synchronized锁，同一时间只允许一个线程对这个StringBuffer构建成String对象，所以是线程安全的： 1234567public String(StringBuffer buffer) &#123; //对当前 StringBuffer 对象加同步锁 synchronized(buffer) &#123; //拷贝 StringBuffer 字符数组给当前实例的字符数组 this.value = Arrays.copyOf(buffer.getValue(), buffer.length()); &#125;&#125; 将StringBuilder构建成一个新的String，与另一个构造器不同的是，此构造器不是线程安全的： 123public String(StringBuilder builder) &#123; this.value = Arrays.copyOf(builder.getValue(), builder.length());&#125; 成员方法value相关 获取字符串长度，实际上是获取字符数组长度： 123public int length() &#123; return value.length;&#125; 判断字符串是否为空，实际上是判断字符数组长度是否为0： 123public boolean isEmpty() &#123; return value.length == 0;&#125; 根据索引参数获取字符： 12345678public char charAt(int index) &#123; //索引小于0或者索引大于字符数组长度，则抛出越界异常 if ((index &lt; 0) || (index &gt;= value.length)) &#123; throw new StringIndexOutOfBoundsException(index); &#125; //返回字符数组指定位置字符 return value[index];&#125; compareTo实现了Comparable接口的compareTo方法：123456789101112131415161718public int compareTo(String anotherString) &#123; int len1 = value.length; int len2 = anotherString.value.length; int lim = Math.min(len1, len2); char v1[] = value; char v2[] = anotherString.value; int k = 0; while (k &lt; lim) &#123; char c1 = v1[k]; char c2 = v2[k]; if (c1 != c2) &#123; return c1 - c2; &#125; k++; &#125; return len1 - len2;&#125; 可以看出该方法实现还是比较简单的，直接逐个比较每个字符是否相等，如果其中某个字符不相等就直接返回结果，否则比较它们的长度。 equals与hashCodeequals方法首先判断两个对象的地址是否相等，如果不等再判断对象是否为String类型，如果是的话再比较它们的长度与值。 12345678910111213141516171819202122232425 public boolean equals(Object anObject) &#123; // 先判断地址是否相等 if (this == anObject) &#123; return true; &#125; // 判断要比较的对象是否为 String 类型 if (anObject instanceof String) &#123; String anotherString = (String)anObject; int n = value.length; // 比较两个字符串的长度 if (n == anotherString.value.length) &#123; char v1[] = value; char v2[] = anotherString.value; int i = 0; // 逐个比较两个字符串中每个字符是否相等 while (n-- != 0) &#123; if (v1[i] != v2[i]) return false; i++; &#125; return true; &#125; &#125; return false;&#125; hashCode方法：123456789101112public int hashCode() &#123; int h = hash; if (h == 0 &amp;&amp; value.length &gt; 0) &#123; char val[] = value; for (int i = 0; i &lt; value.length; i++) &#123; h = 31 * h + val[i]; &#125; hash = h; &#125; return h;&#125; 因为在大多数构造函数中，其实并没有设置成员变量hash的值，默认值是为0的，因此调用此方法会根据value数组重新计算哈希值，并赋给成员变量hash，下次就可以直接拿到该哈希值了。这里还有一行h = 31 * h + val[i];比较特别，它其实可以推导成一个公式：val[0]*31^(n-1) + val[1]*31^(n-2) + ... + val[n-1]，这里之所以要取31这个数字，原因如下： 选择数字31是因为它是一个奇质数，如果选择一个偶数会在乘法运算中产生溢出，导致数值信息丢失，因为乘二相当于移位运算。选择质数的优势并不是特别的明显，但这是一个传统。同时，数字31有一个很好的特性，即乘法运算可以被移位和减法运算取代，来获取更好的性能：31 * i == (i &lt;&lt; 5) - i，现代的 Java 虚拟机可以自动的完成这个优化。 具体可以参考这篇文章：String hashCode 方法为什么选择数字31作为乘子 intern在Java中有8种基本类型和一种比较特殊的类型String，这些类型为了使他们在运行过程中速度更快，更节省内存，都提供了一种常量池的概念。8种基本类型的常量池都是系统协调的，String类型的常量池比较特殊，它的主要使用方法有两种： 直接使用双引号声明出来的String对象会直接存储在常量池中。 如果不是用双引号声明的String对象，可以使用String提供的intern方法。intern方法会从字符串常量池中查询当前字符串是否存在，若不存在就会将当前字符串放入常量池中。 关于这个方法网上的解释有很多，但大多都比较混乱，我暂时还没有整理清楚，日后回来填坑。 String对 + 的重载12345678public class StringTest &#123; public static void main(String[] args) &#123; String apple = "Apple,"; String fruit = apple + "Pear," + "Orange"; System.out.println(fruit); &#125;&#125; 编译器在执行上述代码的时候会自动引入StringBuilder类。虽然在上面的代码中我们并没有使用到StringBuilder类，但是编译器却自动引入了它，因为它更高效。编译器首先会创建一个StringBuilder对象，用来构造最终要生成的String，并为每一个字符串调用一次StringBuilder中的append()方法，因此上述代码一共执行了三次append()方法，最后调用toString生成最终的结果，并保存为fruit。 但是我们不能认为编译器已经帮我们做了优化，我们就可以随意的使用String对象，下面是两种方法生成一个String，一个方法使用了String对象，另一个使用了StringBuilder： 123456789101112131415public static String getString1(String[] strArray)&#123; String result = ""; for(int i = 0; i &lt; strArray.length; i++) result += strArray[i]; return result; &#125;public static String getString2(String[] strArray)&#123; StringBuilder result = new StringBuilder(); for(int i = 0; i &lt; strArray.length; i++) result.append(strArray[i]); return result.toString(); &#125; 上面两个方法都是用来对一个数组中的数据进行连接并返回一个String对象，但是需要我们注意的是getString1方法是在循环内部构造StringBuilder对象的，这意味着每循环一次就会创建一个新的StringBuilder对象。 getString2方法只生成了一个StringBuilder对象，这样更简单更高效的实现了同getString1一样的功能。所以在我们使用String对象时，最好考虑一下是否可以用StringBuilder对象更高效的实现我们想要的功能。 总结 String类被修饰符final修饰是无法被继承的，而它内部的关键成员变量char value[]同样也是被final修饰不能更改的，因此String是不可变的。 String实现了Serializable接口，可以被序列化；实现了Comparable接口，可用于比较大小；实现了CharSequence，实现了通用的字符序列的只读方法。 String重载了+运算符，会创建一个StringBuilder对象并调用其append()实现字符串拼接。 参考资料 《Java 编程思想》Bruce Eckel 著 陈昊鹏 译 String 源码浅析(一) String源码分析 String hashCode 方法为什么选择数字31作为乘子]]></content>
      <categories>
        <category>JDK源码分析</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
        <tag>JDK</tag>
        <tag>String</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis缓存设计与优化]]></title>
    <url>%2F2019%2F03%2F31%2FRedis%E7%BC%93%E5%AD%98%E8%AE%BE%E8%AE%A1%E4%B8%8E%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[过期策略Redis过期策略是：定期删除+惰性删除。 所谓定期删除，指的是Redis默认每隔100ms就随机抽取一些设置了过期时间的key（全部都检查的话十分消耗CPU资源），检查其是否过期，如果过期了就删除。但仅依赖此策略会有许多过期的key未被检查到，因此Redis还使用惰性删除策略，即在读/写key的时候再检查其是否过期，如果过期了则删除。 内存淘汰机制如果某些key没有被定期删除，也没及时去读/写以触发惰性删除，那么Redis的内存会越来越高，当已用内存超过maxmemory限定时，就会根据内存淘汰机制删除部分key。Redis内存淘汰机制有以下几个： noeviction: 当内存不足以容纳新写入数据时，新写入操作会报错。 allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。 allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。 volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。 volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。 volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。 缓存穿透一般的缓存系统，都是根据key去缓存查询，如果不存在对应的value，就应该去数据库查找。如果key对应的value是一定不存在的，并且对该key并发请求量很大，就会对数据库造成很大的压力，这就叫做缓存穿透。 第一个解决办法是对查询结果为空的键也进行缓存，由于这种方式需要更多的键，所以可以设置一个短一点的过期时间。 第二个解决方案则是使用布隆过滤器拦截。布隆过滤器的原理是，当一个元素被加入集合时，通过K个Hash函数将这个元素映射成一个位数组中的K个点，并把它们置为1。检索时，我们只要看看这些点是不是都是1就（大约）知道集合中有没有它了：如果这些点有任何一个0，则被检元素一定不在；如果都是1，则被检元素有可能在。 通过布隆过滤器，一个一定不存在的数据会被它拦截掉，从而避免了对数据库的查询压力。 缓存雪崩当缓存服务器重启或者大量缓存集中在某一个时间段失效，这样在失效的时候，所有请求都会查询数据库，也会给数据库带来很大压力，这就叫做缓存雪崩。对于缓存雪崩有以下几种解决方案： 可以给缓存设置过期时间时加上一个随机时间，使得每个key的过期时间分散开来，不会集中在同一时刻失效。 进行缓存预热，避免在系统刚启动不久由于还未将大量数据进行缓存而导致缓存雪崩。 使用分布式缓存。 提前演练。 热点key重建当前key是一个热点key（比如说某个热门的娱乐新闻），如果在缓存失效时有大量线程并发请求，那么这些线程会同时去访问数据库并重建key，导致后端系统负载过大，甚至因此崩溃。 为此有以下几种解决方案： 互斥锁可以使用互斥锁的方式实现，直接利用redis的set命令即可（如SET mutexKey &quot;1&quot; EX 10086 NX），为了防止该锁未被正确释放，还应给该锁设置一个过期时间。 这种方式的缺点在于重建的过程中别的线程都会处于等待状态，整体性能不高。 永远不过期我们不为每个key设置一个过期时间，但会添加一个逻辑过期时间属性，每次去读的时候都判断一下当前时间是否已经大于逻辑过期时间，如果是的话就使用单独的线程去构建缓存。 这种方式的缺点在于缓存的构建是异步的，因此别的线程在这个过程中依然会取到老值，不保证数据的一致性。 参考资料 《Redis开发与运维》 缓存穿透与缓存雪崩 分布式缓存击穿（布隆过滤器 Bloom Filter）]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis Cluster]]></title>
    <url>%2F2019%2F03%2F31%2FRedis-Cluster%2F</url>
    <content type="text"><![CDATA[Redis Cluster作用Redis Cluster是Redis 3.0开始引入的分布式存储方案，集群由多个节点组成，Redis的数据分布在这些节点中。集群中的节点分为主节点和从节点：只有主节点负责读写请求和集群信息的维护，从节点只进行主节点数据和状态信息的复制。集群的作用，可以归纳为两点： 数据分片：集群将数据分散到多个节点，突破了Redis单机内存大小的限制，存储容量大大增加。 高可用：集群支持主从复制和主节点的自动故障转移（与哨兵类似），当任一节点发生故障时，集群仍然可以对外提供服务。 数据分区方案常见的哈希分区方案包括：哈希取余分区、一致性哈希分区、带虚拟节点的一致性哈希分区等。 哈希取余分区：哈希取余分区思路非常简单，首先计算key的hash值，然后对节点数量进行取余，从而决定数据映射到哪个节点上。该方案最大的问题是，当新增或删减节点时，节点数量发生变化，系统中所有的数据都需要重新计算映射关系，引发大规模数据迁移。 一致性哈希分区：一致性哈希算法将整个哈希值空间组织成一个虚拟的圆环，范围为0 ~ 2^32-1。对于每个数据，根据key计算hash值，确定数据在环上的位置，然后从此位置沿环顺时针行走，找到的第一台服务器就是其应该映射到的服务器。与哈希取余分区相比，一致性哈希分区将增减节点的影响限制在相邻节点。 一致性哈希分区（虚拟节点机制）：普通的一致性哈希在服务器节点数量较少时容易产生数据倾斜问题，各个服务器的负载不均匀。为解决这个问题，引入了虚拟节点机制，每台机器可以负责更多节点，数据负担更加均匀。 虚拟槽分区：Redis Cluser底层使用的虚拟槽分区，有一个长度为16384的虚拟槽，每个Master节点都会负责一部分的槽，Redis对key计算哈希值，使用的算法是CRC16，然后根据哈希值计算数据属于哪个槽，最后根据槽与节点的映射关系，计算数据属于哪个节点。其中哪个节点负责哪个槽，这是可以由用户指定的。 节点通信机制两个端口在redis sentinel中，节点分为数据节点和sentinel节点：前者存储数据，后者实现额外的控制功能。在redis cluster中，没有数据节点与非数据节点之分，所有的节点都存储数据，也都参与集群状态的维护。为此，集群中的每个节点都提供了两个TCP端口，普通端口主要用于为客户端提供服务，集群端口用于节点之间的通信，如搭建集群、增减节点、故障转移等操作时节点间的通信。 Gossip协议Gossip过程是由种子节点发起，当一个种子节点有状态需要更新到网络中的其他节点时，它会随机的选择周围几个节点散播消息，收到消息的节点也会重复该过程，直至最终网络中所有的节点都收到了消息。这个过程可能需要一定的时间，由于不能保证某个时刻所有节点都收到消息，但是理论上最终所有节点都会收到消息，因此它是一个最终一致性协议。 Gossip协议的优点： 负载低：比广播低，广播每条消息都要发送给所有节点，CPU、带宽等消耗较大。 去中心化：Gossip协议不要求任何中心节点，所有节点都可以是对等的，任何一个节点无需知道整个网络状况，只要网络是连通的，任意一个节点就可以把消息散播到全网。 容错性高：网络中任何节点的宕机和重启都不会影响Gossip消息的传播，Gossip协议具有天然的分布式系统容错特性。Gossip协议的缺点： 消息的延迟：由于节点只会随机向少数几个节点发送消息，消息最终是通过多个轮次的散播而到达全网的，因此使用Gossip协议会造成不可避免的消息延迟，不适合用在对实时性要求较高的场景下。 消息类型集群节点间发送的消息有以下几种类型： meet：在节点握手阶段，当节点收到客户端的cluster meet命令时，会向新加入的节点发送meet消息，请求新节点加入到当前集群，新节点收到meet消息后会回复一个pong消息。 ping：集群里每个节点每秒钟会选择部分节点发送ping消息，接收者收到消息后会回复一个pong消息。ping消息使用Gossip协议发送，内容是自身节点和部分其他节点的状态信息，作用是彼此交换信息，以及检测节点是否在线。 pong：pong消息封装了自身状态数据，可以分为两种：第一种是在接到meet/ping消息后回复的pong消息，第二种是指节点向集群广播pong消息，这样其他节点可以获知该节点的最新信息，例如故障恢复后新的主节点会广播pong消息。 fail：当一个主节点判断另一个主节点客观下线后，会向集群广播这一fail消息，通知集群中所有节点标记故障节点为客观下线，并通知故障节点的从节点触发故障转移流程。 publish：节点收到publish命令后，会先执行该命令，然后向集群广播这一消息，接收节点也会执行该publish命令。 客户端路由moved重定向moved异常代表槽已经确认迁移至别的节点。 ask重定向在集群缩容扩容的时候，要对槽进行迁移，在迁移的过程中访问一个key，但是key已经迁移到目标节点，那么就会返回一个ask异常。 Smart Clientredis-cli这一类客户端称为Dummy客户端，因为它们在执行命令前不知道数据在哪个节点上，因此需要借助moved异常重定向。为了追求性能，我们不可能每次都随机访问一个节点，再根据moved或ask异常去重定向到目标节点，因此需要实现一个Smart客户端，比如说JedisCluster。JedisCluster的基本原理大致如下： 从集群中选一个可运行节点，使用cluster slots命令并将结果映射到本地，这样本地就有了slot-&gt;node的映射关系缓存。 JedisCluster为每个节点创建连接池(即JedisPool)。 当执行命令时，JedisCluster根据key-&gt;slot-&gt;node选择需要连接的节点，发送命令。如果成功，则命令执行完毕。如果执行失败，则会随机选择其他节点进行重试，并在出现moved错误时，刷新本地的映射关系缓存。 这里需要注意的是，JedisCluster中已经包含所有节点的连接池，因此JedisCluster要使用单例。 集群伸缩集群伸缩的核心是槽迁移，通过修改槽与节点的对应关系，实现槽（即数据）在节点之间的移动。例如，如果槽均匀分布在集群的3个节点中，此时增加一个节点，则需要从3个节点中分别拿出一部分槽给新节点，从而实现槽在4个节点中的均匀分布。 增加节点 启动节点 加入集群：使用cluster meet命令。 迁移槽和数据 减少节点 迁移槽和数据 忘记节点：使用cluster forget命令 关闭节点 这里要注意应先下线从节点再下线主节点，因为若主节点先下线，会触发故障的自动转移。 在槽迁移未完成时，客户端访问了负责该槽的节点，但key此时已经迁移到了别的节点下，这时候会返回ask异常，通过这个机制使得redis cluster可以无痛的完成扩缩容操作。 故障转移集群对故障发现与故障转移的实现与哨兵思路类似：通过定时任务发送ping消息检测其他节点状态，若某个主节点发现另一个主节点不可用（与参数cluster-node-timeout有关），则标记该节点进行主观下线，而当半数以上持有槽的主节点都标记该节点主观下线，则对该节点进行客观下线，并向集群广播fail消息，让集群中所有节点都将其标记为客观下线，并触发从节点的故障转移。 在故障转移阶段，主要有以下几个步骤： 检查资格：每个从节点都会检查与故障主节点的断线时间，如果超过默认值150s（cluster-node-timeout * cluster-slave-validity-factor）则会取消资格。 准备选举时间：为了保证偏移量比较大的从节点更有可能成为主节点，会将该从节点的延迟时间设置更小一些。 选举投票：从节点选举胜出需要的票数为N/2+1，其中N为主节点数量（包括故障主节点），但故障主节点实际上不能投票。因此为了能够在故障发生时顺利选出从节点，集群中至少需要3个主节点。 替换主节点。 与哨兵一样，集群只实现了主节点的故障转移，从节点故障时只会被下线，不会进行故障转移。因此，使用集群时，应谨慎使用读写分离技术，因为从节点故障会导致读服务不可用，可用性变差。 参数优化cluster_node_timeoutcluster_node_timeout的默认值是15s，影响包括： 值越大对延迟容忍度越高，并且由于节点发现与其它节点最后通信时间超过cluster_node_timeout / 2时会直接发送ping消息，因此调大该参数还可以降低带宽消耗，但同时也会降低收敛速度。 影响故障转移的判定和时间，值越大越不容易误判，但完成转移消耗时间越长。 cluster-require-full-coveragecluster-require-full-coverage参数设置为yes时，当主节点发生故障而故障转移尚未完成，原主节点中的槽不在任何节点中，此时集群会处于下线状态，无法响应客户端的请求。但在实际应用中为了保证服务的高可用性，都会将该参数设置为no。 参考资料 《Redis开发与运维》 哈希分区技术之间的对比（一致性哈希、Redis cluster虚拟槽） 深入学习Redis（5）：集群 P2P 网络核心技术：Gossip 协议 Redis cluster 客户端路由]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper集群节点为什么推荐为奇数]]></title>
    <url>%2F2019%2F03%2F31%2FZookeeper%E9%9B%86%E7%BE%A4%E8%8A%82%E7%82%B9%E4%B8%BA%E4%BB%80%E4%B9%88%E6%8E%A8%E8%8D%90%E4%B8%BA%E5%A5%87%E6%95%B0%2F</url>
    <content type="text"><![CDATA[不止包括Zookeeper集群，其它大多数集群都推荐节点数最好为奇数个，因此本文将详细说明其中的缘由。首先我们需要明白一个概念“脑裂”： 集群的脑裂通常是发生在节点之间通信不可达的情况下，集群会分裂成不同的小集群，每个小集群都认为其它小集群的节点是不可用的，小集群各自选出自己的master节点，导致原有的集群出现多个master节点的情况，这就是脑裂。 在zookeeper的选举过程中，有个规则是要求可用节点数量&gt;总节点数量/2。之所以会有这样的要求，就是为了防止集群出现脑裂的时候，可能会出现多个子集群同时服务的情况（即子集群各组选举出自己的leader）。如果遵守这个规则，那么只会有一个子集群能进行Leader选举，因为当前集群中只可能有一个子集群的节点数能超过总节点数的一半。 说明了可用节点数量&gt;总节点数量/2这个规则后，我们再进一步探索为什么Zookeeper集群节点数推荐为奇数个。主要有以下两个原因： 1. 防止脑裂造成集群不可用如果集群的数量为偶数个，那么在发生脑裂的时候，可能两个子集群的数量都无法超过总节点数量的一半，也就无法满足Zookeeper进行选举的规则，这时候整个服务对外是彻底不可用的。但是如果集群的数量为奇数个的话，发生脑裂时必然有一个子集群的节点数目大于总节点数目的一半，这时候可以保证当前服务对外依然是可用的。 2. 在容错能力相同的情况下，奇数台更节省资源比如说，如果当前集群有四个节点，要想完成Leader选举，只允许一个节点不可用，这样才能保证可用的节点数大于总节点数的一半。但如果当前集群有三个节点，要想完成Leader选举，同样也只允许一个节点不可用，因为只有当两个节点都存活的时候才能满足可用节点数大于总节点数的一半。可以看出，以上两个集群都只有一个节点的容错能力，但是第二个集群比第一个集群节约了更多的资源，因此，更推荐Zookeeper的节点数为奇数个。]]></content>
      <categories>
        <category>Zookeeper</category>
      </categories>
      <tags>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis Sentinel]]></title>
    <url>%2F2019%2F03%2F30%2FRedis-Sentinel%2F</url>
    <content type="text"><![CDATA[Redis Sentinel架构复制是高可用Redis的基础，哨兵和集群都是在复制基础上实现高可用的，但它故障恢复无法自动化，因此Redis提供了哨兵（Sentinel）这么一个高可用方案。Redis Sentinel由两部分组成，哨兵节点和数据节点： 哨兵节点：哨兵系统由一个或多个哨兵节点组成，哨兵节点是特殊的redis节点，不存储数据。 数据节点：主节点和从节点都是数据节点。 Redis Sentinel具有以下功能： 监控：哨兵通过心跳检测会不断地检查主节点和从节点是否运作正常。 自动故障转移：当主节点不能正常工作时，哨兵会开始自动故障转移操作，它会将失效主节点的其中一个从节点升级为新的主节点，并让其他从节点改为复制新的主节点。 配置提供者：客户端在初始化时，通过连接哨兵来获得当前Redis服务的主节点地址。 通知：哨兵可以将故障转移的结果发送给客户端。 客户端连接Redis Sentinel对于Redis Sentinel，它仅仅完成了服务端的高可用，当master挂掉时能选举出一个新的master节点来完成故障转移，但是我们客户端并没有去连接新的master节点，因此我们还要使得客户端也是高可用的。 Jedis客户端对Redis Sentinel提供了很好的支持。我们只需要向Jedis提供sentinel节点集合和masterName，构造JedisSentinelPool对象，然后便可以像使用普通redis连接池一样来使用了：通过pool.getResource()获取连接，执行具体的命令。 123456789101112public static void testSentinel() throws Exception &#123; String masterName = "mymaster"; Set&lt;String&gt; sentinels = new HashSet&lt;&gt;(); sentinels.add("192.168.92.128:26379"); sentinels.add("192.168.92.128:26380"); sentinels.add("192.168.92.128:26381"); JedisSentinelPool pool = new JedisSentinelPool(masterName, sentinels); //初始化过程做了很多工作 Jedis jedis = pool.getResource(); jedis.set("key1", "value1"); pool.close();&#125; 在整个过程中，我们的代码不需要显式的指定主节点的地址，就可以连接到主节点。代码中对故障转移也没有任何体现，就可以在sentinel完成故障转移后自动的切换主节点。之所以可以做到这些，是因为客户端完成了以下几个工作： 遍历sentinel节点，找到一个可用的sentinel节点，通过sentinel get-master-addr-by-name命令获取master节点的信息（IP和端口），之后再对master节点执行role命令判断其是否真的为master节点。 客户端和sentinel使用了一个发布订阅模式，客户端订阅sentinel的某一个频道，当master发生变化时，sentinel向这个频道发布一条消息，客户端就可以获取再对新的master进行一个连接。 前面说过sentinel相当于配置提供者，我们得到了sentinel的集合后就可以通过sentinel节点获取到master的地址。这里要注意sentinel只是配置提供者，而不是代理，二者的区别在于如果是配置提供者，客户端在通过sentinel获得master信息后，会直接建立到master的连接，后续的请求会直接发向master，而如果是代理，客户端的每一次请求都会发向sentinel，sentinel再通过主节点处理请求。 基本原理三个定时任务 10秒每个sentinel对master和slave执行info，以此发现slave节点并确认主从关系。 2秒每个sentinel通过master节点的channel交换信息（因此sentinel节点之间能够自动感知）。 每1秒每个sentinel对其它sentinel和redis执行ping也就是心跳检测。 主观下线和客观下线 主观下线：在心跳检测的定时任务中，如果其他节点超过一定时间没有回复，哨兵节点就会将其进行主观下线。顾名思义，主观下线的意思是一个哨兵节点“主观地”判断下线。 客观下线：哨兵节点在对主节点进行主观下线后，会通过sentinel is-master-down-by-addr命令询问其他哨兵节点该主节点的状态。如果判断主节点下线的哨兵数量达到设置的法定人数（quorum），则对该主节点进行客观下线。 需要特别注意的是，客观下线是主节点才有的概念，如果从节点和哨兵节点发生故障，被哨兵主观下线后，不会再有后续的客观下线和故障转移操作。 领导者选举由于只需要一个sentinel节点完成故障转移，因此sentinel内部需要选举出一个节点作为领导者，同样也是通过sentinel is-master-down-by-addr这个命令完成领导者的选举（这正是这条命令的第二个作用）。过程如下： 每个做主观下线的sentinel节点向其它sentinel节点发送命令，要求将它设置为领导者。 收到命令的sentinel节点如果没有同意通过其它sentinel节点发送的命令，那么将同意该请求，否则拒绝。 如果该sentinel节点发现自己的票数已经超过sentinel集合半数并且超过quorum，那么将它成为领导者。 故障转移完成了领导者选举后，由领导者进行故障转移操作： 从slave节点中选出一个“合适的”节点作为新的master节点：选择优先级最高的从节点(由slave-priority指定)；如果优先级无法区分，则选择复制偏移量最大的从节点；如果仍无法区分，则选择runid最小的从节点。 对上面slave节点执行slaveof no one命令让其成为master节点。 向剩余的slave节点发送命令，让它们成为新master节点的slave节点，复制规则和parallel-syncs参数有关。 更新原来master节点配置为slave，并保持着对其“关注”，当其恢复后命令它去复制新的master节点。 常见问题Redis Sentinel无法对从节点进行自动故障转移，在读写分离场景下，从节点故障会导致读服务不可用，需要我们对从节点做额外的监控、切换操作。除此之外，它的存储能力受到单机限制的问题，因此如果我们对扩容有需求的话，应当使用Redis Cluster这么一个高可用的集群方案。 参考资料 《Redis开发与运维》 深入学习Redis（4）：哨兵]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis主从复制]]></title>
    <url>%2F2019%2F03%2F30%2Fdis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%2F</url>
    <content type="text"><![CDATA[概述主从复制是指将主节点（master）的数据复制到从节点（slave）中，数据的复制是单向的，只能由主节点到从节点。 基本原理主从复制过程大体可以分为3个阶段：连接建立阶段、数据同步阶段、命令传播阶段。 连接建立阶段主从复制的开启，完全是在从节点发起的（通过slaveof命令），不需要我们在主节点做任何事情。需要注意的是，slaveof是异步命令，从节点完成主节点ip和port的保存后，向发送slaveof命令的客户端直接返回OK，实际的复制操作在这之后才开始进行。 数据同步阶段主从节点之间的连接建立以后，便可以开始进行数据同步。数据同步阶段是主从复制最核心的阶段，由从节点向主节点发送psync命令开始同步，并且根据主从节点当前状态的不同，可以分为全量复制和部分复制。 全量复制全量复制用于初次复制或其他无法进行部分复制的情况，将主节点中的所有数据都发送给从节点，是一个非常重型的操作。执行过程如下： 主节点收到全量复制的命令后，执行bgsave，在后台生成RDB文件，并使用一个缓冲区（称为复制缓冲区）记录从现在开始执行的所有写命令。 主节点的bgsave执行完成后，将RDB文件发送给从节点，从节点首先清除自己的旧数据，然后载入接收的RDB文件，将数据库状态更新至主节点执行bgsave时的数据库状态。 主节点将复制缓冲区中的所有写命令发送给从节点，从节点执行这些写命令，将数据库状态更新至主节点的最新状态。 如果从节点开启了AOF，则会触发bgrewriteaof的执行，从而保证AOF文件更新至主节点的最新状态。 部分复制复制偏移量：主节点和从节点分别维护一个复制偏移量（offset），代表的是主节点向从节点传递的字节数。主节点每次向从节点传播N个字节数据时，主节点的offset增加N；从节点每次收到主节点传来的N个字节数据时，从节点的offset增加N。offset用于判断主从节点的数据库状态是否一致：如果二者offset相同，则一致；如果offset不同，则不一致，此时可以根据两个offset找出从节点缺少的那部分数据。 复制缓冲区：复制缓冲区是由主节点维护的、固定长度的、先进先出队列，默认大小1MB，当主节点开始有从节点时创建。在命令传播阶段，主节点除了将写命令发送给从节点，还会发送一份给复制缓冲区，作为写命令的备份。除了存储写命令，复制缓冲区中还存储了其中的每个字节对应的复制偏移量（offset）。由于复制缓冲区定长且是先进先出，所以它保存的是主节点最近执行的写命令，时间较早的写命令会被挤出缓冲区，因此当主从节点offset的差距过大超过缓冲区长度时，将无法执行部分复制，只能执行全量复制。 服务器运行ID（runid）：每个Redis节点（无论主从），在启动时都会自动生成一个随机ID（每次启动都不一样），runid用来唯一识别一个Redis节点。主从节点初次复制时，主节点将自己的runid发送给从节点，从节点将这个runid保存起来。当断线重连时，从节点会将这个runid发送给主节点；主节点根据runid判断能否进行部分复制： 如果从节点保存的runid与主节点现在的runid相同，说明主从节点之前同步过，主节点会继续尝试使用部分复制(到底能不能部分复制还要看offset和复制积压缓冲区的情况)； 如果从节点保存的runid与主节点现在的runid不同，说明从节点在断线前同步的Redis节点并不是当前的主节点，只能进行全量复制。 命令传播阶段数据同步阶段完成后，主从节点进入命令传播阶段。在这个阶段主节点将自己执行的写命令发送给从节点，从节点接收命令并执行，从而保证主从节点数据的一致性。需要注意的是，命令传播是异步的过程，即主节点发送写命令后并不会等待从节点的回复，因此实际上主从节点之间很难保持实时的一致性，延迟在所难免。 故障转移在没有使用哨兵或集群的场景下，当主节点挂掉了以后，从节点没法完成master选举，从而导致整个服务对外不可用。我们需要自行选择一个从节点作为主节点并继续对外提供服务，并将其它从节点的主节点设为它，由于这些过程都需要手动完成，出错率比较高，因此在真实场景中往往都会使用哨兵或者集群来实现系统的高可用。 参考资料 《Redis开发与运维》 深入学习Redis（3）：主从复制]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis持久化：AOF与RDB]]></title>
    <url>%2F2019%2F03%2F30%2FRedis%E4%BA%94%E7%A7%8D%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[Redis持久化Redis是内存数据库，数据都是存储在内存中，为了避免进程退出导致数据的永久丢失，需要定期将Redis中的数据以某种形式(数据或命令)从内存保存到硬盘，当下次Redis重启时，利用持久化文件实现数据恢复。 Redis持久化分为RDB持久化和AOF持久化：前者将当前数据保存到硬盘，后者则是将每次执行的写命令保存到硬盘（类似于MySQL的binlog）。 RDBRDB持久化是将当前进程中的数据生成快照保存到硬盘，保存的文件后缀是rdb，当Redis重新启动时，可以读取快照文件恢复数据。RDB持久化分为手动触发和自动触发两种方式： 手动触发手动触发可以使用save命令和bgsave命令，都可以生成rdb文件。它们的区别在于save命令会阻塞Redis服务器进程，直到RDB文件创建完毕为止，在Redis服务器阻塞期间，服务器不能处理任何命令请求；而bgsave命令会创建一个子进程，由子进程来负责创建RDB文件，父进程（即Redis主进程）则继续处理请求，整个过程中只有fork子进程时会阻塞服务器。 自动触发自动触发最常见的情况是在配置文件中通过save m n，指定当m秒内发生n次变化时，会触发bgsave。例如默认配置文件中有以下三行：123save 900 1save 300 10save 60 10000 只要上面三行任意一条满足时，就会执行bgsave。除此之外，在主从复制的场景下，如果从节点执行全量复制操作，则主节点会执行bgsave命令，并将rdb文件发送给从节点。执行shutdown命令时，也会自动执行rdb持久化。 启动时加载RDB文件的载入工作是在服务器启动时自动执行的，并没有专门的命令。但是由于AOF的优先级更高，因此当AOF开启时，Redis会优先载入AOF文件来恢复数据；只有当AOF关闭时，才会在Redis服务器启动时检测RDB文件，并自动载入。服务器载入RDB文件期间处于阻塞状态，直到载入完成为止。 AOFRDB持久化是将进程数据写入文件，而AOF持久化则是将Redis执行的每次写命令记录到单独的日志文件中（有点像MySQL的binlog），当Redis重启时再次执行AOF文件中的命令来恢复数据。与RDB相比，AOF的实时性更好，因此已成为主流的持久化方案。 三种策略为了提高文件写入效率，在现代操作系统中，当用户将数据写入文件时（write命令），操作系统通常会将数据暂存到一个内存缓冲区里，当缓冲区被填满或超过了指定时限，才真正将缓冲区的数据写入到硬盘里。这样的操作虽然提高了效率，但如果系统崩溃，内存缓冲区中的数据将会丢失。因此可以设置同步选项，强制操作系统什么时候将缓冲区中的数据写入到硬盘中（fsync命令），Redis提供了以下三种同步策略： always：每个写命令都同步 everysec：每秒同步一次 no：让操作系统来决定何时同步 always会严重降低服务器的性能，而no的不可控性太强，因此Redis使用everysec作为默认配置，但在系统崩溃时可能会丢失一秒的数据。 文件重写随着Redis服务器执行的写命令越来越多，AOF文件也会越来越大，过大的AOF文件不仅会影响服务器的正常运行，也会导致数据恢复需要的时间过长。文件重写是指定期重写AOF文件，减小AOF文件的体积。需要注意的是，AOF重写是把Redis进程内的数据转化为写命令，同步到新的AOF文件，而不会对旧的AOF文件进行任何读取、写入操作。 文件重写主要是针对以下一些语句： 过期的数据（如expire），可以不用再写入文件。 多次INCR命令可以合并为一个SET命令。 无效的命令不再写入文件，比如有些数据被删除了。 手动触发可以直接调用bgrewriteaof命令重写文件，该命令的执行与bgsave有些类似，都是fork子进程进行具体的工作，且都只有在fork时阻塞。 自动触发默认配置是当AOF文件大小是上次重写后大小的一倍（auto-aof-rewrite-min-size）且文件大于64M时触发（auto-aof-rewrite-percentage）。 具体流程 父进程执行fork操作创建子进程，这个过程中父进程是阻塞的。 子进程创建后，Redis的所有写命令依然写入AOF缓冲区，并根据设置策略同步到硬盘，保证原有AOF机制的正确。 由于fork操作使用写时复制技术，子进程只能共享fork操作时的内存数据。由于父进程依然在响应命令，因此Redis使用AOF重写缓冲区（图中的aof_rewrite_buf）保存这部分数据，防止新AOF文件生成期间丢失这部分数据。也就是说，bgrewriteaof执行期间，Redis的写命令同时追加到aof_buf和aof_rewirte_buf两个缓冲区。 子进程根据内存快照，按照命令合并规则写入到新的AOF文件。 子进程写完新的AOF文件后，向父进程发信号，父进程把AOF重写缓冲区的数据写入到新的AOF文件，这样就保证了新AOF文件所保存的数据库状态和服务器当前状态一致。 使用新的AOF文件替换老文件，完成AOF重写。 RDB与AOF对比 RDB持久化：RDB文件紧凑，体积小，恢复速度比AOF快很多，但数据的实时性较低。 AOF持久化：实时性较高，但是文件大，并且恢复速度较慢，且对性能有一定影响。 常见问题fork阻塞：CPU的阻塞在Redis中，无论是RDB持久化的bgsave，还是AOF重写的bgrewriteaof，都需要fork出子进程来进行操作，而在操作系统fork的实现中，基本都采用了写时复制技术，即在父/子进程试图修改数据空间之前，父子进程实际上共享数据空间，但是当父/子进程的任何一个试图修改数据空间时，操作系统会为修改的那一部分（内存的一页）制作一个副本。 也就是说，虽然fork时子进程不会复制父进程的数据空间，但是会复制内存页表，如果Redis内存过大，会导致fork操作时复制内存页表耗时过多，而Redis主进程在进行fork时是完全阻塞的，意味着无法响应客户端的请求，造成请求延迟过大。 为了防止该问题的发生，我们需要控制Redis单机内存的大小，并且适当放宽AOF重写的触发条件，尽量在写入较少的时间段完成重写。 AOF追加阻塞：硬盘的阻塞AOF持久化过程中，通过fsync命令每秒一次将缓冲区的数据写入磁盘中，但在硬盘负载过高时，fsync操作可能会超过1s，当继续向缓冲区内写入数据时，磁盘负载会越来越大，如果此时Redis进程异常退出，丢失的数据也有可能远超1s。 为此，Redis的处理策略是这样的：主线程每次进行AOF会对比距离上次fsync成功的时间，如果距上次不到2s，主线程直接返回；如果超过2s，则主线程阻塞直到fsync同步完成。因此，如果系统硬盘负载过大导致fsync速度太慢，会导致Redis主线程的阻塞。这里还要注意的是，如果使用everysec策略，AOF最多可能丢失2s的数据，而不是1s。 参考资料 《Redis开发与运维》 深入学习Redis（2）：持久化]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux五种IO模型]]></title>
    <url>%2F2019%2F03%2F27%2FLinux-%E4%BA%94%E7%A7%8DIO%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[IO模型对于一次IO访问，会分为两个阶段，首先等待数据准备好后被拷贝到操作系统内核的缓冲区中，然后再从操作系统内核的缓冲区拷贝到用户空间。IO模型可以分为以下五种类型： 阻塞式I/O（Blocking I/O） 非阻塞式I/O（Non-blocking I/O） 多路复用I/O（Multiplexing I/O） 信号驱动I/O（Signal-driven I/O） 异步I/O（Asynchronous I/O） 其中信号驱动式IO并不常用，所以重点关注另外四种IO模型。 阻塞式I/O在这个IO模型中，用户空间的应用程序执行一个系统调用（recvform），这会导致应用程序阻塞，什么也不干，直到数据准备好，并且将数据从内核复制到用户进程，最后进程再处理数据，在等待数据到处理数据的两个阶段，整个进程都被阻塞，不能处理别的IO。 阻塞IO的特点就是能够及时的返回数据，但是在IO执行的两个阶段都被阻塞了，只有当数据从内核复制到了用户空间中，进程才能继续往下执行，因此对性能有所牺牲。 非阻塞式I/O应用进程执行系统调用之后，内核会立即返回一个错误码，但IO操作还没完成。此时应用进程并没有被阻塞，可以继续执行，但是需要不断的执行系统调用来获知IO操作是否完成，这种方式称为轮询。 这种模型的CPU利用率比较低，并且因为每过一段时间才去轮询一次，所以存在一个响应延迟。还需要注意的是，拷贝数据的整个过程，进程仍然是属于阻塞的状态。 I/O多路复用使用select或者poll对多个IO端口进行监听，只要多个套接字中的任何一个数据准备好了，就能返回可读，之后应用进程再执行recvfrom系统调用把数据从内核复制到进程中。 I/O复用模型让单个进程具有处理多个I/O事件的能力，因此相比多进程和多线程技术，它的系统开销小了许多。但是select，poll，epoll函数依然会阻塞应用进程，并且由于多路复用可以处理多个IO，那么多个IO之间的顺序就变得不确定了。 信号驱动I/O应用进程使用sigaction系统调用，内核立即返回，应用进程可以继续执行，也就是说等待数据阶段应用进程是非阻塞的。内核在数据到达时向应用进程发送SIGIO信号，应用进程收到之后在信号处理程序中调用recvfrom将数据从内核复制到应用进程中。 相比于非阻塞式I/O的轮询方式，信号驱动I/O的CPU利用率更高。 异步非阻塞I/O用户进程进行aio_read系统调用之后，无论内核数据是否准备好，都会直接返回给用户进程，然后用户进程就可以去做别的事情。等到数据准备好了，内核直接复制数据给进程，然后从内核向进程发送通知。这个IO模式的两个阶段，进程都是非阻塞的。 五种I/O模型对比 阻塞式I/O：同步阻塞 非阻塞式I/O：同步非阻塞（轮询） I/O多路复用：同步阻塞（可以监听多个IO） 信号驱动I/O：同步非阻塞（收到SIGIO信号后才执行recvfrom并阻塞） 异步I/O：异步非阻塞（两个阶段都不会阻塞） I/O多路复用中的select、poll、epollselect，poll，epoll都是IO多路复用的机制，select出现的最早，之后是poll，再是epoll。I/O多路复用就是通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。 文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。 select：它仅仅知道有I/O事件发生了，却并不知道是哪几个流（可能有一个，多个，甚至全部），我们只能无差别轮询所有流，测试每个流是否有事件发生，找出能读出数据，或者写入数据的流，对他们进行操作。所以select具有O(n)的时间复杂度，同时处理的流越多，无差别轮询时间就越长。 poll：poll本质上和select没有区别，需要查询每个fd对应的设备状态，但是它没有最大连接数的限制，因为select的描述符类型使用数组实现，而poll的描述符类型使用链表实现。 epoll：epoll可以理解为event poll，不同于忙轮询和无差别轮询，epoll会把哪个流发生了怎样的I/O事件通知我们。所以我们说epoll实际上是事件驱动（每个事件关联上fd）的，此时我们对这些流的操作都是有意义的。（复杂度降低到了O(1)） 参考资料 Linux IO模式及 select、poll、epoll详解 select、poll、epoll之间的区别(搜狗面试)]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>IO</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NIO知识点总结]]></title>
    <url>%2F2019%2F03%2F10%2FNIO%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[简介Java NIO是一个可以替代标准Java IO API的IO API，主要有以下三个核心组件： Channels Buffers Selectors NIO与IO的主要区别在于： IO是面向流的，NIO是面向缓冲区的。 IO是阻塞的，NIO是非阻塞的。 NIO有选择器，允许一个单独的线程来管理多个输入通道。 ChannelJava NIO的通道类似流，主要区别在于： 既可以从通道中读取数据，又可以写数据到通道。但流的读写通常是单向的。 通道可以异步地读写。 通道中的数据总是要先读到一个Buffer，或者总是要从一个Buffer中写入。 NIO中有以下几个重要的通道实现。 FileChannelFileChannel是一个连接到文件的通道。可以通过文件通道读写文件。 注意：FileChannel无法设置为非阻塞模式，它总是运行在阻塞模式下。 12345678910111213//打开FileChannelRandomAccessFile aFile = new RandomAccessFile("data/nio-data.txt", "rw");FileChannel inChannel = aFile.getChannel();//在FileChannel的某个特定位置进行数据的读/写操作long pos = channel.position();channel.position(pos +123);//可以使用FileChannel.truncate()方法截取一个文件，指定长度后面的部分将被删除channel.truncate(1024);//出于性能方面的考虑，操作系统会将数据缓存在内存中，所以无法保证写入到FileChannel里的数据一定会即时写到磁盘上，而通过FileChannel.force()方法则可以将通道里尚未写入磁盘的数据强制写到磁盘上channel.force(true); SocketChannelSocketChannel是一个连接到TCP网络套接字的通道。可以通过以下2种方式创建SocketChannel： 打开一个SocketChannel并连接到互联网上的某台服务器。 一个新连接到达ServerSocketChannel时，会创建一个SocketChannel。 SocketChannel是可以设置为非阻塞模式的，设置之后，就可以在异步模式下调用connect(), read()和write()了。 12345678910//打开并连接SocketChannel socketChannel = SocketChannel.open();socketChannel.connect(new InetSocketAddress("http://jenkov.com", 80));//非阻塞模式可以调用finishConnect()的方法确定连接是否建立socketChannel.configureBlocking(false);socketChannel.connect(new InetSocketAddress("http://jenkov.com", 80));while(! socketChannel.finishConnect() )&#123; //wait, or do something else...&#125; ServerSocketChannelServerSocketChannel是一个可以监听新进来的TCP连接的通道。在打开了ServerSocketChannel之后，可以通过accept()方法监听新进来的连接，当accept()方法返回的时候，它返回一个包含新进来的连接的SocketChannel。因此，accept()方法会一直阻塞到有新连接到达。 ServerSocketChannel也可以设置成非阻塞模式。在非阻塞模式下，accept()方法会立刻返回，如果还没有新进来的连接,返回的将是null。 1234567//打开通道并监听新进来的连接ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();serverSocketChannel.socket().bind(new InetSocketAddress(9999));while(true)&#123; SocketChannel socketChannel = serverSocketChannel.accept(); //do something with socketChannel...&#125; DatagramChannelDatagramChannel是一个能收发UDP包的通道。因为UDP是无连接的网络协议，所以不能像其它通道那样读取和写入。它发送和接收的是数据包。 12345678910111213141516//打开DatagramChannelDatagramChannel channel = DatagramChannel.open();channel.socket().bind(new InetSocketAddress(9999));//通过receive()方法从DatagramChannel接收数据到指定的Buffer，如果Buffer容不下收到的数据，多出的数据将被丢弃ByteBuffer buf = ByteBuffer.allocate(48);buf.clear();channel.receive(buf);//通过send()方法从DatagramChannel发送数据String newData = "New String to write to file..." + System.currentTimeMillis();ByteBuffer buf = ByteBuffer.allocate(48);buf.clear();buf.put(newData.getBytes());buf.flip();int bytesSent = channel.send(buf, new InetSocketAddress("jenkov.com", 80)); BufferBuffer本质是一块可以写入数据，并可以从中读取数据的内存，用于和通道进行交互，过程如下： 写入数据到Buffer 调用flip()方法 从Buffer中读取数据 调用clear()方法或者compact()方法 其中flip()方法是将Buffer从写模式切换到读模式，clear()方法会清空整个缓冲区，compact()方法只会清除已经读过的数据并将所有未读的数据拷贝到Buffer起始处。 Buffer有三个属性： capacity position：当写数据到Buffer中时，position表示当前的位置；当从Buffer读取数据时，也是从当前位置开始读；将Buffer从写模式切换到读模式，position会被重置为0。 limit：在写模式下，limit表示你最多能往Buffer里写多少数据，此时limit等于capacity；在读模式下，limit表示最多能读到多少数据，因此，当切换Buffer到读模式时，limit会被设置成写模式下的position值。 Buffer有以下几种类型，它们代表了不同的数据类型： ByteBuffer MappedByteBuffer CharBuffer DoubleBuffer FloatBuffer IntBuffer LongBuffer ShortBuffer Buffer的分配要想获得一个Buffer对象首先要进行分配。每一个Buffer类都有一个allocate方法：1ByteBuffer buf = ByteBuffer.allocate(48); 向Buffer写数据写数据到Buffer有两种方式： 从Channel写到Buffer。 通过Buffer的put()方法写到Buffer里。 123int bytesRead = inChannel.read(buf); //read into buffer.buf.put(127); 从Buffer读数据从Buffer中读取数据有两种方式： 从Buffer读取数据到Channel。 使用get()方法从Buffer中读取数据。 123int bytesWritten = inChannel.write(buf);byte aByte = buf.get(); rewind()方法rewind()将position设回0，所以可以重读Buffer中的所有数据。limit保持不变，仍然表示能从Buffer中读取多少个元素。 SelectorSelector是NIO中能够检测一到多个通道，并能够知晓通道是否为诸如读写事件做好准备的组件。这样，一个单独的线程可以管理多个channel，从而管理多个网络连接。 创建并注册与Selector一起使用时，Channel必须处于非阻塞模式下。这意味着不能将FileChannel与Selector一起使用，因为FileChannel不能切换到非阻塞模式。 1234567//Selector的创建Selector selector = Selector.open(); //向Selector注册通道 channel.configureBlocking(false);SelectionKey key = channel.register(selector, Selectionkey.OP_READ); 注意register()方法的第二个参数。这是一个interest集合，意思是在通过Selector监听Channel时对什么事件感兴趣。可以监听四种不同类型的事件，用SelectionKey的四个常量来表示: SelectionKey.OP_CONNECT：某个channel成功连接到另一个服务器称为“连接就绪” SelectionKey.OP_ACCEPT：一个server socket channel准备好接收新进入的连接称为“接收就绪” SelectionKey.OP_READ：一个有数据可读的通道可以说是“读就绪” SelectionKey.OP_WRITE：等待写数据的通道可以说是“写就绪”。 如果对不止一种事件感兴趣，那么可以用“位或”操作符将常量连接起来，如int interestSet = SelectionKey.OP_READ | SelectionKey.OP_WRITE; SelectionKey当向Selector注册Channel时，register()法会返回一个SelectionKey对象，这个对象包含以下几个属性： terest集合 ready集合 Channel Selector 附加的对象（可选） interest集合可以用位与操作interest集合和给定的SelectionKey常量来确定某个事件是否在interest集合中。 123456int interestSet = selectionKey.interestOps();boolean isInterestedInAccept = (interestSet &amp; SelectionKey.OP_ACCEPT) == SelectionKey.OP_ACCEPT；boolean isInterestedInConnect = interestSet &amp; SelectionKey.OP_CONNECT;boolean isInterestedInRead = interestSet &amp; SelectionKey.OP_READ;boolean isInterestedInWrite = interestSet &amp; SelectionKey.OP_WRITE; ready集合ready集合是通道已经准备就绪的操作的集合。可以用像检测interest集合那样的方法，来检测channel中什么事件或操作已经就绪，也可以通过如下的方法：1234selectionKey.isAcceptable();selectionKey.isConnectable();selectionKey.isReadable();selectionKey.isWritable(); Channel Selector12Channel channel = selectionKey.channel();Selector selector = selectionKey.selector(); 附加的对象可以将一个对象或者更多信息附着到SelectionKey上，这样就能方便的识别某个给定的通道。使用方法如下： 12selectionKey.attach(theObject);Object attachedObj = selectionKey.attachment(); 选择通道一旦向Selector注册了一或多个通道，就可以调用select()方法选择就绪的通道，方法返回已经就绪的通道数目。select()阻塞到至少有一个通道在你注册的事件上就绪了，而selectNow()不会阻塞。 一旦调用了select()方法，并且返回值表明有一个或更多个通道就绪了，就可以通过调用selectedKeys()方法返回就绪通道的集合：1Set selectedKeys = selector.selectedKeys(); 之后就可以通过遍历这个集合来访问就绪的通道：123456789101112131415Set selectedKeys = selector.selectedKeys();Iterator keyIterator = selectedKeys.iterator();while(keyIterator.hasNext()) &#123; SelectionKey key = keyIterator.next(); if(key.isAcceptable()) &#123; // a connection was accepted by a ServerSocketChannel. &#125; else if (key.isConnectable()) &#123; // a connection was established with a remote server. &#125; else if (key.isReadable()) &#123; // a channel is ready for reading &#125; else if (key.isWritable()) &#123; // a channel is ready for writing &#125; keyIterator.remove();&#125; 注意每次迭代末尾的keyIterator.remove()调用。Selector不会自己从集合中移除SelectionKey实例，必须在处理完通道时自己移除。下次该通道变成就绪时，Selector会再次将其放入集合中。 关闭用完Selector后调用其close()方法会关闭该Selector，且使注册到该Selector上的所有SelectionKey实例无效，但通道本身并不会关闭。 Scatter/GatherJava NIO支持scatter/gather，scatter是指数据从一个channel读取到多个buffer中，而gather则是指数据从多个buffer写入到同一个channel。scatter/gather经常用于需要将传输的数据分开处理的场合，例如传输一个由消息头和消息体组成的消息，你可能会将消息体和消息头分散到不同的buffer中，这样可以方便的处理消息头和消息体。 123456789ByteBuffer header = ByteBuffer.allocate(128);ByteBuffer body = ByteBuffer.allocate(1024);ByteBuffer[] bufferArray = &#123; header, body &#125;;channel.read(bufferArray);ByteBuffer header = ByteBuffer.allocate(128);ByteBuffer body = ByteBuffer.allocate(1024);ByteBuffer[] bufferArray = &#123; header, body &#125;;channel.write(bufferArray); 注意，Scattering Reads在移动下一个buffer前，必须填满当前的buffer，这意味着它不适用于动态消息，而Gathering Writes只有position和limit之间的数据才会被写入，因此能较好的处理动态消息。 通道之间的数据传输如果两个通道中有一个是FileChannel，那么可以直接将数据从一个通道传输到另外一个通道。 transferFrom()transferFrom()方法可以将数据从源channel传输到FileChannel中：12345678910RandomAccessFile fromFile = new RandomAccessFile("fromFile.txt", "rw");FileChannel fromChannel = fromFile.getChannel();RandomAccessFile toFile = new RandomAccessFile("toFile.txt", "rw");FileChannel toChannel = toFile.getChannel();long position = 0;long count = fromChannel.size();toChannel.transferFrom(position, count, fromChannel); transferTo()transferTo()方法将数据从FileChannel传输到其他的channel中。 12345678910RandomAccessFile fromFile = new RandomAccessFile("fromFile.txt", "rw");FileChannel fromChannel = fromFile.getChannel();RandomAccessFile toFile = new RandomAccessFile("toFile.txt", "rw");FileChannel toChannel = toFile.getChannel();long position = 0;long count = fromChannel.size();fromChannel.transferTo(position, count, toChannel); PathPath接口表示的是一个与平台无关的路径，既可以是绝对路径也可以是相对路径，文件和目录都用Path表示。 创建Path可以使用Paths工具类的工厂方法创建一个Path对象： 123456Path path = Paths.get("C:\\DATA\\test.txt");Path projects = Paths.get("d:\\data", "projects");Path currentDir = Paths.get(".");Path parentDir = Paths.get(".."); normalize()normalize()方法可以标准化路径，它会处理路径中的相对路径，去除. ..：123456789Path path = Paths.get("c:/Z_DATA/./test.txt");System.out.println("path = " + path);path = path.normalize();System.out.println("path = " + path);//输出path = c:\Z_DATA\.\test.txtpath = c:\Z_DATA\test.txt FilesFiles工具类封装提供了一些操作文件系统中文件的工具方法，往往和和Path一起使用。 exists()exists()可以判断一个Path在文件系统中是否存在。 createDirctory()在调用创建方法前最好先检查是否存在，如果已经存在会抛出FileAlreadyExistsException异常。 12345678Path newDir = Paths.get("c:/Z_DATA/newDir");try &#123; if(!Files.exists(newDir)) &#123; Files.createDirectory(newDir); &#125;&#125; catch (IOException e) &#123; e.printStackTrace();&#125; copy()copy()只能复制到不存在的路径，如果复制的目标文件已存在则会抛出异常。强制覆盖已存在文件也是可以的，需要增加相应参数： 1234567Path sourcePath = Paths.get(classPath,"nio-data.txt");Path targetPath = Paths.get(classPath,"nio-data-copy.txt");try &#123; Files.copy(sourcePath, targetPath, StandardCopyOption.REPLACE_EXISTING); // 复制并覆盖已有文件&#125; catch (IOException e) &#123; e.printStackTrace();&#125; move()Java NIO Files类同样提供了移动文件的方法。 1234567Path sourcePath = Paths.get(classPath,"nio-data.txt");Path targetPath = Paths.get(classPath,"nio-data-copy.txt");try &#123; Files.move(sourcePath, targetPath, StandardCopyOption.REPLACE_EXISTING); // 移动并覆盖已有文件&#125; catch (IOException e) &#123; e.printStackTrace();&#125; delete()删除文件或目录 1Files.delete(targetPath); 如果删除的文件或目录不存在会抛出IOException异常。 AsynchronousFileChannel使用AsynchronousFileChannel可以实现异步地读取和写入文件数据。 创建我们可以使用AsynchronousFileChannel提供的静态方法open()创建它。 123Path path = Paths.get("data/test.xml");AsynchronousFileChannel fileChannel = AsynchronousFileChannel.open(path, StandardOpenOption.READ); 读取数据AsynchronousFileChannel提供了两种读取数据的方式，都是调用它本身的read()方法。 使用Futrue读取数据第一种方式是调用AsynchronousFileChannel的read()方法，该方法返回一个Future类型的对象。 123456789101112131415AsynchronousFileChannel fileChannel = AsynchronousFileChannel.open(path, StandardOpenOption.READ);ByteBuffer buffer = ByteBuffer.allocate(1024);long position = 0;Future&lt;Integer&gt; operation = fileChannel.read(buffer, position);while(!operation.isDone());buffer.flip();byte[] data = new byte[buffer.limit()];buffer.get(data);System.out.println(new String(data));buffer.clear(); 以上代码read()方法会立即返回，即使整个读的过程还没有完全结束。我们可以通过Future.isDone()来检查读取是否完成。 使用CompletionHandler读取数据第二种读取数据的方式是调用AsynchronousFileChannel的另一个read()方法，该方法需要一个CompletionHandler作为参数。 1234567891011121314151617fileChannel.read(buffer, position, buffer, new CompletionHandler&lt;Integer, ByteBuffer&gt;() &#123; @Override public void completed(Integer result, ByteBuffer attachment) &#123; System.out.println("result = " + result); attachment.flip(); byte[] data = new byte[attachment.limit()]; attachment.get(data); System.out.println(new String(data)); attachment.clear(); &#125; @Override public void failed(Throwable exc, ByteBuffer attachment) &#123; &#125;&#125;); 一旦读取操作完成，CompletionHandler的complete()方法将会被调用。它的第一个参数是个Integer类型，表示读取的字节数。第二个参数attachment是ByteBuffer类型的，用来存储读取的数据(ByteBuffer也可以换成其他合适的对象方便数据写入)。它其实就是由read()方法的第三个参数。读取失败的时候，CompletionHandler的failed()方法会被调用。 写入数据就像读取一样，我们同样有两种方式向AsynchronousFileChannel写入数据。 使用Future读取数据12345678910111213141516Path path = Paths.get("data/test-write.txt");AsynchronousFileChannel fileChannel = AsynchronousFileChannel.open(path, StandardOpenOption.WRITE);ByteBuffer buffer = ByteBuffer.allocate(1024);long position = 0;buffer.put("test data".getBytes());buffer.flip();Future&lt;Integer&gt; operation = fileChannel.write(buffer, position);buffer.clear();while(!operation.isDone());System.out.println("Write done"); 注意，写入目标文件要提前创建好，如果它不存在的话，write()方法会抛出一个 NoSuchFileException。 使用CompletionHandler写入数据1234567891011121314151617181920212223242526Path path = Paths.get("data/test-write.txt");if(!Files.exists(path))&#123; Files.createFile(path);&#125;AsynchronousFileChannel fileChannel = AsynchronousFileChannel.open(path, StandardOpenOption.WRITE);ByteBuffer buffer = ByteBuffer.allocate(1024);long position = 0;buffer.put("test data".getBytes());buffer.flip();fileChannel.write(buffer, position, buffer, new CompletionHandler&lt;Integer, ByteBuffer&gt;() &#123; @Override public void completed(Integer result, ByteBuffer attachment) &#123; System.out.println("bytes written: " + result); &#125; @Override public void failed(Throwable exc, ByteBuffer attachment) &#123; System.out.println("Write failed"); exc.printStackTrace(); &#125;&#125;); 当写入程序完成时，CompletionHandler的completed()方法将会被调用，相反的如果写入失败则会调用failed()方法。 参考资料 Java NIO 系列教程]]></content>
      <categories>
        <category>NIO</category>
      </categories>
      <tags>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTPS的过程与原理]]></title>
    <url>%2F2019%2F02%2F17%2FHTTPS%E7%9A%84%E8%BF%87%E7%A8%8B%E4%B8%8E%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[由于HTTP存在明文通信、无法验证服务器的真实性等弊端，使用HTTPS的人变得越来越多。HTTPS并不是新的协议，而是在HTTP基础之上加一层TLS模块，TLS提供了加密、认证以及消息完整性校验的服务，从而保证通信的安全性。 HTTPS过程HTTPS总的流程就相当于使用非对称加密的方式来传递对称私钥，之后的通信就可以使用这个私钥进行对称加密了。 客户端发起HTTPS请求用户在浏览器里输入一个https网址，然后连接到server的443端口。 服务端的配置采用HTTPS协议的服务器必须要有一套数字证书，可以自己制作，也可以向组织申请。区别就是自己颁发的证书需要客户端验证通过，才可以继续访问，而使用受信任的公司申请的证书则不会弹出提示页面。 传送证书这个证书包含了公钥，还包含了很多信息，如证书的颁发机构，过期时间等等。 客户端解析证书这部分工作是由客户端的TLS来完成的，首先会验证证书是否有效，比如颁发机构，过期时间等等，如果发现异常，则会弹出一个警告框，提示证书存在问题。如果证书没有问题，那么就生成一个随机值。然后用证书对该随机值进行加密。 传送加密信息这部分传送的是用证书加密后的随机值，目的就是让服务端得到这个随机值，以后客户端和服务端的通信就可以通过这个随机值来进行加密解密了。 服务端解密信息服务端用私钥解密后，得到了客户端传过来的随机值(私钥)，然后把内容通过该值进行对称加密。所谓对称加密就是，将信息和私钥通过某种算法混合在一起，这样除非知道私钥，不然无法获取内容，而正好客户端和服务端都知道这个私钥，所以只要加密算法够彪悍，私钥够复杂，数据就够安全。 传输加密后的信息这部分信息是服务端用私钥加密后的信息，可以在客户端被还原。 客户端解密信息客户端用之前生成的私钥解密服务段传过来的信息，于是获取了解密后的内容。整个过程第三方即使监听到了数据，也束手无策。 证书认证单纯的加密是无法保证通信安全的，TLS还需要通过证书机制来保证访问的服务器是真实的。 证书是由权威机构颁发的，服务端如果能够提供一个合法的证书，说明这个服务端是合法的，可以被信任。整个证书的认证过程如下： 客户端获取到了站点证书，拿到了站点的公钥 要验证站点可信后，才能使用其公钥，因此客户端找到其站点证书颁发者的信息 站点证书的颁发者验证了服务端站点是可信的，但客户端依然不清楚该颁发者是否可信 再往上回溯，找到了认证了中间证书商的根证书颁发者。由于根证书颁发者非常少，我们浏览器之前就认识了，因此可以认为根证书颁发者是可信的 一路倒推，证书颁发者可信，那么它所颁发的所有站点也是可信的，最终确定我们所要访问的服务端是可信的 客户端使用证书中包含的公钥，继续完成TLS的握手过程 如果证书过期了、颁发机构不受信任或者证书绑定的域名和请求的域名不一致等原因，浏览器会抛出异常信息，说明此时的访问是不安全的。 参考资料 图解HTTPS TLS整理（下）：TLS如何保证安全]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>HTTPS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[InnoDB和MyISAM的区别]]></title>
    <url>%2F2019%2F02%2F16%2FInnoDB%E5%92%8CMyISAM%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[InnoDB支持事务，MyISAM不支持。 InnoDB支持外键，而MyISAM不支持。 InnoDB是聚集索引，而MyISAM是非聚集索引。 InnoDB不保存表的具体行数，执行select count(*) from table时需要全表扫描。而MyISAM用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MyISAM</tag>
        <tag>InnoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[访问一个网页的全过程]]></title>
    <url>%2F2019%2F02%2F13%2F%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[客户端用户从浏览器输入www.google.com网站网址后回车，系统会查询本地hosts文件及DNS缓存信息，查找是否存在网址对应的IP解析记录。如果有就直接获取到IP地址，然后访问网站，一般第一次请求时，DNS缓存是没有解析记录的。 如果hosts与DNS缓存都没有解析记录时，系统会把浏览器的解析请求交给客户端本地设置的DNS服务器地址解析，如果本地DNS服务器的本地缓存有对应的解析记录，就会直接返回IP地址。 如果本地DNS服务器没有对应的解析记录，则根据本地DNS服务器的设置（是否设置转发器）进行查询，如果未用转发模式，本地DNS就把请求发至13台根DNS，根DNS服务器收到请求后会判断这个域名(.com)是谁来授权管理，并会返回一个负责该顶级域名服务器的一个IP。本地DNS服务器收到IP信息后，将会联系负责.com域的这台服务器。这台负责.com域的服务器收到请求后，如果自己无法解析，它就会找一个管理.com域的下一级DNS服务器地址(google.com)给本地DNS服务器。当本地DNS服务器收到这个地址后，就会找google.com域服务器，重复上面的动作，进行查询，直至找到www.google.com主机。 如果用的是转发模式，此DNS服务器就会把请求转发至上一级DNS服务器，由上一级服务器进行解析，上一级服务器如果不能解析，或找根DNS服务器或把请求转发至上上级，以此循环。不管是本地DNS服务器还是转发，还是根DNS，最后都是把结果返回给本地DNS服务器，由此DNS服务器再返回给客户机。 如果配置了CDN，则DNS系统最终会将域名的解析权交给CNAME指向的CDN专用DNS服务器，CDN的DNS服务器将CDN的全局负载均衡设备IP地址返回给本地DNS，本地DNS再向CDN的全局负载均衡设备发起内容URL访问请求，CDN全局负载均衡设备根据用户IP地址，以及用户请求的内容URL，选择一台用户所属区域的区域负载均衡设备，告诉用户向这台设备发起请求。区域负载均衡设备会为用户选择一台合适的缓存服务器提供服务，选择的依据包括：根据用户IP地址，判断哪一台服务器距用户最近；根据用户所请求的URL中携带的内容名称，判断哪一台服务器上有用户所需内容；查询各个服务器当前的负载情况，判断哪一台服务器尚有服务能力。基于以上这些条件的综合分析之后，区域负载均衡设备会向全局负载均衡设备返回一台缓存服务器的IP地址，全局负载均衡设备再把缓存服务器的IP地址返回给本地DNS，此时就可以通过IP向缓存服务器发起请求了，当缓存服务器中不存在请求结果时才会从源站中获取。 通过DNS解析拿到了IP之后，就可以通过IP向服务器发送http请求了，因为http工作在应用层，tcp工作在传输层，所以发生http请求之前，还会进行tcp的三次握手建立连接。 在连接成功建立后，开始向web服务器发送请求，当浏览器向Web服务器发出请求时，它向服务器传递了一个数据块，也就是请求报文，请求报文由请求方法 URI 协议/版本、请求头、请求正文三部分组成。 请求报文由应用层向下，依次经过传输层、网络层、数据链路层与物理层。应用层的任务是通过应用进程间的交互来完成特定网络应用，有HTTP、DNS等众多协议，传输层的主要任务则是负责向两台主机进程之间的通信提供通用的数据传输服务，包括TCP与UDP两种协议，TCP是面向连接的、可靠的的数据传输服务，而UDP提供无连接的、不可靠的数据传输服务，TCP主要提供完整性服务，UDP主要提供及时性服务；传输层是为主机中的进程提供数据传输服务，而网络层则是为不同主机提供数据传输服务，这一层有IP协议，由于主机之间可以有很多链路，数据链路层则是为同一链路的主机提供数据传输服务。最终物理层考虑怎样在传输媒体上传输数据比特流。数据通过以太网电缆传送到服务器，服务器拿到数据包后同样再由数据链路层、网络层、传输层依次向上解析，应用层最终收到请求内容。 服务器收到请求报文之后，就会将响应报文返回给客户端，响应报文由协议/版本 状态码 描述、响应头、响应正文三部分组成。这里的状态码分为1XX（信息类）、2XX（成功类）、3XX（重定向类）、4XX（客户端错误）、5XX（服务器错误）。 当浏览器加载一个完整的页面时，还需要与服务器断开连接，这个过程就是tcp的四次挥手。 在HTTP协议的初始版本中，每进行一次HTTP通信就要断开一次TCP连接。因此，每次的请求都会造成无谓的TCP连接建立与断开，增加通信量的开销。为了解决这个问题，HTTP/1.1使用长连接减少开销，只要任意一端没有明确提出断开连接，就保持TCP连接状态，当客户端再次访问这个服务器上的网页时，会继续使用这一条已经建立的连接。]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[多线程断点续传下载器]]></title>
    <url>%2F2019%2F02%2F12%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%96%AD%E7%82%B9%E7%BB%AD%E4%BC%A0%E4%B8%8B%E8%BD%BD%E5%99%A8%2F</url>
    <content type="text"><![CDATA[最近在研究多线程的断点续传下载。断点续传的原理其实很简单，就是在下载时将下载进度保存到一个临时文件中，如果下载过程遇到什么意外中断了，下次下载同一个文件时就可以从临时文件中读取到上次下载发生中断时的进度，然后从这个进度开始继续下载。 要使用断点续传下载首先要判断服务器是否支持范围请求，假如在响应中存在Accept-Ranges首部并且它的值不为 none，那么表示该服务器支持范围请求。通常情况下Web服务器会默认开启对范围请求的支持，我们只需要在请求头中加入Range首部来指示服务器应该返回文件的哪一部分，例如使用Range: bytes=0-1023返回某个资源的前1024个字节，在代码中体现为：httpcon.setRequestProperty(&quot;Range&quot;, &quot;bytes=&quot; + startPos + &quot;-&quot; + endPos);，这时候服务器会返回状态码为206 Partial Content的响应表示成功。 项目中还使用了多线程进行分块下载，要注意的是并非线程数越多下载就越快（受限于带宽），一般开十个线程就差不多了，多线程之所以能提高下载速度的原因也很复杂，具体可以参考为什么多线程下载能加速？以及为什么多 TCP 连接分块下载比单连接下载快？。简单来说就是当链路存在争用的情况下，由于传输网络的带宽有限，每个TCP连接可以得到均等的带宽。在多用户环境下，一个用户拥有越多TCP连接，获得的带宽越大。除此之外，由于TCP的拥塞控制机制被设计的十分友好，只要丢了点包就会极大的减慢速率，而此时可能并没有发生拥塞，导致单个连接没法最大化的利用带宽。 下图为该项目的执行流程： 以下为项目源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262import java.io.File;import java.io.FileNotFoundException;import java.io.IOException;import java.io.InputStream;import java.io.RandomAccessFile;import java.net.HttpURLConnection;import java.net.MalformedURLException;import java.net.URL;import java.util.concurrent.CountDownLatch;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;/** * @Project: breakpoint * @Description: * @Author: Cenjie * @Date: Created in 2019/2/11 */public class Downloader &#123; private String urlStr; private int threadNum; private String filename; private String filename_tmp; private CountDownLatch latch; private long fileLength; private long lenPerThread; //每个线程的下载大小 private long[] start; //保留每个线程下载的起始位置。 private long[] end; //保留每个线程下载的结束位置。 private URL url; public Downloader(String urlStr, int threadNum) &#123; this.urlStr = urlStr; this.threadNum = threadNum; start = new long[this.threadNum]; end = new long[this.threadNum]; latch = new CountDownLatch(this.threadNum); &#125; /** * 文件下载 */ public void download() &#123; File file = null; File file_tmp = null; //从文件链接中获取文件名 filename = urlStr.substring(urlStr.lastIndexOf('/') + 1, urlStr .contains("?") ? urlStr.lastIndexOf('?') : urlStr.length()); //设置临时文件的文件名 filename_tmp = filename + "_tmp"; try &#123; //创建url url = new URL(urlStr); //打开下载链接，并且得到一个HttpURLConnection的一个对象httpcon HttpURLConnection httpcon = (HttpURLConnection) url.openConnection(); httpcon.setRequestMethod("GET"); //获取请求资源的总长度，为Long型 fileLength = httpcon.getContentLengthLong(); //下载文件和临时文件 file = new File(filename); file_tmp = new File(filename_tmp); //每个线程需下载的资源大小；由于文件大小不确定，为避免数据丢失 lenPerThread = fileLength % threadNum == 0 ? fileLength / threadNum : fileLength / threadNum + 1; //打印下载信息 System.out.println("文件名: " + filename + "，" + "文件大小：" + fileLength + "字节，每个线程下载大小：" + lenPerThread + "字节"); if (file.exists() &amp;&amp; file.length() == fileLength) &#123; System.out.println("文件已存在"); return; &#125; else &#123; setBreakPoint(file_tmp); ExecutorService exec = Executors.newCachedThreadPool(); for (int i = 0; i &lt; threadNum; i++) &#123; exec.execute(new DownLoadThread(start[i], end[i], this, i)); &#125; latch.await(); //当所有线程下载完毕后，才会从此阻塞中返回 System.out.println("文件下载完成"); exec.shutdown(); &#125; &#125; catch (MalformedURLException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; //下载完成后，判断文件是否完整，并删除临时文件 if (file.length() == fileLength) &#123; if (file_tmp.exists()) &#123; file_tmp.delete(); System.out.println("删除临时文件完成，下载结束"); &#125; &#125; else&#123; System.out.println("该文件不完整"); &#125; &#125; /** * 读取临时文件中记录的断点，加载每个线程的任务区间，若临时文件不存在，则重新分配每个线程的任务区间 * @param file_tmp */ private void setBreakPoint(File file_tmp) &#123; RandomAccessFile random_file_tmp = null; System.out.println("开始分配任务区间："); try &#123; //如果存在临时文件，则从临时文件记录的位置继续下载 if (file_tmp.exists()) &#123; System.out.println("找到临时文件，将从断点处恢复下载..."); random_file_tmp = new RandomAccessFile(file_tmp, "rw"); for (int i = 0; i &lt; threadNum; i++) &#123; random_file_tmp.seek(i * 8); start[i] = random_file_tmp.readLong(); random_file_tmp.seek(1000 + i * 8); end[i] = random_file_tmp.readLong(); System.out.println("线程" + i + " 起始位置：" + start[i] + "，结束位置：" + end[i]); &#125; &#125; else &#123; System.out.println("未找到临时文件，开始一个新的下载..."); random_file_tmp = new RandomAccessFile(file_tmp, "rw"); for (int i = 0; i &lt; threadNum; i++) &#123; //设置线程i的下载起始位置 start[i] = lenPerThread * i; if (i == threadNum - 1) &#123; //当线程i为最后一个线程时，设置线程i的下载结束位置为文件长度 end[i] = fileLength - 1; &#125; else &#123; end[i] = lenPerThread * (i + 1) - 1; &#125; random_file_tmp.seek(i * 8); random_file_tmp.writeLong(start[i]); random_file_tmp.seek(1000 + i * 8); random_file_tmp.writeLong(end[i]); System.out.println("线程" + i + " 起始位置：" + start[i] + "，结束位置：" + end[i]); &#125; &#125; &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; if (random_file_tmp != null) &#123; random_file_tmp.close(); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; class DownLoadThread implements Runnable &#123; private int id; //线程id private long startPos; //线程下载起始位置 private long endPos; //线程下载结束位置 private Downloader task; private RandomAccessFile rand_file; private RandomAccessFile rand_file_tmp; public DownLoadThread(long startPos, long endPos, Downloader task, int id) &#123; this.startPos = startPos; this.endPos = endPos; this.task = task; this.id = id; try &#123; this.rand_file = new RandomAccessFile(this.task.filename, "rw"); this.rand_file_tmp = new RandomAccessFile(this.task.filename_tmp, "rw"); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; &#125; public void run() &#123; HttpURLConnection httpcon; InputStream is = null; int length; System.out.println("线程" + id + " 开始下载..."); while (true) &#123; try &#123; httpcon = (HttpURLConnection) task.url.openConnection(); httpcon.setRequestMethod("GET"); //防止网络阻塞，设置指定的超时时间；单位都是ms。超过指定时间，就会抛出异常 httpcon.setReadTimeout(20000);//读取数据的超时设置 httpcon.setConnectTimeout(20000);//连接的超时设置 if (startPos &lt; endPos) &#123; //向服务器请求指定区间段的数据，这是实现断点续传的根本。 httpcon.setRequestProperty("Range", "bytes=" + startPos + "-" + endPos); System.out.println("线程" + id + " 长度：" + (endPos - startPos + 1)); rand_file.seek(startPos); is = httpcon.getInputStream();//获取服务器返回的资源流 long count = 0L; byte[] buf = new byte[1024]; while ((length = is.read(buf)) != -1) &#123; count += length; rand_file.write(buf, 0, length); //不断更新每个线程下载资源的起始位置，并写入临时文件 startPos += length; rand_file_tmp.seek(id * 8); rand_file_tmp.writeLong(startPos); &#125; System.out.println("线程" + id + " 总下载大小: " + count); //关闭流 is.close(); httpcon.disconnect(); rand_file.close(); rand_file_tmp.close(); &#125; latch.countDown(); System.out.println("线程" + id + " 下载完成"); break; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; if (is != null) &#123; is.close(); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; &#125; public static void main(String[] args) &#123; int threadNum = 10; String url = "http://blog.default.nanwulife.com/pexels-photo-640947.jpeg"; Downloader load = new Downloader(url, threadNum); load.download(); &#125;&#125;]]></content>
      <categories>
        <category>项目</category>
      </categories>
      <tags>
        <tag>项目</tag>
        <tag>多线程</tag>
        <tag>断点续传</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java线程池与Executor框架]]></title>
    <url>%2F2019%2F02%2F10%2FExecutor%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[为什么要使用线程池 降低资源消耗：通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 提高响应速度：当任务到达时，任务可以不需要等到线程创建就能立即执行。 提高线程的可管理性：线程是稀缺资源，使用线程池可以进行统一分配、调优和监控。 线程池的实现原理 如果当前运行的线程少于corePoolSize，则创建新线程来执行任务（这一步需获取全局锁）。 如果运行的线程等于或多于corePoolSize，则将任务加入BlockingQueue。 如果队列已满，则创建新的线程来处理任务（这一步需获取全局锁）。 如果创建新线程将使当前运行的线程超出maximumPoolSize，任务将被拒绝，并使用相关饱和策略进行处理，默认是直接抛出异常。 之所以采用这个步骤，是因为在执行execute()方法时，尽可能地避免获取全局锁。在线程池完成预热之后（当前运行的线程数大于等于corePoolSize），几乎所有的execute()方法调用都是执行步骤2，而步骤2不需要获取全局锁。 Executor框架Executor框架内部使用了线程池机制，它在java.util.cocurrent包下，通过该框架来控制线程的启动、执行和关闭，可以简化并发编程的操作。因此，通过Executor来启动线程比使用Thread的start()方法更易管理且效率更好。 Executor框架的结构与成员 ThreadPoolExecutorThreadPoolExecutor是Executor框架的最核心的类，是线程池的实现类，用来执行被提交的任务，通常使用工厂类Executors来创建，有以下三种类型： FixedThreadPool：线程数固定。适用于为了满足资源管理而需要限制线程数的场景，适用于负载比较重的服务器。 SingleThreadExecutor：只有一个线程。适用于需要保证顺序地执行各个任务，并且在任意时间点不会有多个线程是活动的场景。 CachedThreadPool：根据需要创建新线程。空闲线程等待新任务超过60秒就会被终止。适用于执行很多短期异步任务的小程序，或者是负载较轻的服务器。 FixedThreadPool和SingleThreadExecutor使用无界队列LinkedBlockingQueue作为线程池的工作队列。CachedThreadPool使用没有容量的SynchronousQueue作为线程池的工作队列。 ScheduledThreadPoolExecutorScheduledThreadPoolExecutor继承自ThreadPoolExecutor，主要用来在给定的延迟之后运行任务，或者定期执行任务。ScheduledThreadPoolExecutor的功能与Timer类似，但ScheduledThreadPoolExecutor功能更强大、更灵活，Timer对应的是单个后台线程，而ScheduledThreadPoolExecutor可以在构造函数中指定多个对应的后台线程数。 FutureTaskFuture接口和实现Future接口的FutureTask类，代表异步计算的结果。FutureTask除了实现Future接口外，还实现了Runnable接口。可以把FutureTask交给Executor执行，也可以通过submit()方法返回一个FutureTask，然后执行FutureTask.get()方法。 线程池的使用线程池的创建我们可以通过ThreadPoolExecutor来创建一个线程池： 1new ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAliveTime, milliseconds,runnableTaskQueue, threadFactory,handler); 当提交一个任务到线程池时，线程池会创建一个线程来执行任务，即使其它空闲的基本线程能够执行新任务也会创建线程，等到需要执行的任务数大于线程池基本大小时就不再创建。 向线程池提交任务可以使用execute()方法提交任务，但是execute()方法没有返回值，所以无法判断任务是否被线程池执行成功。也可以使用submit()方法来提交任务，它会返回一个future，可以通过这个future的get()方法来获取返回值，get()方法会阻塞直到任务完成。 关闭线程池可以通过调用线程池的shutdown()或shutdownNow()方法来关闭线程池。 shutdown()先将线程池状态置为SHUTDOWN，停止接受外部提交的新任务，而等到正在执行的任务以及队列中等待的任务执行完才真正停止。 shutdownNow()先将线程池状态置为STOP，停止接受外部提交的新任务，忽略队列里等待的任务，使用interrupt()方法尝试将正在跑的任务中断，然后返回未执行的任务列表。 注意，如果线程中没有sleep、wait、Condition等应用，interrupt()方法是无法中断当前的线程的。所以，shutdownNow()并不代表线程池一定立即就能退出，它也可能必须要等待所有正在执行的任务都执行完成了才能退出。 参考资料 聊聊并发（三）Java线程池的分析和使用]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>Executor</tag>
        <tag>线程池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中的并发工具类]]></title>
    <url>%2F2019%2F02%2F10%2FJava%E4%B8%AD%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[CountdownLatchCountDownLatch是一个同步工具类，它允许一个或多个线程一直等待，直到其他线程的操作执行完后再执行。例如，应用程序的主线程希望在负责启动框架服务的线程已经启动所有的框架服务之后再执行。 CountDownLatch是通过一个计数器来实现的，计数器的初始值为线程的数量。每当一个线程完成了自己的任务后，计数器的值就会减1。当计数器值到达0时，它表示所有的线程已经完成了任务，然后在闭锁上等待的线程就可以恢复执行任务。例如： 123456789101112131415161718192021public class CountDownLatchTest&#123; static CountDownLatch c = new CountDownLatch(2); public static void main(String[] args)&#123; new Thread(new Runnable()&#123; @Override public void run()&#123; System.out.println(1); c.countDown(); System.out.println(2); c.countDown(); &#125; &#125;).start(); try &#123; c.await(); &#125; catch (InterruptedException e) &#123; &#125; System.out.println(3); &#125;&#125; 还可以通过创建一个初始计数为1的CountDownLatch，并让所有线程都在这个锁上等待，随后调用countDown()方法来同时启动多个线程。 CyclicBarrier同步屏障CyclicBarrier可以让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续运行。例如： 12345678910111213141516171819202122public class CyclicBarrierTest &#123; static CyclicBarrier c = new CyclicBarrier(2); public static void main(String[] args) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; try&#123; c.await(); &#125; catch (Exception e)&#123; &#125; System.out.println(1); &#125; &#125;).start(); try&#123; c.await(); &#125;catch (Exception e)&#123; &#125; System.out.println(2); &#125;&#125; CyclicBarrier和CountDownLatch的区别CountDownLatch的计数器只能使用一次，而CyclicBarrier的计数器可以使用reset()方法重置。所以CyclicBarrier能处理更为复杂的业务场景。例如，如果计算发生错误，可以重置计数器，并让线程重新执行一次。 SemaphoreSemaphore是用来控制同时访问特定资源的线程数量，它通过协调各个线程，以保证合理的使用公共资源。Semaphore的构造方法接受一个整型的数字，表示可用的许可证数量，线程使用acquire()方法获取一个许可证，如果没有许可证能够获得则被阻塞，使用完后调用release()方法归还许可证。还可以使用tryAcquire()方法尝试获取许可证，若获取成功，则立即返回true，若获取失败，则立即返回false。 Semaphore可以用于流量控制，特别是公用资源有限的应用场景，比如数据库连接。如果线程数有几十个，而数据库的连接只有十个，那么就可以使用Semaphore控制同时获取数据库连接的个数。 参考资料 《Java并发编程的艺术》 什么时候使用CountDownLatch]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程基础]]></title>
    <url>%2F2019%2F02%2F09%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[线程状态Java线程在运行的生命周期中可能处于以下6种不同的状态： 状态名称 说明 NEW 初始状态，线程被构建，但是还没调用start()方法 RUNNABLE 运行状态，Java线程将操作系统中的就绪和运行两种状态笼统地称作“运行中” BLOCKED 阻塞状态，表示线程阻塞于锁 WAITING 无限期等待状态，进入该状态表示当前线程需要等待其它线程做出一些特定动作（通知或中断） TIME_WAITING 限期等待状态，可以在指定的时间自行返回 TERMINATED 终止状态，表示当前线程已经执行完毕 Java将操作系统中的运行和就绪两个状态合并称为运行状态。阻塞状态是线程阻塞在进入synchronized关键字修饰的方法或代码块（获取锁）时的状态，但是阻塞在Lock接口的线程状态是等待状态。 Daemon线程用户线程是我们平常创建的普通线程，而守护线程则是用来服务于用户线程的一种支持型线程。当一个Java虚拟机中只存在守护线程的时候，Java虚拟机将会退出。可以在启动线程之前通过调用Thread.setDaemon(true)将该线程设置为守护线程。 守护线程可用于实时监控和管理系统中的可回收资源。例如，Java垃圾回收线程就是一个典型的守护线程，当我们的程序中不再有任何运行中的Thread，程序就不会再产生垃圾，垃圾回收器也就无事可做，所以当垃圾回收线程是Java虚拟机上仅剩的线程时，Java虚拟机会自动退出。 使用线程有三种使用线程的方法： 实现Runnable接口； 实现Callable接口； 继承Thread类。 实现Runnable和Callable接口的类只能当做一个可以在线程中运行的任务，不是真正意义上的线程，因此最后还需要通过Thread来调用。可以说任务是通过线程驱动从而执行的。 实现Runnable接口需要实现run()方法。通过Thread调用start()方法来启动线程。 1234567891011public class MyRunnable implements Runnable &#123; public void run() &#123; // ... &#125;&#125;public static void main(String[] args) &#123; MyRunnable instance = new MyRunnable(); Thread thread = new Thread(instance); thread.start();&#125; 实现Callable接口与Runnable相比，Callable可以有返回值，返回值通过FutureTask进行封装。 12345678910111213public class MyCallable implements Callable&lt;Integer&gt; &#123; public Integer call() &#123; return 123; &#125;&#125;public static void main(String[] args) throws ExecutionException, InterruptedException &#123; MyCallable mc = new MyCallable(); FutureTask&lt;Integer&gt; ft = new FutureTask&lt;&gt;(mc); Thread thread = new Thread(ft); thread.start(); System.out.println(ft.get());&#125; 继承Thread类同样也是需要实现run()方法，因为Thread类也实现了Runable接口。 当调用start()方法启动一个线程时，虚拟机会将该线程放入就绪队列中等待被调度，当一个线程被调度时会执行该线程的run()方法。 12345678910public class MyThread extends Thread &#123; public void run() &#123; // ... &#125;&#125;public static void main(String[] args) &#123; MyThread mt = new MyThread(); mt.start();&#125; 对比实现接口会更好一些，因为： Java不支持多重继承，因此继承了Thread类就无法继承其它类，但是可以实现多个接口。 类可能只要求可执行就行，继承整个Thread类开销过大。 等待/通知机制等待/通知机制是指一个线程A调用了对象O的wait()方法进入等待状态，而另一个线程B调用了对象O的notify()或者notifyAll()方法，线程A收到通知后从对象O的wait()方法返回，进而执行后续操作。以下为等待/通知的经典范式： 12345678910111213//等待方synchronized(对象)&#123; while(条件不满足)&#123; 对象.wait(); &#125; 对应的处理逻辑;&#125;//通知方synchronized(对象)&#123; 改变条件 对象.notifyAll();&#125; wait()，notify()，notifyAll()方法只能用在同步方法或者同步控制块中使用，否则会在运行时抛出IllegalMonitorStateException。使用wait()挂起期间，线程会释放锁，这是因为如果没有释放锁，那么其它线程就无法进入对象的同步方法或者同步控制块中，那么就无法执行notify()或者notifyAll()来唤醒挂起的线程，造成死锁。 注意，wait()是Object的方法，而sleep()是Thread的静态方法；wait()会释放锁，sleep()不会。 线程之间的协作Thread.join()在线程中调用另一个线程的join()方法，会将当前线程挂起，而不是忙等待，直到目标线程结束。 await() signal() signalAll()java.util.concurrent类库中提供了Condition类来实现线程之间的协调，可以在Condition上调用await()方法使线程等待，其它线程调用signal()或signalAll()方法唤醒等待的线程。 相比于wait()这种等待方式，await()可以指定等待的条件，因此更加灵活。 1234567891011121314151617181920212223242526272829303132333435public class AwaitSignalExample &#123; private Lock lock = new ReentrantLock(); private Condition condition = lock.newCondition(); public void before() &#123; lock.lock(); try &#123; System.out.println("before"); condition.signalAll(); &#125; finally &#123; lock.unlock(); &#125; &#125; public void after() &#123; lock.lock(); try &#123; condition.await(); System.out.println("after"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; public static void main(String[] args) &#123; ExecutorService executorService = Executors.newCachedThreadPool(); AwaitSignalExample example = new AwaitSignalExample(); executorService.execute(() -&gt; example.after()); executorService.execute(() -&gt; example.before()); &#125;&#125; ThreadLocalThreadLocal即线程变量，是一个以ThreadLocal对象为键、任意对象为值的存储结构。这个结构被附带在线程上，也就是说一个线程可以根据一个ThreadLocal对象查询到绑定在这个线程上的一个值。可以通过set(T)方法来设置一个值，在当前线程下再通过get()方法获取到原先设置的值。 参考资料 《Java并发编程的艺术》 CS-Notes]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[final域的内存语义]]></title>
    <url>%2F2019%2F02%2F09%2F%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90final%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[对于final域，编译器和处理器要遵守两个重排序规则。 在构造函数内对一个final域的写入，与随后把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。 初次读一个包含final域的对象的引用，与随后初次读这个final域，这两个操作之间不能重排序。 以上规则保证只要对象是正确构造的，那么不需要使用同步（指lock和volatile的使用）就可以保证任意线程都能看到这个final域在构造函数中被初始化之后的值。要实现这个效果，还需要保证在构造函数内部，不能让这个被构造对象的引用为其它线程所见，也就是对象引用不能在构造函数中“逸出”，因为此时的final域由于重排序等原因可能还没被初始化。]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>final</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[顺序一致性模型与happens-before原则]]></title>
    <url>%2F2019%2F02%2F09%2F%E9%A1%BA%E5%BA%8F%E4%B8%80%E8%87%B4%E6%80%A7%E6%A8%A1%E5%9E%8B%E4%B8%8Ehappens-before%E8%A7%84%E5%88%99%2F</url>
    <content type="text"><![CDATA[顺序一致性模型顺序一致性内存模型是一个理论参考模型，在设计的时候，处理器的内存模型和编程语言的内存模型都会以顺序一致性内存模型作为参考。顺序一致性内存模型有两大特性： 一个线程中的所有操作必须按照程序的顺序来执行。 不管程序是否同步，所有线程都只能看到一个单一的操作执行顺序。在顺序一致性内存模型中，每个操作都必须原子执行并且立刻对所有线程可见。 JMM保证如果程序是正确同步的，程序的执行将具有顺序一致性，即程序的执行结果与该程序在顺序一致性内存模型中的执行结果相同。 而对于未同步或未正确同步的多线程程序，JMM只提供最小安全性：线程执行时读取到的值要么是之前某个线程写入的值，要么是默认值（0，null，false），JMM保证线程读操作读取到的值不会无中生有的冒出来。为了实现最小安全性，JVM在堆上分配内存时，首先会对内存空间进行清零，然后才会在上面分配对象（JVM内部会同步这两个操作）。 注意：对于未同步程序，JMM不保证对64位的long型和double型变量的写操作具有原子性。 happens-beforehappens-before原则定义如下： 如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。 两个操作之间存在happens-before关系，并不意味着Java平台的具体实现一定要按照happens-before原则制定的顺序来执行。如果重排序之后的执行结果与按照happens-before关系来执行的结果一致，那么这种重排序并不非法。 参考资料 《Java并发编程的艺术》]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>happens-before</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入分析synchronized关键字]]></title>
    <url>%2F2019%2F02%2F08%2F%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90synchronized%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[简介synchronized是Java中的关键字，是一种同步锁，可作用于一段代码或方法，既可以保证可见性，又能够保证原子性。Java中的每一个对象都可以作为锁： 对于同步方法，锁是当前实例对象。 对于静态同步方法，锁是当前对象的Class对象。 对于同步方法块，锁是Synchonized括号里配置的对象。 当一个线程试图访问同步代码时，它首先必须得到锁，退出或抛出异常时必须释放锁，而没获取到锁的线程将被阻塞。 synchronized实现原理每个对象有一个监视器锁（monitor），当monitor被占用时就会处于锁定状态。 代码块同步是使用monitorenter和monitorexit指令实现的，线程执行monitorenter指令时尝试获取monitor的所有权，过程如下： 如果monitor的进入数为0，则该线程进入monitor，然后将进入数设置为1，该线程即为monitor的所有者。 如果线程已经占有该monitor，只是重新进入，则进入monitor的进入数加1. 如果其他线程已经占用了monitor，则该线程进入阻塞状态，直到monitor的进入数为0，再重新尝试获取monitor的所有权。 而对于monitorexit指令，指令执行时monitor的进入数减1，如果减1后进入数为0，那线程退出monitor，不再是这个monitor的所有者。其他被这个monitor阻塞的线程可以尝试去获取这个monitor的所有权。 方法同步不是使用monitorenter和monitorexit指令来完成，但同样是基于进入和退出monitor对象来实现，在方法执行期间，其他任何线程都无法再获得同一个monitor对象。 锁的升级JDK1.6为了减少获得锁和释放锁所带来的性能消耗，引入了“偏向锁”和“轻量级锁”，所以在JDK1.6里锁一共有四种状态，无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态，它会随着竞争情况逐渐升级。锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。 偏向锁Hotspot的作者经过以往的研究发现大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得。因此，引入偏向锁是为了在无多线程竞争的情况下尽量减少不必要的加锁解锁开销，即退出临界区的时候不需要主动释放锁，因为下一次要进入临界区的往往都是同一个线程。 偏向锁获取过程： 访问Mark Word中偏向锁的标识是否设置成1，锁标志位是否为01，以此确认为可偏向状态。 如果为可偏向状态，则测试线程ID是否指向当前线程，如果是，进入步骤（5），否则进入步骤（3）。 如果线程ID并未指向当前线程，则通过CAS操作获取锁。如果获取成功，则将Mark Word中线程ID设置为当前线程ID，然后执行（5）；如果获取失败，执行（4）。 如果CAS获取偏向锁失败，则表示有竞争。当到达全局安全点时获得偏向锁的线程被挂起，偏向锁升级为轻量级锁，然后被阻塞在安全点的线程继续往下执行同步代码。 执行同步代码。 偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着，如果线程不处于活动状态，则将对象头设置成无锁状态，如果线程仍然活着，将锁升级为标准的轻量级锁。 轻量级锁轻量级锁的加锁过程： 在代码进入同步块的时候，如果同步对象锁状态为无锁状态，虚拟机首先将在当前线程的栈帧中建立一个名为锁记录的空间，拷贝对象头中的Mark Word到锁记录中，官方称之为Displaced Mark Word。 拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向锁记录的指针，并将锁记录里的owner指针指向object mark word。如果更新成功，则执行步骤（3），否则执行步骤（4）。 如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为“00”，即表示此对象处于轻量级锁定状态。 如果这个更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行。否则说明多个线程竞争锁，轻量级锁就要膨胀为重量级锁，锁标志的状态值变为“10”，Mark Word中存储的就是指向重量级锁的指针，后面等待锁的线程也要进入阻塞状态，而当前线程便尝试使用自旋来获取锁。 在最后一步线程获取轻量级锁的过程中执行CAS操作失败时，是要通过自旋来获取重量级锁的，由于自旋是需要消耗CPU的，如果一直获取不到锁的话，那该线程就一直处在自旋状态，白白浪费CPU资源。JDK采用适应性自旋的方式解决这个问题，指定自旋的次数，如果超过次数如果还没获取到锁就进入阻塞状态。线程如果自旋成功了，则下次自旋的次数会更多，如果自旋失败了，则自旋的次数就会减少。 轻量级锁的解锁过程： 通过CAS操作尝试把线程中复制的Displaced Mark Word对象替换当前的Mark Word。 如果替换成功，整个同步过程就完成了。 如果替换失败，说明有其他线程尝试过获取该锁（此时锁已膨胀），那就要在释放锁的同时，唤醒被挂起的线程。 锁的对比 锁 优点 缺点 适用场景 偏向锁 加锁和解锁不需要额外的消耗，和执行非同步方法比仅存在纳秒级的差距。 如果线程间存在锁竞争，会带来额外的锁撤销的消耗。 只有一个线程执行同步块。 轻量级锁 竞争的线程不会阻塞，提高了程序的响应速度。 如果始终得不到锁竞争的线程使用自旋会消耗CPU。 多个线程交替执行同步块。 重量级锁 线程竞争不使用自旋，不会消耗CPU。 线程阻塞，响应时间缓慢。 多个线程同时执行同步块。 参考资料 聊聊并发（二）Java SE1.6中的Synchronized Java锁Synchronized之偏向锁 Java并发编程：Synchronized及其实现原理 Java并发编程：Synchronized底层优化（偏向锁、轻量级锁）]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>锁</tag>
        <tag>synchronized</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入分析volatile关键字]]></title>
    <url>%2F2019%2F02%2F08%2F%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90volatile%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[简介Synchronized能够实现原子性和可见性，在Java内存模型中，Synchronized规定线程在加锁时，先清空工作内存，从主内存中拷贝最新变量的副本到工作内存，执行完代码后再刷新到主内存中，此时才能释放锁。 volatile是轻量级的synchronized，如果使用恰当的话，它会比synchronized的使用成本更低，因为它不会引起线程上下文的切换和调度。如果一个字段被声明成volatile，它将具有以下两个特性： 可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。 禁止指令重排序。 volatile的实现原理如果对声明了volatile的变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据写回到系统内存。为了保证各个处理器的缓存是一致的，就会实现缓存一致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己缓存值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存里。 简单来说就是Lock前缀指令会引起处理器缓存回写到内存，而一个处理器的缓存回写到内存会导致其它处理器的缓存无效。 volatile的内存语义 volatile写的内存语义：当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量值刷新到主内存。 volatile读的内存语义：当读一个volatile变量时，JMM会把该线程对应的本地内存设置为无效。线程接下来将从主内存中读取共享变量。 为了实现volatile内存语义，JMM会限制重排序。其重排序规则如下： 当第二个操作是volatile写时，不管第一个操作是什么，都不能重排序。 当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序。 当第一个操作是volatile写，第二个操作是volatile读时，都不能重排序。 volatile的底层实现，是通过插入内存屏障。但是对于编译器来说，发现一个最优布置来最小化插入内存屏障的总数几乎是不可能的，所以，JMM采用了保守策略，策略如下： 在每个volatile写操作的前面插入一个StoreStore屏障。 在每个volatile写操作的后面插入一个StoreLoad屏障。 在每个volatile读操作的后面插入一个LoadLoad屏障。 在每个volatile读操作的后面插入一个LoadStore屏障。 原因如下： StoreStore屏障：保证在volatile写之前，其前面的所有普通写操作，都已经刷新到主内存中。 StoreLoad屏障：避免volatile写，与后面可能有的volatile读/写操作重排序。 LoadLoad屏障：禁止处理器把上面的volatile读，与下面的普通读重排序。 LoadStore屏障：禁止处理器把上面的volatile读，与下面的普通写重排序。 此策略可以保证在任意处理器平台，任意程序中都能得到正确的volatile内存语义，但其实在实际中，只要不会改变volatile的内存语义，编译器可以根据具体情况优化，省略不必要的屏障。 参考资料 聊聊并发（一）深入分析Volatile的实现原理]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>volatile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[支付宝的支付流程（当面付）]]></title>
    <url>%2F2019%2F02%2F07%2F%E6%94%AF%E4%BB%98%E5%AE%9D%E5%AF%B9%E6%8E%A5%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[由于在之前的项目中使用到了用支付宝完成订单支付这一功能，因此在此篇文章中对支付宝的整个支付流程以及背后的细节做一个简单的总结。具体接入指南以及开发文档参考蚂蚁金服 扫码支付接入指引 。 前期准备整体来说前期准备工作有下面两步： 创建应用并获取APPID 配置密钥 其中配置密钥需要交换双方的公钥，在交易过程中会对交易数据进行双方校验。我们知道公钥加密过的内容只有私钥才可以解密，同样，私钥加签过的内容也只有公钥才能验签。商户系统在发起支付时会使用自己的私钥进行加签，由于私钥只有自己持有（因此要妥善保管），支付宝就可以确认支付是由商户系统发起的而非他人；同样支付宝也会使用自己的私钥对支付结果进行加签，这样商户系统使用支付宝的公钥验签后也就能确定该结果是支付宝返回的了。 支付流程 用户选中购物车的商品，创建一个待支付订单，商户系统生成唯一订单号。 用户点击支付，商户系统调用支付宝的预下单接口发送订单信息，接口返回一个二维码串。 商户系统通过二维码串自行生成订单二维码并显示给用户。 用户扫描二维码并付款。 支付成功后，支付宝根据预先配置的回调接口将支付结果异步通知给商户系统。 商户系统收到支付结果，验签确保是支付宝发出后，告知用户支付完成并更新相关数据库表。]]></content>
      <categories>
        <category>项目</category>
      </categories>
      <tags>
        <tag>支付宝</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring框架知识点总结]]></title>
    <url>%2F2019%2F02%2F06%2FSpring%E6%A1%86%E6%9E%B6%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[Spring概述Spring框架是一个为Java应用程序的开发提供了综合、广泛的基础性支持的Java平台。Spring帮助开发者解决了开发中基础性的问题，使得开发人员可以专注于应用程序的开发。Spring框架本身亦是按照设计模式精心打造，这使得我们可以在开发环境中安心的集成Spring框架，不必担心Spring是如何在后台进行工作的。 Spring框架至今已集成了20多个模块。这些模块主要被分如下图所示的核心容器、数据访问/集成,、Web、AOP（面向切面编程）、工具、消息和测试模块。 使用Spring的好处有以下几点： Spring是轻量的，基本的版本大约2MB。 Spring通过控制反转实现了松散耦合。 Spring支持面向切面编程，把应用业务逻辑和系统服务分开。 Spring包含并管理应用中对象的生命周期和配置。 Spring的Web框架是一个精心设计的Web MVC框架，是其它WEB框架的很好的替代品。 Spring提供了一个便捷的事务管理接口，适用于小型的本地事物处理（比如在单DB的环境下）和复杂的共同事物处理（比如利用JTA的复杂DB环境）。 IOCSpring框架的核心就是IoC容器，要掌握Spring框架，就必须要理解控制反转的思想以及依赖注入的实现方式。 DI与IOC控制反转（Inversion of Control）就是将原本在程序中手动创建对象的控制权，交由Spring框架管理，根据配置文件在运行时动态的去创建对象，并调用对象的方法。作用是实现了程序的解耦合。 依赖注入（Dependency Injection）就是将实例变量传入到一个对象中去，非自己主动初始化依赖，而是通过外部来传入依赖。比如以前可能会在构造函数中自己new一个对象赋给成员变量，依赖注入则是将已经初始化好的对象作为构造函数的一个参数传入。Spring的依赖注入有3种方式： setter方法注入。 构造函数注入。 注解方式注入。 控制反转与依赖注入有着本质的不同： 控制反转是一种思想。 依赖注入是一种实现方式。 IoC容器使用依赖注入作为实现控制反转的方式，但是控制反转还有其他的实现方式，例如说ServiceLocator，所以不能将控制反转和依赖注入等同。 BeanFactory和ApplicationContextBeanFactory是Spring框架最核心、最底层的接口，是Spring IoC容器的具体实现。BeanFactory负责读取bean配置文件实例化Bean并建立Bean之间的依赖关系，提供Bean实例缓存、生命周期管理等服务。 ApplicationContext建立在BeanFactory基础之上，称为应用上下文，提供了更多面向应用的功能。例如提供了支持国际化的文本消息、统一的资源文件读取方式和框架事件体系等，更易于创建实际应用。以下是三种较常见的ApplicationContext实现方式： FileSystemXmlApplicationContext：由文件系统中的XML配置文件中读取上下文。 ClassPathXmlApplicationContext：由类路径的XML配置文件中读取上下文。 WebXmlApplicationContext：由Web应用的XML文件读取上下文。 除了以上的区别外，BeanFactroy采用的是延迟加载形式来注入Bean的，即只有在使用到某个Bean时（调用getBean()），才对该Bean进行加载实例化，这样我们就不能发现一些存在的Spring的配置问题。而ApplicationContext则相反，它是在容器启动时一次性创建了所有的Bean，这样在容器启动时我们就可以发现Spring中存在的配置错误。 Spring BeansSpring beans是那些形成Spring应用的主干java对象。它们被Spring IOC容器初始化，装配和管理。这些beans通过容器中配置的元数据创建，比如以XML文件中&lt;bean/&gt;的形式定义。装配Bean总共有三种方式： XML配置文件。 基于java的配置。 基于注解的配置。 Bean的作用域当定义一个&lt;bean&gt;时，我们能通过定义中的scope属性来给这个bean声明一个作用域。Spring框架支持以下五种bean的作用域： singleton : bean在每个Spring Ioc 容器中只有一个实例。 prototype：一个bean的定义可以有多个实例。 request：每次http请求都会创建一个bean，该作用域仅在基于web的Spring ApplicationContext情形下有效。 session：在一个HTTP Session中，一个bean定义对应一个实例。该作用域仅在基于web的Spring ApplicationContext情形下有效。 global-session：在一个全局的HTTP Session中，一个bean定义对应一个实例。该作用域仅在基于web的Spring ApplicationContext情形下有效。 其中，单例bean不是线程安全的，Spring框架并没有对单例bean进行任何多线程的封装处理，关于单例bean的线程安全和并发问题需要开发者自行去搞定。 Bean的生命周期在一个bean实例被初始化时，需要执行一系列的初始化操作以达到可用的状态。同样的，当一个bean不再被调用时需要进行相关的析构操作，并从bean容器中移除。 Spring容器从XML文件中读取bean的定义并实例化bean。 Spring根据bean的定义填充所有的属性。 调用BeanNameAware的setBeanName方法。 调用BeanFactoryAware的setBeanFactory方法。 调用BeanPostProcessor的postProcesserBeforeInitialization方法。 调用InitializingBean的afterPropertiesSet方法。 调用&lt;bean&gt;的init-method属性指定的初始化方法。 调用BeanPostProcessor的postProcesserAfterInitialization方法。 容器初始化成功，程序执行，业务逻辑调用后，下面销毁容器。 调用DisposableBean的destroy方法。 调用&lt;bean&gt;的destroy-method属性指定的销毁方法。 &lt;bean&gt;有两个重要的属性init-method和destroy-method用来定制初始化和注销方法，它们也有相应的注解@PostConstruct和@PreDestroy。 Inner Bean当一个bean仅被用作另一个bean的属性时，它能被声明为一个内部bean，内部bean通常是匿名的，它们的作用域一般是prototype。 Bean的自动装配Spring引入自动装配机制就是为了解决&lt;bean&gt;标签下&lt;property&gt;标签过多导致可维护性差的问题，Spring容器能够自动装配相互合作的bean，这意味着容器不需要&lt;constructor-arg&gt;和&lt;property&gt;配置，能通过BeanFactory自动处理bean之间的依赖关系。在Spring框架中共有以下5种自动装配： no：这是Spring框架的默认设置，在该设置下自动装配是关闭的，开发者需要自行在bean定义中用标签明确的设置依赖关系。 byName：该选项可以根据bean名称设置依赖关系。当向一个bean中自动装配一个属性时，容器将根据bean的名称自动在在配置文件中查询一个匹配的bean。如果找到的话，就装配这个属性，如果没找到的话就报错。 byType：该选项可以根据bean类型设置依赖关系。当向一个bean中自动装配一个属性时，容器将根据bean的类型自动在在配置文件中查询一个匹配的bean。如果找到的话，就装配这个属性，如果没找到或找到多个相同类型的话就报错。 constructor：构造器的自动装配和byType模式类似，但是仅仅适用于与有构造器相同参数的bean，如果在容器中没有找到与构造器参数类型一致的bean，那么将会抛出异常。 autodetect：该模式自动探测使用构造器自动装配或者byType自动装配。首先会尝试找合适的带参数的构造器，如果找到的话就是用构造器自动装配，如果在bean内部没有找到相应的构造器或者是无参构造器，容器就会自动选择byTpe的自动装配方式。 AOP面向切面编程（AOP）就是在运行时，动态地将代码切入到类的指定方法、指定位置上的一种编程思想。 通知（Advice）就是想要的功能，也就是上说的安全、事物、日子等。你给先定义好，然后再想用的地方用一下。Spring可以应用五种类型的通知： before：前置通知，在一个方法执行前被调用。 after：在方法执行之后调用的通知，无论方法执行是否成功。 after-returning：仅当方法成功完成后执行的通知。 after-throwing：在方法抛出异常退出时执行的通知。 around：在方法执行之前和之后调用的通知。 连接点（JoinPoint）就是Spring允许是通知（Advice）的地方，基本每个方法的前、后（两者都有也行），或抛出异常时都可以是连接点，Spring只支持方法连接点。 切入点（Pointcut）上面说的连接点的基础上，来定义切入点，你的一个类里，有15个方法，那就有十几个连接点了对吧，但是你并不想在所有方法附件都使用通知（使用叫织入，下面再说），你只是想让其中几个，在调用这几个方法之前、之后或者抛出异常时干点什么，那么就用切入点来定义这几个方法，让切入点来筛选连接点，选中那几个你想要的方法。 切面（Aspect）切面是通知和切入点的结合。通知说明了干什么和什么时候干（什么时候通过方法名中的befor，after，around等就能知道），二切入点说明了在哪干（指定到底是哪个方法），这就是一个完整的切面定义。 织入（weaving）把切面应用到目标对象来创建新的代理对象的过程。 引入（introduction）允许我们在已存在的类中增加新的方法和属性。 代理（proxy）通知目标对象后创建的对象。从客户端的角度看，代理对象和目标对象是一样的。 Spring MVCSpring MVC是一个基于MVC架构的用来简化web应用程序开发的应用开发框架，它是Spring的一个模块。在web模型中，MVC是一种很流行的架构，通过把Model，View，Controller分离，把较为复杂的web应用分成逻辑清晰的几部分，简化开发，减少出错，方便组内开发人员之间的配合。 执行流程 用户发送请求至前端控制器DispatcherServlet； DispatcherServlet收到请求后，调用HandlerMapping处理器映射器，请求获取Handle； 处理器映射器根据请求url找到具体的处理器，生成处理器对象及处理器拦截器(如果有则生成)一并返回给DispatcherServlet； DispatcherServlet通过HandlerAdapter处理器适配器调用处理器； 执行处理器(Handler，也叫后端控制器)； Handler执行完成返回ModelAndView； HandlerAdapter将Handler执行结果ModelAndView返回给DispatcherServlet； DispatcherServlet将ModelAndView传给ViewResolver视图解析器进行解析； ViewResolver解析后返回具体View； DispatcherServlet对View进行渲染视图（即将模型数据填充至视图中） DispatcherServlet响应用户。 SpringMVC如何和AJAX相互调用通过Jackson框架就可以把Java里面的对象直接转化成js可以识别的Json对象。具体步骤如下 ： 加入Jackson.jar 在配置文件中配置json的映射 在方法前面要加上@ResponseBody注解。 Spring注解 @Required：该注解表明bean的属性必须在配置的时候设置，若@Required注解的bean属性未被设置，容器将抛出BeanInitializationException。注意@Required只能设置在setter方法上。 @Autowired：该注解可以对类成员变量、方法及构造函数进行标注，完成自动装配的工作，默认是按类型进行装配。在类成员变量上加上该注解时，就可以去掉相应的getter和setter方法了，Spring将直接采用Java反射机制对成员变量进行自动注入。 @Qualifier：当有多个相同类型的bean却只有一个需要自动装配时，将@Qualifier注解和@Autowired注解结合使用以消除这种混淆，指定需要装配的确切的bean。 @Resource：与@Autowired不同的是该注解默认按照名称装配，当找不到与名称匹配的bean时才会按照类型装配。注意如果没有指定name属性，并且按照默认的名称仍然找不到依赖的对象时候，会回退到按照类型装配，但一旦指定了name属性，就只能按照名称 装配了。 其它Spring框架中都用到了哪些设计模式？待更。。。]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>AOP</tag>
        <tag>IOC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[电商项目优化实践]]></title>
    <url>%2F2019%2F02%2F05%2Fmmall%E7%94%B5%E5%95%86%E9%A1%B9%E7%9B%AE%E4%BC%98%E5%8C%96%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[本篇日志将记录之前做过的mmall项目的一些优化过程，主要包括JVM调优和数据库优化两个方面，通过不断动手实践并总结心得，希望能在此积累起许多经验，为以后能更得心应手的写出高效而又稳健的代码打好基础。 商品表的优化在实际应用中我们往往都会遇到根据名称来查询某个商品或者根据昵称查询某个用户，如果返回的行数较多则要使用分页，而之前项目一直都是使用的PageHelper这个框架来完成分页功能的，这么做自然简单方便，但是当数据量达到几十万甚至百万时就会遇到性能瓶颈，尽管能够使用一些索引进行优化，但一个查询仍然需要十几二十秒才能完成，显然还远不能达标。在阅读PageHelper源码后可以发现，之所以会发生这种情况是因为PageHelper主要是通过拼接LIMIT语句来实现分页功能的，我们知道LIMIT在偏移量很大的时候会扫描很多不必要的行，因此需要对查询进行改进才能更好的应用在数据量比较大的场景下。 我们先建立一张商品表，还未在上面建立任何索引（除主键外）： 12345678910111213141516DROP TABLE IF EXISTS `mmall_product`;CREATE TABLE `mmall_product` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT '商品id', `category_id` int(11) NOT NULL COMMENT '分类id,对应mmall_category表的主键', `name` varchar(100) NOT NULL COMMENT '商品名称', `subtitle` varchar(200) DEFAULT NULL COMMENT '商品副标题', `main_image` varchar(500) DEFAULT NULL COMMENT '产品主图,url相对地址', `sub_images` text COMMENT '图片地址,json格式,扩展用', `detail` text COMMENT '商品详情', `price` decimal(20,2) NOT NULL COMMENT '价格,单位-元保留两位小数', `stock` int(11) NOT NULL COMMENT '库存数量', `status` int(6) DEFAULT '1' COMMENT '商品状态.1-在售 2-下架 3-删除', `create_time` datetime DEFAULT NULL COMMENT '创建时间', `update_time` datetime DEFAULT NULL COMMENT '更新时间', PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=30 DEFAULT CHARSET=utf8; 接着使用存储过程往里面插入100万条数据，为了提高插入时的速度，需要先修改my.ini配置文件的以下两处： 12innodb_flush_log_at_trx_commit=0max_allowed_packet=100M 重启MySQL后再执行以下代码： 1234567891011121314151617181920drop procedure if exists product_insert;DELIMITER ;; CREATE PROCEDURE product_insert() BEGIN DECLARE y INT DEFAULT 1;WHILE y &lt; 100000DOinsert into mmall_product(category_id, name, subtitle, main_image, sub_images, detail, price, stock, status, create_time, update_time) values(y%30+100001, 'ab', substring(MD5(RAND()),15,20), '241997c4-9e62-4824-b7f0-7425c3c28917.jpeg', '241997c4-9e62-4824-b7f0-7425c3c28917.jpeg,b6c56eb0-1748-49a9-98dc-bcc4b9788a54.jpeg,92f17532-1527-4563-aa1d-ed01baa0f7b2.jpeg,3adbe4f7-e374-4533-aa79-cc4a98c529bf.jpeg', '&lt;p&gt;&lt;img alt="miaoshu.jpg" src="http://img.happymmall.com/9c5c74e6-6615-4aa0-b1fc-c17a1eff6027.jpg" width="790" height="444"&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img alt="miaoshu2.jpg" src="http://img.happymmall.com/31dc1a94-f354-48b8-a170-1a1a6de8751b.jpg" width="790" height="1441"&gt;&lt;img alt="miaoshu3.jpg" src="http://img.happymmall.com/7862594b-3063-4b52-b7d4-cea980c604e0.jpg" width="790" height="1442"&gt;&lt;img alt="miaoshu4.jpg" src="http://img.happymmall.com/9a650563-dc85-44d6-b174-d6960cfb1d6a.jpg" width="790" height="1441"&gt;&lt;br&gt;&lt;/p&gt;',RAND() * 10000,RAND() * 100,1, now(), now()); SET y=y+1; END WHILE ; commit; END;; CALL product_insert(); 这里的商品名、子标题等都使用的随机字符串，没有太多考究。此时就可以根据商品名name按价格price排序后进行查询了： 12345SELECT * FROM mmall_product WHERE name = 'ab' ORDER BY price LIMIT 100, 10;SELECT * FROM mmall_product WHERE name = 'ab' ORDER BY price LIMIT 1000, 10;SELECT * FROM mmall_product WHERE name = 'ab' ORDER BY price LIMIT 10000, 10; 执行时间如下： 可以看出，在不断增大LIMIT的偏移量后，查询时间着实吓人，通过EXPLAIN分析执行计划发现type那列显示ALL，说明要全表扫描一百多万行，并且还有Using filesort。我们先根据WHERE语句和ORDER BY语句建立如下组合索引： 1ALTER TABLE mmall_product ADD INDEX index_name_price (name, price); 执行SHOW INDEX FROM mmall_product;查看索引是否添加如下： 这时在初步优化后分析执行计划可以看到查询不再是全表扫描，而是使用到了上面的索引，效率有所提升，但此时增大偏移量后查询依然会变得十分缓慢，还需要进一步优化。这里就可以用到“延迟关联”的技巧，由于LIMIT每扫描一行时都要去主索引拿到许多不必要的数据再丢弃，那么可以让其先在二级索引覆盖扫描得到满足条件的id，然后再与原表关联得到最终结果，代码如下： 12SELECT * FROM mmall_product INNER JOIN (SELECT id FROM mmall_product WHERE name = 'ab' ORDER BY price LIMIT 100000, 10) AS mmall_product_id USING(id); 此时，就算偏移量为一百万时，查询也可以很轻松的在0.5S内完成，效果还是令人满意的。 PageHelper原理：PageHelper实现了MyBatis提供的Interceptor接口得到分页拦截器PageInterceptor，使用分页查询的时候，先调用PageHelper.startPage在当前线程上下文中设置一个ThreadLocal变量，分页拦截器拦截到SQL后会从ThreadLocal中拿到分页的信息，拼接分页语句并进行分页查询，最后再把ThreadLocal中的东西清除掉。 GC调优看了《深入理解Java虚拟机》也有一段时间了，书本的知识虽然都能理解，但实际的优化却从来没试过，这方面可以说是毫无经验。都说读万卷书不如行万里路，在网上看了一些GC优化的实际案例后，决定亲自动手在这个项目中尝试一下。 这次实践使用的垃圾收集器为ParNew+CMS（CMS失败时Serial Old替补）。首先通过以下参数设置垃圾收集器并打开GC日志：123456-XX:+UseConcMarkSweepGC-XX:+UseParNewGC-XX:+PrintGC-Xloggc:C:\Users\canjie\Desktop\gc.log-XX:+PrintHeapAtGC-XX:+PrintGCDateStamps 然后使用jmeter工具模拟多用户持续请求接口的场景，这里设置的一分钟的用户数5000人。jemeter的聚合报告显示如下，主要关注TP99这一指标： 请求结束后分析GC日志发现Minor GC执行的十分频繁，而Major GC仅仅五分钟内就执行了好几次，每次耗时约0.2s，频繁且耗时的STW对接口响应时间造成了很大的影响，对于追求低延时的服务来说肯定是不可取的。要想优化就必须得先知其原因，首先JVM的默认内存为64M，这肯定是不够的，其次频繁的Major GC主要是因为老年代的空间不够，那接下来就是通过调整总堆大小以及年轻代和老年代的比例来减少GC的频率和STW的时间。当然，这里的内存不是调的越大越好，调的过小会导致GC频率过高，而调的过大虽然GC频率降低了，但每次GC的耗时也会变长。 先通过GC日志得到活跃数据的大小（活跃数据的大小是指Full GC后堆中老年代占用空间的大小），然后通过以下策略设置基本参数： 空间 倍数 总堆 3-4 倍活跃数据的大小 新生代 1-1.5 活跃数据的大小 老年代 2-3 倍活跃数据的大小 永久代 1.2-1.5 倍Full GC后的永久代空间占用 我在这个例子中经过计算后设置的参数如下： 1234-Xmx640m-Xms640m-XX:NewSize=240m-XX:MaxNewSize=240m 此时再启动项目并用jmeter模拟真实环境进行测试，可以发现调大总堆大小并设置合适的年轻代与老年代的比例后，Minor GC每分钟的频率已经降到了70-80次，而Major GC十分钟才会出现一次，每次的耗时在100ms以下，TP95下降了约10ms，TP99下降了约100ms。]]></content>
      <categories>
        <category>项目</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>项目</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java阻塞队列实现生产者-消费者模型]]></title>
    <url>%2F2019%2F02%2F03%2FJava%E5%AE%9E%E7%8E%B0%E7%94%9F%E4%BA%A7%E8%80%85-%E6%B6%88%E8%B4%B9%E8%80%85%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[简介阻塞队列（BlockingQueue）是一个支持阻塞的插入和移除的队列。阻塞插入即当队列满时，队列会阻塞插入元素的线程，直到队列不满；阻塞移除即当队列为空时，获取元素的线程会等待队列变为非空。 阻塞队列提供了四种处理方法： 方法\处理方式 抛出异常 返回特殊值 一直阻塞 超时退出 插入方法 add(e) offer(e) put(e) offer(e,time,unit) 移除方法 remove() poll() take() poll(time,unit) 检查方法 element() peek() 不可用 不可用 分类 ArrayBlockingQueue：一个由数组结构组成的有界阻塞队列。 LinkedBlockingQueue：一个由链表结构组成的有界阻塞队列。 PriorityBlockingQueue：一个支持优先级排序的无界阻塞队列。 DelayQueue：一个支持延时获取元素的无界阻塞队列。队列使用PriorityQueue来实现，队列中的元素必须实现Delayed接口，在创建元素时可以指定多久才能从队列中获取当前元素，只有在延迟期满时才能从队列中提取元素。可以用于设计缓存系统和定时任务调度。 SynchronousQueue：一个不存储元素的阻塞队列。每一个put操作必须等待一个take操作，否则不能继续添加元素。 LinkedBlockingDeque：LinkedBlockingDeque是一个由链表结构组成的双向阻塞队列。 实现JDK是使用通知模式（await()/signal()）实现的阻塞队列：当生产者往满的队列里添加元素时会阻塞住生产者，当消费者消费了一个队列中的元素后，会通知生产者当前队列可用。下面是ArrayBlockingQueue的部分源码： 12345678910111213141516171819202122232425262728293031323334353637383940private final Condition notFull;private final Condition notEmpty;public ArrayBlockingQueue(int capacity, boolean fair) &#123; //省略其他代码 notEmpty = lock.newCondition(); notFull = lock.newCondition(); &#125;public void put(E e) throws InterruptedException &#123; checkNotNull(e); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; while (count == items.length) notFull.await(); insert(e); &#125; finally &#123; lock.unlock(); &#125;&#125;public E take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; while (count == 0) notEmpty.await(); return extract(); &#125; finally &#123; lock.unlock(); &#125;&#125;private void insert(E x) &#123; items[putIndex] = x; putIndex = inc(putIndex); ++count; notEmpty.signal();&#125; 生产者-消费者模式下面通过阻塞队列来实现一个经典的生产者-消费者模式，由于已经将底层封装的很好了，所以代码十分简洁： 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class ProducerConsumer &#123; private static BlockingQueue&lt;Task&gt; queue = new ArrayBlockingQueue&lt;&gt;(5); private static AtomicInteger increTaskNo = new AtomicInteger(0); private static class Producer implements Runnable&#123; @Override public void run() &#123; Task task = new Task(increTaskNo.getAndIncrement()); try &#123; queue.put(task); System.out.println("produce: " + task.no); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; private static class Consumer implements Runnable&#123; @Override public void run()&#123; try &#123; Task task = queue.take(); System.out.println("consume: " + task.no); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; private static class Task&#123; public int no; public Task(int no) &#123; this.no = no; &#125; &#125; public static void main(String[] args) &#123; for (int i = 0; i &lt; 5; i++) &#123; new Thread(new Producer()).start(); &#125; for (int i = 0; i &lt; 5; i++) &#123; new Thread(new Consumer()).start(); &#125; &#125;&#125; 这里要注意，put()与take()方法与输出语句不是原子的，这会导致日志的输出顺序与实际任务的入队/出队顺序不一定匹配。 参考资料 聊聊并发（七）——Java中的阻塞队列]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fork/join框架分析与实战]]></title>
    <url>%2F2019%2F02%2F02%2FFork-join%E6%A1%86%E6%9E%B6%E5%88%86%E6%9E%90%E4%B8%8E%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[简介Fork/Join框架是Java7提供了的一个用于并行执行任务的框架，是一个把大任务分割成若干个小任务，最终汇总每个小任务结果后得到大任务结果的框架。Fork就是把一个大任务切分为若干子任务并行的执行，Join就是合并这些子任务的执行结果，最后得到这个大任务的结果。 工作窃取算法工作窃取算法（work-stealing）是指当一个队列所对应的线程先执行完队列中的所有任务后，从其他线程的队列里窃取一个任务来执行。为了减少竞争，通常会使用双端队列，被窃取任务线程永远从双端队列的头部拿任务执行，而窃取任务的线程永远从双端队列的尾部拿任务执行。 Fork/join的使用 ForkJoinTask：我们要使用Fork/Join框架，必须首先创建一个ForkJoin任务。它提供在任务中执行fork()和join()操作的机制，通常情况下我们不需要直接继承ForkJoinTask类，而只需要继承它的子类，Fork/Join框架提供了以下两个子类： RecursiveAction：用于没有返回结果的任务。 RecursiveTask ：用于有返回结果的任务。 ForkJoinPool ：ForkJoinTask需要通过ForkJoinPool来执行，任务分割出的子任务会添加到当前工作线程所维护的双端队列中，进入队列的头部。当一个工作线程的队列里暂时没有任务时，它会随机从其他工作线程的队列的尾部获取一个任务。 接下来我们看一个问题：如何充分利用多核 CPU 计算很大 List 中所有整数的和？ 这里就可以用到Fork/join框架将求和任务分成许多子任务来完成，再将子任务的计算结果相加即可，代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class ForkJoinLargeListSum &#123; public static void main(String[] args) &#123; int[] array = new int[100000000]; // 初始化 for(int i = 0; i &lt; array.length; i++)&#123; array[i] = i + 1; &#125; ForkJoinPool forkJoinPool = new ForkJoinPool(); long begintime = System.currentTimeMillis(); CountSumTask task = new CountSumTask(100000, 0, array.length-1, array); Future&lt;Long&gt; future = forkJoinPool.submit(task); try &#123; System.out.println("计算结果为：" + future.get()); long endtime=System.currentTimeMillis(); System.out.println("耗时：" + (endtime - begintime) + "ms"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; &#125; static class CountSumTask extends RecursiveTask&lt;Long&gt; &#123; private int threshold; private int hi, lo; private int[] array; public CountSumTask(int threshold, int lo, int hi, int[] array) &#123; this.threshold = threshold; this.hi = hi; this.lo = lo; this.array = array; &#125; @Override protected Long compute() &#123; long sum = 0L; //如果任务足够小就计算任务 boolean canCompute = (hi - lo) &lt;= threshold; if(canCompute)&#123; for(int i = lo; i &lt;= hi; i++)&#123; sum += array[i]; &#125; &#125; else&#123; //如果任务大于阈值，就分裂成两个子任务计算 int middle = lo + (hi - lo) / 2; CountSumTask leftTask = new CountSumTask(threshold, lo, middle, array); CountSumTask rightTask = new CountSumTask(threshold, middle+1, hi, array); //执行子任务 leftTask.fork(); rightTask.fork(); //等待子任务执行完，并得到结果 long leftResult = leftTask.join(); long rightResult = rightTask.join(); //合并子任务 sum = leftResult + rightResult; &#125; return sum; &#125; &#125;&#125; 此时输出： 12计算结果为：5000000050000000耗时：69ms 当我们调大阈值threshold时，意味着分割任务的次数减少，直接计算的次数增多，此时计算的效率也有可能降低。例如，当把阈值增大为100000000时，输出结果为： 12计算结果为：5000000050000000耗时：110ms 参考资料 聊聊并发（八）——Fork/Join框架介绍 重做一道Java面试题（Fork/Join）]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>Fork/join</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ConcurrentHashMap源码分析]]></title>
    <url>%2F2019%2F02%2F01%2FConcurrentHashMap%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[为什么要使用ConcurrentHashMap HashMap线程不安全。在JDK1.8之前的版本中，HashMap的实现在并发执行put操作时会导致HashMap的Entry链表形成环形数据结构，Entry的next节点永远不为空，就会产生死循环获取Entry。在之后的版本中这个死循环的问题不再发生，但仍然无法保证并发环境下的线程安全。 HashTable使用synchronized来保证线程安全，因此当一个线程访问HashTable的同步方法时，其它线程也访问同步方法就会被阻塞，在线程竞争激烈时效率很低。 基于以上两点，我们在并发环境中应该选择线程安全且高效的ConcurrentHashMap。 版本演进 jdk1.7采用分段锁技术，整个哈希表被分成多个段，每个段中会对应一个Segment段锁，段与段之间可以并发访问，但是多线程想要操作同一个段是需要获取锁的。所有的put，get，remove等方法都是根据键的哈希值对应到相应的段中，然后尝试获取锁进行访问。 jdk1.8取消了基于Segment的分段锁思想，改用CAS + synchronized控制并发操作，在某些方面提升了性能。并且追随1.8版本的 HashMap 底层实现，使用数组+链表+红黑树进行数据存储。 JDK1.8分析属性12345678910111213transient volatile Node&lt;K,V&gt;[] table; //哈希表，第一次put时才进行初始化private transient volatile Node&lt;K,V&gt;[] nextTable; //扩容时新生成的数组，其大小为原数组的两倍。private transient volatile long baseCount; //哈希表中存储的所有的结点的个数总和/** * 用来控制table的初始化和扩容操作，默认为0。 * 当为-1时代表table正在初始化，-N代表N-1个线程正在进行扩容操作，其余情况： * 如果table未初始化，表示table需要初始化的大小。 * 如果table初始化完成，表示table的容量。 */private transient volatile int sizeCtl; ForwardingNode这是一个特殊的Node节点，用来占位表示扩容时该桶的所有节点已完成迁移，hash值为-1，key和value都为null，并且内部存储着扩容后的表nextTable的引用。 1234567final class ForwardingNode&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; final Node&lt;K,V&gt;[] nextTable; ForwardingNode(Node&lt;K,V&gt;[] tab) &#123; super(MOVED, null, null, null); this.nextTable = tab; &#125;&#125; put() 在计算键所对应的哈希值后，如果哈希表还未初始化，那么初始化它。此时只允许一个线程对表进行初始化，如果不巧有其他线程进来了，那么会让其他线程交出CPU等待下次系统调度。 初始化完后，获取table中对应索引的元素f，如果f为null，说明table中这个位置第一次插入元素，利用Unsafe.compareAndSwapObject方法插入Node节点。如果CAS成功，说明Node节点已经插入，随后addCount()方法会检查当前容量是否需要进行扩容。如果CAS失败，说明有其它线程提前插入了节点，自旋重新尝试在这个位置插入节点。 如果f的hash值等于MOVED也就是-1时，说明当前f是ForwardingNode节点，意味着有其它线程正在扩容，于是调用helpTransfer()方法让当前线程去协助扩容。 其余情况把新的Node节点按链表或红黑树的方式插入到合适的位置，这个过程采用同步内置锁实现并发。 transfer()ConcurrentHashMap的扩容是高度并发的，执行逻辑如下： 通过计算CPU核心数和Map数组的长度得到每个线程要帮助处理多少个桶，并且这里每个线程处理都是平均的。默认每个线程处理16个桶，因此，当长度是16的时候，扩容的时候只会有一个线程扩容。 初始化nextTable，将其在原有基础上扩容两倍。 进入一个while循环，每个线程会先领取自己的任务区间，然后开始--i来遍历自己的任务区间，对每个桶进行处理。 如果遇到桶的头结点是空的，那么使用ForwardingNode标识该桶已经被处理完成了。如果遇到已经处理完成的桶，直接跳过进行下一个桶的处理。如果是正常的桶，对桶首节点加锁，正常的迁移即可，迁移结束后依然会将原表的该位置标识位已经处理。 finnish如果为true 则说明整张表的迁移操作已经全部完成了，我们只需要重置table的引用并将nextTable赋为空即可。否则，CAS式的将sizeCtl减一，表示当前线程已经完成了任务，退出扩容操作。 addCount()当我们成功的添加完成一个结点，最后是需要判断添加操作后是否会导致哈希表达到它的阈值，并针对不同情况决定是否需要进行扩容，还有CAS式更新哈希表实际存储的键值对数量，这些操作都封装在addCount这个方法中，当然putVal方法的最后必然会调用该方法进行处理。该方法主要做两个事情：一是更新 baseCount，二是判断是否需要扩容。 remove()ConcurrentHashMap的并发删除过程：首先遍历整张表的桶结点，如果表还未初始化或者无法根据参数的哈希值定位到桶结点，那么将返回null。如果定位到的桶结点类型是ForwardingNode结点，调用helpTransfer协助扩容。否则给桶加锁，删除一个节点，最后调用addCount()方法CAS式更新baseCount的值。 参考资料 为并发而生的 ConcurrentHashMap（Java 8） 深入浅出ConcurrentHashMap1.8 并发编程——ConcurrentHashMap#transfer() 扩容逐行分析 谈谈ConcurrentHashMap1.7和1.8的不同实现]]></content>
      <categories>
        <category>JDK</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
        <tag>JDK</tag>
        <tag>ConcurrentHashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式]]></title>
    <url>%2F2019%2F01%2F29%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[七大设计原则开闭原则定义：一个软件实体如类、模块和函数应该对扩展开放，对修改关闭。 用抽象构建框架，用实现扩展细节。 依赖倒置原则定义：高层模块不应该依赖低层模块，二者都应该依赖其抽象。 做到针对接口编程，不要针对实现编程。 单一职责原则定义：不要存在多于一个导致类变更的原因。一个类/接口/方法只负责一项职责。 接口隔离原则定义：用多个专门的接口，而不使用单一的总接口，客户端不应该依赖它不需要的接口。 建立单一接口，不要建立庞大臃肿的接口；尽量细化接口，接口中的方法尽量少；接口中不要存在子类用不到却必须实现的方法。 迪米特法则定义：一个对象应该对其它对象保持最少的了解。又叫最少知道原则。 只与朋友说话，而不和陌生人说话。这里的朋友指的是出现在成员变量，方法输入、输出参数中的类，而出现在方法体内部的不属于朋友。 里氏替换原则定义：如果对每一个类型为T1的对象o1，都有类型为T2的对象o2，使得以T1定义的所有程序P在所有的对象o1都替换成o2时，程序P的行为没有发生变化，那么类型T2是类型T1的子类型。 子类可以实现父类的抽象方法，但不能覆盖父类的非抽象方法 子类中可以增加自己特有的方法 当子类的方法重载（注意不是覆盖）父类的方法时，方法的前置条件（即方法的输入/入参）要比父类方法的输入参数更宽松 当子类的方法实现父类的方法时（重写/重载或实现抽象方法），方法的后置条件（即方法的输出/返回值）要比父类更严格或相等 合成复用原则定义：尽量使用对象组合/聚合，而不是继承关系达到软件复用的目的。 创建型简单工厂（Simple Factory）简单工厂模式是由一个工厂对象决定创建出哪一种产品类的实例，而不向客户暴露内部细节。 简单工厂不属于23种设计模式，但是之后的工厂方法模式、抽象工厂模式都是由其演化而来，并且在实际场景中也有应用，因此有必要了解。 适用场景：工厂类负责创建的对象比较少。 优缺点优点：只需要传入一个正确的参数，就可以获取所需要的对象而无须知道其创建细节。 缺点：工厂类的职责相对过重，增加新的产品需要修改工厂类的判断逻辑，违背开闭原则。 应用场景创建五个类：Video、JavaVideo、PythonVideo、VideoFactory、Test： 抽象产品类Video：123public abstract class Video &#123; public abstract void produce();&#125; 具体产品类JavaVideo、PythonVideo：12345678910111213public class JavaVideo extends Video &#123; @Override public void produce() &#123; System.out.println("录制Java课程视频"); &#125;&#125;public class PythonVideo extends Video &#123; @Override public void produce() &#123; System.out.println("录制Python课程视频"); &#125;&#125; 客户端类Test，这里可以传入字符串参数或者Class类参数：1234567891011121314151617public class Test &#123; public static void main(String[] args) &#123; VideoFactory videoFactory = new VideoFactory(); Video video = videoFactory.getVideo("java"); if(video == null)&#123; return; &#125; video.produce(); VideoFactory videoFactory2 = new VideoFactory(); Video video2 = videoFactory2.getVideo(JavaVideo.class); if(video2 == null)&#123; return; &#125; video2.produce(); &#125;&#125; 在简单工厂中，客户端不应该直接创建出具体的产品类，而应交给工厂类去创建，下面看看工厂类VideoFactory，使用了if-else判断参数或者使用使用反射技术从而决定创建哪个具体子类：123456789101112131415161718192021222324public class VideoFactory &#123; public Video getVideo(Class c)&#123; Video video = null; try &#123; video = (Video) Class.forName(c.getName()).newInstance(); &#125; catch (InstantiationException e) &#123; e.printStackTrace(); &#125; catch (IllegalAccessException e) &#123; e.printStackTrace(); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; return video; &#125; public Video getVideo(String type)&#123; if("java".equalsIgnoreCase(type))&#123; return new JavaVideo(); &#125; else if("python".equalsIgnoreCase(type))&#123; return new PythonVideo(); &#125; return null; &#125;&#125; 通过简单工厂，客户端类就不需要自己去实例化具体的产品类，做到了客户端类和产品类的解耦。 Calendar类的应用java.util下的Calendar类是一个抽象类，我们看看其中的getInstance方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public static Calendar getInstance(TimeZone zone, Locale aLocale)&#123; return createCalendar(zone, aLocale);&#125;private static Calendar createCalendar(TimeZone zone, Locale aLocale)&#123; CalendarProvider provider = LocaleProviderAdapter.getAdapter(CalendarProvider.class, aLocale) .getCalendarProvider(); if (provider != null) &#123; try &#123; return provider.getInstance(zone, aLocale); &#125; catch (IllegalArgumentException iae) &#123; // fall back to the default instantiation &#125; &#125; Calendar cal = null; if (aLocale.hasExtensions()) &#123; String caltype = aLocale.getUnicodeLocaleType("ca"); if (caltype != null) &#123; switch (caltype) &#123; case "buddhist": cal = new BuddhistCalendar(zone, aLocale); break; case "japanese": cal = new JapaneseImperialCalendar(zone, aLocale); break; case "gregory": cal = new GregorianCalendar(zone, aLocale); break; &#125; &#125; &#125; if (cal == null) &#123; if (aLocale.getLanguage() == "th" &amp;&amp; aLocale.getCountry() == "TH") &#123; cal = new BuddhistCalendar(zone, aLocale); &#125; else if (aLocale.getVariant() == "JP" &amp;&amp; aLocale.getLanguage() == "ja" &amp;&amp; aLocale.getCountry() == "JP") &#123; cal = new JapaneseImperialCalendar(zone, aLocale); &#125; else &#123; cal = new GregorianCalendar(zone, aLocale); &#125; &#125; return cal;&#125; 在后半段中可以看出其根据参数通过switch和if-else创建了相应的具体子类对象，与之前的应用场景十分类似。在这里，Calendar既作为抽象产品类，也作为一个工厂类。 工厂方法（Factory Method）定义一个创建对象的接口，但让实现这个接口的类来决定实例化哪个类，工厂方法让类的实例化推迟到子类中进行。 适用场景： 创建对象需要大量重复的代码 客户端不依赖于产品类示例如何被创建、实现等细节 一个类通过其子类来指定创建哪个对象 优缺点优点：用户只需要关心所需产品对应的工厂，无需关心创建细节；加入新产品符合开闭原则，提高可扩展性。 缺点：类的个数容易过多，增加复杂度。 应用场景 抽象产品类Video： 1234public abstract class Video &#123; public abstract void produce();&#125; 具体产品类JavaVideo、PythonVideo： 12345678910111213public class JavaVideo extends Video &#123; @Override public void produce() &#123; System.out.println("录制Java课程视频"); &#125;&#125;public class PythonVideo extends Video &#123; @Override public void produce() &#123; System.out.println("录制Python课程视频"); &#125;&#125; 抽象工厂类VideoFactory： 123public abstract class VideoFactory &#123; public abstract Video getVideo();&#125; 具体工厂类JavaVideoFactory、PythonVideo： 12345678910111213public class JavaVideoFactory extends VideoFactory &#123; @Override public Video getVideo() &#123; return new JavaVideo(); &#125;&#125;public class PythonVideoFactory extends VideoFactory &#123; @Override public Video getVideo() &#123; return new PythonVideo(); &#125;&#125; 客户端类Test： 12345678public class Test &#123; public static void main(String[] args) &#123; VideoFactory videoFactory = new PythonVideoFactory(); VideoFactory videoFactory2 = new JavaVideoFactory(); Video video = videoFactory.getVideo(); video.produce(); &#125;&#125; 这时如果需要增加一个新的产品时，只需要添加一个新的具体产品类和具体工厂类，而无需像简单工厂一样修改工厂类里面的判断逻辑，即满足了开闭原则。 例如，如果要增加新产品FEVideo，我们需要先加入一个具体产品类： 123456public class FEVideo extends Video &#123; @Override public void produce() &#123; System.out.println("录制FE课程视频"); &#125;&#125; 再增加这个具体产品所对应的具体工厂类： 123456public class FEVideoFactory extends VideoFactory&#123; @Override public Video getVideo() &#123; return new FEVideo(); &#125;&#125; 之后在应用层就可以直接使用了： 12345678910public class Test &#123; public static void main(String[] args) &#123; VideoFactory videoFactory = new PythonVideoFactory(); VideoFactory videoFactory2 = new JavaVideoFactory(); VideoFactory videoFactory3 = new FEVideoFactory(); Video video = videoFactory.getVideo(); video.produce(); &#125;&#125; 此时的UML类图： Java集合接口Collection中的应用java.util.Collection接口下的iterator()方法：1234public interface Collection&lt;E&gt; extends Iterable&lt;E&gt; &#123; //... Iterator&lt;E&gt; iterator(); //... 查看该接口的其中一个实现类ArrayList： 1234567891011121314151617181920212223 public Iterator&lt;E&gt; iterator() &#123; return new Itr(); &#125; private class Itr implements Iterator&lt;E&gt; &#123;//... public boolean hasNext() &#123; return cursor != size; &#125; @SuppressWarnings("unchecked") public E next() &#123; //... &#125; public void remove() &#123; //... &#125; @Override @SuppressWarnings("unchecked") public void forEachRemaining(Consumer&lt;? super E&gt; consumer) &#123; //... &#125; //... &#125; 在这里，Collection相当于一个抽象工厂，而ArrayList相当于一个具体工厂，这个具体工厂实现了工厂方法iterator()实例化具体产品Itr，而这个具体产品实现了抽象产品Iterator。 logback中的应用 由UML可以看出ILoggerFactory作为抽象的工厂类，实现有三个具体的工厂类，以其中的NOPLoggerFactory为例，实现了抽象方法getLogger来实例化具体产品类： 12345678public class NOPLoggerFactory implements ILoggerFactory &#123; public NOPLoggerFactory() &#123; &#125; public Logger getLogger(String name) &#123; return NOPLogger.NOP_LOGGER; &#125;&#125; 抽象工厂（Abstract Factory）抽象工厂模式提供一个创建一系列相关或相互依赖对象的接口。 抽象工厂是面向产品族的，而工厂方法是面向产品等级结构的，这是两者的主要区别。 适用场景： 客户端不依赖于产品类实例如何被创建、实现等细节 强调一系列相关的产品对象（属于同一产品族）一起使用创建对象时需要大量重复的代码 提供一个产品类的库，所有的产品以同样的接口出现 优缺点优点：具体产品在应用层代码隔离，无须关心创建细节；将一个系列的产品族统一到一起创建。 缺点：规定了所有可能被创建的产品集合，产品族中扩展新的产品困难，需要修改抽象工厂的接口。 应用场景对于一个课程，既包含课程视频，也包含课程笔记： 抽象视频产品Video: 123public abstract class Video &#123; public abstract void produce();&#125; 具体视频产品JavaVideo、PythonVideo： 12345678910111213public class JavaVideo extends Video &#123; @Override public void produce() &#123; System.out.println("录制Java课程视频"); &#125;&#125;public class PythonVideo extends Video&#123; @Override public void produce() &#123; System.out.println("录制Python课程视频"); &#125;&#125; 同样，也有抽象笔记产品Article和具体笔记产品JavaArticle、PythonArticle： 1234567891011121314151617public abstract class Artical &#123; public abstract void produce();&#125;public class JavaArticle extends Artical &#123; @Override public void produce() &#123; System.out.println("编写Java课程手记"); &#125;&#125;public class PythonArticle extends Artical&#123; @Override public void produce() &#123; System.out.println("编写Python课程手记"); &#125;&#125; 课程的抽象工厂CourseFactory，生产视频和笔记两类产品： 1234public interface CourseFactory &#123; Video getVideo(); Artical getArtical();&#125; Java课程的具体工厂JavaCourseFactory： 123456789public class JavaCourseFactory implements CourseFactory &#123; public Video getVideo() &#123; return new JavaVideo(); &#125; public Artical getArtical() &#123; return new JavaArticle(); &#125;&#125; Python课程的具体工厂PythonCourseFactory： 123456789public class PythonCourseFactory implements CourseFactory &#123; public Video getVideo() &#123; return new PythonVideo(); &#125; public Artical getArtical() &#123; return new PythonArticle(); &#125;&#125; 客户端Test： 123456789public class Test &#123; public static void main(String[] args) &#123; CourseFactory courseFactory = new JavaCourseFactory(); Video video = courseFactory.getVideo(); Artical artical = courseFactory.getArtical(); video.produce(); artical.produce(); &#125;&#125; 可以看出，每一个具体工厂中都只会生产同一产品族下的产品。如果要扩展新的产品族，例如要添加一个算法课程，则添加一个AlgorithmCourseFactory工厂类即可，十分简单；但是如果要增加新的产品等级，比如在课程中除了视频和笔记外还要添加源码，那么就要修改抽象工厂中的实现，并且每一个具体工厂的实现也都要修改，抽象工厂模式在这种场景下就不适用了。 Connection中的应用java.sql.Connection接口定义了与指定数据库的连接： 123456public interface Connection extends Wrapper, AutoCloseable &#123; //... Statement createStatement() throws SQLException; PreparedStatement prepareStatement(String sql) throws SQLException; //...&#125; 其中，Statement、PreparedStatement等也都为接口。我们查看Connection的其中一个实现类ConnectionImpl： 1234567891011121314151617public class ConnectionImpl extends ConnectionPropertiesImpl implements Connection &#123; //... public Statement createStatement() throws SQLException &#123; return this.createStatement(1003, 1007); &#125; public Statement createStatement(int resultSetType, int resultSetConcurrency) throws SQLException &#123; this.checkClosed(); StatementImpl stmt = new StatementImpl(this, this.database); stmt.setResultSetType(resultSetType); stmt.setResultSetConcurrency(resultSetConcurrency); return stmt; &#125; //...&#125; 在createStatement方法中实例化了Statement接口的一个具体实现类，也就是com.mysql.jdbc.StatementImpl。 由此可见，在这个场景中Connection相当于一个抽象工厂，而ConnectionImpl是一个具体工厂，抽象产品为Statement，具体产品为StatementImpl。在这个例子中，mysql产品族的工厂只会生产mysql的Statement、PreparedStatement等产品。 建造者（Builder）将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。 工厂方法模式注重的是整体对象的创建方法，而建造者模式注重的是部件构建的过程，旨在通过一步一步地精确构造创建出一个复杂的对象。 适用场景： 如果一个对象有非常复杂的内部结构（很多属性） 想把复杂对象的创建和使用分离 优缺点优点：封装性好，创建和使用分离；扩展性好、建造类之间独立、一定程度上解耦。 缺点：产生多余的Builder对象；产品内部发生变化，建造者都要修改，成本较大。 应用场景CourseBuilder作为抽象建造者类，CourseActualBuilder作为具体建造者类，Coach作为教练类根据传入的建造者类安排复杂对象的建造次序（非必需），而Course作为产品类。 抽象建造者CourseBuilder： 123456789public abstract class CourseBuilder &#123; public abstract void buildCourseName(String courseName); public abstract void buildCoursePPT(String coursePPT); public abstract void buildCourseVideo(String courseVideo); public abstract void buildCourseArticle(String courseArticle); public abstract void buildCourseQA(String courseQA); public abstract Course makeCourse();&#125; 具体建造者CourseActualBuilder： 12345678910111213141516171819202122232425262728293031323334public class CourseActualBuilder extends CourseBuilder &#123; private Course course = new Course(); @Override public void buildCourseName(String courseName) &#123; course.setCourseName(courseName); &#125; @Override public void buildCoursePPT(String coursePPT) &#123; course.setCoursePPT(coursePPT); &#125; @Override public void buildCourseVideo(String courseVideo) &#123; course.setCourseVideo(courseVideo); &#125; @Override public void buildCourseArticle(String courseArticle) &#123; course.setCourseArticle(courseArticle); &#125; @Override public void buildCourseQA(String courseQA) &#123; course.setCourseQA(courseQA); &#125; @Override public Course makeCourse() &#123; return course; &#125;&#125; 教练Coach： 123456789public abstract class CourseBuilder &#123; public abstract void buildCourseName(String courseName); public abstract void buildCoursePPT(String coursePPT); public abstract void buildCourseVideo(String courseVideo); public abstract void buildCourseArticle(String courseArticle); public abstract void buildCourseQA(String courseQA); public abstract Course makeCourse();&#125; 产品Course： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class Course &#123; private String courseName; private String coursePPT; private String courseVideo; private String courseArticle; private String courseQA; //question &amp; answer public String getCourseName() &#123; return courseName; &#125; public void setCourseName(String courseName) &#123; this.courseName = courseName; &#125; public String getCoursePPT() &#123; return coursePPT; &#125; public void setCoursePPT(String coursePPT) &#123; this.coursePPT = coursePPT; &#125; public String getCourseVideo() &#123; return courseVideo; &#125; public void setCourseVideo(String courseVideo) &#123; this.courseVideo = courseVideo; &#125; public String getCourseArticle() &#123; return courseArticle; &#125; public void setCourseArticle(String courseArticle) &#123; this.courseArticle = courseArticle; &#125; public String getCourseQA() &#123; return courseQA; &#125; public void setCourseQA(String courseQA) &#123; this.courseQA = courseQA; &#125; @Override public String toString() &#123; return "Course&#123;" + "courseName='" + courseName + '\'' + ", coursePPT='" + coursePPT + '\'' + ", courseVideo='" + courseVideo + '\'' + ", courseArticle='" + courseArticle + '\'' + ", courseQA='" + courseQA + '\'' + '&#125;'; &#125;&#125; 客户端Test: 12345678910public class Test &#123; public static void main(String[] args) &#123; CourseBuilder courseBuilder = new CourseActualBuilder(); Coach coach = new Coach(); coach.setCourseBuilder(courseBuilder); Course course = coach.makeCourse("Java设计模式", "Java设计模式PPT", "Java设计模式视频", "Java设计模式笔记", "Java设计模式问答"); System.out.println(course); &#125;&#125; 客户端创建了一个建造者和一个教练，并将这个建造者作为参数传给教练，之后直接通过教练进行产品的创建，而对客户端隐藏了具体的创建细节。在教练内部，实际上是通过建造者一步步构造出复杂的产品的。 我们对以上的场景做进一步演化，省略了教练类，并且将建造者放在产品类的内部。这种做法在实际场景中更为常见，利于维护与扩展，并且支持链式调用。 产品类Course以及作为建造者的内部类CourseBuilder： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class Course &#123; private String courseName; private String coursePPT; private String courseVideo; private String courseArticle; private String courseQA; //question &amp; answer public Course(CourseBuilder courseBuilder) &#123; this.courseName = courseBuilder.courseName; this.coursePPT = courseBuilder.coursePPT; this.courseVideo = courseBuilder.courseVideo; this.courseArticle = courseBuilder.courseArticle; this.courseQA = courseBuilder.courseQA; &#125; @Override public String toString() &#123; return "Course&#123;" + "courseName='" + courseName + '\'' + ", coursePPT='" + coursePPT + '\'' + ", courseVideo='" + courseVideo + '\'' + ", courseArticle='" + courseArticle + '\'' + ", courseQA='" + courseQA + '\'' + '&#125;'; &#125; public static class CourseBuilder&#123; private String courseName; private String coursePPT; private String courseVideo; private String courseArticle; private String courseQA; //question &amp; answer public CourseBuilder buildCourseName(String courseName)&#123; this.courseName = courseName; return this; &#125; public CourseBuilder buildCoursePPT(String coursePPT) &#123; this.coursePPT = coursePPT; return this; &#125; public CourseBuilder buildCourseVideo(String courseVideo) &#123; this.courseVideo = courseVideo; return this; &#125; public CourseBuilder buildCourseArticle(String courseArticle) &#123; this.courseArticle = courseArticle; return this; &#125; public CourseBuilder buildCourseQA(String courseQA) &#123; this.courseQA = courseQA; return this; &#125; public Course build()&#123; return new Course(this); &#125; &#125;&#125; CourseBuilder中的每一个构建方法都返回对象自身，使得其支持链式调用，而build()方法将建造者作为参数传给产品类的构造函数，其根据建造者初始化产品各属性值，并将构建完毕的产品返回。 客户端Test： 1234567public class Test &#123; public static void main(String[] args) &#123; Course course = new Course.CourseBuilder().buildCourseName("Java设计模式").buildCoursePPT("Java设计模式PPT"). buildCourseVideo("Java设计模式视频").build(); System.out.println(course); &#125;&#125; 可以看出，演进之后的建造过程更为简洁明了。 StringBuilder中的应用Java.util.StringBuilder类下的append方法： 123456789101112131415161718192021222324252627public final class StringBuilder extends AbstractStringBuilder implements java.io.Serializable, CharSequence&#123; //... public StringBuilder append(String str) &#123; super.append(str); return this; &#125; public StringBuilder append(StringBuffer sb) &#123; super.append(sb); return this; &#125; public StringBuilder append(CharSequence s) &#123; super.append(s); return this; &#125; public StringBuilder append(CharSequence s, int start, int end) &#123; super.append(s, start, end); return this; &#125; //... 可以看出，这里使用了建造者模式，append方法总是返回建造者自身。StringBuilder既担任建造者，又担任产品，而建造方法的实现由父类AbstractStringBuilder完成。 StringBuffer的实现与上面类似，区别在于StringBuffer中的append方法加了synchronized关键字，因而是线程安全的。 mybatis中的应用查看org.apache.ibatis.session包下的SqlSessionFactoryBuilder： 1234567891011121314151617181920212223242526272829303132333435363738394041public class SqlSessionFactoryBuilder &#123; //... public SqlSessionFactory build(Reader reader) &#123; return this.build((Reader)reader, (String)null, (Properties)null); &#125; public SqlSessionFactory build(Reader reader, String environment) &#123; return this.build((Reader)reader, environment, (Properties)null); &#125; public SqlSessionFactory build(Reader reader, Properties properties) &#123; return this.build((Reader)reader, (String)null, properties); &#125; public SqlSessionFactory build(Reader reader, String environment, Properties properties) &#123; SqlSessionFactory var5; try &#123; XMLConfigBuilder parser = new XMLConfigBuilder(reader, environment, properties); var5 = this.build(parser.parse()); &#125; catch (Exception var14) &#123; throw ExceptionFactory.wrapException("Error building SqlSession.", var14); &#125; finally &#123; ErrorContext.instance().reset(); try &#123; reader.close(); &#125; catch (IOException var13) &#123; ; &#125; &#125; return var5; &#125; //... public SqlSessionFactory build(Configuration config) &#123; return new DefaultSqlSessionFactory(config); &#125; 这里面两个参数的build方法大多直接调用后面三个参数的build方法，返回值都为SqlSessionFactory，而这个方法中又有另一个建造者XMLConfigBuilder构建出一个Configuration对象，我们查看XMLConfigBuilder中的相关方法： 1234567891011121314151617181920212223242526272829public Configuration parse() &#123; if (this.parsed) &#123; throw new BuilderException("Each XMLConfigBuilder can only be used once."); &#125; else &#123; this.parsed = true; this.parseConfiguration(this.parser.evalNode("/configuration")); return this.configuration; &#125;&#125;private void parseConfiguration(XNode root) &#123; try &#123; Properties settings = this.settingsAsPropertiess(root.evalNode("settings")); this.propertiesElement(root.evalNode("properties")); this.loadCustomVfs(settings); this.typeAliasesElement(root.evalNode("typeAliases")); this.pluginElement(root.evalNode("plugins")); this.objectFactoryElement(root.evalNode("objectFactory")); this.objectWrapperFactoryElement(root.evalNode("objectWrapperFactory")); this.reflectorFactoryElement(root.evalNode("reflectorFactory")); this.settingsElement(settings); this.environmentsElement(root.evalNode("environments")); this.databaseIdProviderElement(root.evalNode("databaseIdProvider")); this.typeHandlerElement(root.evalNode("typeHandlers")); this.mapperElement(root.evalNode("mappers")); &#125; catch (Exception var3) &#123; throw new BuilderException("Error parsing SQL Mapper Configuration. Cause: " + var3, var3); &#125;&#125; 构建出一个Configuration对象的过程都在parseConfiguration方法中，而parse方法主要用来标记是否已经parse过并且返回构建好的Configuration对象。 单例模式（Singleton）保证一个类仅有一个实例，并提供一个全局访问点 适用场景：想确保任何情况下都绝对只有一个实例。 优缺点优点：在内存里只有一个实例，减少了内存开销；可以避免对资源的多重占用；设置全局访问点，严格控制访问。 缺点：可扩展性较差。 重点 私有构造器 线程安全 延迟加载 序列化和反序列化 反射 懒汉式实现线程不安全以下实现中延迟了lazySingleton的实例化，因此如果没有使用该类，那么就不会实例化lazySingleton，从而节约了资源。 但这种实现是线程不安全的，在多线程的环境下多个线程有可能同时判断if(lazySingleton == null)为true而进行实例化，导致多次实例化lazySingleton。 12345678910111213public class LazySingleton &#123; private static LazySingleton lazySingleton = null; private LazySingleton()&#123; &#125; public static LazySingleton getInstance()&#123; if(lazySingleton == null)&#123; lazySingleton = new LazySingleton(); &#125; return lazySingleton; &#125;&#125; synchronized关键字要想其变为线程安全的，第一种方式是在getInstance()方法加上synchronized关键字，使这个方法变为同步方法： 123456public synchronized static LazySingleton getInstance()&#123; if(lazySingleton == null)&#123; lazySingleton = new LazySingleton(); &#125; return lazySingleton;&#125; 由于这个方法是静态方法，因此这个锁将锁住这个类，等效于以下代码： 12345678public static LazySingleton getInstance()&#123; synchronized (LazySingleton.class)&#123; if(lazySingleton == null)&#123; lazySingleton = new LazySingleton(); &#125; &#125; return lazySingleton;&#125; 通过这种方式，虽然解决了懒汉式在多线程环境下的同步问题，但由于同步锁消耗的资源较多，且锁的范围较大，对性能有一定影响，因此还需要进行演进。 双重校验锁当lazyDoubleCheckSingleton就算没有被实例化时，synchronized关键字也保证了不会出现同步问题，例如，如果两个线程同时判断第一个if(lazyDoubleCheckSingleton == null)为true，其中一个线程会进入到第二个if(lazyDoubleCheckSingleton == null)并开始实例化lazyDoubleCheckSingleton，而另一个线程则被阻塞直到前一个进程释放锁。一旦前一个线程实例化完并释放锁，被阻塞的线程将进入第二个if(lazyDoubleCheckSingleton == null)且判断为false。之后，由于lazyDoubleCheckSingleton已经被实例化过，再有线程调用此方法都会在第一个if(lazyDoubleCheckSingleton == null)就判断为false，不会再进行加锁操作。 1234567891011121314151617public class LazyDoubleCheckSingleton &#123; private static LazyDoubleCheckSingleton lazyDoubleCheckSingleton = null; private LazyDoubleCheckSingleton()&#123; &#125; public static LazyDoubleCheckSingleton getInstance()&#123; if(lazyDoubleCheckSingleton == null)&#123; synchronized (LazyDoubleCheckSingleton.class) &#123; if (lazyDoubleCheckSingleton == null) &#123; lazyDoubleCheckSingleton = new LazyDoubleCheckSingleton(); &#125; &#125; &#125; return lazyDoubleCheckSingleton; &#125;&#125; 这种实现依然存在问题，对于lazyDoubleCheckSingleton = new LazyDoubleCheckSingleton();这一行代码其实是分为以下三步执行的： 分配内存给这个对象 初始化对象 设置lazyDoubleCheckSingleton指向刚分配的内存地址 但是JVM为了优化指令，提高程序运行效率，会进行指令重排序，指令顺序有可能由1-&gt;2-&gt;3变为1-&gt;3-&gt;2，这在单线程下不会出现问题，但是在多线程下会导致一个线程获得还没有被初始化的实例。例如，一个线程已经执行到了lazyDoubleCheckSingleton = new LazyDoubleCheckSingleton();这一行，且完成了1-&gt;3这两步，即lazyDoubleCheckSingleton已经不为null，但还没有进行初始化，此时另一个线程在第一个if(lazyDoubleCheckSingleton == null)判断为false后便将还未被初始化的lazyDoubleCheckSingleton返回，从而产生问题。 要解决指令重排序导致的问题，第一种方式是使用volatile关键字禁止JVM进行指令重排序： 12345678910public class LazyDoubleCheckSingleton &#123; private volatile static LazyDoubleCheckSingleton lazyDoubleCheckSingleton = null; private LazyDoubleCheckSingleton()&#123; &#125; public static LazyDoubleCheckSingleton getInstance()&#123; //... &#125;&#125; 静态内部类另一种解决指令重排序所导致的问题的方式是使用静态内部类让其它线程看不到这个线程的指令重排序： 12345678910111213public class StaticInnerClassSingleton &#123; private static class InnerClass&#123; private static StaticInnerClassSingleton staticInnerClassSingleton = new StaticInnerClassSingleton(); &#125; public static StaticInnerClassSingleton getInstance()&#123; return InnerClass.staticInnerClassSingleton; &#125; private StaticInnerClassSingleton()&#123; &#125;&#125; 当StaticInnerClassSingleton类加载时，静态内部类InnerClass还不会加载进内存，只有调用getInstance()方法使用到了InnerClass.staticInnerClassSingleton时才会加载。在多线程环境下，只有一个线程能获得Class对象的初始化锁，从而加载StaticInnerClassSingleton类，也就是这时候完成staticInnerClassSingleton的实例化，另一个线程此时只能在这个Class对象的初始化锁上等待。因此，由于等待的线程是看不见指令重排序的过程的，所以指令重排的顺序不会有任何影响。 饿汉式实现饿汉式即当类加载的时候就完成实例化，避免了同步问题，但同时也因为没有延迟实例化的特性而导致资源的浪费。 12345678910public class HungrySingleton implements Serializable &#123; private final static HungrySingleton hungrySingleton = new HungrySingleton(); private HungrySingleton()&#123; &#125; public static HungrySingleton getInstance()&#123; return hungrySingleton; &#125;&#125; 以上代码与以下代码等效： 1234567891011121314public class HungrySingleton implements Serializable &#123; private final static HungrySingleton hungrySingleton; static&#123; hungrySingleton = new HungrySingleton(); &#125; private HungrySingleton()&#123; &#125; public static HungrySingleton getInstance()&#123; return hungrySingleton; &#125;&#125; 单例模式存在的问题序列化破坏单例模式通过对Singleton的序列化与反序列化得到的对象是一个新的对象，这就破坏了Singleton的单例性。 123456789101112131415public class Test &#123; public static void main(String[] args)&#123; HungrySingleton instance = HungrySingleton.getInstance(); ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream("singleton_file")); oos.writeObject(instance); File file = new File("singleton_file"); ObjectInputStream ois = new ObjectInputStream(new FileInputStream(file)); HungrySingleton newInstance = (EnumInstance) ois.readObject(); System.out.println(instance); System.out.println(newInstance); System.out.println(instance == newInstance); &#125;&#125; 之所以会如此，是因为序列化会通过反射调用无参数的构造方法创建一个新的对象。要解决这个问题很简单：只要在Singleton类中定义readResolve即可： 123456789public class HungrySingleton implements Serializable &#123; //... private Object readResolve()&#123; return hungrySingleton; &#125; //...&#125; 反射攻击通过反射可以打开Singleton的构造器权限，由此实例化一个新的对象。 123456789101112131415public class Test &#123; public static void main(String[] args)&#123; Class objectClass = HungrySingleton.class; Class objectClass = LazySingleton.class; Constructor constructor = objectClass.getDeclaredConstructor(); constructor.setAccessible(true); HungrySingleton instance = HungrySingleton.getInstance(); HungrySingleton newInstance = (HungrySingleton) constructor.newInstance(); System.out.println(instance); System.out.println(newInstance); System.out.println(instance == newInstance); &#125;&#125; 对于饿汉式，由于是在类加载的时候就实例化对象了，因此要解决反射攻击问题，可以在构造器内部加一个判断用来防御，这样当反射调用构造器的时候hungrySingleton已经存在，不会再进行实例化并抛出异常： 1234567891011public class HungrySingleton implements Serializable &#123; //... private HungrySingleton()&#123; if(hungrySingleton != null)&#123; throw new RuntimeException("单例构造器禁止反射调用"); &#125; &#125; //...&#125; 而对于懒汉式，即使加上了上面的防御代码，依然可以通过调整顺序即先使用反射创建实例，再调用getInstance()创建实例来得到不止一个该类的对象。 枚举实现枚举类是实现单例的最佳方式，其在多次序列化再进行反序列化之后不会得到多个实例，也可以防御反射攻击。这部分的处理是由ObjectInputStream和Constructor这两个类实现的。 12345678910111213141516public enum EnumInstance &#123; INSTANCE; private Object data; public Object getData() &#123; return data; &#125; public void setData(Object data) &#123; this.data = data; &#125; public static EnumInstance getInstance()&#123; return INSTANCE; &#125;&#125; 容器实现如果系统中单例对象特别多，则可以考虑使用一个容器把所有单例对象统一管理，但是是线程不安全的。 123456789101112131415161718public class ContainerSingleton &#123; private static Map&lt;String, Object&gt; singletonMap = new HashMap&lt;String, Object&gt;(); private ContainerSingleton()&#123; &#125; public static void putInstance(String key, Object instance)&#123; if(StringUtils.isNotBlank(key) &amp;&amp; instance != null)&#123; if(!singletonMap.containsKey(key))&#123; singletonMap.put(key, instance); &#125; &#125; &#125; public static Object getInstance(String key)&#123; return singletonMap.get(key); &#125;&#125; Runtime中的应用查看java.lang包下的Runtime类： 123456789public class Runtime &#123; private static Runtime currentRuntime = new Runtime(); public static Runtime getRuntime() &#123; return currentRuntime; &#125; //...&#125; 这里的currentRuntime在类加载的时候就实例化好了，属于饿汉式单例模式。 Spring中的应用查看org.springframework.beans.factory.config包下的AbstractFactoryBean： 1234567891011121314151617181920212223242526public abstract class AbstractFactoryBean&lt;T&gt; implements FactoryBean&lt;T&gt;, BeanClassLoaderAware, BeanFactoryAware, InitializingBean, DisposableBean &#123; //... public final T getObject() throws Exception &#123; if (this.isSingleton()) &#123; return this.initialized ? this.singletonInstance : this.getEarlySingletonInstance(); &#125; else &#123; return this.createInstance(); &#125; &#125; private T getEarlySingletonInstance() throws Exception &#123; Class&lt;?&gt;[] ifcs = this.getEarlySingletonInterfaces(); if (ifcs == null) &#123; throw new FactoryBeanNotInitializedException(this.getClass().getName() + " does not support circular references"); &#125; else &#123; if (this.earlySingletonInstance == null) &#123; this.earlySingletonInstance = Proxy.newProxyInstance(this.beanClassLoader, ifcs, new AbstractFactoryBean.EarlySingletonInvocationHandler()); &#125; return this.earlySingletonInstance; &#125; &#125; //...&#125; 在getObject()方法中，先判断这个对象是否为单例的，如果不是则直接创建；如果是单例的，那么判断是否被初始化过，如果被初始化了则直接返回，没有的话则调用getEarlySingletonInstance()方法获取早期的单例对象，如果早期的单例对象不存在，则通过代理来获取。 结构型外观（Facade）外观模式又叫门面模式，提供了一个统一的接口，用来访问子系统中的一群接口。 外观模式定义了一个高层接口，让子系统更容易使用。 适用场景： 子系统越来越复杂，增加外观模式提供简单调用接口 构建多层系统接口，利用外观对象作为每层的入口，简化层间调用 优缺点优点：简化了调用过程，无需了解子系统，防止带来风险；减少系统依赖、松散耦合；更好的划分访问层次；符合迪米特法则，即最少知道原则。 缺点：增加子系统、扩展子系统行为容易引入风险，不符合开闭原则。 应用场景我们考虑一个用积分兑换礼物的场景，积分兑换礼物需要校验积分是否符合资格、扣减积分以及对接物流系统三个模块，这三个模块也可以理解为三个子系统。 校验资格子系统： 123456public class QualifyService &#123; public boolean isAvailable(PointsGift pointsGift)&#123; System.out.println("校验" + pointsGift.getName() + " 积分资格通过，库存通过"); return true; &#125;&#125; 扣减积分子系统： 1234567public class PointsPaymentService &#123; public boolean pay(PointsGift pointsGift)&#123; //扣减积分 System.out.println("支付" + pointsGift.getName() + " 积分成功"); return true; &#125;&#125; 对接物流系统的子系统： 12345678public class ShippingService &#123; public String shipGift(PointsGift pointsGift)&#123; //物流系统的对接逻辑 System.out.println(pointsGift.getName() + "进入物流系统"); String shippingOrderNo = "666"; return shippingOrderNo; &#125;&#125; 积分礼物类： 123456789101112131415public class PointsGift &#123; private String name; public PointsGift(String name) &#123; this.name = name; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; 外观类： 12345678910111213141516171819202122232425262728293031323334353637383940public class GiftExchangeService &#123; private QualifyService qualifyService = new QualifyService(); private PointsPaymentService pointsPaymentService = new PointsPaymentService(); private ShippingService shippingService = new ShippingService(); public QualifyService getQualifyService() &#123; return qualifyService; &#125; public void setQualifyService(QualifyService qualifyService) &#123; this.qualifyService = qualifyService; &#125; public PointsPaymentService getPointsPaymentService() &#123; return pointsPaymentService; &#125; public void setPointsPaymentService(PointsPaymentService pointsPaymentService) &#123; this.pointsPaymentService = pointsPaymentService; &#125; public ShippingService getShippingService() &#123; return shippingService; &#125; public void setShippingService(ShippingService shippingService) &#123; this.shippingService = shippingService; &#125; public void giftExchange(PointsGift pointsGift)&#123; if(qualifyService.isAvailable(pointsGift))&#123; //资格校验通过 if(pointsPaymentService.pay(pointsGift))&#123; //如果支付积分成功 String shippingOrderNo = shippingService.shipGift(pointsGift); System.out.println("物流系统下单成功，订单号是："+shippingOrderNo); &#125; &#125; &#125;&#125; 客户端类： 1234567public class Test &#123; public static void main(String[] args) &#123; PointsGift pointsGift = new PointsGift("衣服"); GiftExchangeService giftExchangeService = new GiftExchangeService(); giftExchangeService.giftExchange(pointsGift); &#125;&#125; 输出： 1234校验衣服 积分资格通过，库存通过支付衣服 积分成功衣服进入物流系统物流系统下单成功，订单号是：666 客户端创建一个衣服作为积分商品，然后使用积分兑换系统来完成积分兑换，这个积分兑换系统作为一个外观类整合了各个子系统，而客户端无需知道具体的子系统。 Spring中的应用查看org.springframework.jdbc.support下的JdbcUtils： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990public abstract class JdbcUtils &#123; public static void closeConnection(Connection con) &#123; if (con != null) &#123; try &#123; con.close(); &#125; catch (SQLException ex) &#123; logger.debug("Could not close JDBC Connection", ex); &#125; catch (Throwable ex) &#123; // We don't trust the JDBC driver: It might throw RuntimeException or Error. logger.debug("Unexpected exception on closing JDBC Connection", ex); &#125; &#125; &#125; public static Object getResultSetValue(ResultSet rs, int index, Class&lt;?&gt; requiredType) throws SQLException &#123; if (requiredType == null) &#123; return getResultSetValue(rs, index); &#125; Object value = null; boolean wasNullCheck = false; // Explicitly extract typed value, as far as possible. if (String.class.equals(requiredType)) &#123; value = rs.getString(index); &#125; else if (boolean.class.equals(requiredType) || Boolean.class.equals(requiredType)) &#123; value = rs.getBoolean(index); wasNullCheck = true; &#125; else if (byte.class.equals(requiredType) || Byte.class.equals(requiredType)) &#123; value = rs.getByte(index); wasNullCheck = true; &#125; else if (short.class.equals(requiredType) || Short.class.equals(requiredType)) &#123; value = rs.getShort(index); wasNullCheck = true; &#125; else if (int.class.equals(requiredType) || Integer.class.equals(requiredType)) &#123; value = rs.getInt(index); wasNullCheck = true; &#125; else if (long.class.equals(requiredType) || Long.class.equals(requiredType)) &#123; value = rs.getLong(index); wasNullCheck = true; &#125; else if (float.class.equals(requiredType) || Float.class.equals(requiredType)) &#123; value = rs.getFloat(index); wasNullCheck = true; &#125; else if (double.class.equals(requiredType) || Double.class.equals(requiredType) || Number.class.equals(requiredType)) &#123; value = rs.getDouble(index); wasNullCheck = true; &#125; else if (byte[].class.equals(requiredType)) &#123; value = rs.getBytes(index); &#125; else if (java.sql.Date.class.equals(requiredType)) &#123; value = rs.getDate(index); &#125; else if (java.sql.Time.class.equals(requiredType)) &#123; value = rs.getTime(index); &#125; else if (java.sql.Timestamp.class.equals(requiredType) || java.util.Date.class.equals(requiredType)) &#123; value = rs.getTimestamp(index); &#125; else if (BigDecimal.class.equals(requiredType)) &#123; value = rs.getBigDecimal(index); &#125; else if (Blob.class.equals(requiredType)) &#123; value = rs.getBlob(index); &#125; else if (Clob.class.equals(requiredType)) &#123; value = rs.getClob(index); &#125; else &#123; // Some unknown type desired -&gt; rely on getObject. value = getResultSetValue(rs, index); &#125; // Perform was-null check if demanded (for results that the // JDBC driver returns as primitives). if (wasNullCheck &amp;&amp; value != null &amp;&amp; rs.wasNull()) &#123; value = null; &#125; return value; &#125; 可以看出，该工具类主要是对jdbc的封装，向外提供一个隐藏了具体实现细节的接口，对访问屏蔽复杂的子系统调用。 SLF4J中的应用SLF4J是简单的日志外观模式框架，抽象了各种日志框架例如Logback、Log4j、Commons-logging和JDK自带的logging实现接口。它使得用户可以在部署时使用自己想要的日志框架。 SLF4J没有替代任何日志框架，它仅仅是标准日志框架的外观模式。如果在类路径下除了SLF4J再没有任何日志框架，那么默认状态是在控制台输出日志。 适配器（Adapter）将一个类的接口转换成客户期望的另一个接口。 适配器模式使原本接口不兼容的类可以一起工作。根据适配器类与适配者类的关系不同，适配器模式可分为对象适配器和类适配器两种，在对象适配器模式中，适配器与适配者之间是组合关系，使用的是委托机制；在类适配器模式中，适配器与适配者之间是继承（或实现）关系。 适用场景： 已经存在的类，它的方法和需求不匹配时（方法结果相同或相似）。 不是软件设计阶段考虑的设计模式，是随着软件维护，由于不同产品、不同厂家造功能类似而接口不相同情况下的解决方案。 优缺点优点：能提高类的透明性和复用；目标类和适配器类解耦，提高程序扩展性；符合开闭原则。 缺点：增加了系统的复杂性；增加系统代码可读的难度。 应用场景类适配器模式被适配者类： 12345public class Adaptee &#123; public void adapteeRequest()&#123; System.out.println("被适配者的方法"); &#125;&#125; 目标接口： 123public interface Target &#123; void request();&#125; 目标接口实现（非必需的，只是待会用来做对比）： 12345public class ConcreteTarget implements Target &#123; public void request() &#123; System.out.println("concreteTarget目标方法"); &#125;&#125; 适配器类，既实现了目标接口又继承了被适配者类，因此直接在实现的request()中调用父类的adapteeRequest()方法即可： 12345public class Adapter extends Adaptee implements Target&#123; public void request() &#123; super.adapteeRequest(); &#125;&#125; 客户端类： 123456789public class Test &#123; public static void main(String[] args) &#123; Target target = new ConcreteTarget(); target.request(); Target adapterTarget = new Adapter(); adapterTarget.request(); &#125;&#125; 通过适配器，我们就将被适配者类Adaptee的adapteeRequest()方法适配成了目标接口Target的request()方法。 对象适配器模式在对象适配器模式中，被适配者类Adaptee、目标接口与实现类Target ConcreteTarget、客户端类Test 都不需要改变，唯一需要改变的就是适配器类Adapter。 1234567public class Adapter implements Target &#123; private Adaptee adaptee = new Adaptee(); public void request() &#123; adaptee.adapteeRequest(); &#125;&#125; 可以看出，对象适配器与类适配器不同之处在于类适配器是通过继承来完成适配，而对象适配器则组合被适配者并将请求委托给被适配者来完成。 变压器的例子这里考虑一个生活中常见的变压器的场景，我们把220V交流电压适配成5V直流电压，其中220V交流电压就是被适配者类，而5V直流电压则是目标接口，我们需要一个适配器来完成这个变压操作。 被适配者类（220V交流电压）： 1234567public class AC220 &#123; public int outputAC220V()&#123; int output = 220; System.out.println("输出交流电" + output + "V"); return output; &#125;&#125; 目标接口（5V直流电压）： 123public interface DC5 &#123; int outputDC5V();&#125; 适配器类，这里使用的是对象适配器模式： 1234567891011121314public class PowerAdapter implements DC5 &#123; private AC220 ac220 = new AC220(); public int outputDC5V() &#123; //将220V交流电压作为输入电压 int adapterInput = ac220.outputAC220V(); //模拟变压器，得到5V直流电压 int adapterOutput = adapterInput / 44; System.out.println("使用PowerAdapter输入AC：" + adapterInput +"V " + "输出DC：" + adapterOutput + "V"); return adapterOutput; &#125;&#125; 客户端类： 123456public class Test &#123; public static void main(String[] args) &#123; DC5 dc5 = new PowerAdapter(); dc5.outputDC5V(); &#125;&#125; 通过适配器将220V交流电压转换成了5V直流电压，此时输出：12输出交流电220V使用PowerAdapter输入AC：220V 输出DC：5V Spring AOP中的应用在Spring的AOP中，使用的Advice (通知)来增强被代理类的功能。Advice的类型有：MethodBeforeAdvice、AfterReturningAdvice、ThrowsAdvice，而每个类型的Advice都有对应的拦截器MethodBeforeAdviceInterceptor、AfterReturningAdviceInterceptor、ThrowsAdviceInterceptor。 Spring需要将每个Advice都封装成对应的拦截器类型，返回给容器，所以需要使用适配器模式对 Advice进行转换。 三个适配者类： 12345678910public interface MethodBeforeAdvice extends BeforeAdvice &#123; void before(Method var1, Object[] var2, @Nullable Object var3) throws Throwable;&#125;public interface AfterReturningAdvice extends AfterAdvice &#123; void afterReturning(@Nullable Object var1, Method var2, Object[] var3, @Nullable Object var4) throws Throwable;&#125;public interface ThrowsAdvice extends AfterAdvice &#123;&#125; 适配器接口，其中supportsAdvice方法判断Advice类型是否匹配，另一个是创建对应的拦截器的工厂方法： 12345public interface AdvisorAdapter &#123; boolean supportsAdvice(Advice var1); MethodInterceptor getInterceptor(Advisor var1);&#125; 三个适配器类： 1234567891011121314151617181920212223242526272829303132333435class MethodBeforeAdviceAdapter implements AdvisorAdapter, Serializable &#123; @Override public boolean supportsAdvice(Advice advice) &#123; return (advice instanceof MethodBeforeAdvice); &#125; @Override public MethodInterceptor getInterceptor(Advisor advisor) &#123; MethodBeforeAdvice advice = (MethodBeforeAdvice) advisor.getAdvice(); return new MethodBeforeAdviceInterceptor(advice); &#125;&#125;class AfterReturningAdviceAdapter implements AdvisorAdapter, Serializable &#123; @Override public boolean supportsAdvice(Advice advice) &#123; return (advice instanceof AfterReturningAdvice); &#125; @Override public MethodInterceptor getInterceptor(Advisor advisor) &#123; AfterReturningAdvice advice = (AfterReturningAdvice) advisor.getAdvice(); return new AfterReturningAdviceInterceptor(advice); &#125;&#125;class ThrowsAdviceAdapter implements AdvisorAdapter, Serializable &#123; @Override public boolean supportsAdvice(Advice advice) &#123; return (advice instanceof ThrowsAdvice); &#125; @Override public MethodInterceptor getInterceptor(Advisor advisor) &#123; return new ThrowsAdviceInterceptor(advisor.getAdvice()); &#125;&#125; 客户端类： 12345678910111213141516171819202122232425262728293031323334public class DefaultAdvisorAdapterRegistry implements AdvisorAdapterRegistry, Serializable &#123; private final List&lt;AdvisorAdapter&gt; adapters = new ArrayList(3); public DefaultAdvisorAdapterRegistry() &#123; // 这里注册了适配器 this.registerAdvisorAdapter(new MethodBeforeAdviceAdapter()); this.registerAdvisorAdapter(new AfterReturningAdviceAdapter()); this.registerAdvisorAdapter(new ThrowsAdviceAdapter()); &#125; public MethodInterceptor[] getInterceptors(Advisor advisor) throws UnknownAdviceTypeException &#123; List&lt;MethodInterceptor&gt; interceptors = new ArrayList(3); Advice advice = advisor.getAdvice(); if (advice instanceof MethodInterceptor) &#123; interceptors.add((MethodInterceptor)advice); &#125; Iterator var4 = this.adapters.iterator(); while(var4.hasNext()) &#123; AdvisorAdapter adapter = (AdvisorAdapter)var4.next(); if (adapter.supportsAdvice(advice)) &#123; // 这里调用适配器方法 interceptors.add(adapter.getInterceptor(advisor)); // 这里调用适配器方法 &#125; &#125; if (interceptors.isEmpty()) &#123; throw new UnknownAdviceTypeException(advisor.getAdvice()); &#125; else &#123; return (MethodInterceptor[])interceptors.toArray(new MethodInterceptor[0]); &#125; &#125; // ...&#125; 上面的代码在while循环里逐个取出注册的适配器，调用supportsAdvice()方法来判断Advice对应的类型，然后调用 getInterceptor() 创建对应类型的拦截器。 这里应该属于对象适配器模式，不过这里的Advice对象是从外部传进来，而不是成员属性。 组合（Composite）将对象组合成树形结构来表示“整体-部分”层次关系，允许用户以相同的方式处理单独对象和组合对象。 适用场景： 希望客户端可以忽略组合对象与单个对象的差异时。 处理一个树形结构时。 优缺点优点：客户端不必关心处理的是单个对象还是整个组合结构，简化了客户端代码；增加新的构件无须对现有类库进行任何修改，符合开闭原则。 缺点：限制类型时会较为复杂；使设计变得更加抽象。 应用场景一个在线学习网站下有许多目录以及学习视频，而目录下可能还会存在子目录，这里就可以使用组合模式。 抽象构件： 123456789101112131415161718192021public abstract class CatalogComponent &#123; public void add(CatalogComponent catalogComponent)&#123; throw new UnsupportedOperationException("不支持添加操作"); &#125; public void remove(CatalogComponent catalogComponent)&#123; throw new UnsupportedOperationException("不支持删除操作"); &#125; public String getName(CatalogComponent catalogComponent)&#123; throw new UnsupportedOperationException("不支持获取名称操作"); &#125; public double getPrice(CatalogComponent catalogComponent)&#123; throw new UnsupportedOperationException("不支持获取价格操作"); &#125; public void print()&#123; throw new UnsupportedOperationException("不支持打印操作"); &#125;&#125; 叶子构件（课程视频）： 123456789101112131415161718192021222324public class Course extends CatalogComponent&#123; private String name; private double price; public Course(String name, double price) &#123; this.name = name; this.price = price; &#125; @Override public String getName(CatalogComponent catalogComponent) &#123; return this.name; &#125; @Override public double getPrice(CatalogComponent catalogComponent) &#123; return this.price; &#125; @Override public void print() &#123; System.out.println("Course Name: " + name + " Price: " + price); &#125;&#125; 容器构件（课程目录）： 12345678910111213141516171819202122232425262728293031323334353637public class CourseCatalog extends CatalogComponent &#123; private List&lt;CatalogComponent&gt; items = new ArrayList&lt;CatalogComponent&gt;(); private String name; private Integer level; public CourseCatalog(String name, Integer level) &#123; this.name = name; this.level = level; &#125; @Override public String getName(CatalogComponent catalogComponent) &#123; return this.name; &#125; @Override public void add(CatalogComponent catalogComponent) &#123; items.add(catalogComponent); &#125; @Override public void remove(CatalogComponent catalogComponent) &#123; items.remove(catalogComponent); &#125; @Override public void print() &#123; System.out.println(this.name); for(CatalogComponent catalogComponent : items)&#123; if(this.level != null)&#123; for(int i = 0; i &lt; this.level; i++) System.out.print(" "); &#125; catalogComponent.print(); &#125; &#125;&#125; 客户端类： 12345678910111213141516171819202122public class Test &#123; public static void main(String[] args) &#123; CatalogComponent linuxCourse = new Course("linux课程", 11); CatalogComponent windowsCourse = new Course("Windows课程", 11); CatalogComponent javaCourseCatalog = new CourseCatalog("Java课程目录", 2); CatalogComponent mallCourse1 = new Course("Java电商一期", 55); CatalogComponent mallCourse2 = new Course("Java电商二期", 66); CatalogComponent designPattern = new Course("Java设计模式", 77); javaCourseCatalog.add(mallCourse1); javaCourseCatalog.add(mallCourse2); javaCourseCatalog.add(designPattern); CatalogComponent mainCourseCatalog = new CourseCatalog("课程主目录", 1); mainCourseCatalog.add(linuxCourse); mainCourseCatalog.add(windowsCourse); mainCourseCatalog.add(javaCourseCatalog); mainCourseCatalog.print(); &#125;&#125; 组合模式的关键是定义了一个抽象构件类，它既可以代表叶子，又可以代表容器，而客户端针对该抽象构件类进行编程，无须知道它到底表示的是叶子还是容器，可以对其进行统一处理。同时容器对象与抽象构件类之间还建立一个聚合关系，在容器对象中既可以包含叶子，也可以包含容器，以此实现递归组合，形成一个树形结构。 装饰者（Decorator）在不改变原有对象的基础之上，将功能附加到对象上。 提供了比继承更有弹性的替代方案（扩展原有对象功能）。 适用场景： 扩展一个类的功能或给一个类添加附加职责。 动态的给一个对象添加功能，这些功能可以再动态的撤销。 优缺点优点：继承的有力补充，比继承灵活，不改变原有对象的情况下给一个对象扩展功能；通过使用不同装饰类以及这些装饰类的排列组合，可以实现不同效果；符合开闭原则。 缺点：会出现更多的代码，更多的类，增加程序复杂性；动态装饰时、多层装饰时会更复杂。 应用场景我们考虑一个买煎饼的例子，人们可以自由地选择是否要在煎饼上加鸡蛋或者火腿，每次要加多少个，而总共价格是多少。 煎饼抽象类： 1234public abstract class ABattercake &#123; protected abstract String getDesc(); protected abstract int cost();&#125; 煎饼类： 1234567891011public class Battercake extends ABattercake &#123; @Override protected String getDesc() &#123; return "煎饼"; &#125; @Override protected int cost() &#123; return 8; &#125;&#125; 抽象装饰类（并不是真正的抽象类，因为这个场景中不需要抽象方法），这个类将抽象煎饼类作为成员属性，并且也继承了抽象煎饼类： 1234567891011121314151617public class AbstractDecorator extends ABattercake &#123; private ABattercake aBattercake; public AbstractDecorator(ABattercake aBattercake) &#123; this.aBattercake = aBattercake; &#125; @Override protected String getDesc() &#123; return this.aBattercake.getDesc(); &#125; @Override protected int cost() &#123; return this.aBattercake.cost(); &#125;&#125; 加鸡蛋的装饰类，继承了抽象装饰类： 123456789101112131415public class EggDecorator extends AbstractDecorator &#123; public EggDecorator(ABattercake aBattercake) &#123; super(aBattercake); &#125; @Override protected String getDesc() &#123; return super.getDesc() + " 加一个鸡蛋"; &#125; @Override protected int cost() &#123; return super.cost()+1; &#125;&#125; 加火腿的装饰类，继承了抽象装饰类： 123456789101112131415public class SausageDecorator extends AbstractDecorator &#123; public SausageDecorator(ABattercake aBattercake) &#123; super(aBattercake); &#125; @Override protected String getDesc() &#123; return super.getDesc() + " 加一根香肠"; &#125; @Override protected int cost() &#123; return super.cost()+2; &#125;&#125; 客户端类： 1234567891011public class Test &#123; public static void main(String[] args) &#123; ABattercake aBattercake; aBattercake = new Battercake(); aBattercake = new EggDecorator(aBattercake); aBattercake = new EggDecorator(aBattercake); aBattercake = new SausageDecorator(aBattercake); System.out.println(aBattercake.getDesc() + " 销售价格：" + aBattercake.cost()); &#125;&#125; 输出： 1煎饼 加一个鸡蛋 加一个鸡蛋 加一根香肠 销售价格：12 装饰类和具体组件类都继承了抽象组件类。所谓装饰，就是把这个装饰者套在被装饰者之上，从而动态扩展被装饰者的功能，装饰者的方法有一部分是自己的，这属于它的功能，然后调用被装饰者的方法实现，从而也保留了被装饰者的功能。 Java I/O中的应用在Java中应用程序通过输入流（InputStream）的Read方法从源地址处读取字节，然后通过输出流（OutputStream）的Write方法将流写入到目的地址。 流的来源主要有三种：本地的文件（File）、控制台、通过socket实现的网络通信。 下面查看其中InputStream的类图，而关于OutputStream、Reader、Writer等都与此类似： 由上图可以看出只要继承了FilterInputStream的类就是装饰者类，可以用于包装其他的流，装饰者类还可以对装饰者和类进行再包装。以下是对其中部分类的简要介绍： 流名称 简介 ByteArrayInputStream 字节数组输入流在内存中创建一个字节数组缓冲区，从输入流读取的数据保存在该字节数组缓冲区中 PipedInputStream 访问管道，主要在线程中使用，一个线程通过管道输出流发送数据，而另一个线程通过管道输入流读取数据，这样可实现两个线程间的通讯 FileInputStream 访问文件，把一个文件作为 InputStream ，实现对文件的读取操作 PushBackInputStream 推回输入流，可以把读取进来的某些数据重新回退到输入流的缓冲区之中 BufferedInputStream 带缓冲的输入流一次读很多字节先放到内存中，等缓冲区满的时候一次性写入磁盘，这种方式可以减少磁盘操作次数，因此效率很高 DataInputStream 允许应用程序以与机器无关方式从底层输入流中读取基本Java数据类型 Spring中的应用查看org.springframework.cache.transaction下的TransactionAwareCacheDecorator： 该类实现了Cache接口，同时将Cache组合到类中成为了成员属性，所以可以大胆猜测TransactionAwareCacheDecorator是一个装饰类，不过这里并没有抽象装饰类，且TransactionAwareCacheDecorator没有子类，这里的装饰类关系并没有Java I/O中的装饰关系那么复杂。 实际上，Spring cache是对缓存使用的抽象，通过它我们可以在不侵入业务代码的基础上让现有代码即刻支持缓存。通过Spring的TransactionSynchronizationManager将其缓存操作与Spring管理的事务同步，仅在成功事务的提交之后执行实际的缓存操作。 MyBatis中的应用查看包org.apache.ibatis.cache： 代理（Proxy）代理模式为其它对象提供一种代理，以控制对这个对象的访问，代理对象在客户端和目标对象之间起到中介的作用。 我们有多种不同的方式来实现代理。如果按照代理创建的时期来进行分类的话， 可以分为两种：静态代理、动态代理。静态代理是由程序员创建或特定工具自动生成源代码，再对其编译，在运行之前，代理类.class文件就已经被创建了。动态代理是在程序运行时通过反射机制动态创建的。 适用场景： 保护目标对象 增强目标对象 优缺点优点：能将代理对象与真实被调用的目标对象分离；保护目标对象；增强目标对象。 缺点：会造成系统设计中类的数目增加；在客户端和目标对象增加一个代理对象，会造成请求处理速度变慢；增加系统的复杂度。 应用场景静态代理使用静态代理可以做到在符合开闭原则的情况下对目标对象进行功能扩展，但我们得为每一个服务都创建代理类，工作量太大，不易管理。 服务接口： 123public interface BuyHouse &#123; void buyHosue();&#125; 实现服务接口： 1234567public class BuyHouseImpl implements BuyHouse &#123; @Override public void buyHosue() &#123; System.out.println("我要买房"); &#125;&#125; 代理类： 123456789101112131415161718192021222324public class BuyHouseProxy implements BuyHouse &#123; private BuyHouse buyHouse; public BuyHouseProxy(BuyHouse buyHouse) &#123; this.buyHouse = buyHouse; &#125; @Override public void buyHosue() &#123; beforeMethod(); buyHouse.buyHosue(); afterMethod(); &#125; private void beforeMethod()&#123; System.out.println("买房前准备"); &#125; private void afterMethod()&#123; System.out.println("买房后装修"); &#125;&#125; 客户端类： 12345678public class Test&#123; public static void main(String[] args) &#123; BuyHouse buyHouse = new BuyHouseImpl(); buyHouse.buyHosue(); BuyHouseProxy buyHouseProxy = new BuyHouseProxy(buyHouse); buyHouseProxy.buyHosue(); &#125;&#125; 动态代理在动态代理中我们不再需要手动的创建代理类，我们只需要编写一个动态处理器就可以了。真正的代理对象由JDK再运行时为我们动态的来创建。 动态处理器，实现了InvocationHandler接口： 123456789101112131415161718192021222324public class DynamicProxyHandler implements InvocationHandler &#123; private Object object; public DynamicProxyHandler(final Object object) &#123; this.object = object; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; beforeMethod(); Object result = method.invoke(object, args); afterMethod(); return result; &#125; private void beforeMethod()&#123; System.out.println("买房前准备"); &#125; private void afterMethod()&#123; System.out.println("买房后装修"); &#125;&#125; 客户端类： 1234567public class Test &#123; public static void main(String[] args) &#123; BuyHouse buyHouse = new BuyHouseImpl(); BuyHouse proxyBuyHouse = (BuyHouse) Proxy.newProxyInstance(buyHouse .getClass().getClassLoader(), buyHouse.getClass().getInterfaces(), new DynamicProxyHandler(buyHouse)); proxyBuyHouse.buyHosue(); &#125;&#125; 其中Proxy.newProxyInstance()方法接受三个参数： ClassLoader loader：指定当前目标对象使用的类加载器，获取加载器的方法是固定的 Class&lt;?&gt;[] interfaces：指定目标对象实现的接口的类型，使用泛型方式确认类型 InvocationHandler：指定动态处理器，执行目标对象的方法时，会触发事件处理器的方法 动态代理虽然不需要自己手动实现代理类和目标方法，但动态代理目标对象必须有接口，没有接口不能实现JDK版动态代理。 CGLIB代理JDK实现动态代理需要实现类通过接口定义业务方法，对于没有接口的类，如何实现动态代理呢，这就需要CGLib了。CGLib采用了非常底层的字节码技术，其原理是通过字节码技术为一个类创建子类，并在子类中采用方法拦截的技术拦截所有父类方法的调用，顺势织入横切逻辑。但因为采用的是继承，所以不能对final修饰的类进行代理。JDK动态代理与CGLib动态代理均是实现Spring AOP的基础。 CGLIB创建的动态代理对象比JDK创建的动态代理对象的性能更高，但是CGLIB创建代理对象时所花费的时间却比JDK多得多。所以对于单例的对象，因为无需频繁创建对象，用CGLIB合适，反之使用JDK方式要更为合适一些。 Spring的代理选择 当Bean有实现接口时，Spring就会用JDK的动态代理。 当Bean没有实现接口时，Spring使用CGlib。 可以强制使用CGLib。 桥接（Bridge）将抽象部分与它的具体实现部分分离，使它们都可以独立地变化。 通过组合的方式建立两个类之间联系，而不是继承。 适用场景： 抽象和具体实现之间增加更多的灵活性。 一个类存在两个（或多个）独立变化的维度，且这两个（或多个）维度都需要独立进行扩展。 不希望使用继承，或因为多层继承导致系统类的个数剧增。 优缺点优点：分离抽象部分及其具体实现部分；提高了系统的可扩展性；符合开闭原则与合成复用原则。 缺点：增加了系统的设计难度；需要正确地识别出系统中两个独立变化的维度。 应用场景画图时可以画正方形、长方形、圆形三种形状，而每种形状又可以画白色、灰色、黑色三种颜色，因此我们可以很自然地想出以下的继承关系： 对于这种方案，假如我们要添加一个椭圆形状，我们又要增加三种颜色，也就是白椭圆、灰椭圆和黑椭圆。假如我们要添加一个绿色，我们就要增加绿正方形、绿椭圆和绿长方形。每次增加都会增加若干个类（如果增加颜色则会增加形状个数个类，若增加形状则会增加颜色个数个类），这会导致系统类的个数剧增，且不利于系统的扩展。 对于这种有几个变化维度的场景，我们就可以使用桥接模式来减少系统中的类个数。这里提供两个父类一个是颜色、一个形状，颜色父类和形状父类两个类都包含了相应的子类，然后根据需要对颜色和形状进行组合： 形状抽象类，将颜色接口设为其成员变量： 12345678910public abstract class Shape &#123; Color color; public void setColor(Color color) &#123; this.color = color; &#125; public abstract void draw();&#125; 具体形状类： 1234567891011121314151617public class Circle extends Shape&#123; public void draw() &#123; color.bepaint("圆形"); &#125;&#125;public class Rectangle extends Shape&#123; public void draw() &#123; color.bepaint("长方形"); &#125;&#125;public class Square extends Shape&#123; public void draw() &#123; color.bepaint("正方形"); &#125;&#125; 颜色接口： 123public interface Color &#123; public void bepaint(String shape);&#125; 具体颜色类： 1234567891011121314151617public class White implements Color&#123; public void bepaint(String shape) &#123; System.out.println("白色的" + shape); &#125;&#125;public class Gray implements Color&#123; public void bepaint(String shape) &#123; System.out.println("灰色的" + shape); &#125;&#125;public class Black implements Color&#123; public void bepaint(String shape) &#123; System.out.println("黑色的" + shape); &#125;&#125; 客户端类： 12345678910111213141516public class Test&#123; public static void main(String[] args) &#123; //白色 Color white = new White(); //正方形 Shape square = new Square(); //白色的正方形 square.setColor(white); square.draw(); //长方形 Shape rectange = new Rectangle(); rectange.setColor(white); rectange.draw(); &#125;&#125; 这里在实现时要注意，抽象类的方法要调用组合的实现类的方法（如类Square中的color.bepaint(&quot;正方形&quot;)这行代码），这样才能体现出桥接的意义。 JDBC的应用jdbc的类族设计是由sun公司设计了一套接口，再由各个数据库公司实现接口，我们在调用的过程中只需要使用接口去定义，然后在加载Driver的过程中底层代码会给我们选择好接口真正的实现类，以此来实现真正的数据库连接，此后所有的方法，包括获取statement等等，都是由接口声明调用，但是底层返回的是接口实现类。用这种桥接的模式，我们可以很轻松地在不同的数据库连接中进行转化，只需要修改Driver加载的类，如果把加载类的声明放入配置文件中，更是不需要重新去编译，可以很方便地在不同数据库间进行转化。 享元（Flyweight）享元模式提供了减少对象数量从而改善应用所需的对象结构的方式。 适用场景： 常常应用于系统底层的开发，以便解决系统的性能问题。 系统有大量相似对象、需要缓冲池的场景。 优缺点优点：减少对象的创建，降低内存中对象的数量，降低系统的内存，提高效率；减少内存之外的其它资源占用（比如创建对象所需的时间）。 缺点：关注内外部状态以及线程安全问题；使系统的逻辑复杂化。 应用场景在年底的时候公司的老总、副总等许多高层经常需要将部门经理叫去办公室汇报工作，而汇报的往往都是同样的内容，部门经理没有必要每次汇报前都准备一份全新的相同报告，而可以直接使用之前的报告，在这里可以应用享元模式。 雇员接口： 123public interface Employee &#123; void report();&#125; 部门经理类，在创建部门经理的时候需要指定部门department，这个部门就是外部状态，而职位title是固定设为部门经理的，因此就是内部状态： 1234567891011121314151617public class Manager implements Employee &#123; public void report() &#123; System.out.println(reportContent); &#125; private String title = "部门经理"; private String department; private String reportContent; public void setReportContent(String reportContent) &#123; this.reportContent = reportContent; &#125; public Manager(String department) &#123; this.department = department; &#125;&#125; 雇员工厂类，用于创建并管理享元对象。这里使用了一个HashMap作为缓存池，如果某个部门经理没有做过汇报，那么就创建这个部门经理，并且设置汇报内容，然后将其加入到缓存池中。如果以后再叫到了这个部门经理，就直接从缓存池中取出而不必再创建一遍了： 12345678910111213141516public class EmployeeFactory &#123; private static final Map&lt;String, Employee&gt; EMPLOYEE_MAP = new HashMap&lt;String, Employee&gt;(); public static Employee getManager(String department)&#123; Manager manager = (Manager) EMPLOYEE_MAP.get(department); if(manager == null)&#123; manager = new Manager(department); System.out.print("创建部门经理: " + department); String repportContent = department + "部门汇报: 此次报告的主要内容是..."; manager.setReportContent(repportContent); System.out.println(" 创建报告: " + repportContent); EMPLOYEE_MAP.put(department, manager); &#125; return manager; &#125;&#125; 客户端类，随机取出一个部门的部门经理做汇报： 1234567891011public class Test &#123; private static final String departments[] = &#123;"RD", "QA", "PM", "BD"&#125;; public static void main(String[] args) &#123; for(int i = 0; i &lt; 10; i++)&#123; String department = departments[(int) (Math.random() * departments.length)]; Manager manager = (Manager) EmployeeFactory.getManager(department); manager.report(); &#125; &#125;&#125; 输出： 1234567891011121314创建部门经理: BD 创建报告: BD部门汇报: 此次报告的主要内容是...BD部门汇报: 此次报告的主要内容是...BD部门汇报: 此次报告的主要内容是...创建部门经理: QA 创建报告: QA部门汇报: 此次报告的主要内容是...QA部门汇报: 此次报告的主要内容是...QA部门汇报: 此次报告的主要内容是...创建部门经理: RD 创建报告: RD部门汇报: 此次报告的主要内容是...RD部门汇报: 此次报告的主要内容是...BD部门汇报: 此次报告的主要内容是...RD部门汇报: 此次报告的主要内容是...RD部门汇报: 此次报告的主要内容是...创建部门经理: PM 创建报告: PM部门汇报: 此次报告的主要内容是...PM部门汇报: 此次报告的主要内容是...QA部门汇报: 此次报告的主要内容是... 可以发现每个部门经理只创建过一次报告，之后都使用的同一份报告做汇报。 Integer中的应用我们查看jdk中Integer类下的valueOf方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243//... public static Integer valueOf(int i) &#123; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i); &#125; private static class IntegerCache &#123; static final int low = -128; static final int high; static final Integer cache[]; static &#123; // high value may be configured by property int h = 127; String integerCacheHighPropValue = sun.misc.VM.getSavedProperty("java.lang.Integer.IntegerCache.high"); if (integerCacheHighPropValue != null) &#123; try &#123; int i = parseInt(integerCacheHighPropValue); i = Math.max(i, 127); // Maximum array size is Integer.MAX_VALUE h = Math.min(i, Integer.MAX_VALUE - (-low) -1); &#125; catch( NumberFormatException nfe) &#123; // If the property cannot be parsed into an int, ignore it. &#125; &#125; high = h; cache = new Integer[(high - low) + 1]; int j = low; for(int k = 0; k &lt; cache.length; k++) cache[k] = new Integer(j++); // range [-128, 127] must be interned (JLS7 5.1.7) assert IntegerCache.high &gt;= 127; &#125; private IntegerCache() &#123;&#125; &#125;//... 可以看出，在使用valueOf方法时，如果传入的参数在缓存范围内（这个范围在IntegerCache中设置为-128~127），那么直接从缓存中读取并返回，否则就创建一个新的对象返回。 我们可以通过一个实验来加以验证：12345678910111213public static void main(String[] args) &#123; Integer t1 = new Integer(100); Integer t2 = new Integer(100); System.out.println(t1 == t2); Integer t3 = 100; Integer t4 = 100; System.out.println(t3 == t4); Integer t5 = 128; Integer t6 = 128; System.out.println(t5 == t6);&#125; 输出： 123falsetruefalse 使用new创建的Integer对象用==比较的是对象地址，因为对象不同所以地址也不相同，故输出false；而像Integer t = xxx 这种形式的定义实际会变成Integer t = Integer.valueOf(xxx)，先判断是否能直接从缓存中取出，100是在缓存范围内的也加入过缓存，因此可以直接取出；而128超出了缓存范围，所以在valueOf方法中会创建一个新的对象返回。 行为型模板方法（Template Method）定义了一个算法的骨架，并允许子类为一个或多个步骤提供实现。模板方法使得子类可以在不改变算法结构的情况下，重新定义算法的某些步骤。 适用场景： 一次性实现一个算法的不变的部分，并将可变的行为留给子类来实现。 各子类中公共的行为被提取出来并集中到一个公共父类中，从而避免代码重复。 优缺点优点：提高复用性；提高扩展性；符合开闭原则。 缺点：类数目增加，增加了系统实现的复杂度；继承关系自身缺点，即如果父类添加新的抽象方法，所有子类都要改一遍。 应用场景制作一节网课的步骤可以简化为4个步骤：制作PPT；录制视频；编写笔记；提供课程资料。 所有课程都需要制作PPT、录制视频，但不是每个课程都需要编写笔记，而提供的课程资料在每个课程都不尽不同（有些课程需要提供源代码，有些需要提供图片文件等）。 我们可以在抽象父类中确定整个流程的模板，并实现固定不变的步骤，而把不固定的步骤留给子类实现。除此之外，对于类似编写笔记这个不一定有的步骤，我们可以通过一个钩子方法，让子类来决定流程中其执行与否。 抽象父类，由于制作PPT、录制视频对于每节课都是必须且相同的，因此声明为final使得子类无法对其修改，而编写笔记虽然可有可无，但是具体的操作对于所有课程也是相同的因此不需要修改，所以也声明为final，而提供课程资料(packageCourse方法)这一步骤则交由具体子类实现： 12345678910111213141516171819202122232425public abstract class ACourse &#123; protected final void makeCourse()&#123; this.makePPT(); this.makeVideo(); if(needWriteArticle())&#123; this.writeArticle(); &#125; this.packageCourse(); &#125; final void makePPT()&#123; System.out.println("制作PPT"); &#125; final void makeVideo()&#123; System.out.println("制作视频"); &#125; final void writeArticle()&#123; System.out.println("编写笔记"); &#125; //钩子方法 protected boolean needWriteArticle()&#123; return false; &#125; abstract void packageCourse();&#125; 前端课程： 1234567public class FECourse extends ACourse &#123; @Override void packageCourse() &#123; System.out.println("提供课程的前端代码"); System.out.println("提供课程的图片等多媒体素材"); &#125;&#125; 设计模式课程，覆盖了钩子方法，让其可以编写笔记： 1234567891011public class DesignPatternCourse extends ACourse &#123; @Override void packageCourse() &#123; System.out.println("提供课程Java源码"); &#125; @Override protected boolean needWriteArticle() &#123; return true; &#125;&#125; 客户端类： 12345678910111213public class Test &#123; public static void main(String[] args) &#123; System.out.println("后端设计模式课程start---"); ACourse designPatternCourse = new DesignPatternCourse(); designPatternCourse.makeCourse(); System.out.println("后端设计模式课程end---"); System.out.println("前端设计模式课程start---"); ACourse feCourse = new FECourse(); feCourse.makeCourse(); System.out.println("前端设计模式课程end---"); &#125;&#125; JDK中的应用我们查看java.util下的AbstractList抽象类： 1234567891011121314public abstract class AbstractList&lt;E&gt; extends AbstractCollection&lt;E&gt; implements List&lt;E&gt; &#123; //... public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; rangeCheckForAdd(index); boolean modified = false; for (E e : c) &#123; add(index++, e); modified = true; &#125; return modified; &#125; //... 这里面的addAll方法就相当于一个模板方法，它定义了这个算法的整体流程，而其具体的步骤如rangeCheckForAdd、add则交由子类如ArrayList等来完成。 Servlet中的应用Servlet是用Java编写的服务器端程序，主要功能在于交互式地浏览和修改数据，生成动态Web内容。狭义的Servlet是指Java语言实现的一个接口，广义的Servlet是指任何实现了这个Servlet接口的类，一般情况下，人们将Servlet理解为后者。 每一个Servlet都必须要实现Servlet接口，GenericServlet是个通用的、不特定于任何协议的Servlet，它实现了Servlet接口，而HttpServlet继承于GenericServlet，实现了Servlet接口，为Servlet接口提供了处理HTTP协议的实现，所以我们定义的Servlet只需要继承HttpServlet即可。 在HttpServlet的service方法中，首先获得到请求的方法名，然后根据方法名调用对应的doXXX方法，比如说请求方法为GET，那么就去调用doGet方法；请求方法为POST，那么就去调用doPost方法。 HttpServlet相当于定义了一套处理HTTP请求的模板。service方法为模板方法，定义了处理HTTP请求的基本流程，doXXX等方法为基本步骤，根据请求方法做相应的处理，编写自定义的Servlet时可以重写这些方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public abstract class HttpServlet extends GenericServlet &#123; //,,, protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; String method = req.getMethod(); if (method.equals(METHOD_GET)) &#123; long lastModified = getLastModified(req); if (lastModified == -1) &#123; // servlet doesn't support if-modified-since, no reason // to go through further expensive logic doGet(req, resp); &#125; else &#123; long ifModifiedSince; try &#123; ifModifiedSince = req.getDateHeader(HEADER_IFMODSINCE); &#125; catch (IllegalArgumentException iae) &#123; // Invalid date header - proceed as if none was set ifModifiedSince = -1; &#125; if (ifModifiedSince &lt; (lastModified / 1000 * 1000)) &#123; // If the servlet mod time is later, call doGet() // Round down to the nearest second for a proper compare // A ifModifiedSince of -1 will always be less maybeSetLastModified(resp, lastModified); doGet(req, resp); &#125; else &#123; resp.setStatus(HttpServletResponse.SC_NOT_MODIFIED); &#125; &#125; &#125; else if (method.equals(METHOD_HEAD)) &#123; long lastModified = getLastModified(req); maybeSetLastModified(resp, lastModified); doHead(req, resp); &#125; else if (method.equals(METHOD_POST)) &#123; doPost(req, resp); &#125; else if (method.equals(METHOD_PUT)) &#123; doPut(req, resp); &#125; else if (method.equals(METHOD_DELETE)) &#123; doDelete(req, resp); &#125; else if (method.equals(METHOD_OPTIONS)) &#123; doOptions(req,resp); &#125; else if (method.equals(METHOD_TRACE)) &#123; doTrace(req,resp); &#125; else &#123; // // Note that this means NO servlet supports whatever // method was requested, anywhere on this server. // String errMsg = lStrings.getString("http.method_not_implemented"); Object[] errArgs = new Object[1]; errArgs[0] = method; errMsg = MessageFormat.format(errMsg, errArgs); resp.sendError(HttpServletResponse.SC_NOT_IMPLEMENTED, errMsg); &#125; &#125; //...&#125; 策略模式（Strategy）定义了算法家族，分别封装起来，让它们之间可以互相替代，此模式让算法的辩护权啊不会影响到使用算法的用户。 适用场景： 系统有很多类，而他们的区别仅仅在于他们的行为不同。 一个系统需要动态地在几种算法中选择一种。 优缺点 优点：符合开闭原则；避免使用多重条件转移语句；提高算法的保密性和安全性。 缺点：客户端必须知道所有的策略类，并自行决定使用哪一个策略类。 应用场景在促销期间商家有不同的促销策略：返现、立减和满减。 策略抽象类： 123public interface PromotionStrategy &#123; void doPromotion();&#125; 返现策略： 12345public class FanXianPromotionStrategy implements PromotionStrategy &#123; public void doPromotion() &#123; System.out.println("返现促销，返回的金额存放到用户余额中"); &#125;&#125; 立减策略： 12345public class LiJianPromotionStrategy implements PromotionStrategy&#123; public void doPromotion() &#123; System.out.println("立减促销，课程的价格直接减去配置的价格"); &#125;&#125; 满减策略： 12345public class ManJianPromotionStratehy implements PromotionStrategy &#123; public void doPromotion() &#123; System.out.println("满减促销，满200-20元"); &#125;&#125; 促销活动，将促销策略作为成员变量： 1234567891011public class PromotionActivity &#123; private PromotionStrategy promotionStrategy; public PromotionActivity(PromotionStrategy promotionStrategy) &#123; this.promotionStrategy = promotionStrategy; &#125; public void executePromotionStrategy()&#123; promotionStrategy.doPromotion(); &#125;&#125; 客户端类： 12345678public class Test &#123; public static void main(String[] args) &#123; PromotionActivity promotionActivity618 = new PromotionActivity(new LiJianPromotionStrategy()); PromotionActivity promotionActivity1111 = new PromotionActivity(new FanXianPromotionStrategy()); promotionActivity618.executePromotionStrategy(); promotionActivity1111.executePromotionStrategy(); &#125;&#125; 每当要新增一个促销策略的时候，直接增加一个策略实现即可，十分方便。 命令模式（Command）命令模式允许请求的一方和接收的一方独立开来，使得请求的一方不必知道接收请求的一方的接口，更不必知道请求是怎么被接收，以及操作是否被执行、何时被执行、是怎么被执行的。 命令允许请求的一方和接收请求的一方能够独立演化，从而具有以下的优点： 命令模式使新的命令很容易地被加入到系统里。 能较容易地设计一个命令队列。 可以容易地实现对请求的撤销和恢复。 在需要的情况下，可以较容易地将命令记入日志。 命令模式涉及到五个角色，它们分别是： 客户端（Client）角色：创建一个具体命令（ConcreteCommand）对象并确定其接收者。 命令（Command）角色：声明了一个给所有具体命令类的抽象接口。 具体命令（ConcreteCommand）角色：实现execute()方法，负责调用接收者的相应操作。 调用者（Invoker）角色：负责调用命令对象执行请求。 接收者（Receiver）角色：负责具体实施和执行一个请求。 应用场景设计一个遥控器，可以控制电灯开关。 命令与具体命令：1234567891011121314151617181920212223242526272829public interface Command &#123; void execute();&#125;public class LightOnCommand implements Command &#123; Light light; public LightOnCommand(Light light) &#123; this.light = light; &#125; @Override public void execute() &#123; light.on(); &#125;&#125;public class LightOffCommand implements Command &#123; Light light; public LightOffCommand(Light light) &#123; this.light = light; &#125; @Override public void execute() &#123; light.off(); &#125;&#125; 接收者：123456789public class Light &#123; public void on() &#123; System.out.println("Light is on!"); &#125; public void off() &#123; System.out.println("Light is off!"); &#125;&#125; 调用者：1234567891011121314151617181920212223242526public class Invoker &#123; private Command[] onCommands; private Command[] offCommands; private final int slotNum = 7; public Invoker() &#123; this.onCommands = new Command[slotNum]; this.offCommands = new Command[slotNum]; &#125; public void setOnCommand(Command command, int slot) &#123; onCommands[slot] = command; &#125; public void setOffCommand(Command command, int slot) &#123; offCommands[slot] = command; &#125; public void onButtonWasPushed(int slot) &#123; onCommands[slot].execute(); &#125; public void offButtonWasPushed(int slot) &#123; offCommands[slot].execute(); &#125;&#125; 客户端：123456789101112public class Client &#123; public static void main(String[] args) &#123; Invoker invoker = new Invoker(); Light light = new Light(); Command lightOnCommand = new LightOnCommand(light); Command lightOffCommand = new LightOffCommand(light); invoker.setOnCommand(lightOnCommand, 0); invoker.setOffCommand(lightOffCommand, 0); invoker.onButtonWasPushed(0); invoker.offButtonWasPushed(0); &#125;&#125; 与策略模式的区别命令模式与策略模式的区别主要在于目的上。策略模式是通过不同的算法做同一件事情，而命令模式则是通过不同的命令做不同的事情。 Runnable中的应用命令模式最典型的一个应用就是Runnable。Thread是一个调用者，它提供了start()，join()，interrupt()等方法让我们来控制命令（也就是Runnable）的执行。并且，常常会将Runnable的实现类直接当作接收者。 观察者模式（Observer）定义了对象之间的一对多依赖，让多个观察者对象同时监听某一个主题对象，当主题对象发生变化时，它的所有依赖者（观察者）都会收到通知并更新。 优缺点 优点：观察者和被观察者之间建立一个抽象的耦合；支持广播通信。 缺点：观察者之间有过多的细节依赖、提高时间消耗及程序复杂度。 应用场景每个课程有一名老师，而课程的学生可能提出许多问题，因此创建三个类Course、Question、Teacher。其中课程应该作为被观察者，而老师由于要回答学生们的问题，因此作为观察者时刻观察着。 课程类Course：123456789101112131415161718192021public class Course extends Observable &#123; private String courseName; public Course(String courseName) &#123; this.courseName = courseName; &#125; public String getCourseName() &#123; return courseName; &#125; public void setCourseName(String courseName) &#123; this.courseName = courseName; &#125; public void produceQuestion(Course course, Question question)&#123; System.out.println(question.getUserName() + "在" + course.getCourseName() + "提交了一个问题"); setChanged(); notifyObservers(question); &#125;&#125; 问题类Question：1234567891011121314151617181920public class Question &#123; private String userName; private String questionContent; public String getUserName() &#123; return userName; &#125; public void setUserName(String userName) &#123; this.userName = userName; &#125; public String getQuestionContent() &#123; return questionContent; &#125; public void setQuestionContent(String questionContent) &#123; this.questionContent = questionContent; &#125;&#125; 教师类Teacher：12345678910111213public class Teacher implements Observer &#123; private String teacherName; public Teacher(String teacherName) &#123; this.teacherName = teacherName; &#125; public void update(Observable o, Object arg) &#123; Course course = (Course)o; Question question = (Question) arg; System.out.println(teacherName + "老师的" + course.getCourseName() + "课程接收到一个" + question.getUserName() + "提交的问答：" + question.getQuestionContent()); &#125;&#125; 可以看出，以上代码通过继承Observable类和实现Observer接口实现了观察者模式。 Observable中有两个方法对Observer特别重要，一个是setChanged()方法用来设置一个内部标志位表示数据发生了变化，一个是notifyObservers()方法会去调用一个列表中所有的Observer的update()方法，通知它们数据发生了变化。 客户端类Test： 123456789101112131415public class Test &#123; public static void main(String[] args) &#123; Course course = new Course("Java设计模式课程"); Teacher teacher1 = new Teacher("Alpha"); Teacher teacher2 = new Teacher("Belta"); course.addObserver(teacher1); course.addObserver(teacher2); Question question = new Question(); question.setUserName("cenjie"); question.setQuestionContent("Java的主函数如何编写"); course.produceQuestion(course, question); &#125;&#125; Observable通过addObserver()方法把任意多个Observer添加到这个列表中。 运行结果： 123cenjie在Java设计模式课程提交了一个问题Belta老师的Java设计模式课程课程接收到一个cenjie提交的问答：Java的主函数如何编写Alpha老师的Java设计模式课程课程接收到一个cenjie提交的问答：Java的主函数如何编写 可以看出，当被观察者course对象发生变化时，teacher1和teacher2这两个观察者都得到了通知。 责任链模式（Chain Of Responsibility）使多个对象都有机会处理请求，从而避免请求的发送者和接收者之间的耦合关系。将这些对象连成一条链，并沿着这条链发送该请求，直到有一个对象处理它为止。 应用场景抽象处理器，组合有一个同类型的成员变量： 12345678910public abstract class Handler &#123; protected Handler successor; public Handler(Handler successor) &#123; this.successor = successor; &#125; protected abstract void handleRequest(Request request);&#125; 具体处理器一：1234567891011121314151617public class ConcreteHandler1 extends Handler &#123; public ConcreteHandler1(Handler successor) &#123; super(successor); &#125; @Override protected void handleRequest(Request request) &#123; if (request.getType() == RequestType.TYPE1) &#123; System.out.println(request.getName() + " is handle by ConcreteHandler1"); return; &#125; if (successor != null) &#123; successor.handleRequest(request); &#125; &#125;&#125; 具体处理器二：1234567891011121314151617public class ConcreteHandler2 extends Handler &#123; public ConcreteHandler2(Handler successor) &#123; super(successor); &#125; @Override protected void handleRequest(Request request) &#123; if (request.getType() == RequestType.TYPE2) &#123; System.out.println(request.getName() + " is handle by ConcreteHandler2"); return; &#125; if (successor != null) &#123; successor.handleRequest(request); &#125; &#125;&#125; 要处理的请求： 12345678910111213141516171819202122public class Request &#123; private RequestType type; private String name; public Request(RequestType type, String name) &#123; this.type = type; this.name = name; &#125; public RequestType getType() &#123; return type; &#125; public String getName() &#123; return name; &#125;&#125;public enum RequestType &#123; TYPE1, TYPE2&#125; 客户端：1234567891011121314public class Client &#123; public static void main(String[] args) &#123; Handler handler1 = new ConcreteHandler1(null); Handler handler2 = new ConcreteHandler2(handler1); Request request1 = new Request(RequestType.TYPE1, "request1"); handler2.handleRequest(request1); Request request2 = new Request(RequestType.TYPE2, "request2"); handler2.handleRequest(request2); &#125;&#125; 可以看出，handler2中包含了一个handler1，当发送一个request给handler2时，handler2可以将request继续传递给handler1，由handler1完成处理并结束。 备忘录模式（Memento）保存一个对象的某个状态，以便在适当的时候恢复对象。 为用户提供一种可恢复机制，并对存档信息进行封装，但如果使用不当的话会造成资源的浪费。 应用场景可以通过备忘录模式对用户的文章进行修改保存与回滚。 文章类：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class Article &#123; private String title; private String content; private String imgs; public Article(String title, String content, String imgs) &#123; this.title = title; this.content = content; this.imgs = imgs; &#125; public String getTitle() &#123; return title; &#125; public void setTitle(String title) &#123; this.title = title; &#125; public String getContent() &#123; return content; &#125; public void setContent(String content) &#123; this.content = content; &#125; public String getImgs() &#123; return imgs; &#125; public void setImgs(String imgs) &#123; this.imgs = imgs; &#125; public ArticleMemento saveToMemento() &#123; ArticleMemento articleMemento = new ArticleMemento(this.title,this.content,this.imgs); return articleMemento; &#125; public void undoFromMemento(ArticleMemento articleMemento) &#123; this.title = articleMemento.getTitle(); this.content = articleMemento.getContent(); this.imgs = articleMemento.getImgs(); &#125; @Override public String toString() &#123; return "Article&#123;" + "title='" + title + '\'' + ", content='" + content + '\'' + ", imgs='" + imgs + '\'' + '&#125;'; &#125;&#125; 文章备忘录，属性与文章类一致，当没有setter方法，防止他人的修改：1234567891011121314151617181920212223242526272829303132public class ArticleMemento &#123; private String title; private String content; private String imgs; public ArticleMemento(String title, String content, String imgs) &#123; this.title = title; this.content = content; this.imgs = imgs; &#125; public String getTitle() &#123; return title; &#125; public String getContent() &#123; return content; &#125; public String getImgs() &#123; return imgs; &#125; @Override public String toString() &#123; return "ArticleMemento&#123;" + "title='" + title + '\'' + ", content='" + content + '\'' + ", imgs='" + imgs + '\'' + '&#125;'; &#125;&#125; 文章备忘录管理器，聚合了之前保存的管理器，可以随时调取上一个备忘录，也可以加入一个新的备忘录：1234567891011121314public class ArticleMementoManager &#123; private final Stack&lt;ArticleMemento&gt; ARTICLE_MEMENTO_STACK = new Stack&lt;ArticleMemento&gt;(); public ArticleMemento getMemento() &#123; ArticleMemento articleMemento= ARTICLE_MEMENTO_STACK.pop(); return articleMemento; &#125; public void addMemento(ArticleMemento articleMemento) &#123; ARTICLE_MEMENTO_STACK.push(articleMemento); &#125;&#125; 客户端：123456789101112131415161718192021222324252627282930313233343536373839404142434445public class Test &#123; public static void main(String[] args) &#123; ArticleMementoManager articleMementoManager = new ArticleMementoManager(); Article article= new Article("如影随行的设计模式A","手记内容A","手记图片A"); ArticleMemento articleMemento = article.saveToMemento(); articleMementoManager.addMemento(articleMemento); System.out.println("标题:"+article.getTitle()+" 内容:"+article.getContent()+" 图片:"+article.getImgs()+" 暂存成功"); System.out.println("手记完整信息:"+article); System.out.println("修改手记start"); article.setTitle("如影随行的设计模式B"); article.setContent("手记内容B"); article.setImgs("手记图片B"); System.out.println("修改手记end"); System.out.println("手记完整信息:"+article); articleMemento = article.saveToMemento(); articleMementoManager.addMemento(articleMemento); article.setTitle("如影随行的设计模式C"); article.setContent("手记内容C"); article.setImgs("手记图片C"); System.out.println("暂存回退start"); System.out.println("回退出栈1次"); articleMemento = articleMementoManager.getMemento(); article.undoFromMemento(articleMemento); System.out.println("回退出栈2次"); articleMemento = articleMementoManager.getMemento(); article.undoFromMemento(articleMemento); System.out.println("暂存回退end"); System.out.println("手记完整信息:"+article); &#125;&#125; 中介者模式（Mediator）用一个中介对象来封装一系列的对象交互，中介者使各对象不需要显示的相互引用，从而降低耦合。 应用场景用户（同事类）：12345678910111213141516171819public class User &#123; private String name; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public User(String name) &#123; this.name = name; &#125; public void sendMessage(String message) &#123; StudyGroup.showMessage(this, message); &#125;&#125; 学习小组：123456public class StudyGroup &#123; public static void showMessage(User user, String message)&#123; System.out.println(new Date().toString() + " [" + user.getName() + "] : " + message); &#125;&#125; 客户端：123456789public class Test &#123; public static void main(String[] args) &#123; User geely = new User("Geely"); User tom= new User("Tom"); geely.sendMessage(" Hey! Tom! Let's learn Design Pattern"); tom.sendMessage("OK! Geely"); &#125;&#125; 参考资料 弗里曼. Head First 设计模式 [M]. 中国电力出版社, 2007. 慕课网java设计模式精讲 Debug 方式+内存分析 SLF4J和Logback日志框架详解 设计模式—代理模式 设计模式读书笔记–桥接模式 JDBC源码分析&amp;桥接模式 模板方法模式及典型应用]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《剑指Offer》题解与笔记]]></title>
    <url>%2F2019%2F01%2F29%2F%E3%80%8A%E5%89%91%E6%8C%87Offer%E3%80%8B%E9%A2%98%E8%A7%A3%E4%B8%8E%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[3.1 找出数组中重复的数字题目描述在一个长度为n的数组里的所有数字都在0到n-1的范围内。 数组中某些数字是重复的，但不知道有几个数字是重复的。也不知道每个数字重复几次。请找出数组中任意一个重复的数字。 例如，如果输入长度为7的数组{2,3,1,0,2,5,3}，那么对应的输出是第一个重复的数字2。 题解对数组进行移位，判断i下标的数字等于i，如果不等则对其进行交换，eg: {1，3，4，6，5，2，5} –&gt; {3，1，4，6，5，2，5} //下标为0的数字为1，因此将下标为1的数字即3与1换位，使得1到了其应在的地方 {3，1，4，6，5，2，5} –&gt; {6，1，4，3，5，2，5} //此时下标为0的数字为3，依然不等于其下标，因此找到下标为3的数字6与其交换，使3到了其应在的地方 {6，1，4，3，5，2，5} –&gt; {5，1，4，3，5，2，6} //同理 {5，1，4，3，5，2，6} –&gt; {2，1，4，3，5，5，6} {2，1，4，3，5，5，6} –&gt; {4，1，2，3，5，5，6} {4，1，2，3，5，5，6} –&gt; {5，1，2，3，4，5，6} {5，1，2，3，4，5，6} //此时，要交换的两个数字相等，则证明该数字重复 可以看出，其时间复杂度为O(n)，且不需要额外分配空间，空间复杂度为O(1) 12345678910111213141516171819202122232425262728293031public class Solution &#123; // Parameters: // numbers: an array of integers // length: the length of array numbers // duplication: (Output) the duplicated number in the array number,length of duplication array is 1,so using duplication[0] = ? in implementation; // Here duplication like pointor in C/C++, duplication[0] equal *duplication in C/C++ // 这里要特别注意~返回任意重复的一个，赋值duplication[0] // Return value: true if the input is valid, and there are some duplications in the array number // otherwise false public boolean duplicate(int numbers[],int length,int [] duplication) &#123; if(numbers == null)&#123; return false; &#125; for(int i = 0; i &lt; length; i++)&#123; while(numbers[i] != i)&#123; if(numbers[i] == numbers[numbers[i]])&#123; duplication[0] = numbers[i]; return true; &#125; swap(numbers, numbers[i], i); &#125; &#125; return false; &#125; private void swap(int[] numbers, int a, int b)&#123; int temp = numbers[a]; numbers[a] = numbers[b]; numbers[b] = temp; &#125;&#125; 3.2 不修改数组找出重复的数字题目描述在一个长度为n+1的数组里的所有数字都在1~n的范围内，所以数组中至少有一个数字是重复的。请找出数组中任意一个重复的数字，但不能修改输入的数组。例如，如果输入长度为7的数组{2,3,1,0,2,5,3}，那么对应的输出是第一个重复的数字2。 题解此道题与上题类似，但有不同的几点： 1、题目要求不能修改输入的数组，因此可能要考虑创建辅助数组，这里的一个思路是将原数组的数字m移动到辅助数组中下标为m的位置，因此当移动时检测到辅助数组该下标已经有数字时，表示此数字重复了。这里的的空间复杂度为O(n)，时间复杂度为O(n)。 2、题目中提到“在一个长度为n+1的数组里的所有数字都在1-n的范围内”，例如，若有个包含5个数的数组，但里面的数字只有1、2、3、4，那么必然有一个是重复的。这时候另一个思路则是在1、2、3、4、5中找出中间数3，以此将数组分割成两块，左半块是1-3（注意不是1-2），右半块是4-5，之后遍历整个数组，若数字在左半边的范围内，则将计数器加一。结束遍历时，若计数器的值大于这边块包含的个数，就说明重复的数字在这边块里，否则其就在右半块。紧接着把范围缩小到其中一边，继续重复以上操作。此操作类似二分查找法，需要的时间为O(nlogn)，空间复杂度为o(1)，相当于以时间换空间。下面给出的代码将根据此种思路。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class Solution &#123; // Parameters: // numbers: an array of integers // length: the length of array numbers // duplication: (Output) the duplicated number in the array number,length of duplication array is 1,so using duplication[0] = ? in implementation; // Here duplication like pointor in C/C++, duplication[0] equal *duplication in C/C++ // 这里要特别注意~返回任意重复的一个，赋值duplication[0] // Return value: true if the input is valid, and there are some duplications in the array number // otherwise false public boolean duplicate(int numbers[],int length,int [] duplication) &#123; if(numbers == null)&#123; return false; &#125; int start = 1; int end = length - 1; while(end &gt;= start)&#123; int middle = (end - start) / 2 + start; int count = countRange(numbers, length, start, middle); if(end == start)&#123; if(count &gt; 1)&#123; duplication[0] = start; return true; &#125; break; &#125; if(count &gt; middle - start + 1) end = middle; else start = middle + 1; &#125; return false; &#125; public int countRange(int numbers[],int length, int start, int end)&#123; if(numbers == null)&#123; return 0; &#125; int count = 0; for(int i = 0; i &lt; length; i++)&#123; if(numbers[i] &gt;= start &amp;&amp; numbers[i] &lt;= end)&#123; count++; &#125; &#125; return count; &#125;&#125; 4.二维数组中的查找题目描述在一个二维数组中（每个一维数组的长度相同），每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。 题解12345678910111213141516public class Solution &#123; public boolean Find(int target, int [][] array) &#123; int len = array.length - 1; int i = 0; while(i &lt; array[0].length &amp;&amp; len &gt;= 0)&#123; if(array[len][i] &gt; target)&#123; len--; &#125; else if(array[len][i] &lt; target)&#123; i++; &#125; else&#123; return true; &#125; &#125; return false; &#125;&#125; 5.替换空格题目描述请实现一个函数，将一个字符串中的每个空格替换成“%20”。例如，当字符串为We Are Happy.则经过替换之后的字符串为We%20Are%20Happy。 题解先遍历一次字符串，得到空格的总数，然后将字符串的长度设置为字符串的原长度加上空格数的两倍。将原始字符串末尾的值不断复制给新新字符串的末尾，每次遇到空格的时候在新字符串前插入%20。此算法中所有字符都只复制了一次，因此时间复杂度为O(n)。 在合并两个数组时，如果从前往后复制每个数字（或字符）则需要重复移动数字（或字符）多次，那么我们可以考虑从后往前复制，这样就能减少移动的次数，从而提高效率。 12345678910111213141516171819202122232425262728public class Solution &#123; public String replaceSpace(StringBuffer str) &#123; if(str == null)&#123; return null; &#125; int spaceNum = 0; for(int i = 0; i &lt; str.length(); i++)&#123; if(str.charAt(i) == ' ')&#123; spaceNum++; &#125; &#125; int oldIndex = str.length() - 1; int newLength = str.length() + spaceNum * 2; str.setLength(newLength); int newIndex = newLength - 1; for(; oldIndex &gt;= 0 &amp;&amp; oldIndex &lt;= newIndex; oldIndex--)&#123; if(str.charAt(oldIndex) == ' ') &#123; str.setCharAt(newIndex--, '0'); str.setCharAt(newIndex--, '2'); str.setCharAt(newIndex--, '%'); &#125;else&#123; str.setCharAt(newIndex--, str.charAt(oldIndex)); &#125; &#125; return str.toString(); &#125;&#125; 6.从尾到头打印链表题目描述输入一个链表，按链表值从尾到头的顺序返回一个ArrayList。 1234567891011/*** public class ListNode &#123;* int val;* ListNode next = null;** ListNode(int val) &#123;* this.val = val;* &#125;* &#125;**/ 题解使用递归每访问到一个节点的时候，先递归输出它后面的节点，再输出该节点自身。 12345678910public class Solution &#123; public ArrayList&lt;Integer&gt; printListFromTailToHead(ListNode listNode) &#123; ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;&gt;(); if(listNode != null)&#123; arrayList.addAll(printListFromTailToHead(listNode.nextNode)); arrayList.add(listNode.val); &#125; return arrayList; &#125;&#125; 使用栈利用栈“先进后出”的特性，实现最先入栈的节点值最后输出。 123456789101112public ArrayList&lt;Integer&gt; printListFromTailToHead(ListNode listNode) &#123; Stack stack = new Stack(); while(listNode != null)&#123; stack.push(listNode.val); listNode = listNode.nextNode; &#125; ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;&gt;(); while(!stack.isEmpty())&#123; arrayList.add((Integer) stack.pop()); &#125; return arrayList;&#125; 7.重建二叉树题目描述输入某二叉树的前序遍历和中序遍历的结果，请重建出该二叉树。假设输入的前序遍历和中序遍历的结果中都不含重复的数字。例如输入前序遍历序列{1,2,4,7,3,5,6,8}和中序遍历序列{4,7,2,1,5,3,8,6}，则重建二叉树并返回。 123456789/** * Definition for binary tree * public class TreeNode &#123; * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) &#123; val = x; &#125; * &#125; */ 题解对于前序遍历，第一个数字即为根节点的值；对于中序遍历，根据根节点值将序列划分为左右子树。接下来使用递归分别继续进行如上操作，便可不断构建出左右子树。 12345678910111213141516171819202122232425public class Solution &#123; public TreeNode reConstructBinaryTree(int [] pre,int [] in) &#123; if(pre == null || in == null)&#123; return null; &#125; return reConstructBinaryTree(pre, 0, pre.length-1, in, 0, in.length-1); &#125; private TreeNode reConstructBinaryTree(int[] pre, int startPre, int endPre, int[] in, int startIn, int endIn)&#123; if(startPre &gt; endPre || startIn &gt; endIn) return null; TreeNode root = new TreeNode(pre[startPre]); for(int i = startIn; i &lt;= endIn; i++)&#123; if(in[i] == pre[startPre])&#123; root.left = reConstructBinaryTree(pre, startPre+1, i-startIn+startPre, in, startIn, i-1); root.right = reConstructBinaryTree(pre, startPre+i-startIn+1, endPre, in, i+1, endIn); break; &#125; &#125; return root; &#125;&#125; 8.二叉树的下一个节点题目描述给定一个二叉树和其中的一个结点，请找出中序遍历顺序的下一个结点并且返回。注意，树中的结点不仅包含左右子结点，同时包含指向父结点的指针。 123456789101112/*public class TreeLinkNode &#123; int val; TreeLinkNode left = null; TreeLinkNode right = null; TreeLinkNode next = null; TreeLinkNode(int val) &#123; this.val = val; &#125;&#125;*/ 题解此题可分为两种情况：一种是一个节点有右子树，那么它的下一个节点就是它的右子树中的最左子节点；另一种是没有右子树，那么就判断它是否为父节点的左节点，如果是，则父结点为其下一个节点，如果不是，则向上遍历其父结点，找到为其祖先节点左节点的父结点，这个祖先节点就是它的下一个节点。 1234567891011121314151617181920public class Solution &#123; public TreeLinkNode GetNext(TreeLinkNode pNode) &#123; //1、一个节点有右子树，那么找到右子树的最左子节点 if (pNode.right != null) &#123; TreeLinkNode node = pNode.right; while (node.left != null) &#123; node = node.left; &#125; return node; &#125; //2、一个节点没有右子树 while (pNode.next != null) &#123; if(pNode.next.left == pNode) return pNode.next; pNode = pNode.next; &#125; return null; &#125;&#125; 9.用两个栈实现队列题目描述用两个栈来实现一个队列，完成队列的Push和Pop操作。 队列中的元素为int类型。 题解此题思路较为简单，主要就是利用栈“先入后出”和队列“先入先出”的特性，每次push的时候将值存到栈1中，pop的时候先将栈1的值放入栈2从而实现逆序，然后再对栈2进行pop操作，就实现了队列的“先进先出”。 1234567891011121314151617public class Solution &#123; Stack&lt;Integer&gt; stack1 = new Stack&lt;Integer&gt;(); Stack&lt;Integer&gt; stack2 = new Stack&lt;Integer&gt;(); public void push(int node) &#123; stack1.push(node); &#125; public int pop() &#123; if (stack2.size() &lt;= 0) &#123; while (stack1.size() &gt; 0) &#123; stack2.push(stack1.pop()); &#125; &#125; return stack2.pop(); &#125;&#125; 10.1 斐波那契数列题目描述大家都知道斐波那契数列，现在要求输入一个整数n，请你输出斐波那契数列的第n项（从0开始，第0项为0）。 题解传统的做法是使用递归：return Fibonacci(n-1)+Fibonacci(n-2)。但是这种做法画出树形图就能看出有许多重复的节点，而且容易导致内存溢出，因而不建议使用。 使用循环使用循环是一个较好的做法，不仅提高了时间效率，也解决了内存溢出的问题。实际上，任何递归都可以用循环来实现。 1234567891011121314151617public class Solution &#123; public int Fibonacci(int n) &#123; if(n == 0) return 0; if(n == 1) return 1; int num = 0; int num1 = 0; int num2 = 1; for(int i = 2; i &lt;= n; i++)&#123; num = num1 + num2; num1 = num2; num2 = num; &#125; return num; &#125;&#125; 使用尾递归尾递归是递归的一种特殊形式，本质上和递归没有什么区别，但优化后可以重复利用同一个栈帧，大幅提高效率，具体介绍在我的博客中有介绍：。由于java没有对尾递归进行优化，所以在此题中用java解题时依旧无法解决内存溢出的问题，主要提供一种答题思路。 1234567891011121314public class Solution &#123; public int Fibonacci(int n) &#123; return Fibonacci(n, 0, 1); &#125; private static int Fibonacci(int n, int num1, int num2)&#123; if(n == 0) return 0; if(n == 1) return num2; else return Fibonacci(n - 1, num2, num1 + num2); &#125;&#125; 10.2 跳台阶题目描述一只青蛙一次可以跳上1级台阶，也可以跳上2级。求该青蛙跳上一个n级的台阶总共有多少种跳法（先后次序不同算不同的结果）。 题解如果只有1级台阶，则只有一种跳法；如果有2级台阶，则可以一次跳两阶，或者一次跳一阶；如果有n级台阶，第一次跳就有两种不同的选择：当第一次只跳一阶时，总的跳法数等于后面n-1级台阶的跳法数，而如果第一次跳两阶的话，总的跳法数就等于后面n-2级台阶的跳法数。根据此规律可以得到以下公式：1234f(n) = 0, 当n=0时f(n) = 1, 当n=1时f(n) = 2, 当n=2时f(n) = f(n-1) + f(n-2), 当n&gt;2时 12345678910111213141516171819public class Solution &#123; public int JumpFloor(int n) &#123; if(n &lt;= 0) return 0; if(n == 1) return 1; if(n == 2) return 2; int num = 0; int num1 = 1; int num2 = 2; for(int i = 3; i &lt;= n; i++)&#123; num = num1 + num2; num1 = num2; num2 = num; &#125; return num; &#125;&#125; 10.3 变态跳台阶题目描述一只青蛙一次可以跳上1级台阶，也可以跳上2级……它也可以跳上n级。求该青蛙跳上一个n级的台阶总共有多少种跳法。 题解思路一此题和上题类似，但是一次可以跳多级台阶，依旧可以根据“第一次跳多少台阶，则跳法数等于剩下多少台阶的跳法数目”的思路进行分析，因此我们可以如下分析： 12345678910111213如果有1级台阶，则有f(1) = 1 种跳法如果有2级台阶，则有f(2) = f(2-1) + f(2-2) = 2 种跳法如果有3级台阶，则有f(3) = f(3-1) + f(3-2) + f(3-3) = 4 种跳法···如果有n级台阶，则有f(n) = f(n-1) + f(n-2) + f(n-3) + ··· + f(0) 种跳法 又 f(n-1) = f(n-2) + f(n-3) + f(n-4) + ··· + f(0) 进行相减可得，f(n) - f(n-1) = f(n-1) 即，f(n) = 2f(n-1) 由此得出，f(n) = 1, 当n=0时f(n) = 1, 当n=1时f(n) = f(n-1) + f(n-2), 当n&gt;=2时 此题一个比较难理解的部分是，在公式中当n=0时，f(n)应当等于1而不是0。因为如果第一次就跳完了所有台阶，这也算一种跳法，此时f(n-n)=f(0)应当等于1而非0。 1234567891011121314151617public class Solution &#123; public int JumpFloorII(int n) &#123; if(n &lt;= 0) return 0; if(n == 1) return 1; int num = 0; int num1 = 1; //初始值应为1而非0 int num2 = 1; for(int i = 2; i &lt;= n; i++)&#123; num = num1 + num2; num2 = num1; num1 = num; &#125; return num; &#125;&#125; 思路二在跳台阶的整个过程中，除了最后一阶是必须要跳的，其它每个台阶都有跳或者不跳两种可能性，因此f(n) = 2^(n-1)。 12345678public class Solution &#123; public int JumpFloorII(int n) &#123; if(n &lt;= 0) return 0; else return (int)Math.pow(2, n-1); &#125;&#125; 10.4 矩形覆盖题目描述我们可以用2 1的小矩形横着或者竖着去覆盖更大的矩形。请问用n个2 1的小矩形无重叠地覆盖一个2 * n的大矩形，总共有多少种方法？ 题解123f(n) = 1, 当n=0时f(n) = 1, 当n=1时f(n) = f(n-1) + f(n-2), 当n&gt;=2时 1234567891011121314151617public class Solution &#123; public int RectCover(int n) &#123; if(n &lt;= 0) return 0; if(n == 1) return 1; int num = 0; int num1 = 1; int num2 = 1; for(int i = 2; i &lt;= n; i++)&#123; num = num1 + num2; num2 = num1; num1 = num; &#125; return num; &#125;&#125; 14 剪绳子题目描述一根长度为n的绳子，将绳子剪为m段（剪m-1次），每段绳子的长度为k[0] - k[m]；要求k[0] k[1] k[2] ··· k[m]的乘积为最大。n &gt;1 且 m&gt; 1。 题解这道题可以采用动态规划来做。在剪第一刀的时候，我们有n-1种可能的选择，因此f(n)=max(f(i) * f(n-i))。由于递归会产生很多重复的子问题，因此采用由下而上的循环方式，将每个子问题的最优解放到数组dp里。最终的答案就是dp[n]。 在刚开始看书的时候并不理解为什么要对dp[1], dp[2], [dp3]逐一初始化，后来经过反复调试并思考，发现当n&gt;3时dp[3]也就是当绳子长度为3时，不应该对其进行切割，因为切割后理论应得问题最优解就是2，而它的父问题要想得到最优解，应该直接使用整段未切割绳子也就是3。而当n&lt;=3时，将在方法最开始就进行了一个正确的返回，即当绳子长度为3时，对其进行切割得到最优解为2。 1234567891011121314151617181920212223242526public class Solution &#123; public int integerBreak(int n) &#123; if(n &lt; 2) return 0; if(n == 2) return 1; if(n == 3) return 2; int []dp = new int[n +1]; dp[1] = 1; dp[2] = 2; dp[3] = 3; for(int i = 4; i &lt;= n; i++)&#123; //把长度为i的绳子切成若干段 int max = 0; for(int j = 1; j &lt;= i/2; j++)&#123; int p = dp[j] * dp[i-j]; if(max &lt; p) max = p; &#125; dp[i] = max; &#125; return dp[n]; &#125;&#125; 15 二进制中1的个数题目描述输入一个整数，输出该数二进制表示中1的个数。 题解常规解法将输入的数字n与1做与运算，如果得出的结果是1，说明n的最低位是1，从而将计数器加一，并将1左移，进行n的次低位的判断，如此反复。这种做法整数为多少位就要循环多少次。 1234567891011121314public class Solution &#123; public int NumberOf1(int n)&#123; int count = 0; int flag = 1; while(flag != 0)&#123; if((n &amp; flag) != 0)&#123; count++; &#125; flag = flag &lt;&lt; 1; &#125; return count; &#125;&#125; 优化解法对输入的数字n减1再与自身进行与运算，即(n-1)&amp;n可以将n最低位的1变成0：123n: 11101100n-1: 11101011n&amp;(n-1): 11101000 基于以上，n中有多少个1，就可以进行多少次这样的操作。 12345678910public class Solution &#123; public int NumberOf1(int n)&#123; int count = 0; while(n != 0)&#123; count++; n = (n - 1) &amp; n; &#125; return count; &#125;&#125; 16 数值的整数次方题目描述给定一个double类型的浮点数base和int类型的整数exponent。求base的exponent次方。 题解此题的关键在于对base、exponent为正数、负数和零的考虑。 循环123456789101112131415public class Solution &#123; public double Power(double base, int exponent) &#123; boolean isNegative = false; if(exponent &lt; 0)&#123; isNegative = true; exponent = -exponent; &#125; double result = 1; for(int i = 1; i &lt;= exponent; i++)&#123; result = base * result; &#125; return isNegative ? 1 / result : result; &#125;&#125; 递归a的n次方可以通过如下公式求解： 12a^n = a^(n/2) * a^(n/2), n为偶数a^n = a^((n-1)/2) * a^((n-1)/2) * a, n为奇数 每次计算n都会变为原来的1/2，因此通过递归算法可以使时间复杂度降到logn，效率得到提升。除此之外，可以用右移运算和位与运算代替除2和求余运算两个操作，从而得到进一步优化。 12345678910111213141516171819202122public class Solution &#123; public double Power(double base, int exponent) &#123; if(exponent == 0) return 1; if(exponent == 1) return base; boolean isNegative = false; if(exponent &lt; 0)&#123; isNegative = true; exponent = -exponent; &#125; double result = Power(base, exponent &gt;&gt; 1); result *= result; if((exponent &amp; 0x1) == 1)&#123; result *= base; &#125; if(exponent &lt; 0)&#123; result = 1 / result; &#125; return isNegative ? 1 / result : result; &#125;&#125; 17 打印从1到最大的n位数题目描述输入数字n，按顺序打印出从1到最大的n位十进制数。比如输入3，则打印出1、2、3一直到最大的3位数999。 题解这道题可以使用递归对n位数进行全排列，在每一次递归调用之前都设置好下一位，当index为最后一位时，结束递归并打印。 123456789101112131415161718192021222324public class Solution &#123; public void PrintToMaxOfNDigits(int n)&#123; if(n &lt;= 0) return; char[] nums = new char[n]; for(int i = 0; i &lt; 10; i++)&#123; nums[0] = (char) ('0' + i); PrintToMaxOfNDigits(nums, 0); &#125; &#125; public void PrintToMaxOfNDigits(char[] nums, int index)&#123; if(index == nums.length - 1)&#123; System.out.println(nums); return; &#125; for(int i = 0; i &lt; 10; i++)&#123; nums[index+1] = (char) ('0' + i); PrintToMaxOfNDigits(nums, index+1); &#125; &#125;&#125; 18.1 在O(1)时间内删除链表节点题目描述给定单向链表的头指针和一个节点指针，定义一个函数在O(1)时间内删除该节点。 12345678910/*public class ListNode &#123; int val; ListNode next = null; ListNode(int val) &#123; this.val = val; &#125;&#125;*/ 题解对于一个链表：1-&gt;2-&gt;3-&gt;4-&gt;5，如果要删除节点4， 首先想到的思路是找到节点4前面的节点（此处也就是节点3），将3的下一个节点重新设置为要删除的节点的下一个节点（此处也就是5），此时链表就变为了1-&gt;2-&gt;3-&gt;5。但由于链表是单向链表，不能从要删除的节点直接得到上一个节点，因此只能从头开始顺序查找，时间复杂度就为O(n)了。 另一种思路则是将要删除的节点的下一个节点的值赋值给要删除的节点，再将要删除的节点的下一个节点重新设置为下下个节点：1-&gt;2-&gt;3-&gt;5-&gt;51-&gt;2-&gt;3-&gt;5此时，时间复杂度就为O(1)了。 但如果要删除的节点为尾节点，则没有下一个节点，此种情况依然要使用顺序查找的方式删除节点。 123456789101112131415161718192021222324252627public class Solution &#123; public ListNode deleteNode(ListNode head, ListNode tobeDelete) &#123; if(head == null || tobeDelete == null) &#123; return null; &#125; //要删除的节点不是尾节点 if(tobeDelete.next != null) &#123; tobeDelete.val = tobeDelete.next.val; tobeDelete.next = tobeDelete.next.next; &#125; else &#123; //要删除的节点是尾节点 ListNode node = head; if(node == tobeDelete) &#123; //如果链表中只有要删除的这一个节点 return null; &#125; while(node.next != tobeDelete) &#123; node = node.next; &#125; node.next = null; &#125; return head; &#125;&#125; 18.2 删除链表中重复的结点题目描述在一个排序的链表中，存在重复的结点，请删除该链表中重复的结点，重复的结点不保留，返回链表头指针。 例如，链表1-&gt;2-&gt;3-&gt;3-&gt;4-&gt;4-&gt;5 处理后为 1-&gt;2-&gt;5 12345678910/*public class ListNode &#123; int val; ListNode next = null; ListNode(int val) &#123; this.val = val; &#125;&#125;*/ 题解如果当前节点的值与下一个节点的值相同，那么它们就是重复的节点，都可以被删除。为了保证删除之后的链表仍然是相连的，我们要把当前节点的前一个节点和后面值比当前节点的值大的节点相连。 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class Solution &#123; public ListNode deleteDuplication(ListNode pHead) &#123; if(pHead == null) &#123; return null; &#125; //如果链表中只存在一个节点，则不存在重复的节点 if(pHead.next == null) &#123; return pHead; &#125; ListNode preNode = null; ListNode node = pHead; while(node != null) &#123; ListNode nextNode = node.next; if(nextNode != null &amp;&amp; !(nextNode.val == node.val)) &#123; //当前节点与下一个节点不同 preNode = node; node = nextNode; &#125; else &#123; if(node.next == null) &#123; break; &#125; //当前节点与下一个相同 int value = node.val; ListNode toBeDel = node; while(toBeDel != null &amp;&amp; toBeDel.val == value) &#123; nextNode = toBeDel.next; toBeDel = nextNode; &#125; if(preNode == null) &#123; pHead = nextNode; &#125; else &#123; preNode.next = nextNode; &#125; node = nextNode; &#125; &#125; return pHead; &#125;&#125; 19 正则表达式匹配题目描述请实现一个函数用来匹配包括’.’和’‘的正则表达式。模式中的字符’.’表示任意一个字符，而’‘表示它前面的字符可以出现任意次（包含0次）。在本题中，匹配是指字符串的所有字符匹配整个模式。例如，字符串”aaa”与模式”a.a”和”abaca”匹配，但是与”aa.a”和”ab*a”均不匹配. 题解123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class Solution &#123; public boolean match(char[] str, char[] pattern) &#123; if(str == null || pattern == null) &#123; return false; &#125; int strIndex = 0; int patternIndex = 0; return matchCore(str, pattern, strIndex, patternIndex); &#125; public boolean matchCore(char[] str, char[] pattern, int strIndex, int patternIndex) &#123; //字符串与模式完全匹配 if(strIndex == str.length &amp;&amp; patternIndex == pattern.length) &#123; return true; &#125; //字符串未到达末尾，而模式已到达末尾，则匹配失败 if(strIndex != str.length &amp;&amp; patternIndex == pattern.length) &#123; return false; &#125; if(patternIndex + 1 &lt; pattern.length &amp;&amp; pattern[patternIndex + 1] == '*') &#123; //模式的第二个字符为* if(strIndex &lt; str.length &amp;&amp; str[strIndex] == pattern[patternIndex] || strIndex &lt; str.length &amp;&amp; pattern[patternIndex] == '.') &#123; //*前的字符与字符串中的字符相等时 //可能的情况：匹配0位，模式向后移动两位跳过*；匹配一位，模式向后移动两位跳过*；匹配一位，模式不移动，下次继续匹配。 return matchCore(str, pattern, strIndex, patternIndex+2) || matchCore(str, pattern, strIndex+1, patternIndex+2) || matchCore(str, pattern, strIndex+1, patternIndex); &#125; else &#123; //*前的字符与字符串中的字符不相等时，匹配0位，跳过* return matchCore(str, pattern, strIndex, patternIndex+2); &#125; &#125; if(pattern[patternIndex] == '.' &amp;&amp; strIndex &lt; str.length || strIndex &lt; str.length &amp;&amp; pattern[patternIndex] == str[strIndex]) &#123; //模式的第二个字符不为* if(str[strIndex] == pattern[patternIndex] || pattern[patternIndex] == '.') &#123; //如果字符相匹配,则接续操作 return matchCore(str, pattern, strIndex+1, patternIndex+1); &#125; else &#123; //字符不匹配，直接返回false return false; &#125; &#125; return false; &#125;&#125; 20 表示数值的字符串题目描述请实现一个函数用来判断字符串是否表示数值（包括整数和小数）。例如，字符串”+100”,”5e2”,”-123”,”3.1416”和”-1E-16”都表示数值。 但是”12e”,”1a3.14”,”1.2.3”,”+-5”和”12e+4.3”都不是。 题解表示数值的字符串遵循模式：A[.[b]][e|EC]或者.B[e|EC]。A和C都可以带有符号’+’或’-‘，B则不行，且A、B、C都必须为整数。因此，可以根据模式的顺序去依次匹配A、B、C。如果字符串中包含’.’，则’.’左右至少要有一方有数字，而如果字符串中包含’e’或’E’，则’e’或’E’两方都必须要有数字，且右方必须为整数。 12345678910111213141516171819202122232425262728293031323334353637public class Solution &#123; private int index = 0; public boolean isNumeric(char[] str) &#123; boolean flag; if(str == null) return false; flag = scanInteger(str); if(index &lt; str.length &amp;&amp; str[index] == '.') &#123; index++; flag = scanUnsignedInteger(str) || flag; &#125; if(index &lt; str.length &amp;&amp; (str[index] == 'e' || str[index] == 'E')) &#123; index++; flag = scanInteger(str) &amp;&amp; flag; &#125; return flag &amp;&amp; (index == str.length); &#125; boolean scanUnsignedInteger(char[] str) &#123; int before = index; while(index &lt; str.length &amp;&amp; str[index] &gt;= '0' &amp;&amp; str[index] &lt;= '9') &#123; index++; &#125; return index &gt; before; &#125; boolean scanInteger(char[] str) &#123; if(index &lt; str.length &amp;&amp; (str[index] == '+' || str[index] == '-')) index++; return scanUnsignedInteger(str); &#125;&#125; 21 调整数组顺序使奇数位于偶数前面题目描述输入一个整数数组，实现一个函数来调整该数组中数字的顺序，使得所有的奇数位于数组的前半部分，所有的偶数位于数组的后半部分（拓展：并保证奇数和奇数，偶数和偶数之间的相对位置不变）。 题解基本解法一前一后扫描数组，若发现有偶数在前，奇数在后，则交换它们两的位置。此算法的时间复杂度为O(n)，但是算法是不稳定的，也就是没法保证奇数和奇数，偶数和偶数之间的相对位置不变。 123456789101112131415161718192021public class Solution &#123; public void reOrderArray(int [] array) &#123; int head = 0; int tail = array.length - 1; while(head &lt; tail) &#123; while(head &lt; array.length &amp;&amp; array[head] % 2 != 0) &#123; //正向遍历不为偶数的时候 head++; &#125; while(tail &gt;= 0 &amp;&amp; array[tail] % 2 == 0) &#123; //反向遍历不为奇数的时候 tail--; &#125; if(head &lt; tail) &#123; int temp = array[head]; array[head] = array[tail]; array[tail] = temp; &#125; &#125; &#125;&#125; 拓展解法要保证奇数和奇数，偶数和偶数之间的相对位置不变，则需要使用一个辅助数组，首先计算出奇数的个数，以此作为将偶数插入辅助数组的起始坐标。然后遍历原数组，将奇数放置于辅助数组的奇数起始坐标（也就是0），将偶数放置于辅助数组的偶数起始坐标，最后再将调整完毕的辅助数组中的元素依次放回原数组。此算法的时间复杂度为O(n)，空间复杂度为O(n)，相当于以空间换时间。另一种思路是可以使用插入排序的思想，在此不再阐述。 1234567891011121314151617181920212223242526272829public class Solution &#123; public void reOrderArray(int [] array) &#123; int[] copy = new int[array.length]; int index = 0; int count = 0; for(int i = 0; i &lt; array.length; i++) &#123; //统计奇数个数 if(array[i] % 2 != 0) count++; &#125; int odd = 0; int even = count; while(index &lt; array.length) &#123; if(array[index] % 2 != 0) &#123; //如果是奇数 copy[odd] = array[index]; odd++; &#125; else &#123; //如果是偶数 copy[even] = array[index]; even++; &#125; index++; &#125; for(int i = 0; i &lt; array.length; i++) &#123; array[i] = copy[i]; &#125; &#125;&#125; 22 链表中倒数第K个节点题目描述输入一个链表，输出该链表中倒数第k个结点。 123456789/*public class ListNode &#123; int val; ListNode next = null; ListNode(int val) &#123; this.val = val; &#125;&#125;*/ 题解传统的思路是先遍历一遍链表，计算出节点数n，则倒数第k个节点就是从头开始的第n-k+1个节点。但此种做法要遍历链表两边，效率不高。 另一种思路是定义两个指针，让两个指针之间的距离保持在k-1，则当第一个指针到达链表的尾节点时，第二个指针则指向倒数第k个节点。这种实现只需要遍历链表一次即可。 1234567891011121314151617181920public class Solution &#123; public ListNode FindKthToTail(ListNode head,int k) &#123; if(head == null || k &lt;= 0) return null; ListNode node1 = head; ListNode node2 = head; for(int i = 0; i &lt; k-1; i++) &#123; if(node1.next == null) return null; node1 = node1.next; &#125; while(node1.next != null) &#123; node1 = node1.next; node2 = node2.next; &#125; return node2; &#125;&#125; 23 链表中环的入口节点题目描述给一个链表，若其中包含环，请找出该链表的环的入口结点，否则，输出null。 123456789/*public class ListNode &#123; int val; ListNode next = null; ListNode(int val) &#123; this.val = val; &#125;&#125;*/ 题解要找到链表中环的入口节点，整体思路与上一题类似。例如，如果环中有4个节点，则第二个指针要比第一个指针先走四步，然后同时向前走，当两个指针相遇时，所指向的节点就是入口节点。 根据此思路，要解决的问题是：如何计算环的节点数？这里可以先使用一快一慢两个指针，得到相遇时的节点（若第一个指针走到了null，说明链表中没有环，返回null），此节点必然在环内，然后从此节点开始绕环一圈，每走一步计数器加一，当回到原点时便得到了环的节点数。 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class Solution &#123; public ListNode EntryNodeOfLoop(ListNode head) &#123; if(head == null) return null; ListNode meetingNode = MeetingNode(head); if(meetingNode == null) return null; ListNode node1 = head; ListNode node2 = head; ListNode node = meetingNode.next; int count = 1; while(node != meetingNode) &#123; count++; node = node.next; &#125; for(int i = 0; i &lt; count; i++) &#123; node1 = node1.next; &#125; while(node1 != node2) &#123; node1 = node1.next; node2 = node2.next; &#125; return node1; &#125; public ListNode MeetingNode(ListNode head) &#123; ListNode node1 = head; ListNode node2 = head; while(node1.next != null &amp;&amp; node1.next.next != null) &#123; node1 = node1.next.next; node2 = node2.next; if(node1 == node2) return node1; &#125; return null; &#125; &#125; 24 反转链表题目描述输入一个链表，反转链表后，输出新链表的表头。 123456789/*public class ListNode &#123; int val; ListNode next = null; ListNode(int val) &#123; this.val = val; &#125;&#125;*/ 题解定义三个指针分别指向前一个节点，当前节点和后一个节点。 123456789101112131415161718192021222324public class Solution &#123; public ListNode ReverseList(ListNode head) &#123; if(head == null) return null; ListNode preNode = null; ListNode currNode = head; ListNode nextNode = head.next; ListNode reNode = null; while(currNode != null) &#123; if(nextNode == null) &#123; reNode = currNode; currNode.next = preNode; break; &#125; currNode.next = preNode; preNode = currNode; currNode = nextNode; nextNode = currNode.next; &#125; return reNode; &#125;&#125; 25 合并两个排序的链表题目描述输入两个单调递增的链表，输出两个链表合成后的链表，当然我们需要合成后的链表满足单调不减规则。 123456789/*public class ListNode &#123; int val; ListNode next = null; ListNode(int val) &#123; this.val = val; &#125;&#125;*/ 题解1234567891011121314151617181920public class Solution &#123; public ListNode Merge(ListNode list1,ListNode list2) &#123; if(list1 == null) return list2; if(list2 == null) return list1; ListNode head = null; if(list1.val &lt; list2.val) &#123; head = list1; head.next = Merge(list1.next, list2); &#125; else &#123; head = list2; head.next = Merge(list1, list2.next); &#125; return head; &#125;&#125; 26 树的子结构题目描述输入两棵二叉树A，B，判断B是不是A的子结构。（ps：我们约定空树不是任意一个树的子结构） 1234567891011/**public class TreeNode &#123; int val = 0; TreeNode left = null; TreeNode right = null; public TreeNode(int val) &#123; this.val = val; &#125;&#125;*/ 题解第一步是在树A中查找与根节点的值一样的节点，第二步是判断以此节点为根节点的子树是不是和树B具有相同的结构。此题要特别注意由于计算机表示小数含有误差，不能直接使用==进行double类型的等值判断，而是判断两个小数的差的绝对值是否小于某一个可忽略的数。 12345678910111213141516171819202122232425262728293031323334public class Solution &#123; public boolean HasSubtree(TreeNode root1,TreeNode root2) &#123; boolean result = false; if(root1 != null &amp;&amp; root2 != null) &#123; if(Equal(root1.val, root2.val)) result = DoesTree1HaveTree2(root1, root2); if(!result) result = HasSubtree(root1.left, root2); if(!result) result = HasSubtree(root1.right, root2); &#125; return result; &#125; public boolean DoesTree1HaveTree2(TreeNode root1, TreeNode root2) &#123; if(root2 == null) return true; if(root1 == null) return false; if(!Equal(root1.val, root2.val)) return false; return DoesTree1HaveTree2(root1.left, root2.left) &amp;&amp; DoesTree1HaveTree2(root1.right, root2.right); &#125; public boolean Equal(double num1, double num2) &#123; if(num1- num2 &gt; -0.0000001 &amp;&amp; num1 - num2 &lt; 0.0000001) return true; return false; &#125;&#125; 27 二叉树的镜像题目描述操作给定的二叉树，将其变换为源二叉树的镜像。 123456789101112131415二叉树的镜像定义： 源二叉树 8 / \ 6 10 / \ / \ 5 7 9 11 镜像二叉树 8 / \ 10 6 / \ / \ 11 9 7 5 1234567891011/**public class TreeNode &#123; int val = 0; TreeNode left = null; TreeNode right = null; public TreeNode(int val) &#123; this.val = val; &#125;&#125;*/ 题解123456789101112131415161718public class Solution &#123; public void Mirror(TreeNode root) &#123; if(root == null) return; if(root.left == null &amp;&amp; root.right == null) return; TreeNode temp; temp = root.left; root.left = root.right; root.right = temp; if(root.left != null) Mirror(root.left); if(root.right != null) Mirror(root.right); &#125;&#125; 28 对称的二叉树题目描述请实现一个函数，用来判断一颗二叉树是不是对称的。注意，如果一个二叉树同此二叉树的镜像是同样的，定义其为对称的。 12345678910111213 对称的二叉树 8 / \ 6 6 / \ / \5 7 7 5 非对称的二叉树 8 / \ 6 9 / \ / \5 7 7 5 1234567891011/**public class TreeNode &#123; int val = 0; TreeNode left = null; TreeNode right = null; public TreeNode(int val) &#123; this.val = val; &#125;&#125;*/ 题解对于上图的非对称的二叉树，可以发现前序序列为{8, 6, 5, 7, 6, 7, 5}，对称前序序列为{8, 9, 5, 7, 6, 7, 5}。而对于对称的二叉树，前序序列与对称前序序列都为{8, 6, 5, 7, 6, 7, 5}。因此，通过比较二叉树的前序序列和对称前序序列即可判断出二叉树是否对称。 12345678910111213141516public class Solution &#123; boolean isSymmetrical(TreeNode pRoot) &#123; return isSymmetrical(pRoot, pRoot); &#125; boolean isSymmetrical(TreeNode pRoot1, TreeNode pRoot2) &#123; if(pRoot1 == null &amp;&amp; pRoot2 == null) return true; if(pRoot1 == null || pRoot2 == null) return false; if(pRoot1.val != pRoot2.val) return false; return isSymmetrical(pRoot1.left, pRoot2.right) &amp;&amp; isSymmetrical(pRoot1.right, pRoot2.left); &#125;&#125; 29 顺时针打印矩阵题目描述输入一个矩阵，按照从外向里以顺时针的顺序依次打印出每一个数字，例如，如果输入如下4 X 4矩阵： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 则依次打印出数字1,2,3,4,8,12,16,15,14,13,9,5,6,7,11,10. 题解12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061import java.util.ArrayList;public class Solution &#123; public ArrayList&lt;Integer&gt; printMatrix(int [][] matrix) &#123; if(matrix == null) return null; int columns = matrix[0].length; int rows = matrix.length; if(columns == 0 || rows == 0) return null; ArrayList&lt;Integer&gt; arr = new ArrayList(); int start = 0; while(columns &gt; start*2 &amp;&amp; rows &gt; start*2) &#123; arr.addAll(PrintMatrixInCircle(matrix, columns, rows, start)); start++; &#125; return arr; &#125; public ArrayList&lt;Integer&gt; PrintMatrixInCircle(int [][]matrix, int columns, int rows, int start)&#123; ArrayList&lt;Integer&gt; arr = new ArrayList(); int endX = columns - 1 - start; int endY = rows - 1 - start; //从左到右打印一行 for(int i = start; i &lt;= endX; ++i) &#123; int number = matrix[start][i]; arr.add(number); &#125; //从上到下打印一列 if(start &lt; endY) &#123; for(int i = start + 1; i &lt;= endY; ++i) &#123; int number = matrix[i][endX]; arr.add(number); &#125; &#125; //从右到左打印一行 if(start &lt; endX &amp;&amp; start &lt; endY) &#123; for(int i = endX - 1; i &gt;= start; --i) &#123; int number = matrix[endY][i]; arr.add(number); &#125; &#125; //从下到上打印一行 if(start &lt; endX &amp;&amp; start &lt; endY - 1) &#123; for(int i = endY - 1; i &gt;= start + 1; --i) &#123; int number = matrix[i][start]; arr.add(number); &#125; &#125; return arr; &#125;&#125; 30 包含min函数的栈题目描述定义栈的数据结构，请在该类型中实现一个能够得到栈中所含最小元素的min函数（时间复杂度应为O（1））。 题解使用一个辅助栈。第一次压入的时候，把该元素同时也压入到辅助栈中。以后每次压入新元素的时候，如果新元素比辅助栈栈顶的元素小，就把新元素也压入到辅助栈中，否则，就把辅助栈栈顶的元素再次压入。这么做可以使辅助栈的每个元素对应着数据栈中该位置元素之前的最小元素，即每次从数据栈和辅助栈中弹出一个元素时，辅助栈的栈顶都保存着数据栈的最小元素。由此我们也可以发现，在辅助栈中，新元素的值要么比上一层的值小，要么等于上一层的值。 1234567891011121314151617181920212223242526272829303132333435import java.util.Stack;public class Solution &#123; private Stack&lt;Integer&gt; data = new Stack&lt;&gt;(); private Stack&lt;Integer&gt; dataHelper = new Stack&lt;&gt;(); public void push(int node) &#123; data.push(node); if(dataHelper.isEmpty()) &#123; dataHelper.push(node); &#125; else &#123; if(node &lt; dataHelper.peek()) &#123; dataHelper.push(node); &#125; else &#123; dataHelper.push(dataHelper.peek()); &#125; &#125; &#125; public void pop() &#123; data.pop(); dataHelper.pop(); &#125; public int top() &#123; return data.peek(); &#125; public int min() &#123; return dataHelper.peek(); &#125;&#125; 31 栈的压入、弹出序列题目描述输入两个整数序列，第一个序列表示栈的压入顺序，请判断第二个序列是否可能为该栈的弹出顺序。假设压入栈的所有数字均不相等。例如序列1,2,3,4,5是某栈的压入顺序，序列4,5,3,2,1是该压栈序列对应的一个弹出序列，但4,3,5,1,2就不可能是该压栈序列的弹出序列。（注意：这两个序列的长度是相等的） 题解使用一个栈来模拟压入、弹出的操作，可以得到以下规律： 如果下一个弹出的数字刚好是栈顶数字，直接弹出 否则，把压栈序列中还没有入栈的数字压入栈中，直到把下一个需要弹出的数字压入栈顶为止 压栈序列为空还没找到，离开循环 判断栈是否为空，为空则说明弹出序列匹配，否则，不匹配 1234567891011121314151617181920212223import java.util.ArrayList;import java.util.Stack;public class Solution &#123; Stack&lt;Integer&gt; helper = new Stack&lt;&gt;(); public boolean IsPopOrder(int [] pushA,int [] popA) &#123; if(pushA == null || popA == null) return false; for(int i = 0, j = 0; i &lt; pushA.length; i++) &#123; helper.push(pushA[i]); while(!helper.isEmpty() &amp;&amp; j &lt; popA.length &amp;&amp; helper.peek() == popA[j]) &#123; helper.pop(); j++; &#125; &#125; return helper.isEmpty(); &#125;&#125; 32.1 从上往下打印二叉树题目描述从上往下打印出二叉树的每个节点，同层节点从左至右打印。 题解每次打印一个节点的时候，如果该节点有子节点，就把子节点加入到队列中，然后再从队列头取首元素并打印，重复以上操作，直至队列为空。 123456789101112131415161718192021222324import java.util.ArrayList;import java.util.LinkedList;import java.util.Queue;public class Solution &#123; public ArrayList&lt;Integer&gt; PrintFromTopToBottom(TreeNode root) &#123; ArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;(); Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); if(root == null) return list; queue.add(root); while(queue.size() != 0) &#123; TreeNode node = queue.poll(); list.add(node.val); if(node.left != null) &#123; queue.add(node.left); &#125; if(node.right != null) &#123; queue.add(node.right); &#125; &#125; return list; &#125;&#125; 32.2 把二叉树打印成多行题目描述从上到下按层打印二叉树，同一层结点从左至右输出。每一层输出一行。 题解用两个变量分别记录当前行还剩余的节点与下一行需要打印的节点。每打印完一行，都将下一行需要打印的节点数赋给当前剩余节点数，并将自身置0，以便重新开始新的一行。 123456789101112131415161718192021222324252627282930313233343536import java.util.ArrayList;import java.util.LinkedList;import java.util.Queue;public class Solution &#123; ArrayList&lt;ArrayList&lt;Integer&gt; &gt; Print(TreeNode root) &#123; ArrayList&lt;ArrayList&lt;Integer&gt;&gt; listAll = new ArrayList&lt;&gt;(); ArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;(); Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); if(root == null) return listAll; int toBePrinted = 1; //当前层中还没打印的节点数 int nextLevel = 0; //下一层的节点数 queue.add(root); while(queue.size() != 0) &#123; TreeNode node = queue.poll(); list.add(node.val); if(node.left != null) &#123; queue.add(node.left); nextLevel++; &#125; if(node.right != null) &#123; queue.add(node.right); nextLevel++; &#125; toBePrinted--; if(toBePrinted == 0) &#123; listAll.add(list); list = new ArrayList&lt;&gt;(); toBePrinted = nextLevel; nextLevel = 0; &#125; &#125; return listAll; &#125;&#125; 32.3 按之字形顺序打印二叉树题目描述请实现一个函数按照之字形打印二叉树，即第一行按照从左到右的顺序打印，第二层按照从右至左的顺序打印，第三行按照从左到右的顺序打印，其他行以此类推。 题解如果当前节点在奇数层，则将子节点以从左往右的顺序入栈；如果当前节点在偶数层，则将子节点以从右往左的顺序入栈。更简单地说：子节点入栈的方向与当前层节点弹出的方向一致。 在下面的算法中，用一个Stack数组保存当前层的栈与下一层的栈，用1和0表示奇数层和偶数层。当前层栈的节点弹出时，下一层栈的节点压入。如果当前层栈为空，则说明该行已经打印完成，将current与next置换（奇偶置换）后开始新的一行。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import java.util.ArrayList;import java.util.LinkedList;import java.util.Queue;import java.util.Stack;public class Solution &#123; public ArrayList&lt;ArrayList&lt;Integer&gt; &gt; Print(TreeNode root) &#123; if(root == null) return new ArrayList&lt;ArrayList&lt;Integer&gt;&gt;(); Stack&lt;TreeNode&gt;[] stack = new Stack[2]; stack[0] = new Stack&lt;TreeNode&gt;(); stack[1] = new Stack&lt;TreeNode&gt;(); ArrayList&lt;ArrayList&lt;Integer&gt;&gt; listAll = new ArrayList&lt;&gt;(); ArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;(); if(root == null) return listAll; int current = 1; //表示奇数层 int next = 0; //表示偶数层 stack[current].push(root); while(stack[current].size() != 0 || stack[next].size() != 0) &#123; TreeNode node = stack[current].pop(); list.add(node.val); if(current == 1) &#123; //如果在奇数层，则子节点从左往右入栈 if(node.left != null) &#123; stack[next].push(node.left); &#125; if(node.right != null) &#123; stack[next].push(node.right); &#125; &#125; else &#123; //如果在偶数层，则子节点从右往左入栈 if(node.right != null) &#123; stack[next].push(node.right); &#125; if(node.left != null) &#123; stack[next].push(node.left); &#125; &#125; if(stack[current].size() == 0) &#123; listAll.add(list); list = new ArrayList&lt;&gt;(); current = 1 - current; next = 1 - next; &#125; &#125; return listAll; &#125;&#125; 33 二叉搜索树的后序遍历序列题目描述输入一个整数数组，判断该数组是不是某二叉搜索树的后序遍历的结果。如果是则输出Yes,否则输出No。假设输入的数组的任意两个数字都互不相同。 题解先以以下二叉树为例，其输入数组为{5, 7, 6, 9, 11, 10, 8}。 12345 8 / \ 6 10 / \ / \5 7 9 11 我们可以发现，数组的最后一个数字8就是二叉树的根节点，然后从数组开始进行遍历，凡是比8小的都属于根节点的左子树，其余的就是根节点的右子树，即{5, 7, 6, /9, 11, 10,/ 8}。我们在看看根节点的左子树，同样最后一个数字6是左子树的根节点，而5、7分别属于左子树根节点的左右子树。 再看看另一个例子：{7, 4, 6, 5}，由以上分析的规律可以发现，5为二叉树的根节点，而7、4、6都比5大，说明此二叉树没有左子树，而在右子树{7, 4, 6}中，7比6大，说明7在根节点的右子树中，而4却又比6小，这有违二叉树的定义，说明此数组不属于任何一个二叉树。 因此，我们可以使用递归来解决这个问题，先找到二叉树的根节点，再基于此根节点将数组拆分成左右子树，然后对左右子树分别进行递归。 123456789101112131415161718192021222324252627282930313233343536public class Solution &#123; public boolean VerifySquenceOfBST(int [] sequence) &#123; if(sequence == null || sequence.length &lt;= 0) return false; return VerifySquenceOfBST(sequence, 0, sequence.length - 1); &#125; public boolean VerifySquenceOfBST(int [] sequence, int begin, int end) &#123; if(end-begin&lt;0) return true; int root = sequence[end]; int i = begin; for(;i &lt; end; i++) &#123; if(sequence[i] &gt; root) break; &#125; int j = i; for(;j &lt; end; j++) &#123; if(sequence[j] &lt; root) return false; &#125; boolean left = true; if(i &gt; 0) left = VerifySquenceOfBST(sequence, begin, i-1); boolean right = true; if(i &lt; end) right = VerifySquenceOfBST(sequence, i, end - 1); return (right &amp;&amp; left); &#125;&#125; 34 二叉树中和为某一值的路径题目描述输入一颗二叉树的跟节点和一个整数，打印出二叉树中结点值的和为输入整数的所有路径。路径定义为从树的根结点开始往下一直到叶结点所经过的结点形成一条路径。(注意: 在返回值的list中，数组长度大的数组靠前)。 1234567891011/**public class TreeNode &#123; int val = 0; TreeNode left = null; TreeNode right = null; public TreeNode(int val) &#123; this.val = val; &#125;&#125;*/ 题解此题运用深度优先搜索的思想。从左开始向下深度遍历，遇到叶节点之后，判断其值是否等于target，如果相等则将此路径加入到所有路径的列表中。每次回退的时候，都要将路径最后一个节点删除。 此题需要注意，将某一路径加入到所有路径列表时，必须新建一个ArrayList，否则每次都是将对同一个对象的引用加入到listAll中，而java中通过引用是可以改变对象内部的属性的，所以每次对list进行remove操作都会影响到listAll中已加入的所有list，最后由于list会回退到根节点并把根节点remove掉，导致listAll的路径数目虽然正确，但每条路径列表都为空。 12345678910111213141516171819202122232425262728293031public class Solution &#123; public ArrayList&lt;ArrayList&lt;Integer&gt;&gt; FindPath(TreeNode root,int target) &#123; ArrayList&lt;ArrayList&lt;Integer&gt;&gt; listAll = new ArrayList&lt;&gt;(); ArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;(); if(root == null) return listAll; findPath(listAll, list, root, target); return listAll; &#125; public void findPath(ArrayList&lt;ArrayList&lt;Integer&gt;&gt; listAll, ArrayList&lt;Integer&gt; list, TreeNode root, int target) &#123; list.add(root.val); //如果为叶节点 if(root.left == null &amp;&amp; root.right == null) &#123; if(root.val == target) &#123; ArrayList&lt;Integer&gt; newList = new ArrayList&lt;&gt;(); newList.addAll(list); listAll.add(newList); &#125; list.remove(list.size() - 1); return; &#125; if(root.left != null) findPath(listAll, list, root.left, target-root.val); if(root.right != null) findPath(listAll, list, root.right, target-root.val); list.remove(list.size() - 1); return; &#125;&#125; 35 复杂链表的复制题目描述输入一个复杂链表（每个节点中有节点值，以及两个指针，一个指向下一个节点，另一个特殊指针指向任意一个节点），返回结果为复制后复杂链表的head。（注意，输出结果中请不要返回参数中的节点引用，否则判题程序会直接返回空） 1234567891011/*public class RandomListNode &#123; int label; RandomListNode next = null; RandomListNode random = null; RandomListNode(int label) &#123; this.label = label; &#125;&#125;*/ 题解解决此题大体有以下两个步骤： 1、根据原始链表的每个节点创建对应的复制节点 2、设置复制出来的节点的random节点 此题的关键在于定位random节点，需保证算法的时间复杂度在O(n)。 哈希表在第一步创建每个复制节点时，使用哈希表保存原节点与复制节点，之后设置random节点时，每当通过查找哈希表原节点的random节点便可以在O(1)的时间找到该复制节点应指向的random节点。此算法相当于以空间换时间，空间复杂度为O(n)。 这里需要注意，java中的map是不能直接使用iterator遍历的，因此需要先通过entrySet()方法获取set视图。 1234567891011121314151617181920212223242526272829303132import java.util.HashMap;import java.util.Iterator;import java.util.Map.Entry;public class Solution &#123; public RandomListNode Clone(RandomListNode head)&#123; if(head == null) return null; HashMap&lt;RandomListNode, RandomListNode&gt; map = new HashMap&lt;&gt;(); RandomListNode cloneNodeHead = new RandomListNode(head.label); RandomListNode cloneNode = cloneNodeHead; map.put(head, cloneNode); while(head.next != null) &#123; RandomListNode nextNode = new RandomListNode(head.next.label); cloneNode.next = nextNode; cloneNode = cloneNode.next; head = head.next; map.put(head, cloneNode); &#125; Iterator&lt;Entry&lt;RandomListNode, RandomListNode&gt;&gt; it = map.entrySet().iterator(); while(it.hasNext()) &#123; Entry&lt;RandomListNode, RandomListNode&gt; entry = it.next(); //时间复杂度为O(1)，相当于以空间换时间 RandomListNode sib = map.get(entry.getKey().random); entry.getValue().random = sib; &#125; return cloneNodeHead; &#125;&#125; 更好的解法思路：在旧链表中创建新链表-&gt;根据旧链表的random节点初始化新链表的random节点-&gt;把新链表从旧链表中拆分出来。 此算法的时间复杂度为O(n)，且不需要辅助空间。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class Solution &#123; public RandomListNode Clone(RandomListNode head) &#123; if(head == null) return null; CloneNodes(head); ConnectSiblingNodes(head); return ReconnectNodes(head); &#125; public void CloneNodes(RandomListNode head) &#123; RandomListNode test = head; while(head != null) &#123; RandomListNode cloneNode = new RandomListNode(head.label); RandomListNode next = head.next; head.next = cloneNode; cloneNode.next = next; head = next; &#125; &#125; public void ConnectSiblingNodes(RandomListNode head) &#123; while(head != null) &#123; RandomListNode cloneNode = head.next; if(head.random != null) &#123; cloneNode.random = head.random.next; &#125; head = head.next.next; &#125; &#125; public RandomListNode ReconnectNodes(RandomListNode head) &#123; RandomListNode cloneNode = head.next; RandomListNode cloneNodeHead = cloneNode; while(head != null) &#123; RandomListNode next = head.next.next; RandomListNode cloneNext; //防止在最后一个节点处报空指针异常 if(next == null) &#123; cloneNext = null; &#125; else &#123; cloneNext = cloneNode.next.next; &#125; head.next = next; cloneNode.next = cloneNext; head = next; cloneNode = cloneNext; &#125; return cloneNodeHead; &#125;&#125; 36 二叉搜索树与双向链表题目描述输入一棵二叉搜索树，将该二叉搜索树转换成一个排序的双向链表。要求不能创建任何新的结点，只能调整树中结点指针的指向。 1234567891011/**public class TreeNode &#123; int val = 0; TreeNode left = null; TreeNode right = null; public TreeNode(int val) &#123; this.val = val; &#125;&#125;*/ 题解1234567891011121314151617181920212223public class Solution &#123; public TreeNode Convert(TreeNode root) &#123; if(root == null) return null; if(root.left == null &amp;&amp; root.right == null) return root; TreeNode left = Convert(root.left); TreeNode p = left; while(p != null &amp;&amp; p.right != null) &#123; p = p.right; &#125; if(left != null) &#123; root.left = p; p.right = root; &#125; TreeNode right = Convert(root.right); if(right != null) &#123; root.right = right; right.left = root; &#125; return left != null ? left : root; &#125;&#125; 37 序列化二叉树题目描述请实现两个函数，分别用来序列化和反序列化二叉树 题解123456789101112131415161718192021222324252627public class Solution &#123; private int index = -1; String Serialize(TreeNode root) &#123; StringBuilder str = new StringBuilder(); if(root == null) &#123; str.append("$,"); return str.toString(); &#125; str.append(root.val+","); str.append(Serialize(root.left)); str.append(Serialize(root.right)); return str.toString(); &#125; TreeNode Deserialize(String str) &#123; String[] newStr = str.split(","); index++; if(index &lt; str.length() &amp;&amp; !newStr[index].equals("$")) &#123; TreeNode root = new TreeNode(Integer.valueOf(newStr[index])); root.left = Deserialize(str); root.right = Deserialize(str); return root; &#125; return null; &#125;&#125; 38 字符串的排列题目描述输入一个字符串,按字典序打印出该字符串中字符的所有排列。例如输入字符串abc,则打印出由字符a,b,c所能排列出来的所有字符串abc,acb,bac,bca,cab和cba。 题解回溯法： 123456789101112131415161718192021222324252627282930313233343536import java.util.ArrayList;import java.util.List;import java.util.Collections;public class Solution &#123; public ArrayList&lt;String&gt; Permutation(String str) &#123; ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(); if(str == null || str.length() == 0) return list; Permutation(str.toCharArray(), 0, list); Collections.sort(list); return list; &#125; public void Permutation(char[] c, int i, ArrayList&lt;String&gt; list) &#123; if(i == c.length) &#123; String str = String.valueOf(c); if(!list.contains(str)) list.add(String.valueOf(c)); return; &#125; else &#123; for(int j = i; j &lt; c.length; j++) &#123; swap(c, i, j); Permutation(c, i+1, list); swap(c, i, j); &#125; &#125; &#125; public void swap(char[] c, int i, int j)&#123; char temp; temp = c[i]; c[i] = c[j]; c[j] = temp; &#125;&#125; 39 数组中出现次数超过一半的数字题目描述数组中有一个数字出现的次数超过数组长度的一半，请找出这个数字。例如输入一个长度为9的数组{1,2,3,2,2,2,5,4,2}。由于数字2在数组中出现了5次，超过数组长度的一半，因此输出2。如果不存在则输出0。 题解基于辅助数组的解法此种解法利用了辅助数组，在辅助数组中以原始数组的值为索引存储该值出现的次数，一旦次数超过原始数组的一半，则跳出循环返回该值。该解法空间复杂度为O(n)，相当于以空间换时间，且由于数组的限制，事先必须要知道原始数组中值的范围，若要克服后者，可以使用其它数据结构。 1234567891011121314151617181920public class Solution &#123; public int MoreThanHalfNum_Solution(int [] array) &#123; if(array == null || array.length == 0) &#123; return 0; &#125; int length = array.length; int[] helper = new int[length+1]; int result = 0; for(int i = 0; i &lt; length; i++) &#123; helper[array[i]]++; if(helper[array[i]] &gt; length / 2) &#123; result = array[i]; break; &#125; &#125; return result; &#125;&#125; 多数投票算法多数投票算(摩尔投票算法)：定义一个结果变量和一个计数器，初始化的情况下计数器为0. 算法依次扫描序列中的元素，当处理某元素的时候，如果计数器为0，那么将该元素赋值给结果变量，然后将计数器设置为1，如果计数器不为0，那么将结果变量和该元素比较，如果相等，那么计数器加1，如果不等，那么计数器减1。处理之后，最后存储的结果变量就是这个数组中超过一半以上的元素。 需注意：如果一个元素的出现次数超过数组长度的一半，那么结果变量肯定为该元素，但结果变量元素的出现次数不一定超过数组长度的一半，因此需要进行第二次遍历确认。 12345678910111213141516171819202122232425262728293031public class Solution &#123; public int MoreThanHalfNum_Solution(int [] array) &#123; if(array == null || array.length == 0) &#123; return 0; &#125; int result = array[0]; int n = 1; for(int i = 1; i &lt; array.length; i++) &#123; if(n == 0) &#123; result = array[i]; n = 1; &#125; else if(array[i] == result) n++; else n--; &#125; n = 0; for(int i = 0; i &lt; array.length; i++) &#123; if(array[i] == result) &#123; n++; &#125; &#125; if(n &lt;= array.length / 2) return 0; return result; &#125;&#125; 40 最小的k个数题目描述输入n个整数，找出其中最小的K个数。例如输入4,5,1,6,2,7,3,8这8个数字，则最小的4个数字是1,2,3,4,。 题解123456789101112131415161718192021222324252627import java.util.ArrayList;import java.util.PriorityQueue;import java.util.Comparator;public class Solution &#123; public ArrayList&lt;Integer&gt; GetLeastNumbers_Solution(int [] input, int k) &#123; ArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;(); if(input == null || input.length &lt;= 0 || k &lt; 1 || k &gt; input.length) &#123; return list; &#125; PriorityQueue&lt;Integer&gt; heap = new PriorityQueue&lt;&gt;(k+1, new Comparator&lt;Integer&gt;() &#123; public int compare(Integer o1, Integer o2) &#123; return o2 - o1; &#125; &#125;); for(int i = 0; i &lt; input.length; i++) &#123; heap.add(input[i]); if(heap.size() &gt; k) &#123; heap.poll(); &#125; &#125; for(Integer i : heap) &#123; list.add(i); &#125; return list; &#125;&#125; 41 数据流中的中位数题目描述如何得到一个数据流中的中位数？如果从数据流中读出奇数个数值，那么中位数就是所有数值排序之后位于中间的数值。如果从数据流中读出偶数个数值，那么中位数就是所有数值排序之后中间两个数的平均值。我们使用Insert()方法读取数据流，使用GetMedian()方法获取当前读取数据的中位数。 题解用最大堆与最小堆来实现，插入的时间复杂度为O(log(n))。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960import java.util.PriorityQueue;import java.util.Comparator;public class Solution &#123; PriorityQueue&lt;Integer&gt; max = new PriorityQueue&lt;&gt;(new Comparator&lt;Integer&gt;() &#123; @Override public int compare(Integer o1, Integer o2) &#123; return o2.compareTo(o1); &#125; &#125;); PriorityQueue&lt;Integer&gt; min = new PriorityQueue&lt;&gt;(new Comparator&lt;Integer&gt;() &#123; @Override public int compare(Integer o1, Integer o2) &#123; return o1.compareTo(o2); &#125; &#125;); public void Insert(Integer num) &#123; if((min.size()+max.size() &amp; 1) == 0) &#123; //如果当前总数是偶数，则插入到最大堆 if(min.size() != 0 &amp;&amp; num &gt; min.peek()) &#123; //如果最小堆的数目不为0，且新插入的数字比最小堆的头要大 int temp = min.poll(); max.add(temp); min.add(num); &#125; else &#123; //插入到最大堆 max.add(num); &#125; &#125; else &#123; //如果当前总数是奇数，则插入到最小堆 if(max.size() != 0 &amp;&amp; num &lt; max.peek()) &#123; //同理 int temp = max.poll(); min.add(temp); max.add(num); &#125; else &#123; min.add(num); &#125; &#125; &#125; public Double GetMedian() &#123; int size = max.size() + min.size(); Double d; if(size == 0) return -1.0; if((size &amp; 1) != 0) &#123; d = Double.valueOf(max.peek()); &#125; else &#123; d = (double) (max.peek() + min.peek()) / 2; &#125; return d; &#125;&#125; 42 连续子数组的最大和题目描述HZ偶尔会拿些专业问题来忽悠那些非计算机专业的同学。今天测试组开完会后,他又发话了:在古老的一维模式识别中,常常需要计算连续子向量的最大和,当向量全为正数的时候,问题很好解决。但是,如果向量中包含负数,是否应该包含某个负数,并期望旁边的正数会弥补它呢？例如:{6,-3,-2,7,-15,1,2,2},连续子向量的最大和为8(从第0个开始,到第3个为止)。给一个数组，返回它的最大连续子序列的和，你会不会被他忽悠住？(子向量的长度至少是1) 题解1234567891011121314151617181920public class Solution &#123; public int FindGreatestSumOfSubArray(int[] data) &#123; if(data == null ||data.length &lt;= 0)&#123; return 0; &#125; int sum=data[0], max=data[0]; for(int i = 1; i &lt; data.length; i++)&#123; if(sum &lt;= 0)&#123; sum = data[i]; &#125; else&#123; sum += data[i]; &#125; if(sum &gt; max)&#123; max = sum; &#125; &#125; return max; &#125;&#125; 44 数字序列中某一位的数字题目描述数字以 0123456789101112131415… 的格式序列化到一个字符串中，求这个字符串的第 index 位。 题解12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class Solution &#123; public int digitAtIndex(int index) &#123; if(index &lt; 0) return -1; int digits = 1; //digits表示有几位数，初始为一位数 while(true) &#123; int numbers = countOfIntegers(digits); //返回当前位数共有多少个数 if(index &lt; numbers * digits) &#123; //数字的个数乘位数能得到具体的某一位数字的下标 return digitAtIndex(index, digits); &#125; index -= digits * numbers; //如果要查找的数字不在这位数里面，则跳过这些数字 digits++; //位数加一 &#125; &#125; /* * 在n位数中的第index个数 */ private int digitAtIndex(int index, int digits) &#123; int number = beginNumber(digits) + index / digits; int indexFromRight = digits - index % digits; //得到在查找到的数字中具体从右数的哪一位 for(int i = 1; i &lt; indexFromRight; i++) &#123; number /= 10; &#125; return number % 10; &#125; /* * 计算n位的数字总共有多少，如二位数有10~99这90个数，三位数有100~999这900个数 */ private int countOfIntegers(int digits) &#123; if(digits == 1) return 10; int count = (int) Math.pow(10, digits-1); return count * 9; &#125; /* * 计算n位数的第一个数字，如二位数的第一个数字是10，三位数的第一个数字是100 */ private int beginNumber(int digits) &#123; if(digits == 1) return 0; return (int)Math.pow(10, digits-1); &#125;&#125; 45 把数组排成最小的数题目描述输入一个正整数数组，把数组里所有数字拼接起来排成一个数，打印能拼接出的所有数字中最小的一个。例如输入数组{3，32，321}，则打印出这三个数字能排成的最小数字为321323。 题解本题的关键在于定义一个规则判断两个数中谁应该排在前面，应该排在前面的数我们称其“小于”另一个数。例如，令m=32，n=2，则mn=322，nm=232，因为nm&lt;mn，我们就称n小于m。之后我们便可使用这个比较方法（比较器）对数组中的所有元素进行排序即可。 123456789101112131415161718192021222324252627282930import java.util.Arrays;import java.util.Comparator;public class Solution &#123; public String PrintMinNumber(int [] numbers) &#123; if(numbers == null || numbers.length &lt;= 0) return ""; StringBuilder res = new StringBuilder(); int len = numbers.length; String[] str = new String[len]; for(int i = 0; i &lt; len; i++) &#123; str[i] = numbers[i] + ""; &#125; Arrays.sort(str, new Comparator&lt;String&gt;() &#123; public int compare(String o1, String o2) &#123; String str1 = o1 + o2; String str2 = o2 + o1; return str1.compareTo(str2); &#125; &#125;); for(String s : str) &#123; res.append(s); &#125; return res.toString(); &#125;&#125; 46 把数字翻译成字符串题目描述给定一个数字，按照如下规则翻译成字符串：0 翻译成“a”，1 翻译成“b”… 25 翻译成“z”。一个数字有多种翻译可能，例如 12258 一共有 5 种，分别是 bccfi，bwfi，bczi，mcfi，mzi。实现一个函数，用来计算一个数字有多少种不同的翻译方法。 题解如果用递归方法从上往下求解，必然会遇到许多重复的计算，因此可以从下往上进行求解。 我们可以先得到方程f(i) = f(i+1) + af(i+2)，当第i个数与第i+1个数组成的数字在10-25的范围内，则a=1，否则a=0。以字符串“13225”为例，下标为0和1的数分别是1和3，组成的13是在10-25的范围内的，因此可以将其看成剩下的3225或者225这两种组合方式。以上是自顶向下的分析，再看看自底向上的实现，以下标为2的数2为例，首先就单独把这个数进行翻译，则加上上一个数的计算结果，又因为上一个数2和它组成的22是在10-25的范围内的，所以可以把它们组合在一起翻译，基于这种情况则再加上上上个数的结果，这两种情况的结果相加就是自底到这一个数的计算结果。一直循环到第一个数，dp[0]便是最终答案。 1234567891011121314151617public class Solution &#123; public int numDecodings(String s) &#123; int[] dp = new int[s.length()+1]; dp[s.length()] = 1; dp[s.length()-1] = 1; for(int i = s.length()-2; i &gt;= 0; i--)&#123; int a = s.charAt(i) - '0'; int b = s.charAt(i+1) - '0'; if(a * 10 + b &gt; 25)&#123; dp[i] = dp[i+1]; &#125; else&#123; dp[i] = dp[i+1] + dp[i+2]; &#125; &#125; return dp[0]; &#125;&#125; 47 礼物的最大价值题目描述小东所在公司要发年终奖，而小东恰好获得了最高福利，他要在公司年会上参与一个抽奖游戏，游戏在一个6*6的棋盘上进行，上面放着36个价值不等的礼物，每个小的棋盘上面放置着一个礼物，他需要从左上角开始游戏，每次只能向下或者向右移动一步，到达右下角停止，一路上的格子里的礼物小东都能拿到，请设计一个算法使小东拿到价值最高的礼物。 给定一个6*6的矩阵board，其中每个元素为对应格子的礼物价值,左上角为[0,0],请返回能获得的最大价值，保证每个礼物价值大于100小于1000。 题解使用动态规划的思路：f(i,j) = max(f(i-1,j), f(i,j-1))，每一个坐标(i,j)的解只需要依赖其左边与上边的坐标，且最左边坐标的解只依赖上边的坐标，因此只需要一个一维数组作为缓存即可，该数组存有i行j列左边的所有解以及i-1行j列右边的所有解。 12345678910111213141516public class Solution &#123; public int getMost(int[][] values) &#123; if(values == null || values.length == 0 || values[0].length == 0) return 0; int n = values[0].length; int[] dp = new int[n]; for(int[] value : values) &#123; dp[0] += value[0]; for(int i = 1; i &lt; n; i++) &#123; dp[i] = Math.max(dp[i], dp[i-1]) + value[i]; &#125; &#125; return dp[n-1]; &#125;&#125; 48 最长不含重复字符的子字符串题目描述输入一个字符串（只包含 a~z 的字符），求其最长不含重复字符的子字符串的长度。例如对于 arabcacfr，最长不含重复字符的子字符串为 acfr，长度为 4。 题解1234567891011121314151617181920212223242526272829303132333435public class Solution &#123; public int LongestSubstringWithoutDupSolution(String str) &#123; if(str == null || str.length() &lt;= 0) return 0; int maxLen = 0; int curLen = 0; int[] position = new int[26]; for(int i = 0; i &lt; 26; i++) &#123; position[i] = -1; &#125; for(int i = 0; i &lt; str.length(); i++) &#123; //当前字母在position的下标index int index = str.charAt(i) - 'a'; if(position[index] &lt; 0) &#123; //如果这个字母之前没出现过 curLen += 1; &#125; else &#123; if(i-position[index] &lt;= curLen) &#123; curLen = i-position[index]; &#125; else &#123; curLen += 1; &#125; &#125; position[index] = i; if(curLen &gt; maxLen) maxLen = curLen; &#125; return maxLen; &#125;&#125; 49 丑数题目描述把只包含质因子2、3和5的数称作丑数（Ugly Number）。例如6、8都是丑数，但14不是，因为它包含质因子7。 习惯上我们把1当做是第一个丑数。求按从小到大的顺序的第N个丑数。 题解12345678910111213141516171819202122public class Solution &#123; public int GetUglyNumber_Solution(int index) &#123; if(index &lt;= 6) return index; int[] ugly = new int[index]; ugly[0] = 1; int t2=0, t3=0, t5=0; for(int i = 1; i &lt; index; i++) &#123; ugly[i] = Math.min(ugly[t2]*2, Math.min(ugly[t3]*3, ugly[t5]*5)); while(ugly[t2] * 2 &lt;= ugly[i]) t2++; while(ugly[t3] * 3 &lt;= ugly[i]) t3++; while(ugly[t5] * 5 &lt;= ugly[i]) t5++; &#125; return ugly[ugly.length-1]; &#125;&#125; 50.1 第一个只出现一次的字符题目描述在一个字符串(0&lt;=字符串长度&lt;=10000，全部由字母组成)中找到第一个只出现一次的字符,并返回它的位置, 如果没有则返回 -1（需要区分大小写）. 题解123456789101112131415161718192021222324252627282930import java.util.HashMap;public class Solution &#123; public int FirstNotRepeatingChar(String str) &#123; if(str == null) return -1; HashMap&lt;Character, Integer&gt; map = new HashMap&lt;&gt;(); int index = -1; for(int i = 0; i &lt; str.length(); i++) &#123; char curr = str.charAt(i); if(!map.containsKey(curr)) &#123; map.put(curr, 1); &#125; else &#123; int value = map.get(curr); map.put(curr, ++value); &#125; &#125; for(int i = 0; i &lt; str.length(); i++) &#123; char curr = str.charAt(i); if(map.get(curr) == 1) &#123; index = i; break; &#125; &#125; return index; &#125;&#125; 50.2 字符流中第一个不重复的字符题目描述请实现一个函数用来找出字符流中第一个只出现一次的字符。例如，当从字符流中只读出前两个字符”go”时，第一个只出现一次的字符是”g”。当从该字符流中读出前六个字符“google”时，第一个只出现一次的字符是”l”。 题解1234567891011121314151617181920212223242526272829303132public class Solution &#123; private int[] map = new int[256]; private int index = 0; public Solution() &#123; for(int i = 0; i &lt; map.length; i++) &#123; map[i] = -1; //-1代表从未出现过 &#125; &#125; //Insert one char from stringstream public void Insert(char ch) &#123; if(map[ch] == -1) &#123; map[ch] = index; //从未出现过，将它的下标赋值给它 &#125; else &#123; map[ch] = -2; //出现过，则值为-2 &#125; index++; &#125; //return the first appearence once char in current stringstream public char FirstAppearingOnce() &#123; char result = '#'; int minIndex = Integer.MAX_VALUE; for(int i = 0; i &lt; map.length; i++) &#123; if(map[i] &gt;= 0 &amp;&amp; map[i] &lt; minIndex) &#123; minIndex = map[i]; result = (char)i; &#125; &#125; return result; &#125;&#125; 51 数组中的逆序对题目描述在数组中的两个数字，如果前面一个数字大于后面的数字，则这两个数字组成一个逆序对。输入一个数组,求出这个数组中的逆序对的总数P。并将P对1000000007取模的结果输出。 即输出P%1000000007 题解统计逆序对的过程：先把数组分隔成子数组，统计出子数组内部的逆序对的数目，然后再统计出两个相邻子数组之间的逆序对的数目。在统计逆序对的过程中，还需要对数组进行归并排序，而计算逆序对数目其实就是在进行归并排序的时候完成的。 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class Solution &#123; private long cnt = 0; private int[] tmp; public int InversePairs(int [] array) &#123; tmp = new int[array.length]; if(array == null || array.length &lt;= 0) &#123; return -1; &#125; mergeSort(array, 0, array.length-1); return (int) (cnt % 1000000007); &#125; private void mergeSort(int[] a, int lo, int hi) &#123; if(hi &lt;= lo) return; int m = lo + (hi - lo) / 2; mergeSort(a, lo, m); mergeSort(a, m+1, hi); merge(a, lo, m, hi); &#125; private void merge(int[] a, int lo, int m, int hi) &#123; int i = lo, j = m+1, k = lo; while(k &lt;= hi) &#123; if(i &gt; m) &#123; tmp[k] = a[j++]; &#125; else if(j &gt; hi) &#123; tmp[k] = a[i++]; &#125; else if(a[i] &lt; a[j]) &#123; tmp[k] = a[i++]; &#125; else &#123; tmp[k] = a[j++]; cnt += m - i + 1; &#125; k++; &#125; for(k = lo; k &lt;= hi; k++) &#123; a[k] = tmp[k]; &#125; &#125;&#125; 52 两个链表的第一个公共结点题目描述输入两个链表，找出它们的第一个公共结点。 12345678public class ListNode &#123; int val; ListNode next = null; ListNode(int val) &#123; this.val = val; &#125;&#125; 题解此题大体有两种思路： 1、如果从后往前遍历两条链表，那么最后一个相同的节点就是我们要找的节点。这种思路要解决的问题在于链表是单向链表，该怎么逆序遍历链表。 2、如果从前往后遍历两条链表，那么第一个相同的节点就是我们要找的节点。这种思路要解决的问题在于如果两条链表的长度不同，便无法同时到达第一个公共节点，进而也就无法比较是否相等。 思路一：以空间换时间将两个链表分别装到两个栈中，每次取出链表尾部的一个节点判断是否相等，最后一个相等的节点即为两个链表的第一个公共节点。 1234567891011121314151617181920212223242526272829public class Solution &#123; public ListNode FindFirstCommonNode(ListNode pHead1, ListNode pHead2) &#123; if(pHead1 == null || pHead2 == null) return null; Stack&lt;ListNode&gt; stack1 = new Stack&lt;&gt;(); Stack&lt;ListNode&gt; stack2 = new Stack&lt;&gt;(); ListNode h1 = pHead1; ListNode h2 = pHead2; ListNode common = null; while(h1!=null) &#123; stack1.push(h1); h1 = h1.next; &#125; while(h2 != null) &#123; stack2.push(h2); h2 = h2.next; &#125; while(!stack1.empty() &amp;&amp; !stack2.empty()) &#123; ListNode node1 = stack1.pop(); ListNode node2 = stack2.pop(); if(node1 == node2) &#123; common = node1; &#125; &#125; return common; &#125;&#125; 思路二：进一步优化上一种思路需要两个栈作为辅助空间，其实完全可以不用辅助空间，先分别遍历两个链表并记录他们的长度，长链表先走几步以此和短链表在同一起点出发，之后便可以同时遍历直至找出相同的节点。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class Solution &#123; public ListNode FindFirstCommonNode(ListNode pHead1, ListNode pHead2) &#123; if(pHead1 == null || pHead2 == null) return null; int len1 = 0; int len2 = 0; int diff; //两条链表的长度差 ListNode listLong; //标识链表的长短 ListNode listShort; ListNode h1 = pHead1; //用于遍历的节点 ListNode h2 = pHead2; while(h1!=null) &#123; len1++; h1 = h1.next; &#125; while(h2 != null) &#123; len2++; h2 = h2.next; &#125; if(len1 &gt; len2) &#123; listLong = pHead1; listShort = pHead2; diff = len1 - len2; &#125; else &#123; listLong = pHead2; listShort = pHead1; diff = len2 - len1; &#125; for(int i = 0; i &lt; diff; i++) &#123; listLong = listLong.next; &#125; while(listLong != null &amp;&amp; listShort != null) &#123; if(listLong == listShort) return listLong; listLong = listLong.next; listShort = listShort.next; &#125; return null; &#125;&#125; 53.1 数字在排序数组中出现的次数题目描述统计一个数字在排序数组中出现的次数。 题解最直观的做法是顺序扫描，时间复杂度为O(n)，不是最优解。由于输入的数组是排序的，那么就可以用二分查找的思路，找到第一个要查找的数字和最后一个要查找的数字，其坐标差即为该数字出现的次数。此时时间复杂度为O(logn)。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class Solution &#123; public int GetNumberOfK(int [] array , int k) &#123; if(array == null || array.length &lt;= 0) return 0; int start = getFirstK(array, k); int end = getLastK(array, k); int num = 0; if(start != -1 &amp;&amp; end != -1) &#123; num = end - start + 1; &#125; return num; &#125; public int getFirstK(int[] array, int k) &#123; int lo = 0; int hi = array.length - 1; int middle; while(lo &lt;= hi) &#123; middle = lo + (hi - lo) / 2; if(array[middle] &lt; k) &#123; lo = middle + 1; &#125; else if(array[middle] &gt; k) &#123; hi = middle - 1; &#125; else &#123; if(middle - 1 &gt;= 0 &amp;&amp; array[middle - 1] == k) &#123; hi = middle - 1; &#125; else &#123; return middle; &#125; &#125; &#125; return -1; &#125; public int getLastK(int[] array, int k) &#123; int lo = 0; int hi = array.length - 1; int middle; while(lo &lt;= hi) &#123; middle = lo + (hi - lo) / 2; if(array[middle] &lt; k) &#123; lo = middle + 1; &#125; else if(array[middle] &gt; k) &#123; hi = middle - 1; &#125; else &#123; if(middle + 1 &lt; array.length &amp;&amp; array[middle + 1] == k) &#123; lo = middle + 1; &#125; else &#123; return middle; &#125; &#125; &#125; return -1; &#125;&#125; 53.2 0至n-1中缺失的数字题目描述在范围0~n-1内的n个数字中有且只有一个数字不在长度为n-1的递增排序数组（数字唯一）中，请找出这个数字。例如，{1,2,3,4}中少了0，{0,1,2,3}中少了4，{0,1,3,4}中少了2。 题解用二分查找法找到第一个数字与下标不同的元素。 12345678910111213141516171819202122public class Solution &#123; public int getMissingNumber(int[] array) &#123; if(array == null || array.length &lt;= 0) return -1; int lo = 0; int hi = array.length - 1; int middle; while(lo &lt;= hi) &#123; middle = lo + (hi - lo) / 2; if(array[middle] == middle) &#123; lo = middle + 1; &#125; else &#123; if(middle - 1 &gt;= 0 &amp;&amp; array[middle - 1] != middle - 1) &#123; hi = middle - 1; &#125; else &#123; return middle; &#125; &#125; &#125; return array.length; &#125;&#125; 53.3 数组中数值和下标相等的元素题目描述假设一个单调递增的数组里的每个元素都是整数并且是唯一的。请编写实现一个函数，找出数组中任意一个数值等于其下标的元素。 题解由于每个数都是唯一的，如果第i个数字的值大于i，那么它右边的数字都大于对应的下标；如果第i个数字的值小于i，那么它左边的数字都小于对应的下标。 123456789101112131415161718192021222324public class Solution &#123; public int IntegerIdenticalToIndex(int[] array) &#123; if(array == null || array.length &lt;= 0) return -1; int lo = 0; int hi = array.length - 1; int middle; while(lo &lt;= hi) &#123; middle = lo + (hi - lo) / 2; if(array[middle] &gt; middle) &#123; hi = middle - 1; &#125; else if(array[middle] &lt; middle) &#123; lo = middle + 1; &#125; else &#123; if(middle - 1 &gt;= 0 &amp;&amp; array[middle - 1] == middle - 1) &#123; hi = middle - 1; &#125; else &#123; return middle; &#125; &#125; &#125; return -1; &#125;&#125; 54 二叉搜索树的第k个结点题目描述给定一棵二叉搜索树，请找出其中的第k小的结点。例如，（5，3，7，2，4，6，8）中，按结点数值大小顺序第三小结点的值为4。 123456789public class TreeNode &#123; int val = 0; TreeNode left = null; TreeNode right = null; public TreeNode(int val) &#123; this.val = val; &#125;&#125; 题解12345678910111213141516171819202122public class Solution &#123; private int cnt; private TreeNode target; TreeNode KthNode(TreeNode pRoot, int k) &#123; if(pRoot == null || k &lt;= 0) return null; KthNodeCore(pRoot, k); return target; &#125; void KthNodeCore(TreeNode pRoot, int k) &#123; if(pRoot == null || target != null) &#123; return; &#125; KthNodeCore(pRoot.left, k); cnt++; if(cnt == k) target = pRoot; KthNodeCore(pRoot.right, k); &#125;&#125; 55.1 二叉树的深度题目描述输入一棵二叉树，求该树的深度。从根结点到叶结点依次经过的结点（含根、叶结点）形成树的一条路径，最长路径的长度为树的深度。 123456789public class TreeNode &#123; int val = 0; TreeNode left = null; TreeNode right = null; public TreeNode(int val) &#123; this.val = val; &#125;&#125; 题解123456789public class Solution &#123; public int TreeDepth(TreeNode root) &#123; if(root == null) return 0; int left = TreeDepth(root.left); int right = TreeDepth(root.right); return left &gt; right ? (left+1):(right+1); &#125;&#125; 55.2 平衡二叉树题目描述输入一棵二叉树，判断该二叉树是否是平衡二叉树。 题解1234567891011121314151617public class Solution &#123; public boolean IsBalanced_Solution(TreeNode root) &#123; return IsBalanced(root) != -1; &#125; public int IsBalanced(TreeNode root) &#123; if(root == null) return 0; int left = IsBalanced(root.left); if(left == -1) return left; int right = IsBalanced(root.right); if(right == -1) return right; return Math.abs(left-right) &gt; 1 ? -1 : 1+Math.max(left,right); &#125;&#125; 56.1 数组中只出现一次的数字题目描述一个整型数组里除了两个数字之外，其他的数字都出现了偶数次。请写程序找出这两个只出现一次的数字。 题解因为任何一个数字异或它自己都等于0，而0异或任何一个数字都等于其本身，所以可以将数组中的所有数字都异或，例如对于含有一个数字只出现一次的数组{3,3,4,4,6}：123 3 ^ 3 ^ 4 ^ 4 ^ 6-&gt; 0 ^ 0 ^ 6-&gt; 6 而在此题中，数组里有两个数字只出现了一次，所以从头到尾异或数组中的每个数字会得到这两个数字的异或结果，由于这两个数字肯定不同，所以异或结果至少会包含一个1，我们以最右侧的1为标准将这两个数分到两个子数组中，于此同时这一位为1或0的出现两次的数字也会分别到这两个子数组中，然后再对两个子数组运用最上面的思路。 在这里，diff &amp;= -diff可以得到只有最右侧为1的数，以此作为分割标准。（在计算机中，负数以其正值的补码形式表达，补码=反码+1） 1234567891011121314public class Solution &#123; public void FindNumsAppearOnce(int[] nums, int num1[], int num2[]) &#123; int diff = 0; for (int num : nums) diff ^= num; diff &amp;= -diff; for (int num : nums) &#123; if ((num &amp; diff) == 0) num1[0] ^= num; else num2[0] ^= num; &#125; &#125;&#125; 56.2 数组中唯一只出现一次的数字题目描述在一个数组中除一个数字只出现一次之外，其他数字都出现了三次。请找出那个只出现一次的数字。 题解把数组中所有数字的二进制表示的每一位都加起来，如果某一位的和能被3整除，那么那个只出现一次的数字二进制表示中对应的那一位是0，否则就是1。 1234567891011121314151617181920212223public class NumberAppearingOnce &#123; public int solution(int numbers[]) &#123; if(numbers == null || numbers.length == 0) return -1; int[] bitSum = new int[32]; for(int i = 0; i &lt; numbers.length; i++) &#123; int bitMask = 1; for(int j = 31; j &gt;= 0; j--) &#123; int bit = numbers[i] &amp; bitMask; if(bit != 0) bitSum[j] += 1; bitMask = bitMask &lt;&lt; 1; &#125; &#125; int result = 0; for(int i = 0; i &lt; 32; i++) &#123; result = result &lt;&lt; 1; result += bitSum[i] % 3; &#125; return result; &#125;&#125; 57.1 和为s的两个数字题目描述输入一个递增排序的数组和一个数字S，在数组中查找两个数，使得他们的和正好是S，如果有多对数字的和等于S，输出两个数的乘积最小的。 题解定义两个指针，一个指向数组头，一个指向数组末尾，如果指针指向的这两个数字相加小于S，则将头指针向后移动一位，否则将尾指针向前移动一位。 12345678910111213141516171819202122232425import java.util.ArrayList;public class Solution &#123; public ArrayList&lt;Integer&gt; FindNumbersWithSum(int [] array,int sum) &#123; ArrayList&lt;Integer&gt; result = new ArrayList&lt;&gt;(); if(array == null || array.length == 0) return result; int lo = 0; int hi = array.length - 1; while(lo &lt; hi) &#123; int curSum = array[lo] + array[hi]; if(curSum &lt; sum) &#123; lo++; &#125; else if(curSum &gt; sum) &#123; hi--; &#125; else &#123; result.add(array[lo]); result.add(array[hi]); break; &#125; &#125; return result; &#125;&#125; 57.2 和为s的连续正数序列题目描述小明很喜欢数学,有一天他在做数学作业时,要求计算出9~16的和,他马上就写出了正确答案是100。但是他并不满足于此,他在想究竟有多少种连续的正数序列的和为100(至少包括两个数)。没多久,他就得到另一组连续正数和为100的序列:18,19,20,21,22。现在把问题交给你,你能不能也很快的找出所有和为S的连续正数序列? Good Luck! 题解首先把lo和hi分别初始化为1和2（因为连续序列为正，且至少含有两个数字），如果lo和hi之间的数字相加大于S，将lo加一，而如果lo和hi之间的数字相加小于S，则将hi加一。 12345678910111213141516171819202122232425262728293031import java.util.ArrayList;public class Solution &#123; public ArrayList&lt;ArrayList&lt;Integer&gt; &gt; FindContinuousSequence(int sum) &#123; ArrayList&lt;ArrayList&lt;Integer&gt;&gt; listAll = new ArrayList&lt;&gt;(); if(sum &lt;= 0) return listAll; int lo = 1; int hi = 2; int middle = sum / 2; int curSum = lo + hi; while(lo &lt;= middle) &#123; if(curSum &lt; sum) &#123; hi++; curSum += hi; &#125; else if(curSum &gt; sum) &#123; curSum -= lo; lo++; &#125; else &#123; ArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;(); int i = lo; while(i &lt;= hi) list.add(i++); listAll.add(list); curSum += ++hi; &#125; &#125; return listAll; &#125;&#125; 58.1 翻转单词序列题目描述牛客最近来了一个新员工Fish，每天早晨总是会拿着一本英文杂志，写些句子在本子上。同事Cat对Fish写的内容颇感兴趣，有一天他向Fish借来翻看，但却读不懂它的意思。例如，“student. a am I”。后来才意识到，这家伙原来把句子单词的顺序翻转了，正确的句子应该是“I am a student.”。Cat对一一的翻转这些单词顺序可不在行，你能帮助他么？ 题解进行两次翻转：首先将整体进行翻转，得到.tneduts a ma I，再将每个单词进行局部翻转，得到student. a am I即为答案。 123456789101112131415161718192021222324252627282930public class Solution &#123; public String ReverseSentence(String str) &#123; if(str == null) return null; else if(str == "") return ""; char[] data = str.toCharArray(); int i = 0, j = data.length-1; reverse(data, i, j); j = 0; while(i &lt; data.length) &#123; if(j == data.length || data[j] == ' ') &#123; reverse(data, i, j-1); i = j + 1; &#125; j++; &#125; return new String(data); &#125; private void reverse(char[] data, int i, int j) &#123; while(i &lt;= j) &#123; char temp = data[i]; data[i] = data[j]; data[j] = temp; i++; j--; &#125; &#125;&#125; 58.2 左旋转字符串题目描述汇编语言中有一种移位指令叫做循环左移（ROL），现在有个简单的任务，就是用字符串模拟这个指令的运算结果。对于一个给定的字符序列S，请你把其循环左移K位后的序列输出。例如，字符序列S=”abcXYZdef”,要求输出循环左移3位后的结果，即“XYZdefabc”。是不是很简单？OK，搞定它！ 题解1234567891011121314151617181920212223242526public class Solution &#123; public String LeftRotateString(String str,int n) &#123; if(str == null) return null; else if(str == "") return ""; else if(n &gt;= str.length()) return str; char[] data = str.toCharArray(); reverse(data, 0, n-1); reverse(data, n, data.length-1); reverse(data, 0, data.length-1); return new String(data); &#125; private void reverse(char[] data, int i, int j) &#123; while(i &lt;= j) &#123; char temp = data[i]; data[i] = data[j]; data[j] = temp; i++; j--; &#125; &#125;&#125; 60 n个骰子的点数题目描述把 n 个骰子仍在地上，求点数和为 s 的概率。 题解我们以n表示要扔的骰子数，s为所有骰子的点数之和，f(n, s)表示扔n个骰子时所有骰子的点数之和为s的排列情况总数。例如，n=2，s=5时，f(n, s) = f(2, 5) = 4 （4种情况即{1, 4}, {4, 1}, {2, 3}, {3, 2}） 因为一个骰子有六个点数，那么第n个骰子可能出现1到6的点数，当第n个骰子点数为1的话，f(n,s) = f(n-1, s-1)，当第n个骰子点数为2的话，f(n,s) = f(n-1, s-2)，…，依次类推。 由以上分析我们便可以得到状态转移方程：f(n,s)=f(n-1,s-1)+f(n-1,s-2)+f(n-1,s-3)+f(n-1,s-4)+f(n-1,s-5)+f(n-1,s-6) 使用递归得到状态方程后，最直观的就是使用递归求解。点数和的最小值为骰子数n，而最大值为6 * n。 1234567891011121314151617181920212223242526public class Solution &#123; public List&lt;Map.Entry&lt;Integer, Double&gt;&gt; dicesSum(int n) &#123; List&lt;Map.Entry&lt;Integer, Double&gt;&gt; result = new ArrayList&lt;&gt;(); int minSum = n; int maxSum = 6 * n; double totalCase = Math.pow(6, n); for(int i = minSum; i &lt;= maxSum; i++) &#123; result.add(new AbstractMap.SimpleEntry&lt;&gt;(i, dicesSumCore(n, i) / totalCase)); &#125; return result; &#125; private int dicesSumCore(int n, int sum)&#123; if(n&lt;1||sum&lt;n||sum&gt;6*n)&#123; return 0; &#125; if(n==1)&#123; return 1; &#125; int resCount=0; resCount=dicesSumCore(n-1,sum-1)+dicesSumCore(n-1,sum-2)+ dicesSumCore(n-1,sum-3)+dicesSumCore(n-1,sum-4)+ dicesSumCore(n-1,sum-5)+dicesSumCore(n-1,sum-6); return resCount; &#125;&#125; 动态规划使用递归求解会产生大量重复的计算，所以使用动态规划更好。 在以下代码中使用了一个二维数组dp[2][maxSum+1]，dp[0]和dp[1]表示当前状态和前一个状态（由状态转移方程f(n,s)=f(n-1,s-1)+f(n-1,s-2)+f(n-1,s-3)+f(n-1,s-4)+f(n-1,s-5)+f(n-1,s-6)可以看出当前状态仅依赖前一个状态，所以只用两个一维数组即可），而这两个状态的数组使用flag变量进行旋转。 1234567891011121314151617181920212223242526272829303132333435public class Solution &#123; public List&lt;Map.Entry&lt;Integer, Double&gt;&gt; dicesSum(int n) &#123; List&lt;Map.Entry&lt;Integer, Double&gt;&gt; result = new ArrayList&lt;&gt;(); if(n &lt; 1) return result; int face = 6; int minSum = n; int maxSum = face * n; int flag = 1; double totalCase = Math.pow(face, n); //总共有6的n次方种排列情况 long[][] dp = new long[2][maxSum+1]; //dp[flag][j]表示当前状态下产生点数和为j的排列次数 //设置初始状态，即f(1,1) = f(1,2) = f(1,3) = f(1,4) = f(1,5) = f(1,6) = 1 for(int i = 1; i &lt;= face; i++) dp[0][i] = 1; //i表示当前扔出的骰子数，骰子数为1的情况在上面已经有过初始化 for (int i = 2; i &lt;= n; i++, flag = 1 - flag) &#123; //将表示当前状态的数组清零 for (int j = 0; j &lt;= maxSum; j++) dp[flag][j] = 0; for (int j = i; j &lt;= maxSum; j++) for (int k = 1; k &lt;= face &amp;&amp; k &lt;= j; k++) //此处即体现出状态转移方程 dp[flag][j] += dp[1 - flag][j - k]; &#125; for(int i = minSum; i &lt;= maxSum; i++) &#123; result.add(new AbstractMap.SimpleEntry&lt;&gt;(i, dp[1 - flag][i] / totalCase)); &#125; return result; &#125;&#125; 61 扑克牌顺子题目描述从扑克牌中随机抽5张牌，判断是不是一个顺子，即这5张牌是不是连续的。大小王可看成任意数字。 题解把大小王看成0，首先把数组排序，其次统计数组中0的个数，最后统计排序后的数组中相邻数字之间的空缺总数。如果空缺总数小于或者等于0的个数，那么这个数组就是连续的。 123456789101112131415161718192021222324import java.util.Arrays;public class Solution &#123; public boolean isContinuous(int [] numbers) &#123; if(numbers == null || numbers.length == 0) return false; int numOfZero = 0; int numOfGap = 0; Arrays.sort(numbers); for(int i = 0; i &lt; numbers.length &amp;&amp; numbers[i] == 0; i++) &#123; numOfZero++; &#125; for(int i = numOfZero+1; i &lt; numbers.length; i++) &#123; if(numbers[i] == numbers[i-1]) return false; numOfGap += numbers[i] - numbers[i-1] - 1; &#125; return numOfZero &gt;= numOfGap ? true : false; &#125;&#125; 62 圆圈中最后剩下的数字题目描述首先,让小朋友们围成一个大圈。然后,他随机指定一个数m,让编号为0的小朋友开始报数。每次喊到m-1的那个小朋友要出列唱首歌,然后可以在礼品箱中任意的挑选礼物,并且不再回到圈中,从他的下一个小朋友开始,继续0…m-1报数….这样下去….直到剩下最后一个小朋友,可以不用表演,并且拿到牛客名贵的“名侦探柯南”典藏版。请你试着想下,哪个小朋友会得到这份礼品呢？(注：小朋友的编号是从0到n-1) 题解环形链表法采用链表来模拟整个过程。 1234567891011121314151617181920import java.util.LinkedList;public class Solution &#123; public int LastRemaining_Solution(int n, int m) &#123; if(n &lt; 1 || m &lt; 1) return -1; LinkedList&lt;Integer&gt; list = new LinkedList&lt;&gt;(); int index = 0; for(int i = 0; i &lt; n; i++) &#123; list.add(i); &#125; while(list.size() &gt; 1) &#123; index = (index + m - 1) % list.size(); list.remove(index); &#125; return list.get(0); &#125;&#125; 公式法我们可以根据此公式使用递归或者循环来做：f(n,m) = [f(n-1,m) + m] % n。 123456789public class Solution &#123; public int LastRemaining_Solution(int n, int m) &#123; if (n == 0) return -1; if (n == 1) return 0; return (LastRemaining_Solution(n - 1, m) + m) % n; &#125;&#125; 63 股票的最大利润题目描述假设把某股票的价格按照时间先后顺序存储在数组中，请问买卖该股票一次可获得的最大利润是多少？ 题解12345678910111213141516public class MaximalProfit &#123; public int maxProfit(int[] prices) &#123; if(prices == null || prices.length == 0) return 0; int minPrice = prices[0]; int maxProfit = 0; for(int i = 1; i &lt; prices.length; i++) &#123; if(prices[i] &lt; minPrice) minPrice = prices[i]; int currProfit = prices[i] - minPrice; if(currProfit &gt; maxProfit) maxProfit = currProfit; &#125; return maxProfit; &#125;&#125; 64 求1+2+···+n题目描述题解1234567public class Solution &#123; public int Sum_Solution(int n) &#123; int sum = n; boolean flag = (sum &gt; 0) &amp;&amp; ((sum += Sum_Solution(--n)) &gt; 0); return sum; &#125;&#125; 65 不用加减乘除做加法题目描述写一个函数，求两个整数之和，要求在函数体内不得使用+、-、*、/四则运算符号。 题解十进制加法三步走：1、只做各位相加不进位2、求出进位值3、把前面两个结果加起来 而对于二进制也正是如此。使用异或完成相加的操作，而使用位与运算再左移完成进位的操作。 123456789101112public class Solution &#123; public int Add(int num1,int num2) &#123; int sum, carry; do &#123; sum = num1 ^ num2; carry = (num1 &amp; num2) &lt;&lt; 1; num1 = sum; num2 = carry; &#125; while(carry != 0); return sum; &#125;&#125; 拓展不使用新变量交换两个变量的值: 基于加减法 基于异或运算 a = a + b a = a ^ b b = a - b a = a ^ b a = a - b a = a ^ b 66 构建乘积数组题目描述给定一个数组A[0,1,…,n-1],请构建一个数组B[0,1,…,n-1],其中B中的元素B[i]=A[0] A[1] … A[i-1] A[i+1] … A[n-1]。不能使用除法。 题解12345678910111213141516171819public class Solution &#123; public int[] multiply(int[] A) &#123; int[] B = new int[A.length]; if(A == null || A.length == 0) return B; B[0] = 1; for(int i = 1; i &lt; A.length; i++) &#123; B[i] = B[i-1] * A[i-1]; &#125; int temp = 1; for(int i = B.length - 2; i &gt;= 0; i--)&#123; temp = A[i+1] * temp; B[i] = temp * B[i]; &#125; return B; &#125;&#125; 67 把字符串转换成整数题目描述将一个字符串转换成一个整数(实现Integer.valueOf(string)的功能，但是string不符合数字要求时返回0)，要求不能使用字符串转换整数的库函数。 数值为0或者字符串不是一个合法的数值则返回0。 题解1234567891011121314151617public class Solution &#123; public int StrToInt(String str) &#123; if(str == null || str.length() == 0) return 0; boolean neg = str.charAt(0) == '-'; int num = 0; for(int i = 0; i &lt; str.length(); i++) &#123; char c = str.charAt(i); if(i == 0 &amp;&amp; (c == '+' || c == '-')) continue; if(c &lt; '0' || c &gt; '9') return 0; int temp = num; num = num * 10 + (c - '0'); if((num - c + '0') / 10 != temp) return 0; &#125; return neg ? -num : num; &#125;&#125; 68.1 二叉查找树中两个节点的最低公共祖先题目描述找到二叉查找树中两个节点的最低公共祖先 123456789/** * Definition for a binary tree node. * public class TreeNode &#123; * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) &#123; val = x; &#125; * &#125; */ 题解从根节点开始向下查找直到找到满足root.val &gt;= p.val且root.val &lt;= q.val的节点。 12345678910111213class Solution &#123; public TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) &#123; while(root != null) &#123; if(root.val &gt; p.val &amp;&amp; root.val &gt; q.val) root = root.left; else if(root.val &lt; p.val &amp;&amp; root.val &lt; q.val) root = root.right; else return root; &#125; return null; &#125;&#125; 68.2 普通二叉树中两个节点的最低公共祖先题目描述找到普通二叉树中两个节点的最低公共祖先 123456789/** * Definition for a binary tree node. * public class TreeNode &#123; * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) &#123; val = x; &#125; * &#125; */ 题解深度优先搜索的思想： 12345678910class Solution &#123; public TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) &#123; if(root == null || root.val == p.val || root.val == q.val) return root; TreeNode left = lowestCommonAncestor(root.left, p, q); TreeNode right = lowestCommonAncestor(root.right, p, q); return left == null ? right : right == null ? left : root; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL查询性能优化]]></title>
    <url>%2F2019%2F01%2F28%2FMySQL%E6%9F%A5%E8%AF%A2%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[优化数据访问减少请求的数据量 只返回必要的行：使用LIMIT语句来限制返回的数据。 只返回必要的列：最好不要使用SELECT *语句。 缓存重复查询的数据。 减少服务器端扫描的行数最有效的方式是使用索引来覆盖查询。 重构查询方式切分查询一个大查询如果一次性执行的话，可能一次锁住很多数据、占满整个事务日志、耗尽系统资源、阻塞很多小的但重要的查询。因此可以将大查询切分成小查询，每个查询功能完全一样，只完成一小部分，每次只返回一小部分查询结果。 分解关联查询可以对每一个表进行一次单表查询，然后将结果在应用程序中进行关联。这么做有如下优势： 让缓存的效率更高。对于关联查询，如果其中一个表发生变化，那么整个查询缓存就无法使用。而分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然可以使用。 将查询分解后，执行单个查询可以减少锁的竞争。 分解成多个单表查询，这些单表查询的缓存结果更可能被其它查询使用到，从而减少冗余记录的查询。 查询执行 客户端发送一条查询给服务器。 服务器先检查查询缓存，如果命中了缓存，则立刻返回存储在缓存中的结果。否则进入下一阶段。 服务器端进行SQL解析、预处理再由优化器生成对应的执行计划。 MySQL根据优化器生成的执行计划，调用存储引擎的API来执行查询。 将结果返回给客户端。 MySQL解析器将使用MySQL语法规则验证和解析查询；预处理器则根据一些MySQL规则进一步检查解析树是否合法，例如检查数据表和数据列是否存在，之后会验证权限；查询优化器的作用是根据存储引擎提供的统计信息找出一个最优的执行计划。 优化 Limit 分页在偏移量特别大的时候，例如可能是LIMIT 1000, 20这样的查询，这时MySQL需要查询10020条记录然后只返回最后20条，前面10000条记录都将被抛弃，这样的代价非常高。可以通过延迟关联和书签两个技巧进行优化。 延迟关联优化此类分页查询的一个最简单的办法就是尽可能地使用索引覆盖扫描，而不是查询所有的列。然后根据需要做一次关联操作再返回所需的列。考虑下面的查询： 1SELECT film_id, description FROM sakila.film ORDER BY title LIMIT 50, 5; 此时没有覆盖索引，因此要回表获取记录55条，而只返回最后5条1。这时候可以用延迟关联的技巧改写成如下： 123456SELECT film.film_id, film.descriptionFROM sakila.film INNER JOIN( SELECT film_id FROM sakala.film ORDER BY title LIMIT 50, 5 ) AS lim USING(film_id); 这时候子查询中能使用覆盖索引，因此在索引结构中就能获取到需要访问的记录而无需回表，之后再根据关联列回表查询需要的所有列。 书签LIMIT和OFFSET的问题，其实是OFFSET的问题，它会导致MySQL扫描大量不需要的行然后再抛弃掉。如果可以使用书签记录上次取数据的位置，那么下次就可以直接从该书签记录的位置开始扫描，这样就可以避免使用OFFSET。例如，若需要按照租借记录做翻页，那么可以根据最新一条租借记录向后追溯，首先使用下面的查询获得第一组结果： 12SELECT * FROM sakila.rentalORDER BY rental_id DESC LIMIT 20; 会返回49到30的记录，那么下一页查询就可以从30这个点开始： 123SELECT * FROM sakila.rentalWHERE rental_id &lt; 30ORDER BY rental_id DESC LIMIT 20; 该技术的好处是无论翻页到多么后面，其性能都会很好。 参考资料 高性能 MySQL[M]. 电子工业出版社, 2013. CS-Notes]]></content>
      <categories>
        <category>数据库</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL索引类型与优化]]></title>
    <url>%2F2019%2F01%2F28%2FMySQL%E7%B4%A2%E5%BC%95%E7%B1%BB%E5%9E%8B%E4%B8%8E%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[索引的优点 索引大大减少了服务器需要扫描的数据量 索引可以帮助服务器避免排序、分组和临时表（临时表主要是在排序和分组过程中创建，因为不需要排序和分组，也就不需要创建临时表） 索引可以将随机I/O变为顺序I/O（B-Tree索引是有序的，会将相邻的数据都存储在一起） 索引的类型在MySQL中，索引是在存储引擎层而不是服务器层实现的，所以不同的存储引擎的索引类型和实现不同。 B-Tree索引大多数存储引擎都使用B-Tree作为默认索引类型，但实际在技术上往往使用的是B+Tree，例如InnoDB。B-Tree索引之能够加快访问数据的速度，是因为存储引擎不再需要进行全表扫描来获取需要的数据，取而代之的是从索引的根节点开始进行搜索。关于B-Tree和B+Tree的工作原理可以参考之前的一篇笔记：常用查找算法之B/B+树。 B-Tree索引适用于全键值、键值范围或键前缀（最左前缀）查找。因为索引树中的节点是有序的，所以除了按值查找之外，索引还可以用于查询中的ORDER BY操作。 B-Tree同样也有一些限制： 如果不是按照索引的最左列开始查找，则无法使用索引。 不能跳过索引中的列，否则只会使用跳过之前的索引列。 如果查询中有某个列的范围查询，则其右边所有列都无法使用索引优化查找。 哈希索引哈希索引基于哈希表实现，对于每一行数据，存储引擎都会对所有索引列计算一个哈希码并存储在索引中，同时在哈希表中保存指向每个数据行的指针。如果多个列的哈希值相同，索引会以链表的方式存放多个记录指针到同一个哈希条目中。哈希索引有如下限制： 哈希索引只包含哈希值和行指针，而不存储字段值，所以不能使用索引中的值来避免读取行。 无法用于排序。 不支持部分索引列匹配查找。 不支持范围查询。 哈希冲突。 InnoDB引擎有一个特殊的功能叫做“自适应哈希索引”，当InnoDB注意到某些索引值被使用得非常频繁时，它会在内存中基于B-Tree索引之上再创建一个哈希索引，这样就让B+Tree索引具有哈希索引的一些优点，比如快速的哈希查找。 全文索引全文索引是一种特殊类型的索引，它查找的是文本中的关键词，而不是直接比较索引中的值。全文索引使用倒排索引实现，它记录着关键词到其所在文档的映射。在相同的列上同时创建全文索引和基于值的B-Tree索引不会有冲突，全文索引适用于MATCH AGAINST操作，而不是普通的WHERE条件操作。 空间数据索引MyISAM存储引擎支持空间数据索引（R-Tree），可以用作地理数据存储。空间索引会从所有维度来索引数据，查询时可以有效利用任意维度来组合查询。必须使用MySQL的GIS相关函数来维护数据。 索引优化独立的列在进行查询时，索引列不能是表达式的一部分，也不能是函数的参数，否则MySQL无法使用索引。 例如：SELECT actor_id FROM sakila.actor WHERE actor_id + 1 = 5; 多列索引在需要使用多个列作为条件进行查询时，使用多列索引比使用多个单列索引性能更好。例如下面的语句中，最好把actor_id和film_id设置为多列索引： 12SELECT film_id, actor_id FROM sakila.film_actorWHERE actor_id = 1 AND film_id = 1; 索引列的顺序将选择性最强的索引列放在前面。索引的选择性是指不重复的索引值（基数）和记录总数的比值，选择性越高则查询效率也越高，因为选择性高的索引可以让MySQL在查找时过滤掉更多的行。 前缀索引对于很长的字符串可以索引开始的部分字符，使得前缀的选择性接近于完整列的选择性。 聚簇索引B-Tree索引类型都可以用在MyISAM和InnoDB上，但InnoDB有聚簇索引的特性而MyISAM没有。 聚簇表示数据行和相邻的键值紧凑地存储在一起，因为无法同时把数据行存放在两个不同的地方，所以每张Innodb引擎表都只有一个聚簇索引。一般情况，聚簇索引就是主键索引（因为聚簇索引在有主键的情况下，默认指定主键为聚簇索引），而非聚簇索引都是二级索引。 如果没有定义主键，InnoDB会选择一个唯一的非空索引代替。如果没有这样的索引，InnoDB会隐式定义一个主键来作为聚簇索引。采用聚簇索引，索引和其他列值存储在一起，因此数据访问比采用非聚簇索引（如MyISAM引擎）更快，节省了磁盘I/O资源。 二级索引叶子节点保存的不是指向行的物理位置的指针，而是行的主键值。通过二级索引查找行，存储引擎需要找到二级索引的叶子节点获得对应的主键值，然后根据这个值去聚簇索引中查找到对应的行。这样虽然会让二级索引占用更多的空间，但换来的好处是InnoDB在移动行时减少了二级索引的维护工作。 MyISAM没有聚簇索引的特性，主键索引和其它索引在结构上没有什么不同。 使用InnoDB存储引擎时应该尽可能地按主键顺序插入数据（可以使用AUTO_INCREMENT自增），最好避免随机的插入（例如使用UUID作为主键）。因为当主键的值是顺序的时，InnoDB会把每一条记录都存储在上一条记录的后面，当达到页的最大填充因子时（默认为15/16），下一条记录就会写入新的页中。而每次插入主键的值近似于随机时，新纪录根据值的大小要被插入到现有索引页的中间某个合适位置，此时页分裂会导致大量的数据移动并产生碎片，甚至目标页面可能已经被回写到磁盘上而从缓存中清掉，此时又要从磁盘上读回来，这增加了很多开销。 覆盖索引如果一个索引包含（或者说覆盖）所有需要查询的字段的值，我们就称之为“覆盖索引”，此时不需要回表操作。其具有以下优点： 索引条目通常远小于数据行大小，所以如果只需要读取索引，那MySQL就会极大地减少数据访问量。 因为索引是按照列值顺序存储的，所以对于I/O密集型的范围查询会比随机从磁盘读取每一行数据的I/O要少得多。 一些存储引擎如MyISAM在内存中只缓存索引，数据则依赖于操作系统来缓存，因此要访问数据需要一次系统调用，比较费时。 对于InnoDB引擎，若二级索引能够覆盖查询，则可以避免对主键索引的二次查询。 使用索引扫描来排序MySQL有两种方式可以生成有序的结果：通过排序操作或者按索引顺序扫描。如果EXPLAIN出来的type列的值为index，则说明MySQL使用了索引扫描来做排序。 只有当索引的列顺序和ORDER BY子句的顺序完全一致，并且所有列的排序方向（倒序或正序）都一样时，MySQL才能够使用索引来对结果做排序。如果查询需要关联多张表，则只有当ORDER BY子句引用的字段全部为第一个表时，才能使用索引做排序。ORDER BY子句和查找型查询的限制是一样的：需要满足索引的最左前缀的要求，否则MySQL都需要执行排序操作，而无法利用索引排序。 参考资料 高性能 MySQL[M]. 电子工业出版社, 2013. mysql的索引——innodb索引（1）聚簇索引和次级索引 为什么InnoDB表最好要有自增列做主键]]></content>
      <categories>
        <category>数据库</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>索引</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL常用数据类型]]></title>
    <url>%2F2019%2F01%2F28%2FMySQL%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[整型TINYINT, SMALLINT, MEDIUMINT, INT, BIGINT分别使用1，2，3，4，8字节的存储空间。 可以使用UNSIGNED属性表示不允许负值以提高正数的上限，但有符号和无符号类型的存储空间和性能依旧一样。 MySQL可以为整数类型指定宽度，如INT(11)，但它不会限制值的合法范围，只是规定了交互工具显示字符的个数。 浮点数FLOAT和DOUBLE为浮点类型（浮点数），DECIMAL为高精度小数类型（定点数）。 CPU原生支持浮点运算，但不支持对DECIMAL的运算，因此浮点运算会更快。但是浮点数会引起精度问题，像货币这样对精度敏感的数据，应该用DECIMAL来存储。 浮点和定点都可以指定精度，例如DECIMAL(18, 9)表示总共18位，取9位存储小数部分，剩下9位存储整数部分。 字符串MySQL主要有VARCHAR和CHAR两种字符串类型。 VARCHAR类型是可变长的，它比定长类型更节省空间，因为它仅使用必要的空间。但是在执行UPDATE时可能会使行变得比原来长，当超出一个页所能容纳的大小时，就要执行额外的操作，MyISAM会将行拆成不同的片段存储，InnoDB则需要分裂页来使行放进页内。 CHAR类型是定长的，总是根据定义的字符串长度分配足够的空间，并且在存储和检索时删除末尾的空格，而VARCHAR是会保留末尾的空格的。 当字符串列的长度比平均长度大很多时、列的更新很少时，使用VARCHAR类型更好；对于定长的字符串如MD5、经常变更或者非常短的字符串（因为VARCHAR需要额外的1个或2个字节记录字符串长度）则使用CHAR类型更好。 日期和时间MySQL提供两种相似的日期类型：DATETIME和TIMESTAMP。 DATETIME能够保存从1001年到9999年的日期和时间，精度为秒。它把日期和时间封装到格式为YYYYMMDDHHMMSS的整数中，与时区无关，使用8个字节的存储空间。默认情况下，MySQL以一种可排序的、无歧义的格式显示，例如2008-01-16 22:37:08。 TIMESTAMP保存从1970年1月1日午夜（格林威治时间）以来的秒数，使用4个字节，只能表示从1970年到2038年。这种类型的时间是和时区有关的，默认情况下，如果插入时没有指定TIMESTAMP列的值，MySQL则设置这个列的值为当前时间。 应该尽量使用TIMESTAMP，因为它比DATETIME空间效率更高。]]></content>
      <categories>
        <category>数据库</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库事务、锁与设计原理]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1%E3%80%81%E9%94%81%E4%B8%8E%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[事务事务是指满足ACID特性的一组操作，它们要么完全地执行，要么完全地不执行。 ACID特性原子性（Atomicity）一个事务必须被视为一个不可分割的最小工作单元，整个事务中的所有操作要么全部提交成功，要么全部失败回滚。 想要保证事务的原子性，就需要在异常发生时，对已经执行的操作进行回滚。MySQL中的回滚日志（undo log）就是用于存放数据被修改前的值，如果出现异常，可以使用undo log来实现回滚操作。 一致性（Consistency）数据库总是从一个一致性的状态转换到另外一个一致性状态。事务开始和结束之间的中间状态不会被其他事务看到。 隔离性（Isolation）一个事务所作的修改在最终提交前，对其它事务是不可见的。 持久性（Durability）一旦事务提交，则其所作的修改就会永久保存到数据库中。即使系统崩溃，修改的数据也不会丢失。 MySQL使用重做日志（redo log）实现事务的持久性。当我们在一个事务中尝试对数据进行修改时，它会先将数据从磁盘读入内存，并更新内存中缓存的数据，然后生成一条重做日志并写入重做日志缓存，当事务真正提交时，MySQL会将重做日志缓存中的内容刷新到重做日志文件，再将内存中的数据更新到磁盘上。这样，在事务提交后，就算数据没来得及写回磁盘就宕机时，在下次重新启动后仍然能够成功恢复数据。 理解事务的ACID特性概念简单，但不是很好理解，主要是因为这几个特性不是一种平级关系： 只要满足一致性，事务的执行结果才是正确的。 在无并发的情况下，事务串行执行，隔离性一定能够满足。此时只要满足原子性，就一定能满足一致性。 在并发的情况下，多个事务并行执行，事务不仅要满足原子性，还要满足隔离性，才能满足一致性。 事务满足持久化是为了能应对数据库崩溃的情况。 隔离级别在并发环境下需要关注事务的隔离性，SQL标准中定义了以下四种隔离级别。 未提交读（READ UNCOMMITTED）事务中的修改即使没有提交，对其他事务也都是可见的。事务可以读取未提交的数据，这也被称为脏读。 提交读（READ COMMITTED）一个事务从开始直到提交之前，所做的任何修改对其它事务都是不可见的。 这个级别有时候也叫做不可重复读，因为两次执行同样的查询，可能会得到不一样的结果。例如，T2读取一个数据，T1对该数据做了修改并提交，如果T2再次读取这个数据，那么读取的结果和第一次读取的结果不同。 可重复读（REPEATABLE READ）可重复读保证了在同一事物中多次读取同样记录的结果是一致的。 该级别无法解决幻读问题，即当某个事务在读取某个范围内的记录时，另外一个事务又在该范围内插入了新的记录，当之前的事务再次读取该范围的记录时，会产生幻行。 可串行化（SERIALIZABLE）该级别是最高的隔离级别，通过强制事务串行执行避免上面的幻读问题。 总结 隔离级别 脏读 不可重复读 幻读 加锁读 未提交读 √ √ √ × 提交读 × √ √ × 未提交读 × × √ × 未提交读 × × × √ 锁当多个用户并发地存取数据时，在数据库中就会产生多个事务同时存取同一数据的情况。若对并发操作不加控制就可能会读取和存储不正确的数据，破坏数据库的一致性。所以，锁主要用于处理并发问题。 从数据库系统角度分为三种：排他锁、共享锁、更新锁。从程序员角度分为两种：一种是悲观锁，一种乐观锁。 悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁。 传统的关系数据库里用到了很多这种锁机制，比如按使用性质划分的读锁、写锁和按作用范围划分的行锁、表锁。 共享锁共享锁（S锁）又称为读锁，若事务T对数据对象A加上S锁，则事务T只能读A；其他事务只能再对A加S锁，而不能加X锁，直到T释放A上的S锁。这就保证了其他事务可以读A，但在T释放A上的S锁之前不能对A做任何修改。 排他锁排他锁（X锁）又称为写锁，若事务T对数据对象A加上X锁，则只允许T读取和修改A，其他任何事务都不能再对A加任何类型的锁，直到T释放A上的锁。这就保证了其他事务在T释放A上的锁之前不能再读取和修改A。 表锁每次操作锁住整张表，开销小，加锁快，锁粒度大，发生锁冲突的概率最高，并发度最低。 行锁每次操作锁住一行数据，开销大，加锁慢，锁粒度小，发生锁冲突的概率最低，并发度最高。 数据库能够确定哪些行需要锁的情况下使用行锁，如果不知道会影响哪些行的时候就会使用表锁。 乐观锁总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号机制和CAS算法实现。 版本号机制一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值与当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。 CAS算法CAS即compare and swap（比较并交换），是一种有名的无锁算法，在不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步。CAS算法涉及到三个操作数： 要更新的变量V 预期的值E 新值N 仅当V值等于E值时，才会将V的值设置成N，否则什么都不做。最后CAS返回当前V的值。CAS算法需要你额外给出一个期望值，也就是你认为现在变量应该是什么样子，如果变量不是你想象的那样，就说明已经被别人修改过，就重新读取，再次尝试修改即可。 因为CAS需要在操作值的时候检查下值有没有发生变化，如果没有发生变化则更新，但如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时就会误以为它的值没有发生变化，这个问题称为ABA问题。ABA问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加一，那么A-B-A就会变成1A-2B-3A，以此来防止不恰当的写入。 两种锁的适用场景乐观锁适用于写比较少的情况下（多读场景），即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。但如果是多写的情况，一般会经常产生冲突，这就会导致上层应用会不断的进行重试，这样反倒是降低了性能，所以一般多写的场景下用悲观锁比较合适。 关系型数据库设计函数依赖部分函数依赖设X、Y是关系R的两个属性集合，存在X→Y，若X’是X的真子集，存在X’→Y，则称Y部分函数依赖于X。 完全函数依赖设X、Y是关系R的两个属性集合，X’是X的真子集，存在X→Y，但对每一个X’都有X’ !→Y，则称Y完全函数依赖于X。 传递函数依赖设X、Y、Z是关系R中互不相同的属性集合，存在X→Y（Y !→X），Y→Z，则称Z传递函数依赖于X。 范式第一范式（1NF）在任何一个关系数据库中，第一范式（1NF）是对关系模式的基本要求，不满足第一范式（1NF）的数据库就不是关系数据库。 所谓第一范式（1NF）是指数据库表的每一列（每个属性）都是不可分割的基本数据项，同一列中不能有多个值，即实体中的某个属性不能有多个值或者不能有重复的属性。简而言之，第一范式就是无重复的列。 第二范式（2NF）第二范式（2NF）要求实体的属性完全依赖于主关键字。 第三范式（3NF）在满足第二范式的基础上，且不存在传递函数依赖，那么就是第三范式。简而言之，第三范式就是属性不依赖于其它非主属性。 ER图ER图由三个部分组成：实体、属性、联系。 参考资料 CS-NOTE 数据库锁分类和总结 面试必备之乐观锁与悲观锁 并发策略-CAS算法]]></content>
      <categories>
        <category>数据库</category>
        <category>数据库原理</category>
      </categories>
      <tags>
        <tag>锁</tag>
        <tag>事务</tag>
        <tag>范式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[最短路径问题—Dijkstra算法及相关例题]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E9%97%AE%E9%A2%98%E2%80%94Dijkstra%E7%AE%97%E6%B3%95%E5%8F%8A%E7%9B%B8%E5%85%B3%E4%BE%8B%E9%A2%98%2F</url>
    <content type="text"><![CDATA[最近在做算法题的时候总是遇到Dijkstra相关的题目，之前虽然学过图论的一些算法，但第一次做这类题时完全不知从何入手。看了一些博客，并且在PAT上折腾了几题后，发现一些常用的模板与套路，因此在这里进行一个总结。关于Dijkstra的理论知识可以参考这篇博客：最短路径问题-Dijkstra算法详解 Dijkstra算法Dijkstra算法往往和dfs结合在一起考，因此这里给出一个求解基础Dijkstra+dfs相关题目的大致模板： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485public class Main &#123; static int n; //节点数 static int m; //边数 static int C1; //起始点 static int C2; //终点 static int[][] e;//边权 static int[] weight; //点权（非必需，视题目而定） static int[] dis; //到起始点的最短路径长 static boolean[] visit; //是否访问过 static ArrayList&lt;Integer&gt;[] pre; //可构成最短路径的前一个节点 static LinkedList&lt;Integer&gt; tempPath = new LinkedList&lt;Integer&gt;(); //可能的最短路径 static LinkedList&lt;Integer&gt; path = new LinkedList&lt;Integer&gt;(); //最短路径 public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); n = sc.nextInt(); m = sc.nextInt(); C1 = sc.nextInt(); C2 = sc.nextInt(); visit = new boolean[n]; weight = new int[n]; for(int i = 0; i &lt; n; i++) &#123; weight[i] = sc.nextInt(); &#125; e = new int[n][n]; for(int i = 0; i &lt; n; i++) &#123; for(int j = 0; j &lt; n; j++) &#123; e[i][j] = e[j][i] = Integer.MAX_VALUE; &#125; &#125; for(int i = 0; i &lt; m; i++) &#123; int c1 = sc.nextInt(); int c2 = sc.nextInt(); e[c1][c2] = e[c2][c1] = sc.nextInt(); &#125; dis = new int[n]; for(int i = 0; i &lt; n; i++) &#123; dis[i] = Integer.MAX_VALUE; &#125; dis[C1] = 0; pre = new ArrayList[n]; for(int i = 0; i &lt; n; i++) &#123; pre[i] = new ArrayList&lt;&gt;(); &#125; /**************以上为初始化****************/ for(int i = 0; i &lt; n; i++) &#123; int u = -1, min = Integer.MAX_VALUE; for(int j = 0; j &lt; n; j++) &#123; if(!visit[j] &amp;&amp; dis[j] &lt; min) &#123; min = dis[j]; u = j; &#125; &#125; if(u == -1) break; visit[u] = true; for(int v = 0; v &lt; n; v++) &#123; if(!visit[v] &amp;&amp; e[u][v] != Integer.MAX_VALUE) &#123; if(dis[v] &gt; dis[u] + e[u][v]) &#123; dis[v] = dis[u] + e[u][v]; pre[v].clear(); pre[v].add(u); &#125; else if(dis[v] == dis[u] + e[u][v]) &#123; pre[v].add(u); &#125; &#125; &#125; &#125; //至此已经找到多个最短路径，下面的dfs算法将在多个最短路径中找到最终解 dfs(C2); &#125; private static void dfs(int v) &#123; tempPath.push(v); if(v == C1) &#123; //此处进行一些判断，在多个最短路径中确认最终解 tempPath.pop(); return; &#125; for(int i = 0; i &lt; pre[v].size(); i++) dfs(pre[v].get(i)); tempPath.pop(); &#125;&#125; Emergency题目链接：1003 Emergency 此题要求求出两点之间的最短路径，如果存在多条最短路径，那么就选择点权和最大的路径。这里的代码和上面模板几乎一模一样，做题时都需要考虑点权。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798public class Main &#123; private static int n; private static int m; private static int C1; private static int C2; private static int[][] e; private static int[] weight; private static int[] dis; private static boolean[] visit; private static int max = Integer.MIN_VALUE; private static ArrayList&lt;Integer&gt;[] pre; private static LinkedList&lt;Integer&gt; tempPath = new LinkedList&lt;Integer&gt;(); private static LinkedList&lt;Integer&gt; path = new LinkedList&lt;Integer&gt;(); private static int cnt = 0; public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); n = sc.nextInt(); m = sc.nextInt(); C1 = sc.nextInt(); C2 = sc.nextInt(); visit = new boolean[n]; weight = new int[n]; for(int i = 0; i &lt; n; i++) &#123; weight[i] = sc.nextInt(); &#125; e = new int[n][n]; for(int i = 0; i &lt; n; i++) &#123; for(int j = 0; j &lt; n; j++) &#123; e[i][j] = e[j][i] = Integer.MAX_VALUE; &#125; &#125; for(int i = 0; i &lt; m; i++) &#123; int c1 = sc.nextInt(); int c2 = sc.nextInt(); e[c1][c2] = e[c2][c1] = sc.nextInt(); &#125; dis = new int[n]; for(int i = 0; i &lt; n; i++) &#123; dis[i] = Integer.MAX_VALUE; &#125; dis[C1] = 0; pre = new ArrayList[n]; for(int i = 0; i &lt; n; i++) &#123; pre[i] = new ArrayList&lt;&gt;(); &#125; /**********************************************/ for(int i = 0; i &lt; n; i++) &#123; int u = -1, min = Integer.MAX_VALUE; for(int j = 0; j &lt; n; j++) &#123; if(!visit[j] &amp;&amp; dis[j] &lt; min) &#123; min = dis[j]; u = j; &#125; &#125; if(u == -1) break; visit[u] = true; for(int v = 0; v &lt; n; v++) &#123; if(!visit[v] &amp;&amp; e[u][v] != Integer.MAX_VALUE) &#123; if(dis[v] &gt; dis[u] + e[u][v]) &#123; dis[v] = dis[u] + e[u][v]; pre[v].clear(); pre[v].add(u); &#125; else if(dis[v] == dis[u] + e[u][v]) &#123; pre[v].add(u); &#125; &#125; &#125; &#125; /***********************************************/ dfs(C2); System.out.printf("%d %d", cnt, max); &#125; private static void dfs(int v) &#123; tempPath.push(v); if(v == C1) &#123; int a = 0; for(int i = 0; i &lt; tempPath.size(); i++) &#123; a += weight[tempPath.get(i)]; &#125; if(a &gt; max) &#123; max = a; path = new LinkedList&lt;&gt;(tempPath); &#125; cnt++; tempPath.pop(); return; &#125; for(int i = 0; i &lt; pre[v].size(); i++) dfs(pre[v].get(i)); tempPath.pop(); &#125;&#125; 事实上，我们也可以不使用DFS，而在执行Dijkstra就完成最大点权和的判断: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273public class Main &#123; private static int n; //城市数 private static int m; //路径数 private static int c1; //源城市 private static int c2; //目标城市 private static int[][] e; //边长 private static int[] dis; //从出发点到当前节点的最短路径 private static int[] nums; //从出发点到当前节点最短路径的数目 private static int[] w; //从出发点到当前节点救援对数目之和 private static int[] weight; //当前节点的救援队数目 private static boolean[] visit; public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); n = sc.nextInt(); m = sc.nextInt(); c1 = sc.nextInt(); c2 = sc.nextInt(); weight = new int[n]; e = new int[n][n]; dis = new int[n]; nums = new int[n]; w = new int[n]; visit = new boolean[n]; for(int i = 0; i &lt; n; i++) &#123; weight[i] = sc.nextInt(); &#125; for(int i = 0; i &lt; n; i++) &#123; for(int j = 0; j &lt; n; j++) &#123; e[i][j] = Integer.MAX_VALUE; &#125; &#125; for(int i = 0; i &lt; m; i++) &#123; int s = Integer.valueOf(sc.nextInt()); int d = Integer.valueOf(sc.nextInt()); e[s][d] = e[d][s] = Integer.valueOf(sc.nextInt()); &#125; for(int i = 0; i &lt; n; i++) &#123; dis[i] = Integer.MAX_VALUE; &#125; dis[c1] = 0; nums[c1] = 1; w[c1] = weight[c1]; /******************************************/ for(int i = 0; i &lt; n; i++) &#123; int u = -1, min = Integer.MAX_VALUE; for(int j = 0; j &lt; n; j++) &#123; if(!visit[j] &amp;&amp; dis[j] &lt; min) &#123; u = j; min = dis[j]; &#125; &#125; if(u == -1) break; visit[u] = true; for(int v = 0; v &lt; n; v++) &#123; if(!visit[v] &amp;&amp; e[u][v] != Integer.MAX_VALUE) &#123; if(dis[u] + e[u][v] &lt; dis[v]) &#123; dis[v] = dis[u] + e[u][v]; nums[v] = nums[u]; w[v] = w[u] + weight[v]; &#125; else if(dis[u] + e[u][v] == dis[v]) &#123; nums[v] += nums[u]; w[v] = w[u] + weight[v] &gt; w[v] ? w[u] + weight[v] : w[v]; &#125; &#125; &#125; &#125; System.out.printf("%d %d", nums[c2], w[c2]); &#125;&#125; Travel Plan题目链接：1030 Travel Plan 这题对比上题是将点权换成了边权，先通过Dijkstra算法求出多条最短路径，然后用DFS找到最短路径中边权（此题中就是cost）最小的那条路径。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104public class Main &#123; private static int n; private static int m; private static int s; private static int d; private static int[][] e; private static int[][] cost; private static int[] dis; private static boolean[] visit; private static ArrayList&lt;Integer&gt;[] pre; private static LinkedList&lt;Integer&gt; tempPath = new LinkedList&lt;&gt;(); private static LinkedList&lt;Integer&gt; path = new LinkedList&lt;&gt;(); private static int min = Integer.MAX_VALUE; public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); n = sc.nextInt(); m = sc.nextInt(); s = sc.nextInt(); d = sc.nextInt(); visit = new boolean[n]; e = new int[n][n]; cost = new int[n][n]; for(int i = 0; i &lt; n; i++) &#123; for(int j = 0; j &lt; n; j++) &#123; e[i][j] = e[j][i] = Integer.MAX_VALUE; cost[i][j] = cost[j][i] = Integer.MAX_VALUE; &#125; &#125; for(int i = 0; i &lt; m; i++) &#123; int i1 = sc.nextInt(); int i2 = sc.nextInt(); e[i1][i2] = e[i2][i1] = sc.nextInt(); cost[i1][i2] = cost[i2][i1] = sc.nextInt(); &#125; dis = new int[n]; for(int i = 0; i &lt; n; i++) &#123; dis[i] = Integer.MAX_VALUE; &#125; dis[s] = 0; pre = new ArrayList[n]; for(int i = 0; i &lt; n; i++) &#123; pre[i] = new ArrayList&lt;&gt;(); &#125; /***********************************************/ for(int i = 0; i &lt; n; i++) &#123; int u = -1, min = Integer.MAX_VALUE; for(int j = 0; j &lt; n; j++) &#123; if(!visit[j] &amp;&amp; dis[j] &lt; min) &#123; min = dis[j]; u = j; &#125; &#125; if(u == -1) break; visit[u] = true; for(int v = 0; v &lt; n; v++) &#123; if(!visit[v] &amp;&amp; e[u][v] != Integer.MAX_VALUE) &#123; if(dis[v] &gt; dis[u] + e[u][v]) &#123; dis[v] = dis[u] + e[u][v]; pre[v].clear(); pre[v].add(u); &#125; else if(dis[v] == dis[u] + e[u][v]) &#123; pre[v].add(u); &#125; &#125; &#125; &#125; /**********************************************/ ArrayList&lt;Integer&gt;[] temppre = pre; dfs(d); for(int i = 0; i &lt; path.size(); i++) &#123; System.out.print(path.get(i) + " "); &#125; System.out.print(dis[d] + " "); System.out.print(min); &#125; private static void dfs(int v) &#123; tempPath.push(v); if(v == s) &#123; int c = 0; for(int i = 1; i &lt; tempPath.size(); i++) &#123; c += cost[tempPath.get(i)][tempPath.get(i-1)]; &#125; if(c &lt; min) &#123; min = c; path = new LinkedList&lt;&gt;(tempPath); &#125; tempPath.pop(); return; &#125; for(int i = 0; i &lt; pre[v].size(); i++) dfs(pre[v].get(i)); tempPath.pop(); &#125;&#125; All Roads Lead to Rome题目链接：1087 All Roads Lead to Rome 这题和上面两题也没什么不同，基本思路是一样的，只不过题目输入的是城市的名称也就是字符串，并且输出也要用城市的名称，我们直接用map来存储城市名与下标的映射即可。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112public class Main &#123; private static int[][] e; private static int[] dis; private static int[] weight; private static boolean[] visit; private static int n; private static int k; private static HashMap&lt;Integer, String&gt; map1; private static HashMap&lt;String, Integer&gt; map2; private static LinkedList&lt;Integer&gt; path = new LinkedList&lt;&gt;(); private static LinkedList&lt;Integer&gt; tempPath = new LinkedList&lt;&gt;(); private static ArrayList&lt;Integer&gt;[] pre; private static int max = Integer.MIN_VALUE; private static int avg = Integer.MIN_VALUE; private static int cnt = 0; public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); String[] line1 = sc.nextLine().split(" "); n = Integer.valueOf(line1[0]); k = Integer.valueOf(line1[1]); map1 = new HashMap&lt;&gt;(); map2 = new HashMap&lt;&gt;(); map1.put(0, line1[2]); map2.put(line1[2], 0); weight = new int[n]; for(int i = 1; i &lt; n; i++) &#123; String[] line = sc.nextLine().split(" "); map1.put(i, line[0]); map2.put(line[0], i); weight[i] = Integer.valueOf(line[1]); &#125; e = new int[n][n]; for(int i = 0; i &lt; e.length; i++) &#123; for(int j = 0; j &lt; e.length; j++) &#123; e[i][j] = e[j][i] = Integer.MAX_VALUE; &#125; &#125; for(int i = 0; i &lt; k; i++) &#123; String[] line = sc.nextLine().split(" "); int c1 = map2.get(line[0]); int c2 = map2.get(line[1]); e[c1][c2] = e[c2][c1] = Integer.valueOf(line[2]); &#125; dis = new int[n]; dis[0] = 0; for(int i = 1; i &lt; n; i++) &#123; dis[i] = Integer.MAX_VALUE; &#125; visit = new boolean[n]; pre = new ArrayList[n]; for(int i = 0; i &lt; n; i++) &#123; pre[i] = new ArrayList&lt;&gt;(); &#125; for(int i = 0; i &lt; n; i++) &#123; int u = -1, min = Integer.MAX_VALUE; for(int j = 0; j &lt; n; j++) &#123; if(!visit[j] &amp;&amp; dis[j] &lt; min) &#123; u = j; min = dis[j]; &#125; &#125; if(u == -1) break; visit[u] = true; for(int v = 0; v &lt; n; v++) &#123; if(!visit[v] &amp;&amp; e[u][v] != Integer.MAX_VALUE) &#123; if(dis[u] + e[u][v] &lt; dis[v]) &#123; dis[v] = dis[u] + e[u][v]; pre[v].clear(); pre[v].add(u); &#125; else if(dis[u] + e[u][v] == dis[v]) &#123; pre[v].add(u); &#125; &#125; &#125; &#125; dfs(map2.get("ROM")); System.out.printf("%d %d %d %d\n", cnt, dis[map2.get("ROM")], max, avg); System.out.print(map1.get(0)); for(int i = 1; i &lt; path.size(); i++) &#123; System.out.print("-&gt;" + map1.get(path.get(i))); &#125; &#125; private static void dfs(int v) &#123; tempPath.push(v); if(v == 0) &#123; int happy = 0; int average = 0; for(int i = 1; i &lt; tempPath.size(); i++) &#123; happy += weight[tempPath.get(i)]; &#125; average = happy / (tempPath.size()-1); if(happy &gt; max) &#123; max = happy; avg = average; path = new LinkedList&lt;&gt;(tempPath); &#125; else if(happy == max &amp;&amp; average &gt; avg) &#123; avg = average; path = new LinkedList&lt;&gt;(tempPath); &#125; cnt++; tempPath.pop(); return; &#125; for(int i = 0; i &lt; pre[v].size(); i++) dfs(pre[v].get(i)); tempPath.pop(); &#125;&#125; 至此，简单的Dijkstra题都可以套用上述模板很容易地做出来，当然平时做题时还是需要根据具体题目灵活变通，以上代码只是将其思路梳理了一遍，在实现上也依然存在许多可以优化的地方。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>Dijkstra</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用查找算法之散列表]]></title>
    <url>%2F2019%2F01%2F28%2F%E5%B8%B8%E7%94%A8%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95%E4%B9%8B%E6%95%A3%E5%88%97%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[前言散列表类似于数组，可以把散列表的散列值看成数组的索引值。访问散列表和访问数组元素一样快速，它可以在常数时间内实现查找和插入操作。使用散列的查找算法分为两步：用散列函数将被查找的键转化为数组的一个索引；处理碰撞冲突。 散列函数要为一个数据类型实现优秀的散列方法需要满足三个条件： 一致性：等价的键必然产生相等的散列值。 高效性：计算简便。 均匀性：均匀的散列所有的键。 对于一致性，在Java中意味着每一种数据类型的hashCode()方法都必须和equals()方法一致。也就是说，如果a.equals(b)返回true，那么a.hashCode()和b.hashCode()的返回值必然相同。但要注意，如果a.hashCode()和b.hashCode()的返回值相同，a.equals(b)不一定返回true。 保证均匀性的最好办法就是保证键的每一位都在散列值的计算中起到了相同的作用，而常见的错误就是忽略了键的高位。在jdk的HashMap中，为了保证均匀性将默认散列函数得到的散列值与其高16位进行异或运算重新得到新的散列值。 为了将一个32位的整数散列值转换成数组的索引，我们在实现中还要将散列值和除留余数法结合起来产生一个0到M-1（M代表数组的大小）的整数。这在HashMap中是通过这行代码实现的：hash &amp; (table.length - 1)。 碰撞处理基于拉链法的散列表拉链法是将大小为M的数组中的每个元素指向一条链表，链表中的每个节点都存储了散列值为该元素的索引的键值对。基于拉链法的查找分为两步：首先根据散列值找到对应的链表，然后沿着链表顺序查找相应的键。 在实现基于拉链法的散列表时，要选择适当的数组大小M，既不会因为空链表而浪费大量内存，也不会因为链表太长而在查找上浪费太多时间。 基于线性探测法的散列表实现散列表的另一种方式就是用大小为M的数组保存N个键值对，其中M&gt;N。我们需要依靠数组中的空位解决碰撞冲突，基于这种策略的所有方法被统称为开放地址散列表。 开放地址散列表中最简单的方法叫做线性探测法。我们在实现中使用并行数组，一个保存键，一个保存值。 12345678910111213141516171819202122232425262728293031323334public class LinearProbingHashST&lt;Key, Value&gt; &#123; private static final int INIT_CAPACITY = 4; private int n; //符号表中键值对的总数 private int m; //线性探测表的大小 private Key[] keys; //键 private Value[] vals; //值 public LinearProbingHashST() &#123; this(INIT_CAPACITY); &#125; public LinearProbingHashST(int capacity) &#123; m = capacity; n = 0; keys = (Key[]) new Object[m]; vals = (Value[]) new Object[m]; &#125; private int hash(Key key) &#123; return (key.hashCode() &amp; 0x7fffffff) % m; &#125; //实现见下文 private void resize(int capacity) //实现见下文 public void put(Key key, Value val) //实现见下文 public Value get(Key key) //实现见下文 public void delete(Key key) 查找要查找一个键，我们从它的散列值开始顺序查找，如果找到则命中，否则直接检查散列表中的下一个位置（将索引值加1），直到找到该键或者遇到一个空元素。 123456public Value get(Key key) &#123; for (int i = hash(key); keys[i] != null; i = (i + 1) % m) if (keys[i].equals(key)) return vals[i]; return null;&#125; 插入如果新建的散列值是一个空元素，那么就将它保存在那里；如果不是，我们就顺序查找一个空元素来保存它。 1234567891011121314public void put(Key key, Value val) &#123; if (n &gt;= m/2) resize(2*m); int i; for (i = hash(key); keys[i] != null; i = (i + 1) % m) &#123; if (keys[i].equals(key)) &#123; vals[i] = val; return; &#125; &#125; keys[i] = key; vals[i] = val; n++;&#125; 删除直接将要删除的键所在的位置设为null是不行的，因为这会使在此位置之后的元素无法被查找。因此，我们需要将簇中被删除键的右侧的所有键重新插入散列表。 1234567891011121314151617181920212223242526public void delete(Key key) &#123; int i = hash(key); while (keys[i] != null &amp;&amp; !key.equals(keys[i])) i = (i + 1) % M; // 不存在则直接返回 if (keys[i] == null) return; keys[i] = null; values[i] = null; // 将之后相连的键值对重新插入 i = (i + 1) % M; while (keys[i] != null) &#123; Key keyToRedo = keys[i]; Value valToRedo = values[i]; keys[i] = null; values[i] = null; N--; put(keyToRedo, valToRedo); i = (i + 1) % M; &#125; N--; //如果键值对太小，我们就将数组的大小减半 if (n &gt; 0 &amp;&amp; n &lt;= m/8) resize(m/2);&#125; 为了保证性能，我们会动态调整数组的大小来保证使用率在1/8到1/2之间。 调整数组大小线性探测法的成本取决于连续条目的长度，连续条目也叫聚簇。当聚簇很长时，在查找和插入时需要进行很多次探测。为了保证散列表的性能，应当动态调整数组的大小，使得散列表的使用率不超过1/2。 1234567891011private void resize(int capacity) &#123; LinearProbingHashST&lt;Key, Value&gt; temp = new LinearProbingHashST&lt;Key, Value&gt;(capacity); for (int i = 0; i &lt; m; i++) &#123; if (keys[i] != null) &#123; temp.put(keys[i], vals[i]); &#125; &#125; keys = temp.keys; vals = temp.vals; m = temp.m;&#125; 以上实现会将原表中所有的键重新散列并插入到新表中。 参考资料 Algorithms (Fourth Edition) CS-Notes 算法]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>HashMap</tag>
        <tag>查找</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[树的前中后层序遍历（递归与非递归方式）]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%A0%91%E7%9A%84%E5%89%8D%E4%B8%AD%E5%90%8E%E5%B1%82%E5%BA%8F%E9%81%8D%E5%8E%86%EF%BC%88%E9%80%92%E5%BD%92%E4%B8%8E%E9%9D%9E%E9%80%92%E5%BD%92%E6%96%B9%E5%BC%8F%EF%BC%89%2F</url>
    <content type="text"><![CDATA[DescriptionLeetCode的第590题与429、589题型类似，都为树（不一定是二叉树）的各种形式的遍历，因此放在一起总结。 对于上图，要求求出前序遍历、后序遍历和层级遍历的结果。 Example12345678前序遍历结果：[1,3,5,6,2,4]后序遍历结果：[5,6,3,2,4,1]层级遍历结果：[ [1], [3,2,4], [5,6]] Analysis对于树我们一般有两种策略： 广度优先搜索（BFS）：从上到下一层一层的遍历树 ，也就是题目要求的层级遍历。 深度优先搜索（DFS）：从一个根节点开始，一直到达某个叶子节点，然后回到根节点到达另一个分支的叶子节点。根据根节点、左节点和右节点之间的相对顺序，DFS策略可以进一步区分为前序、中序和后序。 根据深度优先搜索与广度优先搜索可以整理出下图的四种情况： Solution对于第一题求前序遍历，我们可以使用递归或者循环来完成，实际上这三道题都是如此。我们先看看递归版本： 12345678910111213141516171819public class Solution &#123; List&lt;Integer&gt; list; public List&lt;Integer&gt; preorder(Node root) &#123; list = new ArrayList&lt;&gt;(); if(root == null) return list; preorderCore(root); return list; &#125; private void preorderCore(Node root) &#123; if(root == null) return; list.add(root.val); for(Node node : root.children) preorderCore(node); &#125;&#125; 前序遍历就是先将根节点放入结果列表中，然后再将左右子节点放入。递归的解法较为简单，下面看看循环的解法： 123456789101112131415161718public class Solution2 &#123; public List&lt;Integer&gt; preorder(Node root) &#123; LinkedList&lt;Integer&gt; res = new LinkedList&lt;&gt;(); if(root == null) return res; Stack&lt;Node&gt; stack = new Stack&lt;&gt;(); stack.push(root); while(!stack.isEmpty()) &#123; Node node = stack.pop(); res.add(node.val); Collections.reverse(node.children); for(Node children : node.children) &#123; stack.push(children); &#125; &#125; return res; &#125;&#125; 在递归中我们使用栈来保存接下来要访问的节点。首先我们将根节点压入栈，栈中元素为[1]，然后我们将它弹出至结果列表并把它的子节点翻转并放入栈，此时栈中元素为[4, 2, 3]；由于栈顶元素为3，因此将3弹出至结果列表并把它的子节点翻转并放入栈，此时栈中元素为[4, 2, 6, 5]；栈顶元素为5，因此将5弹出至结果列表，5没有子节点，再把6弹出至结果列表。如此反复，我们便可以通过这种方式得到前序遍历的结果列表[1, 3, 5, 6, 2, 4]。 求后序遍历与这题异曲同工，同样先看看递归版本： 123456789101112131415161718public class Solution &#123; List&lt;Integer&gt; list; public List&lt;Integer&gt; postorder(Node root) &#123; list = new ArrayList&lt;&gt;(); if(root == null) return list; postorderCore(root); return list; &#125; private void postorderCore(Node root) &#123; if(root == null) return; for(Node node : root.children) postorderCore(node); list.add(root.val); &#125;&#125; 我们仅仅将list.add(root.val); 这行代码放到了遍历子节点的for语句之后，意味着先将所有子节点加入结果列表，最后再将根节点加入结果列表。下面是使用循环的解法： 123456789101112131415161718public class Solution2 &#123; public List&lt;Integer&gt; postorder(Node root) &#123; LinkedList&lt;Integer&gt; res = new LinkedList&lt;&gt;(); if(root == null) return res; Stack&lt;Node&gt; stack = new Stack&lt;&gt;(); stack.push(root); while(!stack.isEmpty()) &#123; Node node = stack.pop(); res.addFirst(node.val); for(Node children : node.children) &#123; stack.push(children); &#125; &#125; return res; &#125;&#125; 与前序遍历不同的是我们不需要翻转子节点列表，但是每次将结果添加到结果列表头而不是尾。 第三题是层序遍历（广度优先搜索），不像上面两题用递归实现更加简单，我们通过循环来实现会更加简洁明了，思路是使用一个队列而非栈来保存每一层节点： 12345678910111213141516171819public class Solution &#123; public List&lt;List&lt;Integer&gt;&gt; levelOrder(Node root) &#123; List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;(); if(root == null) return res; Queue&lt;Node&gt; queue = new LinkedList&lt;&gt;(); queue.add(root); while(!queue.isEmpty()) &#123; int size = queue.size(); List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); while(size-- != 0) &#123; Node node = queue.poll(); for(Node children : node.children) queue.add(children); list.add(node.val); &#125; res.add(list); &#125; return res; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>树的遍历</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用查找算法之B/B+树]]></title>
    <url>%2F2019%2F01%2F28%2F%E5%B8%B8%E7%94%A8%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95%E4%B9%8BB-B-%E6%A0%91%2F</url>
    <content type="text"><![CDATA[前言从算法逻辑上讲二叉查找树的查找和插入操作效率都已经很高，但是在实际应用中由于我们不能将整个索引表加载到内存，只能逐一加载每个磁盘页，这里的磁盘页就对应着索引树的节点。因此我们要将原本“瘦高”的树结构变得“矮胖”，从而减少磁盘IO的次数。 B- 树B-树是一种多路平衡查找树，是对2-3树的一个扩展。一个m阶的B树（m的大小取决于磁盘页的大小）具有如下几个特征： 根结点至少有两个子女。 每个中间节点都包含k-1个元素和k个孩子，其中 k ∈ [m/2, m] 每一个叶子节点都包含k-1个元素，其中 k ∈ [m/2, m] 所有的叶子结点都位于同一层。 每个节点中的元素从小到大排列，节点当中k-1个元素正好是k个孩子包含的元素的值域分划。 查找下图以一个3阶B-树为例，第一次磁盘IO并在内存中和9比较： 第二次磁盘IO并在内存中和2、6比较： 第三次磁盘IO并在内存中和3、5比较： 单从比较次数来说B树相比二叉查找树并不占优势，但由于节点中存储着多个元素，因此它的磁盘IO次数比二叉查找树少很多，而内存中的比较耗时几乎可以忽略，因此查找性能也就比二叉查找树更好。 插入以插入元素4为例，自顶向下查找4的节点位置，发现4应当插入到节点元素3，5之间，而由于此B-树是3阶的，每个节点最多能有2个元素，因此该节点无法再增加，而其父节点也含有两个元素，根节点只有一个元素。 于是拆分节点3，5与节点2，6，让根节点9升级为两元素节点4，9。节点6独立为根节点的第二个孩子。 删除以删除元素11为例，先自顶向下查找元素11的节点位置。 删除11后，节点12只有一个孩子，不符合B树规范。因此找出12,13,15三个节点的中位数13，取代节点12，而节点12自身下移成为第一个孩子（左旋操作）。 B+ 树B+树是B-树的一个变体，有着比B-树更高的查询性能。一个m阶的B+树（m的大小取决于磁盘页的大小）具有如下几个特征： 有k个子树的中间节点包含有k个元素（B-树中是k-1个元素），每个元素不保存数据，只用来索引，所有数据都保存在叶子节点。 所有的叶子结点中包含了全部元素的信息，及指向含这些元素记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。 所有的中间节点元素都同时存在于子节点，在子节点元素中是最大（或最小）元素。 注意，根节点的最大元素（上图中是15）等同于整个B+树的最大元素；由于父节点的元素都出现在子节点，因此所有叶子节点包含了全量元素信息，并且每一个叶子节点都带有指向下一个节点的指针，形成了一个有序链表。 查找在B-树中，无论中间节点还是叶子节点都带有卫星数据（索引元素所指向的数据记录），而Ｂ+树中间节点没有卫星数据，只有索引，这就意味着同样大小的磁盘页可以容纳更多节点元素，在相同的数据量下，B+树更加“矮胖”，IO操作更少。 下图以查找元素3为例，第一次磁盘IO： 第二次磁盘IO： 第三次磁盘IO： B+树除了比B树更加“矮胖”这一点不同外，由于B+树的查询必须最终查找到叶子节点，而B-树中无论匹配元素处于中间节点还是叶子节点只要找到匹配元素即可，所以B+树的查找性能是稳定的，而B-树的查找性能不稳定（最好情况是只查根节点，最坏情况是查到叶子节点）。 范围查找由于B+树的叶子节点构成了一条有序链表，因此B+树的范围查找比B-树简单得多，下面以查询范围为3到11的元素为例。 自顶向下，查找到范围的下限3： 通过链表指针，遍历到元素6、8： 通过链表指针，遍历到元素9、11，遍历结束： 总结为了减少磁盘IO的次数，必须降低树的深度，将“瘦高”的树变得“矮胖，使得磁盘页可以容纳更多节点元素，因此出现了B-树。B+树是B-树的变体，相比B-树有以下优势： 单一节点存储更多的元素，使得查询的IO次数更少。 所有查询都要查找到叶子节点，查询性能稳定。 所有叶子节点形成有序链表，便于范围查询。 除了B-树和B+树，平时还会听到有B*树的概念，同样B*树是B+树的一个变体，相比B+树的不同之处如下： 将结点的最低利用率从1/2提高到2/3。 在B+树基础上，为非叶子结点也增加链表指针：B+树当一个结点满时，会分配一个新的结点，并将原结点中1/2的数据复制到新结点，最后在父结点中增加新结点的指针；B*树当一个结点满时，如果它的下一个兄弟结点未满，那么将一部分数据移到兄弟结点中，而如果兄弟也满了，则在原结点与兄弟结点之间增加新结点，并各复制1/3的数据到新结点，最后在父结点增加新结点的指针。 参考资料 漫画：什么是B-树？ 漫画：什么是B+树？]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>B树</tag>
        <tag>查找</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用查找算法之红黑树]]></title>
    <url>%2F2019%2F01%2F28%2F%E5%B8%B8%E7%94%A8%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BA%A2%E9%BB%91%E6%A0%91%2F</url>
    <content type="text"><![CDATA[前言二叉查找树对于大多数情况下的查找和插入操作在效率上来说是没有问题的，但是在最差的情况下会达到线性级别，其效率取决于插入顺序。平衡查找树的数据结构能够保证在最差的情况下也能是对数级别，要实现这一目标我们需要保证树在插入完成之后始终保持平衡状态。 2-3查找树在学习红黑树之前要先了解2-3查找树作为基础，一棵2-3查找树或为一棵空树，或由以下节点组成： 2-节点：含有一个键值对和两条链接，左链接指向的2-3树中的键都小于该节点，右链接指向的2-3树中的键都大于该节点。 3-节点：含有两个键值对和三条链接，左链接指向的2-3树中的键都小于该节点，中链接指向的2-3树中的键都位于该节点的两个键之间，右链接指向的2-3树中的键都大于该节点。 指向一棵空树的链接称为空链接，一棵完美平衡的2-3查找树的所有空链接到根节点的距离应该是相同的。 查找要判断一个键是否在树中，我们先将它和根节点中的键比较。如果它和其中任意一个相等，查找命中；否则我们就根据比较的结果找到指向相应区间的链接，并在其指向的子树中递归地继续查找。如果这是个空链接，查找未命中。 插入 如果插入到2-节点上，那么直接将新节点和原来的节点组成3-节点即可。 如果是插入到3-节点上，就会产生一个临时4-节点时，需要将4-节点分裂成3个2-节点，并将中间的2-节点移到上层节点中。如果上移操作继续产生临时4-节点则一直进行分裂上移，直到不存在临时4-节点。 如果从插入节点到根节点的路径上全都是3-节点，我们的根节点最终变成一个临时的4-节点，此时我们将临时的4-节点分解为3个2-节点，使得树高加一。这次最后的变换仍然保持了树的完美平衡性，因为它变换的是根节点。 构造轨迹二叉查找树是由上向下生长的，而2-3树的生长是由下向上的。 红黑树2-3查找树实现起来十分复杂，因此我们使用一种名为红黑二叉查找树的简单数据结构来表达并实现它。 我们将树中的链接分为两种类型：红链接将两个2-节点连接起来构成一个3-节点，黑链接则是2-3树中的普通链接。 红黑树有以下性质: 红链接均为左链接。 没有任何一个节点同时和两条红链接相连。 红黑树是完美黑色平衡的，即任意空链接到根节点的路径上的黑链接数量相同。 如果我们将由红链接相连的节点合并，得到的就是一棵2-3树： 基本实现我们将由父节点指向自己的链接的颜色保存在表示节点的Node数据类型的布尔变量Color中。如果是红色则为true，黑色则为false。 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class RedBlackBST&lt;Key extends Comparable&lt;Key&gt;, Value&gt; &#123; private static final boolean RED = true; private static final boolean BLACK = false; private Node root; private class Node &#123; private Key key; private Value val; private Node left, right; private boolean color; //由其父节点指向它的链接的颜色 private int size; //这棵子树中的节点总数 public Node(Key key, Value val, boolean color, int size) &#123; this.key = key; this.val = val; this.color = color; this.size = size; &#125; &#125; public int size() &#123; return size(root); &#125; private int size(Node x) &#123; if (x == null) return 0; return x.size; &#125; private boolean isRed(Node x) &#123; if (x == null) return false; return x.color == RED; &#125; //实现见下文 private Node rotateLeft(Node h) //实现见下文 private Node rotateRight(Node h) //实现见下文 private void flipColors(Node h)&#125; 旋转假设我们有一条红色的右链接需要被转化为左链接，我们要进行左旋转。同理，也有右旋转。 1234567891011121314151617181920212223//左旋转 private Node rotateLeft(Node h) &#123; Node x = h.right; h.right = x.left; x.left = h; x.color = x.left.color; x.left.color = RED; x.size = h.size; h.size = size(h.left) + size(h.right) + 1; return x; &#125;//右旋转private Node rotateRight(Node h) &#123; Node x = h.left; h.left = x.right; x.right = h; x.color = x.right.color; x.right.color = RED; x.size = h.size; h.size = size(h.left) + size(h.right) + 1; return x; &#125; 颜色转换一个4-节点在红黑树中表现为一个节点的左右子节点都是红色的。分裂4- 节点除了需要将子节点的颜色由红变黑之外，同时需要将父节点的颜色由黑变红，从2-3树的角度看就是将中间节点移到上层节点。 12345private void flipColors(Node h) &#123; h.color = !h.color; h.left.color = !h.left.color; h.right.color = !h.right.color;&#125; 插入先将一个节点按二叉查找树的方法插入到正确位置，然后在沿着插入点到根节点的路径向上移动时，在所经过的每个节点中顺序完成如下操作： 如果右子节点是红色的而左子节点是黑色的，进行左旋转； 如果左子节点是红色的，而且左子节点的左子节点也是红色的，进行右旋转； 如果左右子节点均为红色的，进行颜色转换，将红链接在树中向上传递。 颜色转换会使根节点变为红色，但根节点并没有父节点，因此在每次插入后都将根节点设为黑色。注意，每当根节点由红变黑时树的黑链接高度就会加一，因为这意味着它由一个4-节点分裂出去成为2-节点了。 12345678910111213141516171819202122public void put(Key key, Value val) &#123; //查找key，找到则更新其值，否则为它新建一个节点 root = put(root, key, val); root.color = BLACK;&#125;private Node put(Node h, Key key, Value val) &#123; if (h == null) //标准的插入操作，和父节点用红链接相连 return new Node(key, val, RED, 1); int cmp = key.compareTo(h.key); if (cmp &lt; 0) h.left = put(h.left, key, val); else if (cmp &gt; 0) h.right = put(h.right, key, val); else h.val = val; if (isRed(h.right) &amp;&amp; !isRed(h.left)) h = rotateLeft(h); if (isRed(h.left) &amp;&amp; isRed(h.left.left)) h = rotateRight(h); if (isRed(h.left) &amp;&amp; isRed(h.right)) flipColors(h); h.size = size(h.left) + size(h.right) + 1; return h;&#125; 除了递归调用后的三条if语句，红黑树中put()的递归实现和二叉查找树中put()的实现完全相同。 删除最小键为保证树的完美平衡性，沿着左链接向下进行变换，确保不会删除一个2-节点。在最后得到的含有最小键的3-节点或4-节点中，我们可以直接将最小键删除，然后向上分解所有临时的4-节点。 删除在查找路径上进行和删除最小键相同的变换同样可以保证在查找过程中任意当前节点均不是2-节点。如果被查找的键在树的底部，我们可以直接删除它。如果不在，我们需要将它和它的后继节点交换，就和二叉查找树一样。因为当前节点必然不是2-节点，问题已经转化为在一棵根节点不是2-节点的子树中删除最小的键，可以直接使用上文的算法。删除之后我们需要向上回溯并分解余下的4-节点。 查找红黑树的get()方法不会检查节点的颜色，因此实现和二叉查找树一样，但由于树是平衡的，所以查找比二叉查找树更快。 12345678910111213public Value get(Key key) &#123; return get(root, key);&#125;private Value get(Node x, Key key) &#123; while (x != null) &#123; int cmp = key.compareTo(x.key); if (cmp &lt; 0) x = x.left; else if (cmp &gt; 0) x = x.right; else return x.val; &#125; return null;&#125; 复杂度分析无论键的插入顺序如何，红黑树都几乎是完美平衡的，因此查找、插入等操作在最坏的情况下所需的时间仍是对数级别的。 参考资料 Algorithms (Fourth Edition) CS-Notes 算法]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>查找</tag>
        <tag>红黑树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用查找算法之二叉查找树]]></title>
    <url>%2F2019%2F01%2F28%2F%E5%B8%B8%E7%94%A8%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95%E4%B9%8B%E4%BA%8C%E5%8F%89%E6%9F%A5%E6%89%BE%E6%A0%91%2F</url>
    <content type="text"><![CDATA[定义一棵二叉查找树（又称二叉排序树、二叉搜索树）是一棵二叉树，其中每个节点都含有一个Comparable的键以及相关联的值且每个节点的键都大于其左子树中的任意节点的键而小于右子树的任意节点的键。 二叉查找树有一个重要性质，就是它的中序遍历结果递增排序。 基本实现树由Node对象组成，每个对象都含有一对键值、两条链接和一个节点计数器。节点计数器表示以该节点为根的子树中的节点总数，总是满足size(x) = size(x.left) + size(x.right) + 1。 123456789101112131415161718192021222324252627282930313233public class BST&lt;Key extends Comparable&lt;Key&gt;, Value&gt; &#123; private Node root; // 二叉查找树的根节点 private class Node &#123; private Key key; // 键 private Value val; // 值 private Node left, right; // 指向子树的链接 private int size; // 以该节点为根的子树中的节点总数 public Node(Key key, Value val, int size) &#123; this.key = key; this.val = val; this.size = size; &#125; &#125; public int size() &#123; return size(root); &#125; private int size(Node x) &#123; if (x == null) return 0; else return x.size; &#125; //实现见下文 public Value get(Key key) //实现见下文 public void put(Key key, Value val) //其它有序性相关的方法及删除操作见下文&#125; 查找如果树是空的，则查找未命中；如果被查找的键和根节点的键相等，查找命中；否则递归地在子树中查找：如果被查找的键较小就在左子树中查找，较大就在右子树中查找。 当找到一个含有被查找的键的节点（命中）或者当前子树变为空（未命中）时这个过程才会结束。 123456789101112public Value get(Key key) &#123; return get(root, key);&#125;private Value get(Node x, Key key) &#123; if (x == null) return null; int cmp = key.compareTo(x.key); if (cmp &lt; 0) return get(x.left, key); else if (cmp &gt; 0) return get(x.right, key); else return x.val;&#125; 插入如果树是空的，就返回一个含有该键值对的新节点（使上层节点的链接指向该节点）；如果被查找的键小于根节点的键，继续在左子树中插入该键，否则在右子树中插入该键。 1234567891011121314@Overridepublic void put(Key key, Value value) &#123; root = put(root, key, value);&#125; private Node put(Node x, Key key, Value val) &#123; if (x == null) return new Node(key, val, 1); int cmp = key.compareTo(x.key); if (cmp &lt; 0) x.left = put(x.left, key, val); else if (cmp &gt; 0) x.right = put(x.right, key, val); else x.val = val; x.size = 1 + size(x.left) + size(x.right); return x; &#125; 有序性相关的方法及删除操作范围查找利用二叉查找树中序遍历的结果为递增的特点对其进行指定范围的查找。 12345678910111213141516Overridepublic List&lt;Key&gt; keys(Key l, Key h) &#123; List&lt;Key&gt; list = new ArrayList&lt;&gt;(); keys(root, list, l, h); return list;&#125;private void keys(Node x, List&lt;key&gt; list, Key l, Key h) &#123; if (x == null) return; int cmpL = l.compareTo(x.key); int cmpH = h.compareTo(x.key); if (cmpL &lt; 0) keys(x.left, list, l, h); if (cmpL &lt;= 0 &amp;&amp; cmpH &gt;= 0) list.add(x.key); if (cmpH &gt; 0) keys(x.right, list, l, h);&#125; 删除最小节点只需令指向最小节点的链接指向最小节点的右子树。 1234567891011public void deleteMin() &#123; root = deleteMin(root);&#125;private Node deleteMin(Node x) &#123; if (x.left == null) return x.right; x.left = deleteMin(x.left); x.size = size(x.left) + size(x.right) + 1; return x;&#125; 删除指定节点如果待删除的节点只有一个子树， 那么只需要让指向待删除节点的链接指向唯一的子树即可；否则，让右子树的最小节点替换该节点。 1234567891011121314151617181920212223public void delete(Key key) &#123; root = delete(root, key);&#125;private Node delete(Node x, Key key) &#123; if (x == null) return null; int cmp = key.compareTo(x.key); if (cmp &lt; 0) x.left = delete(x.left, key); else if (cmp &gt; 0) x.right = delete(x.right, key); else &#123; if (x.right == null) return x.left; if (x.left == null) return x.right; Node t = x; x = min(t.right); x.right = deleteMin(t.right); x.left = t.left; &#125; x.size = size(x.left) + size(x.right) + 1; return x;&#125; 查找最小键123456789101112@Overridepublic Key min() &#123; return min(root).key;&#125;private Node min(Node x) &#123; if (x == null) return null; if (x.left == null) return x; return min(x.left);&#125; 排名rank(key)返回key的排名，排名从0开始。如果键和根节点的键相等，返回左子树的节点数；如果小于，递归计算在左子树中的排名；如果大于，递归计算在右子树中的排名，加上左子树的节点数，再加上1（根节点）。 123456789101112@Overridepublic int rank(Key key) &#123; return rank(key, root);&#125;private int rank(Key key, Node x) &#123; if (x == null) return 0; int cmp = key.compareTo(x.key); if (cmp &lt; 0) return rank(key, x.left); else if (cmp &gt; 0) return 1 + size(x.left) + rank(key, x.right); else return size(x.left); &#125; 复杂度分析在最好的情况下，一棵含有N个节点的树是完全平衡的，插入和查找的时间复杂度均为O(logn)；在最坏的情况下，搜索路径上可能有N个节点，此时的时间复杂度为O(n)。 参考资料 Algorithms (Fourth Edition) CS-Notes 算法]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>查找</tag>
        <tag>BST</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用查找算法之二分查找]]></title>
    <url>%2F2019%2F01%2F28%2F%E5%B8%B8%E7%94%A8%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95%E4%B9%8B%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE%2F</url>
    <content type="text"><![CDATA[前言符号表是一种存储键值对的数据结构，可以支持高效地插入、查找等操作，因此在这里使用一个有序符号表接口来定义这些操作，这个符号表将保持键的有序性。 12345678910111213141516public interface OrderedST&lt;Key extends Comparable&lt;Key&gt;, Value&gt; &#123; int size(); void put(Key key, Value value); Value get(Key key); Key min(); Key max(); int rank(Key key); List&lt;Key&gt; keys(Key l, Key h);&#125; 二分查找二分查找先将被查找的键和数组的中间键比较，如果被查找的键小于中间键，我们就在左子数组中继续查找，如果大于我们就在右子数组中继续查找，否则中间键就是我们要找的键。如果表中存在该键，此方法将返回该键的位置，否则，将返回该键应该插入的位置。 二分查找有很多种不同的实现方式，但个人更加喜欢用以下的方式实现，这同时也是书上的实现方式： 1234567891011public int binarySearch(int[] nums, int target) &#123; int low = 0; int high = nums.length - 1; while(low &lt;= high) &#123; int mid = low + (high - low) / 2; if(nums[mid] &lt; target) low = mid + 1; else if(nums[mid] &gt; target) high = mid - 1; else return mid; &#125; return low;&#125; 查找数字第一次出现的位置对二分查找可以做一个简单的拓展，即当一个有序数组中有重复的数字时，查找一个数字在数组中第一次出现的位置。例如，对于数组{1, 2, 3, 3, 3, 3, 4}，要查找的数字3的下标应该为2而不是3。我们仅仅需要对普通的二分查找算法做一个简单的修改就能完成此功能： 12345678910public int binarySearchFirst(int[] nums, int target) &#123; int low = 0; int high = nums.length - 1; while(low &lt;= high) &#123; int mid = low + (high - low) / 2; if(nums[mid] &lt; target) low = mid + 1; else if(nums[mid] &gt;= target) high = mid - 1; &#125; return low;&#125; 查找数字最后一次出现的位置同理，我们也可以使用二分查找找到重复数字在有序数组中最后一次出现的位置： 12345678910public int binarySearchLast(int[] nums, int target) &#123; int low = 0; int high = nums.length - 1; while(low &lt;= high) &#123; int mid = low + (high - low) / 2; if(nums[mid] &lt;= target) low = mid + 1; else if(nums[mid] &gt; target) high = mid - 1; &#125; return high;&#125; 二分查找实现有序符号表使用一对平行数组，分别用来存储键和值。 这份实现的核心是rank()方法，它几乎和上面单独列出的二分查找法一样，返回找到的键的位置或者键应该插入的位置。对于put()方法，如果键存在于表中则更新它的值，否则插入到合适的位置，并将所有更大的键向后移动一格。get()方法根据rank()方法的返回值来取键相应的值，如果不存在则返回null。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677public class BinarySearchOrderedST&lt;Key extends Comparable&lt;Key&gt;, Value&gt; implements OrderedST&lt;Key, Value&gt; &#123; private Key[] keys; private Value[] values; private int N = 0; public BinarySearchOrderedST(int capacity) &#123; keys = (Key[]) new Comparable[capacity]; values = (Value[]) new Object[capacity]; &#125; @Override public int size() &#123; return N; &#125; @Override public int rank(Key key) &#123; int l = 0, h = N - 1; while (l &lt;= h) &#123; int m = l + (h - l) / 2; int cmp = key.compareTo(keys[m]); if (cmp == 0) return m; else if (cmp &lt; 0) h = m - 1; else l = m + 1; &#125; return l; &#125; @Override public List&lt;Key&gt; keys(Key l, Key h) &#123; int index = rank(l); List&lt;Key&gt; list = new ArrayList&lt;&gt;(); while (keys[index].compareTo(h) &lt;= 0) &#123; list.add(keys[index]); index++; &#125; return list; &#125; @Override public void put(Key key, Value value) &#123; int index = rank(key); if (index &lt; N &amp;&amp; keys[index].compareTo(key) == 0) &#123; values[index] = value; return; &#125; for (int j = N; j &gt; index; j--) &#123; keys[j] = keys[j - 1]; values[j] = values[j - 1]; &#125; keys[index] = key; values[index] = value; N++; &#125; @Override public Value get(Key key) &#123; int index = rank(key); if (index &lt; N &amp;&amp; keys[index].compareTo(key) == 0) return values[index]; return null; &#125; @Override public Key min() &#123; return keys[0]; &#125; @Override public Key max() &#123; return keys[N - 1]; &#125;&#125; 复杂度分析二分查找的时间复杂度是对数级别的，故使用二分查找实现的符号表的查找操作所需要的时间也是对数级别的，但是插入操作由于需要移动数组元素，因此是线性级别的。 参考资料 Algorithms (Fourth Edition) CS-Notes 算法]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>查找</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap源码分析]]></title>
    <url>%2F2019%2F01%2F28%2FHashMap%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[HashMap简介（jdk1.8）在jdk1.8中，HashMap底层由数组+链表+红黑树来实现，性能较之前有了较大的提升。如下为HashMap的继承体系结构：12public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable 在这里，AbstractMap已经实现了Map接口，再实现一遍并没有任何用处，java集合框架的创始人也承认其为一个小失误。 HashMap中，当链表节点较多时会转为红黑树进行存储，而红黑树这一数据结构涉及的知识点过多，关于红黑树的基础知识需要另外学习，本篇将以链表为主，红黑树为辅的形式分析其源码。 属性123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172/** * 默认的初始化容量为16 */ static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; /** * 最大容量 */ static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; /** * 默认负载因子为0.75 */ static final float DEFAULT_LOAD_FACTOR = 0.75f; /** * 链表转红黑树的阈值，当有8个节点的时候转换 */ static final int TREEIFY_THRESHOLD = 8; /** * 红黑树转链表的阈值，当有6个节点的时候转换 */ static final int UNTREEIFY_THRESHOLD = 6; /** * 转红黑树时table的最小容量，如果当前容量小于64则进行扩容而非转换 */ static final int MIN_TREEIFY_CAPACITY = 64; /** * 基本hash节点 */ static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + &quot;=&quot; + value; &#125; public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125; &#125; 注意：在HashMap中，table的容量只为2的n次方。 构造函数1234567891011121314151617181920212223242526//指定了初始容量和负载因子 public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal initial capacity: " + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal load factor: " + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity); &#125;//指定了初始容量，将会设置默认负载因子 public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR); &#125; public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted &#125; public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false); &#125; 在构造函数中，并没有对table数组进行初始化，而是在第一次put的时候进行初始化，这会在下文进行详细介绍。 tableSizeFortableSizeFor方法的主要功能是返回一个比给定整数大且最接近的2的幂次方整数，如给定10，返回2的4次方16。 12345678910static final int tableSizeFor(int cap) &#123; //防止当容量已经是2的幂次方(2^m)了，进行如下操作得到的最终结果会多乘个2，即2^(m+1) int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; 这个方法比较巧妙，n|=n&gt;&gt;&gt;1这一操作确保第一次出现1的位及其后一位（也就是头两位）都是1，而n |= n &gt;&gt;&gt; 2确保头四位都是1，n |= n &gt;&gt;&gt; 4确保头八位都是1，以此类推，一直到n |= n &gt;&gt;&gt; 16结束后就能确保第一次出现1的位及其后面所有位都为1。而此时，n+1即为最接近指定容量的2的幂次方整数。举个例子：123456789n: 0000 0000 0110 0001 = 97 n|=n&gt;&gt;&gt;1: 0000 0000 0111 0001 n|=n&gt;&gt;&gt;2: 0000 0000 0111 1001n|=n&gt;&gt;&gt;2: 0000 0000 0111 1101 n|=n&gt;&gt;&gt;4: 0000 0000 0111 1111...n|=n&gt;&gt;&gt;16: 0000 0000 0111 1111n+1: 0000 0000 1000 0000 = 128 hash1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 这个方法先得到key的hashCode，然后将其与高16位进行异或运算重新得到哈希值，之后再通过hash &amp; (table.length - 1) 定位到key在table中的索引位置。假设table的长度为16，具体过程如下： 12345h = key.hashCode(): 1111 1111 1111 1111 0000 0000 0011 0101h &gt;&gt;&gt; 16: 0000 0000 0000 0000 1111 1111 1111 1111hash = h ^ (h &gt;&gt;&gt; 16): 1111 1111 1111 1111 1111 1111 1100 1010table.length - 1: 0000 0000 0000 0000 0000 0000 0000 1111hash &amp; (table.length - 1):0000 0000 0000 0000 0000 0000 0000 1010 其中，&gt;&gt;&gt;为无符号右移，左边都将补0，而之所以要进行这一步，是为了当table的值很小时，能让hashCode的高位也参与运算，以减少碰撞的几率，否则仅在高位发生变化总是会发生碰撞。 我们知道，hash如果对table.length取模将得到key在table长度范围内的索引位置，但由于模运算效率较低，这里便采用了与运算进行优化，提高了效率。 get12345678910111213141516171819202122232425262728public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; &#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; //哈希表不为null &amp;&amp; 表的长度大于0 &amp;&amp; 根据hash值算出表索引的第一个节点不为null if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; //如果第一个节点的key与传入的key相同，则直接返回第一个节点 if (first.hash == hash &amp;&amp; //always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; //如果第一个节点是树节点，则调用红黑树的相关方法 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; //向下遍历链表直至找到key相同的节点并返回 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; //未找到符合要求的节点，返回null return null; &#125; getTreeNode12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849final TreeNode&lt;K,V&gt; getTreeNode(int h, Object k) &#123; //如果当前节点有父节点，则先找到其根节点，之后再调用find方法 return ((parent != null) ? root() : this).find(h, k, null);&#125;final TreeNode&lt;K,V&gt; root() &#123; for (TreeNode&lt;K,V&gt; r = this, p;;) &#123; //如果当前节点的父节点为空，则当前节点为根节点，将其返回 if ((p = r.parent) == null) return r; r = p; &#125;&#125;final TreeNode&lt;K,V&gt; find(int h, Object k, Class&lt;?&gt; kc) &#123; TreeNode&lt;K,V&gt; p = this; do &#123; int ph, dir; K pk; TreeNode&lt;K,V&gt; pl = p.left, pr = p.right, q; //传入的哈希值小于当前节点的哈希值，则向左遍历 if ((ph = p.hash) &gt; h) p = pl; //传入的哈希值大于当前节点的哈希值，则向右遍历 else if (ph &lt; h) p = pr; //传入的哈希值等于当前节点的哈希值，则再判断key值是否相同，因为不同的key有可能有相同的hash，这也正是哈希冲突所在 else if ((pk = p.key) == k || (k != null &amp;&amp; k.equals(pk))) return p; //如果左节点为空，则向右开始遍历 else if (pl == null) p = pr; //如果右节点为空，则向左开始遍历 else if (pr == null) p = pl; //走到这里说明左右节点都不为空，要开始判断究竟往左还是往右 else if ((kc != null || (kc = comparableClassFor(k)) != null) &amp;&amp; //如果不为null，说明key实现了Comparable接口 (dir = compareComparables(kc, k, pk)) != 0) //比较k和pk的大小，若k&lt;pk则dir&lt;0，k&gt;pk则dir&gt;0 p = (dir &lt; 0) ? pl : pr; //key所属类没有实现Comparable接口，则直接向右开始遍历 else if ((q = pr.find(h, k, kc)) != null) return q; //向右没有找到，则向左开始遍历 else p = pl; &#125; while (p != null); //找不到符合的返回null return null;&#125; 在这个方法中有些人可能会疑虑在同一个索引位置下的红黑树各节点hash值不应该相同吗，为什么还会有判断哈希值大小进入左右节点的操作。其实，不同的hash值在与table的长度相与后，是有可能进入同一个索引位置下的，考虑以下这种情况：123节点1的hash值： 1110 0000 0000 1000 0111节点2的hash值： 1001 1111 0000 1010 0111table.length-1：0000 0000 0000 0000 0111 可以看出，节点1与节点2在进行了hash &amp; (table.length - 1)后值都为0000 0000 0000 0000 0111，因此会放置在table中同一个索引位置下。 comparableClassFor、compareComparablescomparableClassFor方法判断对象x所属类c是否实现了Comparable接口，如果实现了则返回所属类c，否则返回null 123456789101112131415161718192021222324static Class&lt;?&gt; comparableClassFor(Object x) &#123; if (x instanceof Comparable) &#123; Class&lt;?&gt; c; Type[] ts, as; Type t; ParameterizedType p; //如果x是个字符串对象则直接返回String类，因为String类本身就已经实现了Comparable接口 if ((c = x.getClass()) == String.class) // bypass checks return c; //Type[] getGenericInterfaces，此方法将返回带泛型参数信息的本类直接实现的接口 if ((ts = c.getGenericInterfaces()) != null) &#123; for (int i = 0; i &lt; ts.length; ++i) &#123; //如果此接口为泛型接口 if (((t = ts[i]) instanceof ParameterizedType) &amp;&amp; //如果该泛型接口的原始类型为Comparable ((p = (ParameterizedType)t).getRawType() == Comparable.class) &amp;&amp; //如果该泛型接口只有一个泛型参数，且此泛型参数类型为c，则返回c (as = p.getActualTypeArguments()) != null &amp;&amp; as.length == 1 &amp;&amp; as[0] == c) // type arg is c return c; &#125; &#125; &#125; //如果该对象所属类没有实现Comparable接口，则返回null return null;&#125; 以上代码中，for (int i = 0; i &lt; ts.length; ++i)下的一系列判断其实就是想要看x所属类c是否实现了Comparable&lt;c&gt;。 1234static int compareComparables(Class&lt;?&gt; kc, Object k, Object x) &#123; return (x == null || x.getClass() != kc ? 0 : ((Comparable)k).compareTo(x));&#125; 此方法中，如果x与k的类相同，则进行比较。否则，返回0。 put1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162 public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true); &#125; /** * @param onlyIfAbsent 如果为true，则不改变已经存在的value，仅仅当不存在value的时候put进去 */ final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //如果table为空或者长度为0，则先调用resize()方法进行扩容 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; //如果通过hash计算得到的table该索引位置还没有节点，则创建一个新节点作为头节点 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); //该索引位置已存在节点 else &#123; Node&lt;K,V&gt; e; K k; //判断当前节点的hash与key是否与参数中的hash与key相同，如果相同，则说明p为要查找的节点，将其赋值给e if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //判断节点是否为红黑树节点，如果是则调用红黑树的相关方法 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; //如果节点不为红黑树节点而是链表节点，则遍历链表节点，并统计该链表的节点数binCount for (int binCount = 0; ; ++binCount) &#123; //如果已经到了链表尾部，则根据传入的hash与key等创建一个新节点加入链表尾部 if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); //如果链表的节点数超过阈值，则将其转换为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) //此时e节点即为目标节点，跳出循环 break; //将p设置为下一个节点 p = e; &#125; &#125;//如果e节点不为null，则说明链表中包含目标节点，用新值覆盖旧值并返回旧值 if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; //走到这一步说明插入了新的节点，size大小需要加一 ++modCount; if (++size &gt; threshold) //如果size超过了阈值，则进行扩容 resize(); afterNodeInsertion(evict); return null; &#125; putTreeVal在进行红黑树的操作时，依然会维护链表的结构。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455final TreeNode&lt;K,V&gt; putTreeVal(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, int h, K k, V v) &#123; Class&lt;?&gt; kc = null; boolean searched = false; TreeNode&lt;K,V&gt; root = (parent != null) ? root() : this; for (TreeNode&lt;K,V&gt; p = root;;) &#123; int dir, ph; K pk; //如果目标节点的hash值小于当前节点，则将dir设为-1，代表向左查找 if ((ph = p.hash) &gt; h) dir = -1; //如果目标节点的hash值大于当前节点，则将dir设为1，代表向右查找 else if (ph &lt; h) dir = 1; //如果目标节点的hash值等于当前节点，则判断key是否相等，如果相等，则说明当前节点为目标节点，将其返回 else if ((pk = p.key) == k || (k != null &amp;&amp; k.equals(pk))) return p; //如果要查找的key没有实现Comparable接口或者pk与k的所属类不同 else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) &#123; //第一次执行查找 if (!searched) &#123; TreeNode&lt;K,V&gt; q, ch; searched = true; //左右子树分别调用find进行查找，如果找到了则返回 if (((ch = p.left) != null &amp;&amp; (q = ch.find(h, k, kc)) != null) || ((ch = p.right) != null &amp;&amp; (q = ch.find(h, k, kc)) != null)) return q; &#125; //如果依然没有找到，则再进行最后一次比较 dir = tieBreakOrder(k, pk); &#125; TreeNode&lt;K,V&gt; xp = p; //如果p节点的左节点或者右节点为null，则说明找到了要放入的位置 if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123; Node&lt;K,V&gt; xpn = xp.next; TreeNode&lt;K,V&gt; x = map.newTreeNode(h, k, v, xpn); if (dir &lt;= 0) xp.left = x; else xp.right = x; //到这里维护了xp-&gt;x-&gt;xpn这一链表结构 xp.next = x; x.parent = x.prev = xp; if (xpn != null) ((TreeNode&lt;K,V&gt;)xpn).prev = x; //进行红黑树的插入平衡操作 moveRootToFront(tab, balanceInsertion(root, x)); return null; &#125; &#125;&#125; resize123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; //如果老table为空，则老t int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; //如果老table不为空 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; //且老table的容量已经大于最大容量 //将阈值设置为最大整型 threshold = Integer.MAX_VALUE; //直接返回老table，不再扩容 return oldTab; &#125; //将新容量设置为老容量的两倍 //如果新容量小于最大容量且老容量大于十六，则将新阈值也提高到原来的两倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; //如果table为空，但老阈值大于0，说明构造函数时指定了初始化容量但从未加入过元素，此时将老阈值赋给新容量，详解见下文 else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; //老table为空，且老阈值为0，说明构造函数时未指定初始化容量 else &#123; // zero initial threshold signifies using defaults //将新容量设置为默认初始化容量 newCap = DEFAULT_INITIAL_CAPACITY; //将新阈值设置为默认负载因子*默认初始化容量 newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; //如果新阈值为0，则用新容量*负载因子赋值 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; //如果新容量或者新阈值大于最大容量，则将新阈值设为最大整型，以后不再扩容 newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; //将新阈值赋值给阈值属性 threshold = newThr; @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) //用新容量大小创建一个新table Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; //将新table赋值给table属性 table = newTab; //如果老table不为空，则将其中的元素全部放到新table中去 if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; //如果该索引位置头节点不为空 if ((e = oldTab[j]) != null) &#123; //将老表该索引位置设为空，方便垃圾收集器回收 oldTab[j] = null; //如果该索引位置只有一个节点，则根据其hash计算值放入新表中 if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; //如果为树节点，则调用红黑树相关方法 else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); //该索引位置有多个节点 else &#123; // preserve order //存储原索引位置的头节点与尾节点 Node&lt;K,V&gt; loHead = null, loTail = null; //存储原索引位置+原容量的头节点与尾节点 Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; //如果hash与oldCap相与为0则存储在原索引位置，详解见下方 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) //e为头节点的情况 loHead = e; else loTail.next = e; loTail = e; &#125; //如果hash与oldCap相与不为0则存储在原索引位置+原容量，详解见下方 else &#123; if (hiTail == null) //e为头节点的情况 hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; //尾节点的next属性为空 loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; //尾节点的next属性为空 hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; //返回新表 return newTab;&#125; 我们可以看到在此方法中有一个条件判断else if (oldThr &gt; 0)，当table为空但阈值却大于零时，将阈值赋值给新容量。这里有个疑问是为什么会发生table为空但阈值却大于零这种情况？我们可以回过头看看构造函数，可以发现在所有构造函数中都没有对数组table进行过分配，而仅仅设置了阈值this.threshold = tableSizeFor(initialCapacity);，既然在构造时没有分配，那肯定就是在第一次扩容时分配的，也就正是上面的代码。 此处还有一个疑问是：为什么扩容后新的存储位置只为原位置或原位置+原容量？请看这么一个例子，假设oldCap=0100, newCap=1000,节点a的hash为1110,节点b的hash为1010。oldCap-1的值为0011，显然对于节点来说只有后两位决定了它们的位置（因为前两位无论如何都为0），而newCap-1的值为0111，此时后三位决定了它们的位置，与之前不同正在于节点的第三位是0还是1，而第三位的值正可以通过oldCap(在此也就是0100)相与来进行判断，如果相与结果为0000，则说明第三位的值为0，在和newCap-1相与后结果将不变，依然在原索引位置；而如果相与结果为0100，则说明节点第三位值是1，也就是原索引值加上原容量。 treeifyBin123456789101112131415161718192021222324252627282930313233final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) &#123; int n, index; Node&lt;K,V&gt; e; //如果table为空或者table的长度小于可转换为红黑树的最小容量，则调用resize方法扩容 if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); //如果根据hash计算得到的索引位置下的节点不为空，则遍历整条链表 else if ((e = tab[index = (n - 1) &amp; hash]) != null) &#123; TreeNode&lt;K,V&gt; hd = null, tl = null; do &#123; //将链表节点转换为红黑树节点 TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); //如果为第一次循环 if (tl == null) //将p设置为头节点 hd = p; //否则，不为第一次循环 else &#123; //将当前节点与上一个节点关联起来，维护链表结构 p.prev = tl; tl.next = p; &#125; tl = p; &#125; while ((e = e.next) != null); //将hash计算得到的索引位置的头节点赋为新的树节点 if ((tab[index] = hd) != null) //以头节点为根构建红黑树 hd.treeify(tab); &#125;&#125;TreeNode&lt;K,V&gt; replacementTreeNode(Node&lt;K,V&gt; p, Node&lt;K,V&gt; next) &#123; return new TreeNode&lt;&gt;(p.hash, p.key, p.value, next);&#125; treeify123456789101112131415161718192021222324252627282930313233343536373839404142434445464748final void treeify(Node&lt;K,V&gt;[] tab) &#123; TreeNode&lt;K,V&gt; root = null; //x的初始值为根节点，但开始时还未赋值给root for (TreeNode&lt;K,V&gt; x = this, next; x != null; x = next) &#123; next = (TreeNode&lt;K,V&gt;)x.next; x.left = x.right = null; //如果root还未被赋值，则将根节点赋值给它 if (root == null) &#123; //根节点没有父节点 x.parent = null; //红黑树根节点必须为黑色 x.red = false; root = x; &#125; else &#123; //见下文 K k = x.key; int h = x.hash; Class&lt;?&gt; kc = null; for (TreeNode&lt;K,V&gt; p = root;;) &#123; int dir, ph; K pk = p.key; if ((ph = p.hash) &gt; h) dir = -1; else if (ph &lt; h) dir = 1; else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) dir = tieBreakOrder(k, pk); TreeNode&lt;K,V&gt; xp = p; if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123; x.parent = xp; if (dir &lt;= 0) xp.left = x; else xp.right = x; //红黑树的插入平衡调整 root = balanceInsertion(root, x); break; &#125; &#125; &#125; &#125; //将根节点移到table索引位置的头节点 moveRootToFront(tab, root);&#125; treeify方法用来构建一棵以调用该方法的节点为根节点的红黑树。由于红黑树依然维护着链表结构，每次通过next属性获得下一个节点时，都会从根节点开始向下查找，根据hash值的大小找到合适的位置放入，并设置好parent与left或right属性以关联节点。 remove12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public V remove(Object key) &#123; Node&lt;K,V&gt; e; //如果未找到要删除的节点则返回空，否则返回要删除的节点的value值 return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value;&#125;/** * @param matchValue 如果为true，则只有当value也相等的时候才移除 */final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; //如果table不为空且table的长度不为0且table该索引位置的头节点不为空 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123; Node&lt;K,V&gt; node = null, e; K k; V v; //如果当前节点的hash值和key都与传入的相等，则当前节点就是目标节点，将其赋值给node if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; //如果当前节点不是目标节点，则遍历之后的节点 else if ((e = p.next) != null) &#123; //如果节点为树节点，则调用红黑树相关方法 if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else &#123; do &#123; //如果当前节点是目标节点，则将其赋值给node，并跳出循环 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; //将p设为下一节点 p = e; &#125; while ((e = e.next) != null); &#125; &#125; //如果找到了要删除的节点且要删除的节点的value与传入的value相等或者压根不需要匹配value if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; //如果节点为树节点，则调用红黑树移除方法 if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); //如果要删除的节点是头节点 else if (node == p) //直接将索引位置指向要删除节点的下一个节点 tab[index] = node.next; else //如果要删除的节点不是头节点，则将要删除节点的上下节点关联起来 p.next = node.next; ++modCount; //总节点数减一 --size; afterNodeRemoval(node); //返回被移除的节点 return node; &#125; &#125; //未找到要删除的节点，直接返回null return null;&#125; 常见问题有关HashMap的常见面试题总结请移步 HashMap常见面试题总结]]></content>
      <categories>
        <category>JDK</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
        <tag>JDK</tag>
        <tag>HashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见排序算法之堆排序]]></title>
    <url>%2F2019%2F01%2F28%2F%E5%B8%B8%E8%A7%81%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E4%B9%8B%E5%A0%86%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[前言排序算法的成本模型计算的是比较和交换的次数。less()方法对元素进行比较，exch()方法将元素交换位置。 123456789private static boolean less(Comparable v, Comparable w) &#123; return (v.compareTo(w) &lt; 0);&#125;private static void exch(Comparable[] a, int i, int j) &#123; Comparable swap = a[i]; a[i] = a[j]; a[j] = swap;&#125; 堆的定义堆的某个节点的值总是大于等于子节点的值，并且堆是一颗完全二叉树。当这棵树的每个结点都大于等于它的两个子节点时，它被称为堆有序。 堆可以用数组来表示，这是因为堆是完全二叉树，而完全二叉树很容易就存储在数组中。位置 k 的节点的父节点位置为 k/2，而它的两个子节点的位置分别为 2k 和 2k+1。 上浮在堆中，当一个节点比父节点大，那么需要交换这个两个节点。交换后还可能比它新的父节点大，因此需要不断地进行比较和交换操作，把这种操作称为上浮。 实现如下： 123456private void swim(int k) &#123; while (k &gt; 1 &amp;&amp; less(k/2, k)) &#123; exch(k, k/2); k = k/2; &#125;&#125; 下沉在堆中，当一个节点比子节点小，需要不断地向下进行比较和交换操作，把这种操作称为下沉。一个节点如果有两个子节点，应当与两个子节点中最大那个节点进行交换。 实现如下： 123456789private void sink(int k) &#123; while (2*k &lt;= N) &#123; int j = 2*k; if (j &lt; N &amp;&amp; less(j, j+1)) j++; if (!less(k, j)) break; exch(k, j); k = j; &#125;&#125; 堆排序堆排序可以分为两个阶段。在堆的构造阶段中，我们将原始数组重新组织安排进一个堆中；然后在下沉排序阶段，我们从堆中按递减顺序取出所有元素并得到排序结果。 堆的构造无序数组建立堆最直接的方法是从左到右遍历数组进行上浮操作。一个更高效的方法是从右至左进行下沉操作，如果一个节点的两个节点都已经是堆有序，那么进行下沉操作可以使得这个节点为根节点的堆有序。叶子节点不需要进行下沉操作，可以忽略叶子节点的元素，因此只需要遍历一半的元素即可。 下沉排序堆排序的主要工作都是在这一阶段完成的。这里我们将堆中的最大元素删除，然后放入堆缩小后数组中空出的位置。 12345678910111213141516171819202122232425262728293031public class Heap &#123; public static void sort(Comparable[] pq) &#123; int n = pq.length; for (int k = n/2; k &gt;= 1; k--) sink(pq, k, n); while (n &gt; 1) &#123; exch(pq, 1, n--); sink(pq, 1, n); &#125; &#125; private static void sink(Comparable[] pq, int k, int n) &#123; while (2*k &lt;= n) &#123; int j = 2*k; if (j &lt; n &amp;&amp; less(pq, j, j+1)) j++; if (!less(pq, k, j)) break; exch(pq, k, j); k = j; &#125; &#125; private static boolean less(Comparable[] pq, int i, int j) &#123; return pq[i-1].compareTo(pq[j-1]) &lt; 0; &#125; private static void exch(Object[] pq, int i, int j) &#123; Object swap = pq[i-1]; pq[i-1] = pq[j-1]; pq[j-1] = swap; &#125;&#125; 复杂度分析一个堆的高度为 logN，因此在堆中插入元素和删除最大元素的复杂度都为 logN。 对于堆排序，由于要对 N 个节点进行下沉操作，因此复杂度为 NlogN。 现代系统的许多应用很少使用它，因为它无法利用缓存。数组元素很少和相邻的其它元素进行比较，因此无法利用局部性原理，缓存未命中的次数很高。 最坏时间复杂度 О(nlogn) 最优时间复杂度 O(nlogn) 平均时间复杂度 O(nlogn) 空间复杂度 O(1) 不稳定 参考资料 Algorithms (Fourth Edition) CS-Notes 算法]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见排序算法之快速排序]]></title>
    <url>%2F2019%2F01%2F28%2F%E5%B8%B8%E8%A7%81%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[前言排序算法的成本模型计算的是比较和交换的次数。less()方法对元素进行比较，exch()方法将元素交换位置。 123456789private static boolean less(Comparable v, Comparable w) &#123; return (v.compareTo(w) &lt; 0);&#125;private static void exch(Comparable[] a, int i, int j) &#123; Comparable swap = a[i]; a[i] = a[j]; a[j] = swap;&#125; 思路快速排序是一种分治的排序算法，它将一个数组分成两个子数组，将两部分独立地排序。 快速排序和归并排序是互补的：归并排序将数组分成两个子数组分别排序，并将有序的子数组归并以将整个数组排序；而快速排序将数组排序的方式则是当两个子数组都有序时整个数组也就自然有序了。前者的递归调用发生在处理整个数组之前，而后者的递归调用则发生在处理整个数组之后。 实现过程 基本算法12345678910111213141516171819public class Quick &#123; public static void sort(Comparable[] a) &#123; shuffle(a); sort(a, 0, a.length - 1); &#125; private static void sort(Comparable[] a, int lo, int hi) &#123; if (hi &lt;= lo) return; int j = partition(a, lo, hi); sort(a, lo, j-1); sort(a, j+1, hi); &#125; private void shuffle(T[] nums) &#123; List&lt;Comparable&gt; list = Arrays.asList(nums); Collections.shuffle(list); list.toArray(nums); &#125;&#125; 该方法的关键在于切分。 切分方法一般策略是先随意地取a[lo]作为切分元素，即那个将会被排序的元素，然后我们从数组的左端开始向右扫描直到找到一个大于等于它的元素，再从数组的右端开始向左扫描直到找到一个小于等于它的元素。这两个元素显然是没有排定的，因此交换它们的位置。如此继续，我们就可以保证左指针i的左侧元素都不大于切分元素，右指针j的右侧元素都不小于切分元素。当两个指针相遇时，我们只需要将切分元素a[lo]和左子数组最右侧的元素（a[j]）交换然后返回j即可。 12345678910111213141516171819private static int partition(Comparable[] a, int lo, int hi) &#123; int i = lo; int j = hi + 1; Comparable v = a[lo]; while (true) &#123; while (less(a[++i], v)) &#123; if (i == hi) break; &#125; while (less(v, a[--j])) &#123; if (j == lo) break; &#125; if (i &gt;= j) break; exch(a, i, j); &#125; exch(a, lo, j); return j;&#125; 这个过程使得数组满足下面三个条件： 对于某个j，a[j]已经排定 a[lo]到a[j-1]中的所有元素都不大于a[j] a[j+1]到a[hi]中的所有元素都不小于a[j] 复杂度分析快速排序的最好情况是每次都正好将数组对半分。在这种情况下快速排序所用的比较次数正好满足分治递归的Cn=2Cn/2+n。2Cn/2表示将两个子数组排序的成本，n表示用切分元素和所有数组元素进行比较的成本，这个递归公式的解Cn~nlogn。（下文有具体数学推导） 而在最坏情况下，切分不平衡使得第一次从最小的元素切分，第二次从第二小的元素切分，如此继续，每次切分后两个子数组之一总是为空的，比较次数为(n - 1) + (n - 2) +...+ 1 = n × (n - 1 ) / 2。 而对于空间复杂度来说，主要考虑的是递归调用使用的栈空间，在最好的情况下（也就是对半分），递归深度为logn，最坏情况下的递归深度为n。 最坏时间复杂度 О(n²) 最优时间复杂度 O(nlogn) 平均时间复杂度 O(nlogn) 最坏空间复杂度 O(n) 最优空间复杂度 O(logn) 不稳定 最优时间复杂度的数学证明 算法改进切换到插入排序因为快速排序在小数组中也会递归调用自己，对于小数组，插入排序比快速排序的性能更好，因此在小数组中可以切换到插入排序。 只需要将代码中的if (hi &lt;= lo) return;改为if (hi &lt;= lo + M) {Insertion.sort(a, lo, hi); return;}。 三取样切分最好的情况下是每次都能取数组的中位数作为切分元素，但是计算中位数的代价很高。人们发现取 3 个元素并将大小居中的元素作为切分元素的效果最好。 三向切分法从左到右遍历数组一次，维护一个指针lt使得a[lo…lt-1]中的元素都小于v，一个指针gt使得a[gt+1…hi]中的元素都大于v，一个指针i使得a[lt..i-1]中的元素都等于v，a[i..gt]中的元素都还未确定。 一开始i和lo相等，对a[i]进行三向比较： a[i]小于v，将a[lt]和a[i]交换，将lt和i加一 a[i]大于v，将a[gt]和a[i]交换，将gt减一 a[i]等于v，将i加一 对于包含大量重复元素的数组，它将排序时间从线性对数级降低到了线性级别。 1234567891011121314151617181920212223242526272829public class Quick3way &#123; public static void sort(Comparable[] a) &#123; shuffle(a); sort(a, 0, a.length - 1); &#125; private static void sort(Comparable[] a, int lo, int hi) &#123; if (hi &lt;= lo) return; int lt = lo, gt = hi; Comparable v = a[lo]; int i = lo + 1; while (i &lt;= gt) &#123; int cmp = a[i].compareTo(v); if (cmp &lt; 0) exch(a, lt++, i++); else if (cmp &gt; 0) exch(a, i, gt--); else i++; &#125; // a[lo..lt-1] &lt; v = a[lt..gt] &lt; a[gt+1..hi]. sort(a, lo, lt-1); sort(a, gt+1, hi); &#125; private void shuffle(T[] nums) &#123; List&lt;Comparable&gt; list = Arrays.asList(nums); Collections.shuffle(list); list.toArray(nums); &#125;&#125; 参考资料 Algorithms (Fourth Edition) CS-NOTE 算法 排序算法之快速排序的时间复杂度和空间复杂度]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见排序算法之归并排序]]></title>
    <url>%2F2019%2F01%2F28%2F%E5%B8%B8%E8%A7%81%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E4%B9%8B%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[前言排序算法的成本模型计算的是比较和交换的次数。less()方法对元素进行比较，exch()方法将元素交换位置。 123456789private static boolean less(Comparable v, Comparable w) &#123; return (v.compareTo(w) &lt; 0);&#125;private static void exch(Comparable[] a, int i, int j) &#123; Comparable swap = a[i]; a[i] = a[j]; a[j] = swap;&#125; 原地归并方法该方法将两个不同的有序数组归并到第三个数组中。 123456789101112131415private static void merge(Comparable[] a, Comparable[] aux, int lo, int mid, int hi) &#123; // copy to aux[] for (int k = lo; k &lt;= hi; k++) &#123; aux[k] = a[k]; &#125; // merge back to a[] int i = lo, j = mid+1; for (int k = lo; k &lt;= hi; k++) &#123; if (i &gt; mid) a[k] = aux[j++]; else if (j &gt; hi) a[k] = aux[i++]; else if (less(aux[j], aux[i])) a[k] = aux[j++]; else a[k] = aux[i++]; &#125;&#125; 自顶向下的归并排序自顶向下的归并排序应用了分治的思想，要对子数组a[lo..hi]进行排序，先将它分为a[lo..mid]和a[mid+1..hi]两部分，分别通过递归调用将它们单独排序，最后将有序的子数组归并为最终的排序结果。 图为自顶向下的归并排序中归并结果的轨迹 1234567891011121314public class Merge &#123; public static void sort(Comparable[] a) &#123; Comparable[] aux = new Comparable[a.length]; sort(a, aux, 0, a.length-1); &#125; private static void sort(Comparable[] a, Comparable[] aux, int lo, int hi) &#123; if (hi &lt;= lo) return; int mid = lo + (hi - lo) / 2; sort(a, aux, lo, mid); sort(a, aux, mid + 1, hi); merge(a, aux, lo, mid, hi); &#125;&#125; 自底向上的归并排序实现归并排序的另一种方法是先归并那些微型数组，然后再成对归并得到子数组，如此这般地多次遍历整个数组，直到我们将整个数组归并到一起。 图为自底向上的归并排序中归并结果的轨迹 12345678910111213public class MergeBU &#123; public static void sort(Comparable[] a) &#123; int n = a.length; Comparable[] aux = new Comparable[n]; for (int len = 1; len &lt; n; len *= 2) &#123; for (int lo = 0; lo &lt; n-len; lo += len+len) &#123; int mid = lo+len-1; int hi = Math.min(lo+len+len-1, n-1); merge(a, aux, lo, mid, hi); &#125; &#125; &#125;&#125; 特点 归并排序的空间复杂度不是最优的 和选择排序一样，排序的性能不受输入数据的影响，但表现比选择排序好的多 复杂度分析 最坏情况时间复杂度 O(nlogn) 最好情况时间复杂度 O(nlogn) 平均情况时间复杂度 O(nlogn) 空间复杂度 O(n) 稳定 参考资料 Wikipedia Algorithms (Fourth Edition) 十大经典排序算法]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初级排序算法]]></title>
    <url>%2F2019%2F01%2F28%2F%E5%88%9D%E7%BA%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[前言排序算法的成本模型计算的是比较和交换的次数。less()方法对元素进行比较，exch()方法将元素交换位置。 123456789private static boolean less(Comparable v, Comparable w) &#123; return (v.compareTo(w) &lt; 0);&#125;private static void exch(Comparable[] a, int i, int j) &#123; Comparable swap = a[i]; a[i] = a[j]; a[j] = swap;&#125; 选择排序首先找到数组中最小的那个元素，其次将它和数组的第一个元素交换位置。再次，在剩下的元素中找到最小的元素，将它与数组的第二个元素交换位置。如此反复，直到将整个数组排序。 上图为选择排序的示例动画。红色表示当前最小值，黄色表示已排序序列，蓝色表示当前位置。 特点 运行时间和输入无关：一个已经有序的数组或主键全部相等的数组和一个元素随机排列的数组所用的排序时间一样长。 数据移动是最少的：每次交换都会改变两个数组的元素的值，因此选择排序用了N次交换。 复杂度分析比较次数与关键字的初始状态无关，总的比较次数N = (n - 1) + (n - 2) +...+ 1 = n × (n - 1 ) / 2。交换次数最好情况是已经有序，交换0次；最坏情况是逆序，交换n-1次。 最坏时间复杂度 О(n²) 最优时间复杂度 О(n²) 平均时间复杂度 О(n²) 空间复杂度 O(1) 不稳定 实现123456789101112public class Selection &#123; public static void sort(Comparable[] a) &#123; int n = a.length; for (int i = 0; i &lt; n; i++) &#123; int min = i; for (int j = i+1; j &lt; n; j++) &#123; if (less(a[j], a[min])) min = j; &#125; exch(a, i, min); &#125; &#125;&#125; 插入排序插入排序是一种简单直观的排序算法。它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。 特点 插入排序所需时间取决于输入中元素的初始顺序。 插入排序对于部分有序的数组十分高效。 复杂度分析最好情况是序列已经是升序排列了，在这种情况下，需要进行的比较操作需n-1次即可，不需要进行交换；最坏情况是降序排列，那么此时需要进行的比较共有n × (n - 1) / 2次，交换同样需要n × (n - 1) / 2次。 最坏时间复杂度 О(n²) 最优时间复杂度 О(n) 平均时间复杂度 О(n²) 空间复杂度 O(1) 稳定 实现12345678910public class Insertion &#123; public static void sort(Comparable[] a) &#123; int n = a.length; for (int i = 1; i &lt; n; i++) &#123; for (int j = i; j &gt; 0 &amp;&amp; less(a[j], a[j-1]); j--) &#123; exch(a, j, j-1); &#125; &#125; &#125;&#125; 希尔排序希尔排序，也称递减增量排序算法，是插入排序的一种更高效的改进版本。希尔排序的思想是使数组中任意间隔为h的元素都是有序的，这样的数组称为h有序数组。 实现希尔排序只需要在插入排序的代码中将移动元素的距离由1改为h即可。 一个h有序数组即一个由h个有序子数组组成的数组 上图表示以23, 10, 4, 1的步长序列进行希尔排序。 特点 希尔排序的时间复杂度与递增序列密切相关，所以分析希尔排序的时间复杂度是个比较麻烦的事。 希尔排序对于中等大小规模表现良好，对规模非常大的数据排序不是最优选择。 希尔排序实现简单，几乎任何排序工作在开始时都可以用希尔排序，若在实际使用中证明它不够快，再改成快速排序这样更高级的排序算法。 实现12345678910111213141516171819public class Shell &#123; public static void sort(Comparable[] a) &#123; int n = a.length; // 3x+1 increment sequence: 1, 4, 13, 40, 121, 364, 1093, ... int h = 1; while (h &lt; n/3) h = 3*h + 1; while (h &gt;= 1) &#123; // h-sort the array for (int i = h; i &lt; n; i++) &#123; for (int j = i; j &gt;= h &amp;&amp; less(a[j], a[j-h]); j -= h) &#123; exch(a, j, j-h); &#125; &#125; h /= 3; &#125; &#125;&#125; 参考资料 Wikipedia Algorithms (Fourth Edition) 十大经典排序算法]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ATR-CKN算法的研究与实现]]></title>
    <url>%2F2019%2F01%2F28%2FATR-CKN%E7%AE%97%E6%B3%95%E7%9A%84%E7%A0%94%E7%A9%B6%E4%B8%8E%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[前言最近在学校做了无线传感器网络（WSN）睡眠调度算法方面的一些研究，本篇文章主要对其中的CKN、EC-CKN算法的学习做个总结，并给出基于这两种算法而改进后的ATR-CKN算法的核心实现以及在Nettopo上的运行结果。 CKN与EC-CKN算法K-邻居节点连通算法（CKN）是一个有效的分布式睡眠/工作时序安排算法。该算法可以在有效的减少网络中处于工作状态的节点个数的同时保证整个网络处于连通状态和需求的路径延迟。执行CKN算法时对WSN中的每个节点u主要进行以下几步： 针对CKN算法在能量消耗方面存在的问题，基于能量消耗的睡眠/工作时序安排算法（EC-CKN）可以延长网络的寿命。EC-CKN算法利用节点当前的剩余能量信息作为参数来决定节点是否进入睡眠状态。EC-CKN算法不仅可以保证整个网络处于K邻居节点连通状态，同时还可以保证每个节点处于工作状态的K个邻居节点当前的剩余能量在所有邻居节点当前剩余能量排序中为最大的K个。 存在的问题EC-CKN对CKN有了一定的改进，但在某些场景下仍然会存在一些问题，例如下文将介绍的死亡加速与网络隔离。 死亡加速在下图的场景中，节点B有很多个邻居节点，按理是可以进入睡眠状态的，但是由于它的其中一个邻居节点A只有它一个邻居节点，因此节点A和B永远得不到睡眠机会，这导致的后果就是：节点B的能量很快就被消耗完了，而节点B周围原本刚好满足睡眠条件的节点由于少了一个醒着的邻居节点，睡眠的几率也因此下降，从而加速了整个网络的死亡。 网络隔离类似于死亡加速，在下面的场景中节点A和B永远也得不到睡眠机会，因此会更快的消耗完能量，导致相连的两个网络被隔离开了。 ATR-CKN算法ATR-CKN算法优于原始的基于CKN的睡眠调度算法，它的优势在于可以在物理上调整传感器节点的传输半径，从而执行CKN使部分节点进入睡眠状态。ATR-CKN算法在继承了EC-CKN算法的所有主要属性的同时，通过提高节点的睡眠率为延长网络生命周期做出了重要贡献。 相较于EC-CKN，ATR-CKN只用在之前加入一个判断逻辑即可： 核心实现下面给出在Nettopo上对于ATR-CKN算法的实现，其关键在于执行EC-CKN之前加入下面一段判断逻辑： 123456789101112131415161718192021private void ATRCKN_Function() &#123;//... boolean flag = false; Integer[] neighbors1 = neighbors.get(currentID); if(neighbors1.length &lt; k) &#123; while(!isUsingMaxTR(currentID)) &#123; increaseTR(currentID); neighbors1 = neighbors.get(currentID); if(neighbors1.length &gt;= k) &#123; for(int j = 0; j &lt; neighbors1.length; j++) &#123; int tr = ((SensorNode)wsn.getNodeByID(currentID)).getMaxTR(); ((SensorNode)wsn.getNodeByID(neighbors1[j])).setMaxTR(tr); &#125; flag = true; break; &#125; &#125; if(!flag) setDefaultTR(currentID); &#125; //...&#125; 运行结果下面将在Nettopo上简单的演示一遍ATR-CKN算法对于死亡加速问题的解决。 k = 2，round = 1的时候： k = 2，round = 10的时候： k = 2，round = 30的时候 k = 2，round = 43的时候： 由于增大了传感器节点的物理传输半径，可以看到两个关键节点都可以进入睡眠状态，以此延长了网络的整体寿命。虽然增大传输半径的同时也增加了能量消耗，但在进行了大量实验并对统计数据进行详细分析后，我们可以发现ATR-CKN的生命周期相比EC-CKN平均增加了19％，最大增加了41%，因此可以得出其更优于EC-CKN的结论。]]></content>
      <categories>
        <category>项目</category>
      </categories>
      <tags>
        <tag>WSN</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM-垃圾收集与内存分配]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM-%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E4%B8%8E%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%2F</url>
    <content type="text"><![CDATA[对象存活判断判断对象是否存活一般有引用计数法和可达性分析两种方式。 引用计数算法为每个对象添加一个引用计数器，新增一个引用时计数器加1，引用释放时计数器减1，计数器为0时该对象可以被回收。 引用计数法实现简单且高效，但无法解决对象之间相互循环引用的问题。 可达性分析算法通过一系列GC Roots作为起始点向下搜索，搜索所走过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可引用的。 可作为GC Roots的对象包括下面几种： 虚拟机栈中引用的对象。 方法区中类静态属性引用的对象。 方法区中常量引用的对象。 本地方法栈中JNI引用的对象。 finalize如果对象在进行可达性分析后发现没有与GC Roots相连接的引用链，那它将会被第一次标记。如果没有覆盖finalize()方法或者该方法已经被虚拟机调用过，那么它将被回收；否则，会将这个对象放置在一个叫做F-Queue的队列中，要想不被回收，就要在finalize()中重新与引用链上的任何一个对象建立关联。 引用类型对象的引用类型分为强引用、软引用、弱引用、虚引用，这四种引用强度依次减弱。 强引用：类似Object obj = new Object()这类的引用，强引用关联的对象永远不会被回收。 软引用：软引用是用来描述一些还有用但并非必需的对象。在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中进行第二次回收，如果这次回收还没有足够的内存才会抛出内存溢出异常。简单的说，被软引用关联的对象只有在内存不够的情况下才会被回收。 弱引用：强度比软引用更弱一些，无论当前内存是否足够，被弱引用关联的对象一定会被回收。 虚引用：一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用取得一个对象。为一个对象设置虚引用关联的唯一目的就是能在这个对象被回收时收到一个系统通知。 垃圾收集算法最基础的垃圾收集算法有三种：标记-清除算法、复制算法、标记-整理算法，我们常用的垃圾回收器一般都采用分代收集算法。 标记-清除算法首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。 不足：标记和清除的两个过程的效率都不高；会产生大量不连续的内存碎片，导致无法给大对象分配内存。 复制算法将内存划分为大小相等的两块，每次只使用其中一块，当这一块内存用完了就将还存活的对象复制到另一块上面，然后再把使用过的内存空间进行一次清理。 现在的商业虚拟机都采用这种收集算法来回收新生代，但并不需要按照1：1的比例来划分内存空间，而是将内存分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中一块Survivor。当回收时，将Eden和Survivor中还活着的对象一次性地复制到另外一块Survivor空间上，最后清理掉Eden和刚才用过的Survivor空间。 如果每次回收有多于 10% 的对象存活，那么一块 Survivor 空间就不够用了，此时需要依赖于老年代进行分配担保，也就是借用老年代的空间存储放不下的对象。 标记-整理算法复制算法在对象存活率较高时要进行较多的复制操作，也有可能需要额外的空间进行分配担保，所以在老年代一般不能直接选用这种算法。 标记-整理算法的标记过程仍与标记-清除算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。 分代收集算法现在的商业虚拟机采用分代收集算法，它根据对象存活周期将内存划分为新生代和老年代，新生代使用复制算法，老年代使用标记-清除或者标记-整理算法。 垃圾收集器如果说收集算法是内存回收的方法论，垃圾收集器就是内存回收的具体实现。 Serial收集器串行收集器是最古老，最稳定以及效率高的收集器，可能会产生较长的停顿，只使用一个线程去回收。 ParNew收集器ParNew收集器其实就是Serial收集器的多线程版本。 Parallel Scavenge收集器Parallel是一个多线程收集器。其它收集器关注点是尽可能缩短垃圾收集时用户线程的停顿时间，而Parallel Scavenge收集器的目标是达到一个可控制的吞吐量，它被称为“吞吐量优先”收集器。这里的吞吐量指 CPU 用于运行用户代码的时间占总时间的比值。 停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验。而高吞吐量则可以高效率地利用 CPU 时间，尽快完成程序的运算任务，适合在后台运算而不需要太多交互的任务。缩短停顿时间是以牺牲吞吐量和新生代空间来换取的：新生代空间变小，收集时间缩短，但同时垃圾回收也变得频繁，导致吞吐量下降。 可以通过一个开关参数打开GC自适应的调节策略（GC Ergonomics），就不需要手工指定新生代的大小、Eden和Survivor区的比例、晋升老年代对象年龄等细节参数了。虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量。 Serial Old收集器Seriol Old是Serial收集器的老年代版本，同样是一个单线程收集器。 Parallel Old收集器Parallel Old是Parallel Scavenge收集器的老年代版本，同样是一个多线程收集器。 CMS收集器CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。目前很大一部分的Java应用都集中在互联网站或B/S系统的服务端上，这类应用尤其重视服务的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。 从名字（包含“Mark Sweep”）上就可以看出CMS收集器是基于“标记-清除”算法实现的，它的运作过程相对于前面几种收集器来说要更复杂一些，整个过程分为以下几个阶段： Initial Mark：这个是CMS两次stop-the-wolrd事件的其中一次，这个阶段的目标是标记那些直接被GC root引用或者被年轻代存活对象所引用的所有对象。 Concurrent Mark：在这个阶段收集器会根据上个阶段找到的GC Roots遍历查找，然后标记所有存活的对象，也就是进行GC Roots Tracing的过程。这个阶段会与用户的应用程序并发运行，因此在标记期间用户的程序可能会改变一些引用，并不是老年代所有的存活对象都会被标记。 Concurrent Preclean：这也是一个并发阶段，与应用的线程并发运行。在并发运行的过程中，一些对象的引用可能会发生变化，但当种情况发生时，JVM会将包含这个对象的区域（Card）标记为Dirty，这也就是Card Marking。在这个阶段，能够从Dirty对象到达的对象也会被标记，这个标记做完之后，dirty card标记就会被清除了。 Concurrent Abortable Preclean：这也是一个并发阶段，这个阶段是为了尽量承担stop-the-world中最终标记阶段的工作。 Final Remark：这是第二个STW阶段，也是CMS中的最后一个，这个阶段的目标是标记老年代所有的存活对象，由于之前的阶段是并发执行的，gc线程可能跟不上应用程序的变化，为了完成标记老年代所有存活对象的目标，STW就非常有必要了。 Concurrent Sweep：这个阶段清除那些不再使用的对象，回收它们的占用空间为将来使用。 Concurrent Reset：这个阶段会重设CMS内部的数据结构，为下次的GC做准备。 由于整个过程中耗时最长的并发标记和并发清除过程中，收集器线程都可以与用户线程一起工作，所以总体上来说，CMS收集器的内存回收过程是与用户线程一起并发地执行。 CMS收集器具有以下几个缺点： 在并发阶段，CMS虽然不会导致用户线程停顿，但是会因为占用了一部分线程（或者说CPU资源）而导致应用程序变慢，总吞吐量会降低。 CMS无法处理浮动垃圾。 需要预留一部分空间提供并发收集时的程序运作使用，因此不能等到老年代完全被填满再进行收集，要是CMS运行期间预留的内存无法满足程序需要，就会出现“Concurrent Mode Failure”失败，这时将会启用Serial Old收集器重新进行老年代的垃圾收集，停顿时间就很长了。 CMS是基于“标记-清除”算法实现的收集器，会产生大量空间碎片。 浮动垃圾：由于CMS并发清理阶段用户线程还在运行着，伴随程序运行自然就还会有新的垃圾不断产生，这一部分垃圾出现在标记过程之后，CMS无法在当次收集中处理掉它们，只好留待下一次GC时再清理掉，这一部分垃圾就称为“浮动垃圾”。 G1收集器G1（Garbage-First）收集器是一款面向服务端应用的垃圾收集器，在多CPU和大内存的场景下有很好的性能。HotSpot开发团队赋予它的使命是未来可以替换掉CMS收集器。G1收集器具有以下几个特点： 垃圾收集线程和应用线程并发执行，和CMS一样。 分代收集：不需要其它收集器配合就能独立管理整个GC堆，采用不同的方式去收集。 空间整合：整体来看是基于“标记 - 整理”算法实现的收集器，从局部（两个Region之间）上来看是基于“复制”算法实现的，这意味着运行期间不会产生内存空间碎片。 可预测的停顿：能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在GC上的时间不得超过N毫秒。 在G1算法中，采用了一种完全不同的方式组织堆内存，它将整个Java堆划分为多个大小相等的独立区域Region，每个Region是逻辑连续的一段内存，虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔离的了。 G1跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region，这保证了G1收集器在有限的时间内可以获取尽可能高的收集效率。 由于难免存在一个Region中的对象引用另一个Region中对象的情况，为了达到可以以Region为单位进行垃圾回收的目的，G1收集器使用了RememberedSet这种技术。G1中每个Region都有一个与之对应的RememberedSet ，在各个Region上记录自家的对象被外面对象引用的情况。当进行内存回收时，在GC根节点的枚举范围中加入RememberedSet即可保证不对全堆扫描也不会有遗漏。 G1收集器的运作大致可划分为以下几个步骤： 初始标记 并发标记 最终标记 筛选回收 前三个步骤与CMS收集器相似，最后的筛选回收阶段对各个Region的回收价值和成本进行排序，根据用户所期望的GC停顿时间来制定回收计划。 内存分配策略 对象优先分配在Eden区：如果Eden区没有足够的空间时，虚拟机执行一次Minor GC。 大对象直接进入老年代：大对象是指需要大量连续内存空间的对象，这样做的目的是避免在Eden区和两个Survivor区之间发生大量的内存拷贝（新生代采用复制算法收集内存）。 长期存活的对象进入老年代：为对象定义年龄计数器，对象在Eden区出生并经过Minor GC依然存活，将被移动到Survivor区中，年龄增加1岁，增加到年龄阈值则移动到老年代中。 动态判断对象的年龄：如果在Survivor区中相同年龄所有对象大小的总和大于Survivor空间的一半，则年龄大于或等于该年龄的对象可以直接进入老年代而无需达到年龄阈值。 空间分配担保：新生代使用复制收集算法，但为了了内存利用率，只是用其中一个Survivor空间来作为轮换备份，因此当出现大量对象在Minor GC后仍然存活的情况，就需要老年代进行分配担保，把Survivor无法容纳的对象直接进入老年代。老年代要进行这样的担保，前提是老年代本身还有容纳这些对象的剩余空间，一共有多少对象会活下来在实际完成内存回收之前是无法明确知道的，所以在发生Minor GC之前，虚拟机先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果大于则确保是安全的，如果不大于，则只好以晋升到老年代对象容量的平均大小值作为经验值，与老年代的剩余空间进行比较，决定是否进行Full GC来让老年代腾出更多的空间。 方法区的回收垃圾收集主要针对于Java堆进行，方法区虽然也有垃圾收集，但性价比很低，主要回收两部分内容：废弃常量和无用的类。 无用的类需要满足下面三个条件： 该类所有的实例都已经被回收，也就是堆中不存在该类的任何实例。 加载该类的ClassLoader已经被回收。 该类对应的Class对象没有在任何地方被引用，也就无法在任何地方通过反射访问该类方法。 参考资料 周志明. 深入理解 Java 虚拟机 [M]. 机械工业出版社, 2011. JVM 之 ParNew 和 CMS 日志分析 JVM 之 OopMap 和 RememberedSet]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>垃圾收集</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM-类加载机制]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM-%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[类的生命周期 类加载过程类加载的过程包括了加载、验证、准备、解析、初始化五个阶段。 在这五个阶段中，加载、验证、准备和初始化这四个阶段发生的顺序是确定的，而解析阶段则不一定，它在某些情况下可以在初始化阶段之后开始，这是为了支持Java语言的运行时绑定（也称为动态绑定或晚期绑定）。另外注意这里的几个阶段是按顺序开始，而不是按顺序进行或完成，因为这些阶段通常都是互相交叉地混合进行的，通常在一个阶段执行的过程中调用或激活另一个阶段。 加载在加载阶段，虚拟机需要完成以下三件事情： 通过一个类的全限定名来获取其定义的二进制字节流。 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。 在Java堆中生成一个代表这个类的java.lang.Class对象，作为对方法区中这些数据的访问入口。 相对于类加载的其他阶段而言，加载阶段（准确地说，是加载阶段获取类的二进制字节流的动作）是可控性最强的阶段，因为开发人员既可以使用系统提供的类加载器来完成加载，也可以自定义自己的类加载器来完成加载。 加载阶段完成后，虚拟机外部的二进制字节流就按照虚拟机所需的格式存储在方法区之中，而且在Java堆中也创建一个java.lang.Class类的对象，这样便可以通过该对象访问方法区中的这些数据。 二进制字节流不一定要从一个Class文件中获取，还可以通过以下几种方式获取： 从ZIP包读取，成为JAR、EAR、WAR格式的基础。 从网络中获取，最典型的应用是Applet。 运行时计算生成，例如动态代理技术，在java.lang.reflect.Proxy中使用ProxyGenerator.generateProxyClass来为特定接口生成代理类的二进制字节流。 由其他文件生成，例如由JSP文件生成对应的Class类。 验证确保 Class 文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。验证阶段大致会完成4个阶段的检验动作： 文件格式验证：验证字节流是否符合Class文件格式的规范。 元数据验证：对类的元数据信息进行语义校验，保证不存在不符合Java语言规范的元数据信息。（例如：这个类是否有父类）。 字节码验证：通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的，保证被校验类的方法在运行时不会做出危害虚拟机安全的事件。 符号引用验证：确保解析动作能正确执行。 验证阶段是非常重要的，但不是必须的，它对程序运行期没有影响，如果所引用的类经过反复验证，那么可以考虑采用-Xverifynone参数来关闭大部分的类验证措施，以缩短虚拟机类加载的时间。 准备准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些变量所使用的内存都将在方法区中进行分配。 注意： 这时候进行内存分配的仅包括类变量（被static修饰的变量），实例变量将会在对象实例化时（实例化不是类加载的一个过程）随着对象一起分配在Java堆中。 初始值通常情况下是数据类型的零值，但如果类字段同时被final和static修饰（即为常量），那么在准备阶段就会被初始化为所指定的值。 解析解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。 符号引用：符号引用以一组符号来描述所引用的目标，可以是任何形式的字面量，与虚拟机实现的内存布局无关，引用的目标不一定已经加载到内存中。 直接引用：直接引用可以是直接指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄。直接引用是和虚拟机实现的内存布局相关的，引用的目标必定已经在内存中存在。 更通俗的解释：符号引用就是字符串，这个字符串包含足够的信息，以供实际使用时可以找到相应的位置。比如说某个方法的符号引用如：java/io/PrintStream.println:(Ljava/lang/String;)V。里面有类的信息，方法名，方法参数等信息。当第一次运行时，要根据字符串的内容，到该类的方法表中搜索这个方法。运行一次之后，符号引用会被替换为直接引用，下次就不用搜索了。直接引用就是偏移量，通过偏移量虚拟机可以直接在该类的内存区域中找到方法字节码的起始位置。 —– 来自知乎 https://www.zhihu.com/question/30300585 其中解析过程在某些情况下可以在初始化阶段之后再开始，这是为了支持Java的动态绑定。 动态绑定是指在执行期间（非编译期）判断所引用对象的实际类型，根据其实际的类型调用其相应的方法。 程序运行过程中，把函数（或过程）调用与响应调用所需要的代码相结合的过程称为动态绑定。 初始化初始化阶段才真正开始执行类中定义的Java程序代码。初始化阶段即虚拟机执行类构造器&lt;clinit&gt;()方法的过程。 &lt;clinit&gt;()方法是由编译器自动收集类中所有类变量的赋值动作和静态语句块中的语句合并产生的，编译器收集的顺序由语句在源文件中出现的顺序决定。特别注意的是，静态语句块只能访问到定义在它之前的类变量，定义在它之后的类变量只能赋值，不能访问。 与类的构造函数（或者说实例构造器&lt;init&gt;()）不同，不需要显式的调用父类的构造器。虚拟机会自动保证在子类的&lt;clinit&gt;()方法运行之前，父类的&lt;clinit&gt;()方法已经执行结束。因此虚拟机中第一个执行&lt;clinit&gt;()方法的类肯定为java.lang.Object。 由于父类的&lt;clinit&gt;()方法先执行，也就意味着父类中定义的静态语句块的执行要优先于子类。 &lt;clinit&gt;()方法对于类或接口不是必须的，如果一个类中不包含静态语句块，也没有对类变量的赋值操作，编译器可以不为该类生成&lt;clinit&gt;()方法。 接口中不可以使用静态语句块，但仍然有类变量初始化的赋值操作，因此接口与类一样都会生成&lt;clinit&gt;()方法。但接口与类不同的是，执行接口的&lt;clinit&gt;()方法不需要先执行父接口的&lt;clinit&gt;()方法。只有当父接口中定义的变量使用时，父接口才会初始化。另外，接口的实现类在初始化时也一样不会执行接口的&lt;clinit&gt;()方法。 虚拟机会保证一个类的&lt;clinit&gt;()方法在多线程环境下被正确的加锁和同步，如果多个线程同时初始化一个类，只会有一个线程执行这个类的&lt;clinit&gt;()方法，其它线程都会阻塞等待，直到活动线程执行&lt;clinit&gt;()方法完毕。如果在一个类的&lt;clinit&gt;()方法中有耗时的操作，就可能造成多个线程阻塞，在实际过程中此种阻塞很隐蔽。 在准备阶段，类变量已经赋过一次系统要求的初始值，而在初始化阶段，根据程序员通过程序制定的主观计划去初始化类变量和其它资源。在Java中对类变量进行初始值设定有两种方式： 声明类变量时指定初始值。 使用静态代码块为类变量指定初始值。 只有当对类主动引用的时候才会导致类的初始化，主动引用有以下几种： 创建类的实例，也就是new的方式。 访问某个类或接口的静态变量，或者对该静态变量赋值。 调用类的静态方法。 使用java.lang.reflect包的方法对类进行反射调用的时候。 当初始化一个类的时候，如果其父类还没有进行过初始化，则需要先触发其父类的初始化。 当虚拟机启动时，用户需要指定一个要执行的主类（包含 main() 方法的那个类），虚拟机会先初始化这个主类。 除主动引用外的所有引用类的方式都不会触发初始化，被称为被动引用，常见有以下几个例子: 通过子类引用父类的静态字段，不会导致子类初始化。 通过数组定义来引用类，不会触发此类的初始化。该过程会对数组类进行初始化，数组类是一个由虚拟机自动生成的、直接继承自Object的子类，其中包含了数组的属性和方法。 类加载器两个类相等需要类本身相等，并且使用同一个类加载器进行加载。这是因为每一个类加载器都拥有一个独立的类名称空间。 从 Java 虚拟机的角度来讲，只存在以下两种不同的类加载器： 启动类加载器（Bootstrap ClassLoader），这个类加载器用C++实现，是虚拟机自身的一部分。 所有其他类的加载器，这些类由Java实现，独立于虚拟机外部，并且全都继承自抽象类java.lang.ClassLoader，这些类加载器需要由启动类加载器加载到内存中之后才能去加载其他的类。 站在Java开发人员的角度来看，类加载器可以大致划分为以下三类： 启动类加载器（Bootstrap ClassLoader）：此类加载器负责将存放在 &lt;JRE_HOME&gt;\lib目录中的，或者被-Xbootclasspath参数所指定的路径中的，并且是虚拟机识别的（仅按照文件名识别，如rt.jar，名字不符合的类库即使放在lib目录中也不会被加载）类库加载到虚拟机内存中。启动类加载器无法被Java程序直接引用，用户在编写自定义类加载器时，如果需要把加载请求委派给启动类加载器，直接使用null代替即可。 扩展类加载器（Extension ClassLoader）：此类加载器是由ExtClassLoader（sun.misc.Launcher$ExtClassLoader）实现的。它负责将&lt;JAVA_HOME&gt;/lib/ext或者被java.ext.dir系统变量所指定路径中的所有类库加载到内存中，开发者可以直接使用扩展类加载器。 应用程序类加载器（Application ClassLoader）：此类加载器是由AppClassLoader（sun.misc.Launcher$AppClassLoader）实现的。由于这个类加载器是ClassLoader中的getSystemClassLoader()方法的返回值，因此一般称为系统类加载器。它负责加载用户类路径（ClassPath）上所指定的类库，开发者可以直接使用这个类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。 双亲委派模型双亲委派模型的工作流程是：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把请求委托给父加载器去完成，依次向上，因此，所有的类加载请求最终都应该被传递到顶层的启动类加载器中，只有当父加载器在它的搜索范围中没有找到所需的类时，即无法完成该加载，子加载器才会尝试自己去加载该类。 该模型要求除了顶层的启动类加载器外，其余的类加载器都应有自己的父类加载器。这里类加载器之间的父子关系一般通过组合关系来实现，而不是通过继承的关系实现。 具体过程 当AppClassLoader加载一个class时，它首先不会自己去尝试加载这个类，而是把类加载请求委派给父类加载器ExtClassLoader去完成。 当ExtClassLoader加载一个class时，它首先也不会自己去尝试加载这个类，而是把类加载请求委派给BootStrapClassLoader去完成。 如果BootStrapClassLoader加载失败（例如在&lt;JRE_HOME&gt;\lib里未查找到该class），会使用ExtClassLoader来尝试加载。 若ExtClassLoader也加载失败，则会使用AppClassLoader来加载，如果AppClassLoader也加载失败，则会报出异常ClassNotFoundException。 优点使得Java类随着它的类加载器一起具有一种带有优先级的层次关系，从而使得基础类得到统一。 例如java.lang.Object存放在rt.jar中，如果编写另外一个java.lang.Object的类并放到ClassPath中，程序可以编译通过。由于双亲委派模型的存在，所以在rt.jar中的Object比在ClassPath中的Object优先级更高，这是因为rt.jar中的Object使用的是启动类加载器，而ClassPath中的Object使用的是应用程序类加载器。rt.jar中的Object优先级更高，那么程序中所有的Object都是这个Object。 自定义类加载器通常情况下，我们都是直接使用系统类加载器，但是有的时候，我们也需要自定义类加载器。 自定义类加载器一般都是继承自ClassLoader类，而java.lang.ClassLoader的loadClass()实现了双亲委派模型的逻辑，因此自定义类加载器最好不要去重写它。 参考资料 周志明. 深入理解 Java 虚拟机 [M]. 机械工业出版社, 2011.]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM-内存模型]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM-%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[Java内存模型由于计算机上的内存模型涉及到物理的主内存、高速缓存和寄存器等。这些不同的计算机不同的操场系统可能会存在差异，Java虚拟机规范中试图定义一种Java内存模型，来屏蔽掉各种硬件和操作系统的内存访问差异，让Java程序在各个平台下都能达到一致的访问效果。 主内存与工作内存 Java内存模型规定了所有变量都存储在主内存内（主内存包括方法区和堆），此处主内存隶属于Java虚拟机内存的一部分，而虚拟机内存是操作系统分配的。每条Java线程还有自己的工作内存，工作内存中保存了被该线程使用到的变量的主内存的副本，线程对变量的所有操作都在工作内存中进行，Java线程之间的变量值传递都通过主内存来完成。 内存间的交互关于主内存和工作内存间的交互协议，即一个变量如何从主内存拷贝到工作内存、又是如何从工作内存同步回主内存之类的实现细节，Java内存模型中定义了8种操作，这8种操作实现时必须保证每一种操作都是原子的、不可再分的，其中前4条是作用于主内存，后4条作用于工作内存： lock锁定：将一个变量标识为线程独占状态 unlock解锁：将锁定状态的变量解除锁定，释放后的变量才可以被其他变量锁定 read读取：将变量从主内存传输到线程的工作内存中，待之后的load加载 write写入：把store操作从工作内存中得到的变量值写入主内存的变量中 load加载：将read后从主内存得到的变量值加载到工作内存的变量副本中 use使用：把工作内存中的一个变量值传递给字节码执行引擎，等待字节码指令使用 assign赋值：把一个从执行引擎接收到的值赋值给工作内存的变量 store存储：把工作内存中一个变量的值传送到主内存中，以便随后的write使用 运行时数据区域Java虚拟机在执行Java程序的过程中会把它所管理的内存划分为若干个不同的数据区域。其中程序计数器、JVM栈、本地方法栈是线程私有的，而方法区和堆是所有线程共享的。 程序计数器一块较小的内存空间，可以看作当前线程所执行的字节码的行号指示器：如果线程正在执行一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行Native方法，这个计数器值为空。 Java虚拟机栈Java虚拟机栈描述的是Java方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。 局部变量表：局部变量表是一组变量值存储空间，用于存放方法参数和方法内部定义的局部变量。局部变量表所需的内存空间在编译期间完成分配。 动态链接：动态链接是在运行时将符号引用解析为直接引用的过程。 操作数：参与运算的常量或者变量称为操作数。 该区域可能抛出以下异常： 当线程请求的栈深度超过最大值，会抛出StackOverflowError异常。 栈进行动态扩展时如果无法申请到足够内存，会抛出OutOfMemoryError异常。 本地方法栈本地方法栈与Java虚拟机栈类似，它们的区别只不过是虚拟机栈为虚拟机执行Java方法服务，而本地方法栈为本地方法服务。该区域可能抛出的异常与Java虚拟机栈一样。 Java堆Java堆是Java虚拟机所管理的内存中最大的一块，是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。 Java堆是垃圾收集器管理的主要区域，还可以细分为新生代和老年代。 一般情况下，新创建的对象都会存放到新生代中。 在新生代每进行一次垃圾收集后，就会给存活的对象“加1岁”，当年龄达到一定数量的时候就会进入老年代，另外，比较大的对象也会进入老年代。 Java堆不需要物理上连续的内存空间，逻辑上连续即可。如果堆中没有内存完成实例分配且堆也无法再扩展时，将抛出OutOfMemoryError异常。 方法区方法区也是各个线程共享的内存区域，之前是用永久代实现的，用于存储已被虚拟机加载的类信息、常量、静态变量等数据。由于永久代的回收效率低，对于永久代的大小指定困难且容易发生内存溢出等原因，JDK1.8彻底废弃永久代而使用元空间取代，并将字符串常量转移到堆中。元空间并不在虚拟机中，而是使用本地内存，因此默认情况下元空间的大小仅受本地内存限制。 控制参数汇总可以通过如下参数来控制各区域的内存大小：1234567891011-Xms设置堆的最小空间大小-Xmx设置堆的最大空间大小-XX:NewRatio老年代/新生代 -XX:NewSize设置新生代最小空间大小-XX:MaxNewSize设置新生代最大空间大小-Xss设置每个线程的堆栈大小 参考资料 周志明. 深入理解 Java 虚拟机 [M]. 机械工业出版社, 2011.]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>内存模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统原理-死锁]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86-%E6%AD%BB%E9%94%81%2F</url>
    <content type="text"><![CDATA[死锁的定义一组进程中，每个进程都无限等待被该组进程中另一进程所占有的资源，因而永远无法得到的资源，这种现象称为进程死锁，这一组进程就称为死锁进程。 死锁与活锁的区别活锁指的是一组进程既无进展也没有阻塞 ，由于某些条件没有满足，导致一直重复尝试并失败。例如错误地使用Pertonson算法： 产生死锁的必要条件 互斥使用（资源独占）：一个资源每次只能给一个进程使用。 占有且等待（请求和保持）：进程在申请新的资源的同时保持对原有资源的占有。 不可抢占：资源申请者不能强行的从资源占有者手中夺取资源，资源只能由占有者自愿释放。 循环等待：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。 资源分配图系统由若干类资源构成，一类资源称为一个资源类；每个资源类中包含若干个同种资源，称为资源实例。用方框表示资源类，用方框中的黑圆点表示资源实例，用圆圈中加进程名表示进程。如果资源分配图中没有环路，则系统中没有死锁， 如果图中存在环路则系统中可能存在死锁。 资源分配图化简 找一个非孤立、且只有分配边的进程结点，去掉分配边，将其变为孤立结点。 再把相应的资源分配给一个等待该资源的进程，即将该进程的申请边变为分配边。 如果一个图可完全化简（所有的资源和进程都变成孤立的点），则不会产生死锁；如果一个图不可完全化简（即图中还有边存在），则会产生死锁。 死锁预防防止产生死锁的四个必要条件中任何一个条件发生，以此排除发生死锁的可能性。 破坏“互斥使用”条件把独占资源变为共享资源。例如在SPOOLing系统中，实际上并没有为任何进程分配这台打印机，而只是在输入井和输出井中，为进程分配一存储区和建立一章I/O请求表。这样，便把独占设备改造为共享设备。 破坏“占有且等待”条件实现方案一：要求每个进程在运行前必须一次性申请它所要求的所有资源，且仅当该进程所要资源均可满足时才给予一次性分配。 实现方案二：在允许进程动态申请资源前提下规定，一个进程在申请新的资源不能立即得到满足而变为等待状态之前，必须释放已占有的全部资 源，若需要再重新申请。 破坏“不可抢占”条件当一个进程申请的资源被其他进程占用时，可以通过操作系统抢占这一资源(两个进程优先级不同) 。 破坏“循环等待”条件通过定义资源类型的线性顺序实现。 把系统中所有资源编号，进程在申请资源时必须严格按资源编号的递增次序进行，否则操作系统不予分配。 死锁避免在系统运行过程中，对进程发出的每一个系统能够满足的资源申请进行动态检查，并根据检查结果决定是否分配资源，若分配后系统发生死锁或可能发生死锁，则不予分配，否则予以分配。 安全状态如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也仍然存在某种调度次序能够使得每一个进程运行完毕，则称该状态是安全的。 例如，图a的第二列Has表示已拥有的资源数，第三列Max表示总共需要的资源数，Free表示还有可以使用的资源数。从图a开始出发，先让B拥有所需的所有资源（图b），运行结束后释放B，此时Free变为5（图c）；接着以同样的方式运行C和A，使得所有进程都能成功运行，因此可以称图a所示的状态时安全的。 单个资源的银行家算法一个小城镇的银行家，他向一群客户分别承诺了一定的贷款额度，算法要做的是判断对请求的满足是否会进入不安全状态，如果是，就拒绝请求；否则予以分配。 由图可知，状态b进入状态c是进入了一个不安全的状态，因此恢复原来状态，避免了进入不安全状态。 多个资源的银行家算法上图中有五个进程，四个资源。左边的图表示已经分配的资源，右边的图表示还需要分配的资源。最右边的E、P以及A分别表示：总资源、已分配资源以及可用资源。 检查一个状态是否安全的算法如下： 查找右边的矩阵是否存在一行小于等于向量A。如果不存在这样的行，那么系统将会发生死锁，状态是不安全的。 假若找到这样一行，将该进程标记为终止，并将其已分配资源加到A 中。 重复以上两步，直到所有进程都标记为终止，则状态是安全的。 如果一个状态不是安全的，需要拒绝进入这个状态。 死锁检测与解除允许死锁发生，但是操作系统会不断监视系统进展情况，判断死锁是否真的发生，一旦死锁发生则采取专门的措施，解除死锁并以最小的代价恢复操作系统运行。 死锁的检测死锁的检测与银行家算法几乎一样，此处不再阐述。 死锁的解除 利用抢占恢复 利用回滚恢复 通过杀死进程恢复 鸵鸟算法把头埋在沙子里，假装根本没发生问题。 因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。 哲学家就餐问题五个哲学家围着一张圆桌，每个哲学家面前放着食物。哲学家的生活有两种交替活动：吃饭以及思考。当一个哲学家吃饭时，需要先拿起自己左右两边的两根筷子，并且一次只能拿起一根筷子。 下面是一种错误的解法，考虑到如果所有哲学家同时拿起左手边的筷子，那么就无法拿起右手边的筷子，造成死锁。 123456789101112#define N 5void philosopher(int i) &#123; while(true) &#123; think(); take(i); // 拿起左边的筷子 take((i+1)%N); // 拿起右边的筷子 eat(); put(i); put((i+1)%N); &#125;&#125; 为了防止死锁的发生，有以下几种解法： 仅当一个哲学家左右两边的筷子都可用时，才允许他拿筷子。 最多允许4个哲学家同时坐在桌子周围。 规定奇数号哲学家先拿左筷子再拿右筷子，而偶数号哲学家相反。 参考资料 Tanenbaum A S, Bos H. Modern operating systems[M]. Prentice Hall Press, 2014. 北京大学操作系统原理（Operating Systems） 计算机操作系统]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统原理-文件系统]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[文件的分类 普通文件：包含了用户的信息，一般为ASCII或二进制文件 目录文件：管理文件系统的系统文件 特殊文件（设备文件） 文件的逻辑结构逻辑结构是从用户观点出发看到的文件的组织形式。分为以下两类： 流式文件：无结构，对文件内信息不再划分单位，它是依次的一串字符流构成的文件。 记录式文件：有结构，文件由若干个记录组成，可以按记 录进行读、写、查找等操作。 存储介质与物理块典型的存储介质磁盘(包括固态盘SSD)、磁带、光盘、U盘等等，以下为典型的磁盘结构： 物理块 信息存储、传输、分配的独立单位 存储设备划分为大小相等的物理块，统一编号 磁盘访问 寻道：磁头移动定位到指定磁道 旋转延迟：等待指定扇区从磁头下旋转经过 数据传输：数据在磁盘与内存之间的实际传输 文件控制块（FCB）为管理文件而设置的数据结构，保存管理文件所需的所有有关信息（文件属性或元数据）。 文件控制块一般包含下列常用属性： 文件名 文件号 文件大小 文件地址 创建时间 最后修改时间 最后访问时间 各种标志(只读、隐藏、系统、归档等) … 文件目录 文件目录：文件目录由目录项构成，统一管理每个文件的元数据，以支持文件名到文件物理地址的转换。 目录文件：将文件目录以文件的形式存放在磁盘上。 目录项：可以看成是FCB。 文件的物理结构文件的物理结构指的是文件在存储介质上的存放方式。 连续结构文件的信息存放在若干连续的物理块中。 连续结构实现简单，且所需的磁盘寻道次数和寻道时间最少，支持顺序存取和随机存取，但文件不能动态增长，且会产生许多外部碎片。 链接结构一个文件的信息存放在若干不连续的物理块中，各块之间通过指针连接，前一个物理块指向下一 个物理块。 使用链接结构不存在外部碎片的问题，提高了磁盘空间利用率，有利于文件的动态扩充，但是比起连续结构需要更多的寻道次数和寻道时间，且存取速度慢，不适于随机存取。 索引结构一个文件的信息存放在若干不连续物理块中，系统为每个文件建立一个专用数据结构索引表，并将这些物理块的块号存放在该索引表中。 索引结构保持了链接结构的优点，也解决了其缺点：既能顺序存取又能随机存取，满足了文件动态增长的要求，能充分利用磁盘空间。但是索引结构依然有较多的寻道次数和寻道时间，而索引表本身也带来了额外系统开销。 多级索引结构（综合模式） UNIX文件系统采用的便是这种多级索引结构（综合模式）：每个文件的索引表有15个索引项，每项2个字节，前12项直接存放文件的物理块号，如果文件大于12块，则利用第13项指向一个物理块作为一级索引表。假设扇区大小为512字节，物理块等于扇区块大小，那么一级索引表可以存放256个物理块号。对于更大的文件还可利用第14和第15项作为二级和三级索引表。 文件目录检索用户给出文件名，按文件名查找到目录项/FCB，根据目录项/FCB中文件物理地址等信息，计算出文件中任意记录或字符在存储介质上的地址。 目录项分解法通过目录项分解法可以加快文件目录的检索速度。 目录项分解法即把FCB分解成两部分：符号目录项（文件名，文件号）、基本目录项（除文件名外的所有字段）。目录文件改进后减少了访盘次数，提高了文件检索速度。 磁盘调度算法当有多个访盘请求等待时，采用一定的策略，对这些请求的服务顺序调整安排，以降低平均磁盘服务时间，达到公平、高效。 先来先服务（FCFS）按访问请求到达的先后次序服务。 优点是简单公平，但效率不高，相临两次请求可能会造成最内到最外的柱面寻道，使磁头反复移动，增加了服务时间，对机械也不利。 最短寻道时间优先（Shortest Seek Time First）优先选择距当前磁头最近的访问请求进行服务。 虽然改善了磁盘平均服务时间，但是造成某些访问请求长期等待得不到服务，也就是饥饿现象。 扫描算法（SCAN）扫描算法又称为电梯算法，当设备无访问请求时，磁头不动；当有访问请求时，磁头按一个方向移动，在移动过程中对遇到的访问请求进行服务，然后判断该方向上是否还有访问请求，如果有则继续扫描；否则改变移动方向，并为经过的访问请求服务，如此反复。 单向扫描算法（CSCAN）扫描调度算法（SCAN）存在这样的问题：当磁头刚从里向外移动过某一磁道时，恰有一进程请求访问此磁道，这时该进程必须等待，待磁头从里向外，然后再从外向里扫描完所有要访问的磁道后，才处理该进程的请求，致使该进程的请求被严重地推迟。 为了减少这种延迟，CSCAN算法规定磁头只做单向移动。例如，磁头只自里向外移动，当磁头移到最外的被访问磁道时，磁头立即返回到最里的欲访磁道，即将最小磁道号紧接着最大磁道号构成循环，进行扫描。 旋转调度算法旋转调度算法根据延迟时间来决定执行次序的调度，请求访问分为以下三种情况： 若干等待访问者请求访问同一磁头上的不同扇区 若干等待访问者请求访问不同磁头上的不同编号的扇区 若干等待访问者请求访问不同磁头上具有相同的扇区 对于前两种情况总是让首先到达读写磁头位置下的扇区先进行传送操作，而对于第三种情况，这些扇区同时到达读写磁头位置下，可任意选择一个读写磁头进行传送操作。 参考资料 Tanenbaum A S, Bos H. Modern operating systems[M]. Prentice Hall Press, 2014. 北京大学操作系统原理（Operating Systems） 计算机操作系统]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统原理-存储模型]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86-%E5%AD%98%E5%82%A8%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[地址重定位为了保证CPU执行指令时可正确访问内存单元，需要将用户程序中的逻辑地址转换为运行时可由机器直接寻址的物理地址，这一过程称为地址重定位（又称地址转换、地址变换、地址翻译、地址映射）。 逻辑地址（相对地址，虚拟地址）：目标代码通常采用相对地址的形式，其首地址为0， 其余地址都相对于首地址而编址。不能用逻辑地址在内存中读取信息。 物理地址（绝对地址，实地址）：内存中存储单元的地址，可直接寻址。 地址重定位分为静态重定位和动态重定位： 静态重定位：当用户程序加载到内存时，一次性实现逻辑地址到物理地址的转换。 动态重定位：在进程执行过程中进行地址变换，即逐条指令执行时完成地址转换。 伙伴系统Linux底层内存管理采用伙伴系统这一种经典的内存分配方案。 主要思想：将内存按2的幂进行划分，组成若干空闲块链表；查找该链表找到能满足进程需求的最佳匹配块。 过程： 首先将整个可用空间看作一块： 2^u 假设进程申请的空间大小为 s，如果满足 2^u-1 &lt; s &lt;= 2^u，则分配整个块；否则，将块划分为两个大小相等的伙伴，大小为2^u-1 一直划分下去直到产生大于或等于 s 的最小块 基本内存管理方案一整个进程进入内存中一片连续区域。 单一连续区内存在此方式下分为系统区和用户区，系统区仅提供给操作系统使用，用户区是为用户提供的、除系统区之外的内存空间。一段时间内只有一个进程在内存，简单但内存利用率低。 固定分区把内存空间分割成若干区域，称为分区，每个分区的大小可以相同也可以不同，但分区大小固定不变，每个分区装一个且只能装一个进程。 这种方式会产生两个问题：一是程序太大而放不进任何一个分区中；二是容易产生内部碎片。 可变分区可变分区是一种动态划分内存的分区方法。这种分区方法不预先将内存划分，而是在进程装入内存时，根据进程的大小动态地建立分区，并使分区的大小正好适合进程的需要。因此系统中分区的大小和数目是可变的。 可变分区虽然不会产生内部碎片，但容易产生外部碎片，导致内存利用率下降。 在进程装入或换入主存时，如果内存中有多个足够大的空闲块，操作系统必须确定分配哪个内存块给进程使用，考虑以下几种分配算法： 首次适配（first fit）：在空闲区表中找到第一个满足进程要求的空闲区。该算法优先使用低址部分空闲区，在低址空间造成许多小的空闲区，在高地址空间保留大的空闲区。 下次适配（next fit）：从上次找到的空闲区处接着查找。 最佳适配（best fit）：查找整个空闲区表，找到能够满足进程要求的最小空闲区。该算法保留大的空闲区，但造成许多小的空闲区。 最差适配（worst fit ）：总是分配满足进程要求的最大空闲区。该算法保留小的空闲区，尽量减少小的碎片产生。 基本内存管理方案二一个进程进入内存中若干片不连续的区域。 页式存储管理方案用户进程地址空间被划分为大小相等的部分，称为页（page）或页面，从0开始编号。内存空间按同样大小划分为大小相等的区域，称为页框（page frame）或物理页面或内存块，从0开始编号。 内存分配规则：以页为单位进行分配，并按进程需要的页数来分配；逻辑上相邻的页，物理上不一定相邻。 每个进程一个页表，存放在内存。 地址转换CPU取到逻辑地址，自动划分为页号和页内地址；用页号查页表，得到页框号，再与页内偏移拼接成为物理地址。 段式存储管理方案将用户进程地址空间按程序自身的逻辑关系划分为若干个程序段，每个程序段都有一个段号。内存空间被动态划分为若干长度不相同的区域， 称为物理段，每个物理段由起始地址和长度确定。 内存分配规则：以段为单位进行分配，每段在内存中占据连续空间，但各段之间可以不相邻。 地址转换CPU取到逻辑地址，自动划分为段号和段内地址；用段号查段表，得到该段在内存的起始地址，与段内偏移地址计算出物理地址。 覆盖技术把一个程序划分为一系列功能相对独立的程序段，让执行时不要求同时装入内存的程序段组成一组（称为覆盖段），共享同一块内存区域 ，这种内存扩充技术就是覆盖技术。 程序段先保存在磁盘上，当有关程序段的前一部分执行结束，把后续程序段调入内存，覆盖前面的程序段。 一般要求作业各模块之间有明确的调用结构，程序员要向系统指明覆盖结构，然后由操作系统完成自动覆盖。 交换技术内存空间紧张时，系统将内存中某些进程暂时移到外存，把外存中某些进程换进内存，占据前者所占用的区域（进程在内存与磁盘之间的动态调度）。 虚拟存储技术所谓虚拟存储技术是指：当进程运行时，先将其一部分装入内存，另一部分暂留在磁盘，当要执行的指令或访问的数据不在内存时，由操作系统自动完成将它们从磁盘调入内存的工作。 虚拟地址空间：分配给进程的虚拟内存 虚拟地址：在虚拟内存中指令或数据的位置， 该位置可以被访问，仿佛它是内存的一部分 虚拟内存：把内存与磁盘有机地结合起来使用，从而得到一个容量很大的“内存” 虚拟页式存储管理系统虚拟页式即将虚拟存储技术和页式存储管理方案结合起来，以CPU时间和磁盘空间换取昂贵内存空间。 基本思想：进程开始运行之前，不是装入全部页面， 而是装入一个或零个页面，之后，根据进程运行的需要，动态装入其他页面。当内存空间已满，而又需要装入新的页面时，则根据某种算法置换内存中的某个页面，以便装入新的页面。 内存管理单元（MMU）内存管理单元（MMU）管理着地址空间和物理内存的转换，其中的页表（Page table）存储着页（程序地址空间）和页框（物理内存空间）的映射表。 上图为一级页表结构的地址转换，下图为二级页表结构的地址转换及MMU的位置。 二级页表结构及地址映射页目录表共有2^10 = 1K个表项，每个表项是4B，因此页目录大小为4K，存储在一个4K字节的页面中。同理，一个页表也存储在一个4K字节的页面中。 为什么要使用多级页表系统分配给每个进程的虚拟地址都是4G，那么采用一级页表需要4G／4K = 2^20个表项，如果每个页表项是4B，那么需要4MB的内存空间。但是大多数程序根本用不到4G的虚拟内存空间，比如hello world程序，这样一个几kb的程序却需要4MB的内存空间是很浪费的。如果采用二级页表，那么一级页表只需要4KB的空间用来索引二级页表的地址，像hello world这样的程序可能只需要一个物理页，那么只需要一条记录就可以了，故对于二级页表也只要4KB就足够了，所以这样只需要8KB就能解决问题。 TLB（快表）页表一般都很大，并且存放在内存中，所以处理器引入MMU后，读取指令、数据需要访问两次内存：首先通过查询页表得到物理地址，然后访问该物理地址读取指令、数据。由于CPU的指令处理速度与内存指令的访问速度差异大，CPU的速度得不到充分利用，为了减少因为MMU导致的处理器性能下降，引入了TLB。 TLB(Translation Lookaside Buffer)转换检测缓冲区相当于页表的缓存，利用程序访问的局部性原理改进虚拟地址到物理地址的转换速度。TLB保存正在运行进程的页表的子集(部分页表项)，只有在TLB无法完成地址转换任务时，才会到内存中查询页表，这样就减少了页表查询导致的处理器性能下降。 缺页异常缺页异常是一种Page Fault（页错误）。在地址映射过程中，硬件检查页表时发现所要访问的页面不在内存，则产生缺页异常，操作系统执行缺页异常处理程序：获得磁盘地址，启动磁盘，将该页调入内存。此时分为两种情况： 如果内存中有空闲页框，则分配一个页框， 将新调入页装入，并修改页表中相应页表项的有效位及相应的页框号。 若内存中没有空闲页框，则要置换内存中某一页框；若该页框内容被修改过，则要将其写回磁盘。 页面置换算法最佳页面置换算法（OPT，Optimal）置换以后不再需要的或最远的将来才会用到的页面。 这是一种理论上的算法，因为无法知道一个页面多长时间不再被访问，它作为一种标准来衡量其他算法的性能。 先进先出算法（FIFO）选择在内存中驻留时间最长的页并置换它。 该算法会将那些经常被访问的页面也被换出，从而使缺页率升高。 第二次机会算法（SCR，Second Chance）当页面被访问 (读或写) 时设置该页面的R位为1。需要替换的时候，检查最老页面的R位。如果R位是0，那么这个页面既老又没有被使用，可以立刻置换掉；如果是1，就将R位清0，并把该页面放到链表的尾端，修改它的装入时间使它就像刚装入的一样，然后继续从链表的头部开始搜索。 这个算法是对FIFO算法的改进，不会像FIFO一样把经常使用的页面置换出去。 时钟算法（CLOCK）第二次机会算法需要在链表中移动页面，降低了效率。时钟算法使用环形链表将页面连接起来，再使用一个指针指向最老的页面。 最近未使用算法（NRU，Not Recently Used）选择在最近一段时间内未使用过的一页并置换。 每个页面都有两个状态位：R与M，当页面被访问时设置页面的R=1，当页面被修改时设置M=1。其中R位会定时被清零。可以将页面分成以下四类： R=0，M=0 R=0，M=1 R=1，M=0 R=1，M=1 当发生缺页中断时，NRU算法随机地从类编号最小的非空类中挑选一个页面将它换出。 NRU算法优先换出已经被修改的脏页面（R=0，M=1），而不是被频繁使用的干净页面（R=1，M=0）。 最近最久未使用算法（LRU，Least Recently Used ）虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。LRU算法选择最后一次访问时间距离当前时间最长的一页并置换，即置换未使用时间最长的一页。 为了实现LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最长时间未访问的。 LRU的性能接近OPT，但因为每次访问都需要更新链表，因此这种方式实现的LRU代价很高。 最不经常使用算法（NFU，Not Frequently Used）NFU算法选择访问次数最少的页面置换。 因为LRU算法的实现比较麻烦而且开销很大，所以提出了用软件来模拟LRU算法的NFU算法，该算法为每一页设置一个软件计数器，初值为0，每次时钟中断的时候就将计数器加R，发生缺页中断时选择计数器值最小的一页置换。 老化算法（AGING）在NFU算法中存在一个问题：在第一次时钟中断的时候其中一页可能被访问了很多次，之后再未被访问过，然而在以后的时钟中断这一页计数器的值仍然高于其它页，因此其虽然长时间未被访问也不会被置换出去。 为了更好地模拟LRU算法，老化算法对NFU进行了改进，计数器在加R前先右移一位，R位加到计数器的最左端。 工作集算法基本思想：根据程序的局部性原理，一般情况下，进程在一段时间内总是集中访问一些页面，这些页面称为活跃页面，如果分配给一个进程的物理页面数太少了，使该进程所需的活跃页面不能全部装入内存，则进程在运行过程中将频繁发生中断 。如果能为进程提供与活跃页面数相等的物理页 面数，则可减少缺页中断次数。 工作集W(t, Δ) = 该进程在过去的Δ个虚拟时间单位中访问到的页面的集合 工作集算法就是找出一个不在工作集中的页面并置换它。具体过程为：扫描所有页表项，如果一个页面的R位是1，则将该页面的最后一次访问时间设为当前时间，将R位清零；如果一个页面的R位是0，则检查该页面的访问 时间是否在“当前时间-T”之前，如果是，则该页面为被置换的页面；如果不是，记录当前所有被扫描过页面的最后访问时间里面的最小值，扫描下一个页面并重复上述过程。 参考资料 Tanenbaum A S, Bos H. Modern operating systems[M]. Prentice Hall Press, 2014. 北京大学操作系统原理（Operating Systems） 计算机操作系统 内存连续分配方式的几种算法及优劣 多级页表]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统原理-同步机制]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86-%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[进程互斥由于各进程要求使用共享资源（变量、文件等），而这些资源需要排他性使用，各进程之间竞争使用这些资源，这一关系称为进程互斥。 临界资源与临界区系统中某些资源一次只允许一个进程使用，称这样的资源为临界资源或互斥资源或共享变量。 而各个进程中对某个临界资源（共享变量）实施操作的程序片段称为临界区或互斥区。 临界区的使用原则 没有进程在临界区时，想进入临界区的进程可进入 不允许两个进程同时处于其临界区中 临界区外运行的进程不得阻塞其他进程进入临界区 不得使进程无限期等待进入临界区 进程互斥的软件解决方案错误解法考虑两个进程p和q，pturn与qturn表示哪个进程要进入临界区，P进入临界区的条件为pturn &amp;&amp; not qturn，而Q进入临界区的条件为not pturn &amp;&amp; qturn: 12345//进程p：pturn = true; while (qturn) ; visit(); //访问临界区pturn = false; 12345//进程q：qturn = true; while (pturn) ; visit(); //访问临界区qturn = false; 如果由于CPU调度使得两个进程都执行完了第一行语句，也就是pturn和qturn都为true了，那么就都会在下一行while语句上死循环，互相都在谦让对方执行，也就不满足了临界区的使用原则—不得使进程无限期等待进入临界区。 Dekker算法Dekker互斥算法是由荷兰数学家Dekker提出的一种解决并发进程互斥与同步的软件实现方法。假设有p和q两个进程，变量pturn、qturn表示p和q进程是否想要资源（可以想象为举手示意想要），变量turn表示安排资源给谁： 123456789101112//进程P：pturn = true; //进程p举手示意想要访问while (qturn) &#123; //如果进程q也举手了 if (turn == 2) &#123; //资源被安排给了q pturn = false; //进程p把手放下 while (turn == 2); //资源安排给q的时候一直等待 pturn = true; //此时资源安排给了自己，进程p再举手 &#125;&#125;visit(); //访问临界区turn = 2; //进程p使用完了，安排资源给qpturn = false; //进程p把手放下 123456789101112//进程q：qturn = true; while (pturn) &#123; if (turn == 1) &#123; qturn = false; while (turn == 1); qturn = true; &#125;&#125;visit(); //访问临界区turn = 1;qturn = false; 如果两个进程都执行完了第一行语句，也就是pturn和qturn都为true了，那么会根据变量turn进一步查看究竟是把资源安排给了谁，如果安排给了另一个进程，那么自己就先把手放下，等待安排资源给自己。 与之前的错误解法相比，可以发现Dekker算法就是在原本的while死循环上做了进一步的判断，引入的turn变量总是会安排一个进程访问临界区。 Peterson算法Peterson算法是另一种解决并发进程互斥与同步的软件实现方法，而且克服了强制轮流法的缺点。其使用十分方便，只需要向如下这样调用即可: 123enter_region(i);visit(); //访问临界区leave_region(i); 其中的enter_region方法实现如下： 1234567891011121314#define FALSE 0#define TRUE 1#define N 2 //进程的个数int turn; //轮到谁int interested[N]; //兴趣数组，初始值均为FALSE void enter_region(int process) // process = 0 或 1&#123; int other; // 另外一个进程的进程号 other = 1 - process; interested[process] = TRUE; // 表明本进程感兴趣 turn = process; // 设置标志位 while(turn == process &amp;&amp; interested[other] == TRUE); &#125; 如果有两个进程都要执行的话，turn会被设置成后一个进程的进程号，这时候因为要按照先来后到的规矩，后一个进程在判断while条件的时候turn == process成立，也就进行循环等待，而先进入的进程可以访问临界区。当先进入的进程离开了临界区，就调用leave_region方法，将自己的兴趣设为FALSE，后一个进程判断interested[other] == TRUE不成立时就可以跳出while循环进入临界区了。 123void leave_region(int process)&#123; interested[process] = FALSE; // 本进程已离开临界区&#125; 进程互斥的硬件解决方案“测试并加锁”指令 “交换”指令 进程同步进程同步指系统中多个进程中发生的事件存在某种时序关系，需要相互合作，共同完成一项任务。具体地说，一个进程运行到某一点时， 要求另一伙伴进程为它提供消息，在未获得消息之前，该进程进入阻塞态，获得消息后被唤醒进入就绪态。 信号量及PV操作信号量是一个特殊变量，用于进程间传递信息的一个整数值，定义如下： 12345struct semaphore&#123; int count; queueType queue;&#125; 可以对其执行down和up操作，也就是常见的P和V操作（PV操作均为原语操作），定义如下： 12345678910111213141516171819P(semaphore s) &#123; s.count--; if (s.count &lt; 0) &#123; //该进程状态置为阻塞状态； //将该进程插入相应的等待队列s.queue末尾; //重新调度； &#125;&#125;V(semaphore s) &#123; s.count++; if (s.count &lt;= 0) &#123; //唤醒相应等待队列s.queue中等待的一个进程； //改变其状态为就绪态，并将其插入就绪队列； &#125; &#125; 用PV操作解决进程间互斥问题 分析并发进程的关键活动，划定临界区 设置信号量 mutex，初值为1 在临界区前实施 P(mutex) 在临界区之后实施 V(mutex) 用信号量解决生产者-消费者问题问题描述：使用一个缓冲区来保存物品，只有缓冲区没有满，生产者才可以放入物品；只有缓冲区不为空，消费者才可以拿走物品。 这里使用三个信号量，其中mutex用于解决互斥问题，empty和full用于解决同步问题。 123456789101112131415161718192021222324252627#define N 100 //缓冲区个数typedef int semaphore; //信号量是一种特殊的整型数据semaphore mutex = 1; //互斥信号量：控制对临界区的访问semaphore empty = N; //空缓冲区个数，初始为Nsemaphore full = 0; //满缓冲区个数，初始为0void producer() &#123; while(TRUE) &#123; int item = produce_item(); p(&amp;empty); p(&amp;mutex); insert_item(item); v(&amp;mutex); v(&amp;full); &#125;&#125;void consumer() &#123; while(TRUE) &#123; p(&amp;full); p(&amp;mutex); int item = remove_item(); v(&amp;mutex); v(&amp;empty); consume_item(item); &#125;&#125; 注意：不能交换p(&amp;empty);和p(&amp;mutex);的顺序，否则会导致死锁。 用信号量解决读者-写者问题问题描述：多个进程共享一个数据区，这些进程分为只读数据区中的数据的读者进程和只往数据区中写数据的写者进程。允许多个读者同时执行读操作，不允许多个写者同时操作，不允许读者、写者同时操作。 1234567891011121314151617181920212223242526typedef int semaphore;semaphore count_mutex = 1; //对count加锁semaphore data_mutex = 1; //对读写的数据加锁int count = 0; //对数据进行读操作的进程数量void reader() &#123; while(TRUE) &#123; p(&amp;count_mutex); count = count + 1; if(count == 1) p(&amp;data_mutex); // 第一个读者需要对数据进行加锁，防止写进程访问 v(&amp;count_mutex); read(); p(&amp;count_mutex); count = count - 1; if(count == 0) v(&amp;data_mutex); v(&amp;count_mutex); &#125;&#125;void writer() &#123; while(TRUE) &#123; p(&amp;data_mutex); write(); v(&amp;data_mutex); &#125;&#125; 管程由于信号量机制程序编写困难、易出错，所以在程序设计语言中引入管程。 管程是一个抽象数据类型，由关于共享资源的数据结构及在其上操作的一组过程组成，进程只能通过调用管程中的过程来间接地访问管程中的数据结构。 互斥/同步互斥：管程是互斥进入的，管程的互斥性是由编译器负责保证的。 同步：管程中设置条件变量及等待/唤醒操作以解决同步问题，可以让一个进程或线程在条件变量上等待（此时，应先释放管程的使用权），也可以通过发送信号将等待在条件变量上的进程或线程唤醒。 Hoare管程因为管程是互斥进入的，所以当一个进程试图进入一个已被占用的管程时，应当在管程的入口处等待，为此，管程的入口处设置一个进程等待队列，称作入口等待队列。 如果进程P唤醒进程Q，则P等待Q执行；如果进程Q执行中又唤醒进程R，则Q等待R执行；如此， 在管程内部可能会出现多个等待进程。在管程内需要设置一个进程等待队列，称为紧急等待队列，紧急等待队列的优先级高于入口等待队列的优先级。 条件变量条件变量是在管程内部说明和使用的一种特殊类型的变量，对于条件变量，可以执行wait和signal操作： wait(c)：如果紧急等待队列非空，则唤醒第一个等待者；否则释放管程的互斥权，执行此操作的进程进入c链末尾。 signal(c)：如果c链为空，则相当于空操作，执行此操作的进程继续执行；否则唤醒第一个等待者，执行此操作的进程进入紧急等待队列的末尾。 用管程解决生产者-消费者问题12345678910111213141516171819202122232425262728293031323334353637383940//管程monitor ProducerConsumer condition full, empty; //条件变量 integer count; procedure insert (item: integer); begin if count == N then wait(full); insert_item(item); count++; if count ==1 then signal(empty); end; function remove: integer; begin if count==0 then wait(empty); remove = remove_item; count--; if count==N-1 then signal(full); end; count:=0; end monitor; //生产者procedure producer; begin while true do begin item = produce_item; ProducerConsumer.insert(item); end end; //消费者procedure consumer; begin while true do begin item=ProducerConsumer.remove; consume_item(item); end end; MESA管程Hoare管程有个缺点就是会有两次额外的进程切换，因此MESA管程将原本的signal操作变为notify操作：当一个正在管程中的进程执行notify(x)时，它使得x条件队列得到通知，发信号的进程继续执行，而位于条件队列头的进程在将来合适的时候且当处理器可用时恢复执行。 由于收到通知时并未执行，且对等待进程在notify之后何时运行没有任何限制，所以当进程真正被调度时，条件不一定成立，因而这个进程必须重新检查条件，也就是用while循环取代if语句。 IPC（进程间通信）进程间通信（IPC，InterProcess Communication）是指在不同进程之间传播或交换信息。 进程通信是一种手段，而进程同步是一种目的。也可以说，为了能够达到进程同步的目的，需要让进程进行通信，传输一些进程同步所需要的信息。 进程通信的方式通常有管道（包括无名管道和命名管道）、消息队列、信号量、共享存储、Socket、Streams等。其中 Socket和Streams支持不同主机上的两个进程IPC。 管道管道，通常指无名管道，是 UNIX 系统IPC最古老的形式。 管道是通过调用 pipe 函数创建的，当一个管道建立时，它会创建两个文件描述符：fd[0]为读而打开，fd[1]为写而打开，要关闭管道只需将这两个文件描述符关闭即可。 单个进程中的管道几乎没有任何用处。所以，通常调用 pipe 的进程接着调用 fork，这样就创建了父进程与子进程之间的 IPC 通道。若要数据流从父进程流向子进程，则关闭父进程的读端（fd[0]）与子进程的写端（fd[1]）；反之，则可以使数据流从子进程流向父进程。 特点: 它是半双工的（即数据只能在一个方向上流动），具有固定的读端和写端。 它只能用于具有亲缘关系的进程之间的通信（也是父子进程或者兄弟进程之间）。 FIFOFIFO也称为命名管道，它是一种文件类型，可以在无关的进程之间交换数据，与无名管道不同。 FIFO 常用于客户-服务器应用程序中，FIFO 用作汇聚点，在客户进程和服务器进程之间传递数据。 消息队列消息队列，是消息的链接表，存放在内核中。一个消息队列由一个标识符（即队列ID）来标识。 消息队列是面向记录的，其中的消息具有特定的格式以及特定的优先级。 消息队列独立于发送与接收进程。进程终止时，消息队列及其内容并不会被删除。 消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取。 信号量信号量是一个计数器。信号量用于实现进程间的互斥与同步，而不是用于存储进程间通信数据。 共享内存共享内存指两个或多个进程共享一个给定的存储区，因为数据不需要在进程之间复制，所以这是最快的一种 IPC。由于多个进程可以同时操作，所以信号量与共享内存通常结合在一起使用，信号量用来同步对共享内存的访问。 套接字与其它通信机制不同的是，它可用于不同机器间的进程通信。 参考资料 Tanenbaum A S, Bos H. Modern operating systems[M]. Prentice Hall Press, 2014. 北京大学操作系统原理（Operating Systems） 计算机操作系统 进程间的五种通信方式介绍]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>同步</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统原理-进程线程模型]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86-%E8%BF%9B%E7%A8%8B%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[进程的定义进程是具有独立功能的程序关于某个数据集合上的一次运行活动，是系统进行资源分配和调度的独立单位。 进程控制块PCBPCB：Process Control Block，又称进程描述符、进程属性，是操作系统用于管理控制进程的一个专门数据结构，是系统感知进程存在的唯一标志。 PCB的内容包括： 进程描述信息 进程控制信息 所拥有的资源和使用情况 CPU现场信息 进程状态及状态转换进程的三种基本状态 运行态（Running）：占有CPU，并在CPU上运行 就绪态（Ready）：已经具备运行条件，但由于没有空闲CPU，而暂时不能运行 等待态（Waiting/Blocked）：因等待某一事件而暂时不能运行（如等待读盘结果，又称为阻塞态、睡眠态） 三状态模型及状态转换 其中，只有就绪态和运行态可以相互转换，其它的都是单向转换。 进程的其它状态 创建：已完成创建一进程所必要的工作，但因为资源有限尚未同意执行该进程 终止：终止执行后，进程进入该状态，回收资源 挂起：用于调节负载，进程不占用内存空间，其进程映像交换到磁盘上 进程的五状态模型 进程队列操作系统为每一类进程建立一个或多个队列，队列元素为PCB，伴随进程状态的改变，其PCB从一个队列进入另一个队列。以下为五状态进程模型的队列模型： 进程控制进程控制操作完成进程各状态之间的转换，由具有特定功能的原语完成： 进程创建原语 进程撤消原语 阻塞原语 唤醒原语 挂起原语… 原语：完成某种特定功能的一段程序，具有不可分割性或不可中断性，即原语的执行必须是连续的，在执行过程中不允许被中断 进程的创建 给新进程分配一个唯一标识以及进程控制块 为进程分配地址空间 初始化进程控制块 设置相应的队列指针（如: 把新进程加到就绪队列链表中） 进程的撤销 收回进程所占有的资源（如：关闭打开的文件、断开网络连接、回收分配的内存） 撤消该进程的PCB 进程阻塞处于运行状态的进程，在其运行过程中期待某一事件发生，如等待键盘输入、等待磁盘数据传输完成、等待其它进程发送消息，当被等待的事件未发生时，由进程自己执行阻塞原语，使自己由运行态变为阻塞态。 上下文切换将CPU硬件状态从一个进程换到另一个进程的过程称为上下文切换。 进程运行时，其硬件状态保存在CPU上的寄存器中；进程不运行时，这些寄存器的值保存在进程控制块PCB中；当操作系统要运行一个新的进程时，将PCB中的相关值送到对应的寄存器中。 线程的定义进程中的一个运行实体，是CPU的调度单位，有时将线程称为轻量级进程。 线程共享所在进程的地址空间和其他资源。 线程机制的实现用户级线程在用户空间建立线程库：提供一组管理线程的过程。运行时系统完成线程的管理工作，内核管理的还是进程，不知道线程的存在，线程切换不需要内核态特权。 优点： 线程切换快 调度算法是应用程序特定的 用户级线程可运行在任何操作系统上（只需要实现线程库） 缺点： 大多数系统调用是阻塞的，因此，由于内核阻塞进程，故进程中所有线程也被阻塞 核心级线程内核管理所有线程管理，并向应用程序提供API接口。内核维护进程和线程的上下文，且线程的切换需要内核支持。 混合模型线程创建在用户空间完成，线程调度等在核心态完成。 线程与进程的区别 拥有资源：进程是资源分配的最小单位，但是线程不拥有资源，线程可以访问隶属进程的资源。 调度：线程是CPU调度的最小单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。 系统开销：由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。 通信方面：线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC。 参考资料 Tanenbaum A S, Bos H. Modern operating systems[M]. Prentice Hall Press, 2014. 北京大学操作系统原理（Operating Systems） 计算机操作系统]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统 </tag>
        <tag>进程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统原理-处理器调度]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86%E2%80%94%2F</url>
    <content type="text"><![CDATA[CPU调度即按一定的调度算法从就绪队列中选择一个进程， 把CPU的使用权交给被选中的进程，其任务是控制、协调进程对CPU的竞争。 调度算法衡量指标吞吐量：每单位时间完成的进程数目 周转时间：每个进程从提出请求到运行完成的时间 响应时间：从提出请求到第一次回应的时间 进程调度算法批处理系统目标：吞吐量，周转时间，cpu利用率，包含以下四种调度算法： 先来先服务（FCFS） 短作业优先（SJF） 最短剩余时间优先（SRTN） 最高响应比优先（HRRN） 先来先服务（FCFS） First Come First Serve 按照进程就绪的先后顺序使用CPU 非抢占 长进程后面的短进程需要等很长时间，不利于用户体验。 短作业优先（SJF） Shortest Job First 具有最短完成时间的进程优先执行 非抢占式 最短剩余时间优先（SRTN） Shortest Remaining Time Next SJF的抢占式版本，即当一个新就绪的进程比当前运行进程具有更短的完成时间时，系统抢占当前进程， 选择新就绪的进程执行 短作业优先的调度算法可以得到最短的平均周转时间，但随着源源不断的短任务到来，可能使长的任务长时间得不到运行，即产生 “饥饿”现象。 最高响应比优先（HRRN） Highest Response Ratio Next 调度时，首先计算每个进程的响应比R；之后，总是选择R最高的进程执行 响应比R = 周转时间 / 处理时间 =（处理时间 + 等待时间）/ 处理时间 = 1 +（等待时间 / 处理时间） 交互式系统目标：响应时间，包含以下三种调度算法： 时间片轮转（RR） 最高优先级（HPF） 多级反馈队列（Multiple feedback queue） 时间片轮转 Round Robin 将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。 时间片轮转算法中选择合适的时间片很重要： 如果太长，会降级为先来先服务算法，延长短进程的响应时间 如果太短，进程切换会浪费CPU时间 最高优先级 Highest Priority First 选择优先级最高的进程投入运行 优先级可以是静态不变的，也可以是动态调整的 不公平 会导致优先级翻转问题，解决方案：1、优先级天花板；2、优先级继承 优先级翻转是当一个高优先级任务通过信号量机制访问共享资源时，该信号量已被一低优先级任务占有，因此造成高优先级任务被许多具有较低优先级任务阻塞，实时性难以得到保证。 例如：有优先级为A、B和C三个任务，优先级A&gt;B&gt;C，任务A，B处于挂起状态，等待某一事件发生，任务C正在运行，此时任务C开始使用某一共享资源S。在使用中，任务A等待事件到来，任务A转为就绪态，因为它比任务C优先级高，所以立即执行。当任务A要使用共享资源S时，由于其正在被任务C使用，因此任务A被挂起，任务C开始运行。如果此时任务B等待事件到来，则任务B转为就绪态。由于任务B优先级比任务C高，因此任务B开始运行，直到其运行完毕，任务C才开始运行。直到任务C释放共享资源S后，任务A才得以执行。在这种情况下，优先级发生了翻转，任务B先于任务A运行。 解决优先级翻转问题有优先级天花板(priority ceiling)和优先级继承(priority inheritance)两种办法。 优先级天花板是当任务申请某资源时， 把该任务的优先级提升到可访问这个资源的所有任务中的最高优先级， 这个优先级称为该资源的优先级天花板。这种方法简单易行， 不必进行复杂的判断， 不管任务是否阻塞了高优先级任务的运行， 只要任务访问共享资源都会提升任务的优先级。 优先级继承是当任务A 申请共享资源S 时， 如果S正在被任务C 使用，通过比较任务C 与自身的优先级，如发现任务C 的优先级小于自身的优先级， 则将任务C的优先级提升到自身的优先级， 任务C 释放资源S 后，再恢复任务C 的原优先级。这种方法只在占有资源的低优先级任务阻塞了高优先级任务时才动态的改变任务的优先级，如果过程较复杂， 则需要进行判断。 多级反馈队列设置多个就绪队列，第一级队列优先级最高，给不同就绪队列中的进程分配长度不同的时间片，第一级队列时间片最小；随着队列优先级别的降低，时间片增大。当第一级队列为空时，在第二级队列调度，以此类推。当一个新创建进程就绪后，进入第一级队列，进程用完时间片而放弃CPU，进入下一级就绪队列。由于阻塞而放弃CPU的进程进入相应的等待队列，一旦等待的事件发生，该进程回到原来一级就绪队列。 调度算法总结 调度算法 占用CPU方式 吞吐量 响应时间 开销 对进程的影响 饥饿问题 FCFS 非抢占式 不强调 可能很慢，特别是当进程的执行时间差别很大时 最小 对短进程不利；对I/O型的进程不利 无 RR 抢占式(时间片用完时) 若时间片小，吞吐量会很低 为短进程提供好的响应时间 较大 公平对待 无 SJF 非抢占式 高 为短进程提供好的响应时间 可能较大 对长进程不利 可能 SRTN 抢占式(到达时) 高 提供好的响应时间 可能较大 对长进程不利 可能 HRRN 非抢占式 高 提供好的响应时间 可能较大 很好的平衡性 无 Feedback 抢占式(时间片用完时) 不强调 不强调 可能较大 对I/O型进程有利 可能 参考资料 Tanenbaum A S, Bos H. Modern operating systems[M]. Prentice Hall Press, 2014. 北京大学操作系统原理（Operating Systems） 计算机操作系统 优先级翻转]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LinkedList源码分析]]></title>
    <url>%2F2018%2F09%2F11%2FLinkedList%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[LinkedList简介（jdk1.8)LinkedList是基于双向链表实现的。如下为LinkedList的继承体系结构： 123public class LinkedList&lt;E&gt; extends AbstractSequentialList&lt;E&gt; implements List&lt;E&gt;, Deque&lt;E&gt;, Cloneable, java.io.Serializable 可以看到，LinkedList实现了Deque接口，Deque表示双端队列，即在两端都可以进行插入和删除的队列。Deque是一个比Stack和Queue功能更强大的接口，它同时实现了栈和队列的功能。Deque接口的部分方法如下：1234567891011// *** Queue methods *** boolean add(E e); boolean offer(E e); E remove(); E poll(); E element(); E peek(); // *** Stack methods *** void push(E e); E pop(); 从代码可以看出，Deque既可以用作后进先出的栈，也可以用作先进先出的队列。 与ArrayList一样，LinkedList也不是线程安全的，因此只能在单线程环境下使用。 属性LinkedList有size、first、last三个属性： 12345678//LinkedList中元素的数量transient int size = 0;//指向第一个元素transient Node&lt;E&gt; first;//指向最后一个元素transient Node&lt;E&gt; last; Node既然LinkedList是基于链表实现的，那就必须要介绍一下它的内部类Node：1234567891011private static class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; next; Node&lt;E&gt; prev; Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element; this.next = next; this.prev = prev; &#125;&#125; 因为是双向链表，所以每个节点都包含前一个节点的指向与后一个节点的指向。 构造函数 无参构造函数 12public LinkedList() &#123;&#125; 有参构造函数 1234public LinkedList(Collection&lt;? extends E&gt; c) &#123; this(); addAll(c);&#125; 此方法先调用一个无参构造函数构造一个空列表，然后再将集合内的所有元素添加进去。 addAll将集合内的所有元素加入到LinkedLiist中。 123public boolean addAll(Collection&lt;? extends E&gt; c) &#123; return addAll(size, c);&#125; 123456789101112131415161718192021222324252627282930313233343536373839 public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123;//判断是否满足index &gt;= 0 &amp;&amp; index &lt;= size，若不满足，则抛出异常 checkPositionIndex(index); Object[] a = c.toArray(); int numNew = a.length; if (numNew == 0) return false; Node&lt;E&gt; pred, succ; if (index == size) &#123; succ = null; pred = last; &#125; else &#123; succ = node(index); pred = succ.prev; &#125; for (Object o : a) &#123; @SuppressWarnings("unchecked") E e = (E) o; Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, null); if (pred == null) first = newNode; else pred.next = newNode; pred = newNode; &#125; if (succ == null) &#123; last = pred; &#125; else &#123; pred.next = succ; succ.prev = pred; &#125; size += numNew; modCount++; return true; &#125; 此段代码中，succ表示后节点，pred表示前节点。 在进行了下标检查与长度检查后，首先判断要加入的元素是加入在末尾还是中间，如果在末尾，则succ应指向null，而pred应指向last，否则，succ应指向下标为index的节点，而pred指向该节点的前一个节点。这样，要插入的节点的前后节点就都有了，接下来就可以将要插入的节点的前后节点都连接好，从而完成插入操作。 这里有必要介绍一下取出指定位置的节点的方法：123456789101112131415Node&lt;E&gt; node(int index) &#123; // assert isElementIndex(index); if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125;&#125; 与数组不同，链表无法直接通过下标找到指定的元素，而需要依次遍历。由于LinkedList是通过双向链表实现的，所以既可以从头也可以从尾开始遍历。为了提高效率，该方法先判断指定的位置index在链表的前半段还是后半段，从而决定从头还是从尾开始遍历。 linkFirst，linkLast，linkBefore在介绍add方法与其它相关方法前，有必要先介绍一下这三个辅助方法：123456789101112131415161718192021222324252627282930313233343536private void linkFirst(E e) &#123; final Node&lt;E&gt; f = first; final Node&lt;E&gt; newNode = new Node&lt;&gt;(null, e, f); first = newNode; if (f == null) last = newNode; else f.prev = newNode; size++; modCount++;&#125;void linkLast(E e) &#123; final Node&lt;E&gt; l = last; final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); last = newNode; if (l == null) first = newNode; else l.next = newNode; size++; modCount++;&#125;void linkBefore(E e, Node&lt;E&gt; succ) &#123; // assert succ != null; final Node&lt;E&gt; pred = succ.prev; final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ); succ.prev = newNode; if (pred == null) first = newNode; else pred.next = newNode; size++; modCount++;&#125; linkFirst、linkLast、linkBefore方法分别将元素加入到链表头部、链表尾部与链表中指定节点之前。 以linkFirst为例，先创建一个新的节点，并将first指向该节点。然后判断以前的first节点是否为null，如果为null，则说明之前链表中没有元素，应将last指向新节点，否则，将原first节点的prev指向新节点。 add，addFirst，addLast介绍完上面三个辅助方法后，我们再来看看add相关的方法。 123456789101112131415161718192021public boolean add(E e) &#123; linkLast(e); return true;&#125;public void add(int index, E element) &#123; checkPositionIndex(index); if (index == size) linkLast(element); else linkBefore(element, node(index));&#125;public void addFirst(E e) &#123; linkFirst(e);&#125;public void addLast(E e) &#123; linkLast(e);&#125; 由源码可以看到，add相关的代码都是直接调用上面介绍的辅助方法，十分简单。 unlink，unlinkFirst，unlinkLast同样，在介绍remove及相关方法时，先介绍这三个辅助方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657E unlink(Node&lt;E&gt; x) &#123; // assert x != null; final E element = x.item; final Node&lt;E&gt; next = x.next; final Node&lt;E&gt; prev = x.prev; if (prev == null) &#123; first = next; &#125; else &#123; prev.next = next; x.prev = null; &#125; if (next == null) &#123; last = prev; &#125; else &#123; next.prev = prev; x.next = null; &#125; x.item = null; size--; modCount++; return element;&#125;private E unlinkFirst(Node&lt;E&gt; f) &#123; // assert f == first &amp;&amp; f != null; final E element = f.item; final Node&lt;E&gt; next = f.next; f.item = null; f.next = null; // help GC first = next; if (next == null) last = null; else next.prev = null; size--; modCount++; return element;&#125;private E unlinkLast(Node&lt;E&gt; l) &#123; // assert l == last &amp;&amp; l != null; final E element = l.item; final Node&lt;E&gt; prev = l.prev; l.item = null; l.prev = null; // help GC last = prev; if (prev == null) first = null; else prev.next = null; size--; modCount++; return element;&#125; 这三个方法也很好理解。以unlink方法为例，将要删除的元素的前后节点相连接，并且把要删除的节点的属性设为null以帮助垃圾回收机制回收，从而达到移除该节点的目的。最后，将要删除的节点的值返回。 remove，removeFirst，removeLast接下来介绍移除链表中元素的几个方法。 123456789101112131415161718192021222324252627public E remove() &#123; return removeFirst();&#125;public E remove(int index) &#123; checkElementIndex(index); return unlink(node(index));&#125;public boolean remove(Object o) &#123; if (o == null) &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (x.item == null) &#123; unlink(x); return true; &#125; &#125; &#125; else &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) &#123; unlink(x); return true; &#125; &#125; &#125; return false;&#125; 前两个方法比较简单，而对于remove(Object o)方法，要先判断对象是否为null，如果为null，则遍历链表找到值为null的节点，并调用unlink方法移除该节点，否则，同样遍历链表并用equals方法根据内容进行等值比较，如果找到值相等的节点，调用unlink方法将其移除。 12345678910111213public E removeFirst() &#123; final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return unlinkFirst(f);&#125; public E removeLast() &#123; final Node&lt;E&gt; l = last; if (l == null) throw new NoSuchElementException(); return unlinkLast(l);&#125; 这两个方法先判断链表中是否有元素，如果没有，则抛出异常，否则就调用辅助方法将其移除。 get，getFirst，getLast123456789101112131415161718public E get(int index) &#123; checkElementIndex(index); return node(index).item;&#125;public E getFirst() &#123; final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return f.item;&#125;public E getLast() &#123; final Node&lt;E&gt; l = last; if (l == null) throw new NoSuchElementException(); return l.item;&#125; get(int index)方法在进行了下标检查后，直接通过node方法找到该节点并返回节点的值。而getFirst和getLast先判断first和last是否为null，如果不为null则返回节点的值，否则抛出异常。 setset方法将替换链表中指定位置的节点的值。 1234567public E set(int index, E element) &#123; checkElementIndex(index); Node&lt;E&gt; x = node(index); E oldVal = x.item; x.item = element; return oldVal;&#125; 该方法先判断index是否合法，然后获取到该下标的节点，并将该节点的值重新设置即可。 linkedList总结 linkedList是通过双向链表实现的，因此删除效率很高，而查找效率很低，且不存在扩容问题。 linkedList实现了Deque接口，因此既可以当作栈，也可以当作队列。 与ArrayList一样，linkedList也是非线程安全的，只能在单线程环境下使用。]]></content>
      <categories>
        <category>JDK</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
        <tag>JDK</tag>
        <tag>LinkedList</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ArrayList源码分析]]></title>
    <url>%2F2018%2F09%2F06%2FArrayList%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[ArrayList简介（jdk1.8）ArrayList就是动态数组，其容量能够自动增长。如下为ArrayList的继承体系结构： 12public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable ArrayList实现了List, RandomAccess, Cloneable, java.io.Serializable接口，且不是线程安全的，因此只能用在单线程环境下。 属性ArrayList主要有elementData和size两个属性：12transient Object[] elementData; private int size; elementData数组是用来存储元素的，而size表示ArrayList中已有的元素数量（不等于elementData.length）。 构造方法ArrayList共有三种构造方法： 指定容量的构造函数 123456789public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException("Illegal Capacity: " + initialCapacity); &#125;&#125; 此方法接受一个初始化容量来初始化底层数组elementData，如果初始化容量值为0则将其初始化为一个空的常量数组：private static final Object[] EMPTY_ELEMENTDATA = {}; ，如果值小于零，则抛出异常。 无参构造函数 12345private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;; public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; &#125; 此方法中的DEFAULTCAPACITY_EMPTY_ELEMENTDATA区别于EMPTY_ELEMENTDATA，通过将数组设为前者，在添加元素的时候会将容量设置为默认值10。 Collection作为参数的构造函数 1234567891011public ArrayList(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); if ((size = elementData.length) != 0) &#123; // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // replace with empty array. this.elementData = EMPTY_ELEMENTDATA; &#125;&#125; 此方法接受一个Collection，并且将其转换为数组赋给elementData，如果被赋值后的elementData长度为0，则将空的常量数组赋值给它。相反，则再判断Collection是否转化为了Object数组，如果没有则将其进行转化。 这里用到了Arrays.copyof()方法：123456789public static &lt;T,U&gt; T[] copyOf(U[] original, int newLength, Class&lt;? extends T[]&gt; newType) &#123; @SuppressWarnings("unchecked") T[] copy = ((Object)newType == (Object)Object[].class) ? (T[]) new Object[newLength] : (T[]) Array.newInstance(newType.getComponentType(), newLength); System.arraycopy(original, 0, copy, 0, Math.min(original.length, newLength)); return copy;&#125; 可以看出，该方法构造了一个新的长度为newLength的Object类型数组，并且将原数组复制到新的数组中 。而此处的复制用了System.arraycopy()方法，该方法被标记了native，调用了系统的C/C++代码，可以在openJDK中查看到源码。 get123456789public E get(int index) &#123; rangeCheck(index); return elementData(index);&#125;E elementData(int index) &#123; return (E) elementData[index];&#125; 此方法可以得到指定下标的元素，先对下标进行越界检查，然后再通过一个间接方法获取到elementData的index下标的元素。 set1234567public E set(int index, E element) &#123; rangeCheck(index); E oldValue = elementData(index); elementData[index] = element; return oldValue;&#125; 此方法用于设置指定下标的元素，并将该下标原有的元素返回。 addadd方法比较复杂，也是ArrayList核心所在，有下面两种形式： 将元素加入到列表末尾 12345public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true;&#125; 12345678910private void ensureCapacityInternal(int minCapacity) &#123; ensureExplicitCapacity(calculateCapacity(elementData, minCapacity));&#125;private static int calculateCapacity(Object[] elementData, int minCapacity) &#123; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; return Math.max(DEFAULT_CAPACITY, minCapacity); &#125; return minCapacity;&#125; 此处的calculateCapacity正是与上文DEFAULTCAPACITY_EMPTY_ELEMENTDATA常量相照应的方法。如果ArrayList是默认构造函数构造的话，在添加元素的时候此方法将返回DEFAULT_CAPACITY也就是10。而size已经大于10的情况，该方法便也失去了意义。12345678910111213141516171819202122232425262728private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // overflow-conscious code if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125;private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity);&#125;private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE;&#125; 从源码可以看出，当需要的容量大于elementData数组的长度时，就需要对其进行扩张。而扩张的大小则根据if条件判断。一般情况下，会将长度扩张为原来的1.5倍，但是当1.5倍仍小于所需的容量时，会将长度直接设为所需容量。而新容量如果大于最大数组长度MAX_ARRAY_SIZE ，则根据所需容量分配Integer.MAX_VALUE或者MAX_ARRAY_SIZE。 ensureExplicitCapacity方法的第一行语句modCount++;的作用是记录修改次数。我们知道，ArrayList不是线程安全的，因此在迭代ArrayList的时候如果有其它线程修改了内容，那么就会导致modCount与迭代器初始化时的modCount不同，从而抛出异常ConcurrentModificationException。说白了，就是防止一个线程正在迭代遍历，另一个线程修改了这个列表的结构。 将元素添加到指定位置上 123456789public void add(int index, E element) &#123; rangeCheckForAdd(index); ensureCapacityInternal(size + 1); // Increments modCount!! System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++;&#125; 在此方法中，先对index进行越界检查，然后再进行扩容。这里用了System.arraycopy方法，j将包括index在内的之后的所有元素均向右移动一位，再将要添加的元素放置在elementData的index下标下。 addAll 将集合中的元素全部添加到ArrayList末尾 12345678public boolean addAll(Collection&lt;? extends E&gt; c) &#123; Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); // Increments modCount System.arraycopy(a, 0, elementData, size, numNew); size += numNew; return numNew != 0;&#125; 将Collection对象转化为Object数组后，先根据其长度进行扩容，再同样利用System.arraycopy函数把数组中的所有元素添加到elementData数组末尾。 将集合中的元素全部添加到ArrayList指定位置 12345678910111213141516public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; rangeCheckForAdd(index); Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); // Increments modCount int numMoved = size - index; if (numMoved &gt; 0) System.arraycopy(elementData, index, elementData, index + numNew, numMoved); System.arraycopy(a, 0, elementData, index, numNew); size += numNew; return numNew != 0;&#125; 原理与add(int index, E element)类似，都是通过将已有元素右移实现，此处将不再阐述。 remove 移除指定下标上的元素 1234567891011121314public E remove(int index) &#123; rangeCheck(index); modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work return oldValue;&#125; 在这里，移除操作是将要移除的元素后面的所有元素均向左移动一位，并将size数减小实现的。此方法将返回要移除的元素。 移除指定的元素 12345678910111213141516171819202122232425public boolean remove(Object o) &#123; if (o == null) &#123; for (int index = 0; index &lt; size; index++) if (elementData[index] == null) &#123; fastRemove(index); return true; &#125; &#125; else &#123; for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) &#123; fastRemove(index); return true; &#125; &#125; return false;&#125;private void fastRemove(int index) &#123; modCount++; int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work&#125; 先找到指定元素的下标，再根据下标进行移除。指定的元素有可能为null，而不为null的情况下将根据元素内容进行比较，因此将分为两种情况遍历数组。fastRemove的实现与remove(int index)基本一致，区别在于fastRemove不需要对下标进行检查，也不返回被移除的元素。 indexOf1234567891011121314151617181920212223242526272829public int indexOf(Object o) &#123; if (o == null) &#123; for (int i = 0; i &lt; size; i++) if (elementData[i]==null) return i; &#125; else &#123; for (int i = 0; i &lt; size; i++) if (o.equals(elementData[i])) return i; &#125; return -1;&#125;public int lastIndexOf(Object o) &#123; if (o == null) &#123; for (int i = size-1; i &gt;= 0; i--) if (elementData[i]==null) return i; &#125; else &#123; for (int i = size-1; i &gt;= 0; i--) if (o.equals(elementData[i])) return i; &#125; return -1;&#125;public boolean contains(Object o) &#123; return indexOf(o) &gt;= 0;&#125; 由源码可以看出，indexOf和lastIndexOf与remove(Object o)方法类似，并且找到元素时返回下标，没找到时返回-1，而contains方法正是通过indexOf判断是否找到元素实现的。 遍历时删除ArrayList循环遍历并删除元素的常见陷阱 ArrayList总结 ArrayList底层是通过数组实现的，随机访问速度快，但插入和移除由于要移动大量的元素，所以性能较差。 ArrayList不是线程安全的，在多线程环境下，通过modCount域检测是否出现问题。 ArrayList每次扩容为原本的1.5倍，若依然不够，则会直接设置为所需容量大小。]]></content>
      <categories>
        <category>JDK</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
        <tag>JDK</tag>
        <tag>ArrayList</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈对尾递归的理解]]></title>
    <url>%2F2018%2F08%2F22%2F%E6%B5%85%E8%B0%88%E5%AF%B9%E5%B0%BE%E9%80%92%E5%BD%92%E7%9A%84%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[今天在做《剑指Offer》第十题时，发现了一个用尾递归的解法，由于之前对于尾递归并没有太多了解，于是查阅了一些资料，在此对其进行一个简单的总结。关于其它题目的题解与笔记，感兴趣的朋友可以到我的Github或个人博客上看看：剑指Offer笔记 Cenjie’s Blog ， 以下是正文。 递归本质递归的本质是自己调用自己，因为是嵌套调用，所以栈帧无法回收，在递归调用的层级太多时，往往会引发调用栈溢出，也就是内存溢出。 尾递归概述尾递归本质与递归并无区别，只不过是递归的一种特殊写法。尾递归要求递归调用是整个函数体中最后执行的语句且它的返回值不属于表达式的一部分，例如 return 3f(n)或者return f(n)+f(n-1) 都是不允许的。 由于尾递归也是一种递归，因此这种写法本身并不会有任何的优化效果，内存依旧会溢出，只不过一些编译器中会加入对尾递归的优化机制，在编译代码时自动根据尾递归的特性对其进行优化。 如何优化尾递归因为在递归调用自身的时候，这一层函数已经没有要做的事情了，虽然被递归调用的函数是在当前的函数里，但是他们之间的关系已经在传参的时候了断了，也就是这一层函数的所有变量什么的都不会再被用到了，所以当前函数虽然没有执行完，不能弹出栈，但它确实已经可以出栈了，这是一方面。 另一方面，正因为调用的是自身，所以需要的存储空间是一模一样的，那干脆重新刷新这些空间给下一层利用就好了，不用销毁再另开空间。 因此，为尾递归进行优化主要分两个步骤：1、写成尾递归的形式。2、编译器遇到此形式时自动为其优化。 而在第十题：斐波那契数列中，由于Java没有对尾递归进行优化，因此与使用普通递归并无太大区别，依然会产生内存溢出的问题。 本文参考：https://www.cnblogs.com/bellkosmos/p/5280619.html]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[README文档的规范写法总结]]></title>
    <url>%2F2018%2F06%2F25%2FREADME%E6%96%87%E6%A1%A3%E7%9A%84%E8%A7%84%E8%8C%83%E5%86%99%E6%B3%95%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[俗话说的好：“一个好开源项目一定有一个好的 README”。 要想自己放到github上的项目能吸引更多人的眼球，就必须写一个规范舒适的README.md，这么做不仅可以梳理自己对于项目的思路，也方便他人上手使用或学习。因此，此文根据Github上众多项目以及查阅相关资料对README做了一个小小的总结， 方便以后写README的时候可以直接套用该模板。 XXX系统（如果有Logo可以加上Logo）xxx系统是一个..系统，支持…，…（此处为简要描述） 官方网站 | 文档手册 | 别的东西 目前，此系统包含有以下功能： 功能1 功能2 功能3 准备 依赖1 依赖2 依赖3 搭建环境IntelliJ IDEA + MySQL 或者 eclipse + MySQL，… 快速开始 步骤1 步骤2 步骤3 相关截图截图1截图2 To Do List 功能1 功能2 功能3 CHANGE LOG此处填写版本更新记录 至此，我们可以看到一个相对规范的README.md模板，在开源项目时可以直接套用该模板，而不必每次都采用不同的零零散散的格式去书写README。Markdown代码在下方给出，当然，大家也可以根据项目具体情况进行修改而使用。 12345678910111213141516171819202122232425262728293031323334## XXX系统（如果有Logo可以加上Logo）xxx系统是一个..系统，支持...，...（此处为简要描述）[官方网站](http://example.com) | [文档手册](http://example.com) | [别的东西](http://example.com) 目前，此系统包含有以下功能：* 功能1* 功能2* 功能3### 准备* 依赖1* 依赖2* 依赖3### 搭建环境IntelliJ IDEA + MySQL 或者 eclipse + MySQL，...### 快速开始* 步骤1* 步骤2* 步骤3### 相关截图截图1截图2### To Do List* 功能1* 功能2* 功能3### CHANGE LOG此处填写版本更新记录 ContactIf you have some questions after you see this article, you can just find some info by clicking these links. Cenjie’s CSDN Cenjie’s Github Cenjie’s Gmail Cenjie’s Weibo]]></content>
      <categories>
        <category>Github</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Welcome To My Blog]]></title>
    <url>%2F2018%2F06%2F22%2FWelcome-To-My-Blog%2F</url>
    <content type="text"><![CDATA[写在前面的话创建这个博客已经一年多过去了，但与其说是博客，我更希望把它当作自己的笔记本，至少在现阶段，学习知识的重要性远比分享知识高。这一年里，学到了很多，也发生了很多事，可以说是整个大学里最充实的一年了，因此在这做一个总结。 很庆幸在一年前，在看了很多大牛的分享后，深刻的认识到自己沉迷于各种编程语言是多么愚昧的事，也从一些粗浅的Web项目和杂七杂八的框架使用中跳了出来，一步一步巩固自己的计算机基础，深入去理解各种底层实现。曾以为会很多框架是一个人竞争力的体现，但却没注意到，盲目的学习如何使用框架才是收获与成长最低的一件事，而在码农过剩的时代里，如果仅仅是学会了大家都能轻易学会且毫无门槛的东西，则越容易被他人替代，所以，如何提高自己的不可替代性才是一个应该沉下心来思考的问题。 在这一年里阅读了不少JDK源码，并且把以前只是抽象层面理解的框架从实现上更深入的分析了一遍，这个过程虽然很枯燥乏味，但是结果却是很好的，通过阅读源码，不仅让我对网上大部分博客的“片面”之言有了辨别能力，也让我在实习的时候能更轻松的将一些思想融入到代码中去，实现起来自然也就更加优雅。并且在这个过程中，能发现到JDK也是有BUG的，Spring也是有很多可以优化的地方的，在分析问题时会渐渐开始关注作者的思路，以及每一行为什么需要这样写，不管是内功还是外功都给了我很大的帮助。 除此之外，半年的实习经历对我来说收获更是不少，也让我第一次有机会接触到企业级的项目，不再是学校里的各种玩具项目。虽然许多项目都是在已有的项目基础上做优化，但也有自己完整的设计并实现了一套系统，并对各种可能产生问题的部分进行思考，也对公司项目的规模以及架构有了一定的理解。 总之，路还长，希望自己能耐心走下去。记于2019年八月。 铭记Work hard in silence, let success make the noise.]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>hello</tag>
        <tag>杂谈</tag>
      </tags>
  </entry>
</search>
