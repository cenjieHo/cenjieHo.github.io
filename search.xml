<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[MySQL查询性能优化]]></title>
    <url>%2F2019%2F01%2F28%2FMySQL%E6%9F%A5%E8%AF%A2%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[优化数据访问减少请求的数据量 只返回必要的行：使用LIMIT语句来限制返回的数据。 只返回必要的列：最好不要使用SELECT *语句。 缓存重复查询的数据。 减少服务器端扫描的行数最有效的方式是使用索引来覆盖查询。 重构查询方式切分查询一个大查询如果一次性执行的话，可能一次锁住很多数据、占满整个事务日志、耗尽系统资源、阻塞很多小的但重要的查询。因此可以将大查询切分成小查询，每个查询功能完全一样，只完成一小部分，每次只返回一小部分查询结果。 分解关联查询可以对每一个表进行一次单表查询，然后将结果在应用程序中进行关联。这么做有如下优势： 让缓存的效率更高。对于关联查询，如果其中一个表发生变化，那么整个查询缓存就无法使用。而分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然可以使用。 将查询分解后，执行单个查询可以减少锁的竞争。 分解成多个单表查询，这些单表查询的缓存结果更可能被其它查询使用到，从而减少冗余记录的查询。 查询执行 客户端发送一条查询给服务器。 服务器先检查查询缓存，如果命中了缓存，则立刻返回存储在缓存中的结果。否则进入下一阶段。 服务器端进行SQL解析、预处理再由优化器生成对应的执行计划。 MySQL根据优化器生成的执行计划，调用存储引擎的API来执行查询。 将结果返回给客户端。 MySQL解析器将使用MySQL语法规则验证和解析查询；预处理器则根据一些MySQL规则进一步检查解析树是否合法，例如检查数据表和数据列是否存在，之后会验证权限；查询优化器的作用是根据存储引擎提供的统计信息找出一个最优的执行计划。 优化 Limit 分页在偏移量特别大的时候，例如可能是LIMIT 1000, 20这样的查询，这时MySQL需要查询10020条记录然后只返回最后20条，前面10000条记录都将被抛弃，这样的代价非常高。可以通过延迟关联和书签两个技巧进行优化。 延迟关联优化此类分页查询的一个最简单的办法就是尽可能地使用索引覆盖扫描，而不是查询所有的列。然后根据需要做一次关联操作再返回所需的列。考虑下面的查询： 1SELECT film_id, description FROM sakila.film ORDER BY title LIMIT 50, 5; 此时没有覆盖索引，因此要回表获取记录55条，而只返回最后5条1。这时候可以用延迟关联的技巧改写成如下： 123456SELECT film.film_id, film.descriptionFROM sakila.film INNER JOIN( SELECT film_id FROM sakala.film ORDER BY title LIMIT 50, 5 ) AS lim USING(film_id); 这时候子查询中能使用覆盖索引，因此在索引结构中就能获取到需要访问的记录而无需回表，之后再根据关联列回表查询需要的所有列。 书签LIMIT和OFFSET的问题，其实是OFFSET的问题，它会导致MySQL扫描大量不需要的行然后再抛弃掉。如果可以使用书签记录上次取数据的位置，那么下次就可以直接从该书签记录的位置开始扫描，这样就可以避免使用OFFSET。例如，若需要按照租借记录做翻页，那么可以根据最新一条租借记录向后追溯，首先使用下面的查询获得第一组结果： 12SELECT * FROM sakila.rentalORDER BY rental_id DESC LIMIT 20; 会返回49到30的记录，那么下一页查询就可以从30这个点开始： 123SELECT * FROM sakila.rentalWHERE rental_id &lt; 30ORDER BY rental_id DESC LIMIT 20; 该技术的好处是无论翻页到多么后面，其性能都会很好。 参考资料 高性能 MySQL[M]. 电子工业出版社, 2013. CS-Notes]]></content>
      <categories>
        <category>数据库</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL索引类型与优化]]></title>
    <url>%2F2019%2F01%2F28%2FMySQL%E7%B4%A2%E5%BC%95%E7%B1%BB%E5%9E%8B%E4%B8%8E%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[索引的优点 索引大大减少了服务器需要扫描的数据量 索引可以帮助服务器避免排序、分组和临时表（临时表主要是在排序和分组过程中创建，因为不需要排序和分组，也就不需要创建临时表） 索引可以将随机I/O变为顺序I/O（B-Tree索引是有序的，会将相邻的数据都存储在一起） 索引的类型在MySQL中，索引是在存储引擎层而不是服务器层实现的，所以不同的存储引擎的索引类型和实现不同。 B-Tree索引大多数存储引擎都使用B-Tree作为默认索引类型，但实际在技术上往往使用的是B+Tree，例如InnoDB。B-Tree索引之能够加快访问数据的速度，是因为存储引擎不再需要进行全表扫描来获取需要的数据，取而代之的是从索引的根节点开始进行搜索。关于B-Tree和B+Tree的工作原理可以参考之前的一篇笔记：常用查找算法之B/B+树。 B-Tree索引适用于全键值、键值范围或键前缀（最左前缀）查找。因为索引树中的节点是有序的，所以除了按值查找之外，索引还可以用于查询中的ORDER BY操作。 B-Tree同样也有一些限制： 如果不是按照索引的最左列开始查找，则无法使用索引。 不能跳过索引中的列，否则只会使用跳过之前的索引列。 如果查询中有某个列的范围查询，则其右边所有列都无法使用索引优化查找。 哈希索引哈希索引基于哈希表实现，对于每一行数据，存储引擎都会对所有索引列计算一个哈希码并存储在索引中，同时在哈希表中保存指向每个数据行的指针。如果多个列的哈希值相同，索引会以链表的方式存放多个记录指针到同一个哈希条目中。哈希索引有如下限制： 哈希索引只包含哈希值和行指针，而不存储字段值，所以不能使用索引中的值来避免读取行。 无法用于排序。 不支持部分索引列匹配查找。 不支持范围查询。 哈希冲突。 InnoDB引擎有一个特殊的功能叫做“自适应哈希索引”，当InnoDB注意到某些索引值被使用得非常频繁时，它会在内存中基于B-Tree索引之上再创建一个哈希索引，这样就让B+Tree索引具有哈希索引的一些优点，比如快速的哈希查找。 全文索引全文索引是一种特殊类型的索引，它查找的是文本中的关键词，而不是直接比较索引中的值。全文索引使用倒排索引实现，它记录着关键词到其所在文档的映射。在相同的列上同时创建全文索引和基于值的B-Tree索引不会有冲突，全文索引适用于MATCH AGAINST操作，而不是普通的WHERE条件操作。 空间数据索引MyISAM存储引擎支持空间数据索引（R-Tree），可以用作地理数据存储。空间索引会从所有维度来索引数据，查询时可以有效利用任意维度来组合查询。必须使用MySQL的GIS相关函数来维护数据。 索引优化独立的列在进行查询时，索引列不能是表达式的一部分，也不能是函数的参数，否则MySQL无法使用索引。 例如：SELECT actor_id FROM sakila.actor WHERE actor_id + 1 = 5; 多列索引在需要使用多个列作为条件进行查询时，使用多列索引比使用多个单列索引性能更好。例如下面的语句中，最好把actor_id和film_id设置为多列索引： 12SELECT film_id, actor_id FROM sakila.film_actorWHERE actor_id = 1 AND film_id = 1; 索引列的顺序将选择性最强的索引列放在前面。索引的选择性是指不重复的索引值（基数）和记录总数的比值，选择性越高则查询效率也越高，因为选择性高的索引可以让MySQL在查找时过滤掉更多的行。 前缀索引对于很长的字符串可以索引开始的部分字符，使得前缀的选择性接近于完整列的选择性。 聚簇索引B-Tree索引类型都可以用在MyISAM和InnoDB上，但InnoDB有聚簇索引的特性而MyISAM没有。 聚簇表示数据行和相邻的键值紧凑地存储在一起，因为无法同时把数据行存放在两个不同的地方，所以每张Innodb引擎表都只有一个聚簇索引。一般情况，聚簇索引就是主键索引（因为聚簇索引在有主键的情况下，默认指定主键为聚簇索引），而非聚簇索引都是二级索引。 如果没有定义主键，InnoDB会选择一个唯一的非空索引代替。如果没有这样的索引，InnoDB会隐式定义一个主键来作为聚簇索引。采用聚簇索引，索引和其他列值存储在一起，因此数据访问比采用非聚簇索引（如MyISAM引擎）更快，节省了磁盘I/O资源。 二级索引叶子节点保存的不是指向行的物理位置的指针，而是行的主键值。通过二级索引查找行，存储引擎需要找到二级索引的叶子节点获得对应的主键值，然后根据这个值去聚簇索引中查找到对应的行。这样虽然会让二级索引占用更多的空间，但换来的好处是InnoDB在移动行时减少了二级索引的维护工作。 MyISAM没有聚簇索引的特性，主键索引和其它索引在结构上没有什么不同。 使用InnoDB存储引擎时应该尽可能地按主键顺序插入数据（可以使用AUTO_INCREMENT自增），最好避免随机的插入（例如使用UUID作为主键）。因为当主键的值是顺序的时，InnoDB会把每一条记录都存储在上一条记录的后面，当达到页的最大填充因子时（默认为15/16），下一条记录就会写入新的页中。而每次插入主键的值近似于随机时，新纪录根据值的大小要被插入到现有索引页的中间某个合适位置，此时页分裂会导致大量的数据移动并产生碎片，甚至目标页面可能已经被回写到磁盘上而从缓存中清掉，此时又要从磁盘上读回来，这增加了很多开销。 覆盖索引如果一个索引包含（或者说覆盖）所有需要查询的字段的值，我们就称之为“覆盖索引”，此时不需要回表操作。其具有以下优点： 索引条目通常远小于数据行大小，所以如果只需要读取索引，那MySQL就会极大地减少数据访问量。 因为索引是按照列值顺序存储的，所以对于I/O密集型的范围查询会比随机从磁盘读取每一行数据的I/O要少得多。 一些存储引擎如MyISAM在内存中只缓存索引，数据则依赖于操作系统来缓存，因此要访问数据需要一次系统调用，比较费时。 对于InnoDB引擎，若二级索引能够覆盖查询，则可以避免对主键索引的二次查询。 使用索引扫描来排序MySQL有两种方式可以生成有序的结果：通过排序操作或者按索引顺序扫描。如果EXPLAIN出来的type列的值为index，则说明MySQL使用了索引扫描来做排序。 只有当索引的列顺序和ORDER BY子句的顺序完全一致，并且所有列的排序方向（倒序或正序）都一样时，MySQL才能够使用索引来对结果做排序。如果查询需要关联多张表，则只有当ORDER BY子句引用的字段全部为第一个表时，才能使用索引做排序。ORDER BY子句和查找型查询的限制是一样的：需要满足索引的最左前缀的要求，否则MySQL都需要执行排序操作，而无法利用索引排序。 参考资料 高性能 MySQL[M]. 电子工业出版社, 2013. mysql的索引——innodb索引（1）聚簇索引和次级索引 为什么InnoDB表最好要有自增列做主键]]></content>
      <categories>
        <category>数据库</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>索引</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL常用数据类型]]></title>
    <url>%2F2019%2F01%2F28%2FMySQL%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[整型TINYINT, SMALLINT, MEDIUMINT, INT, BIGINT分别使用1，2，3，4，8字节的存储空间。 可以使用UNSIGNED属性表示不允许负值以提高正数的上限，但有符号和无符号类型的存储空间和性能依旧一样。 MySQL可以为整数类型指定宽度，如INT(11)，但它不会限制值的合法范围，只是规定了交互工具显示字符的个数。 浮点数FLOAT和DOUBLE为浮点类型（浮点数），DECIMAL为高精度小数类型（定点数）。 CPU原生支持浮点运算，但不支持对DECIMAL的运算，因此浮点运算会更快。但是浮点数会引起精度问题，像货币这样对精度敏感的数据，应该用DECIMAL来存储。 浮点和定点都可以指定精度，例如DECIMAL(18, 9)表示总共18位，取9位存储小数部分，剩下9位存储整数部分。 字符串MySQL主要有VARCHAR和CHAR两种字符串类型。 VARCHAR类型用于存储可变长字符串，它比定长类型更节省空间，因为它仅使用必要的空间。但是在执行UPDATE时可能会使行变得比原来长，当超出一个页所能容纳的大小时，就要执行额外的操作，MyISAM会将行拆成不同的片段存储，InnoDB则需要分裂页来使行放进页内。 CHAR类型是定长的，总是根据定义的字符串长度分配足够的空间，并且在存储和检索时删除末尾的空格，而VARCHAR是会保留末尾的空格的。 当字符串列的长度比平均长度大很多时、列的更新很少时，使用VARCHAR类型更好；对于定长的字符串如MD5、经常变更或者非常短的字符串（因为VARCHAR需要额外的1个或2个字节记录字符串长度）则使用CHAR类型更好。 日期和时间MySQL提供两种相似的日期类型：DATETIME和TIMESTAMP。 DATETIME能够保存从1001年到9999年的日期和时间，精度为秒。它把日期和时间封装到格式为YYYYMMDDHHMMSS的整数中，与时区无关，使用8个字节的存储空间。默认情况下，MySQL以一种可排序的、无歧义的格式显示，例如2008-01-16 22:37:08。 TIMESTAMP保存从1970年1月1日午夜（格林威治时间）以来的秒数，使用4个字节，只能表示从1970年到2038年。这种类型的时间是和时区有关的，默认情况下，如果插入时没有指定TIMESTAMP列的值，MySQL则设置这个列的值为当前时间。 应该尽量使用TIMESTAMP，因为它比DATETIME空间效率更高。]]></content>
      <categories>
        <category>数据库</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库事务、锁与设计原理]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1%E3%80%81%E9%94%81%E4%B8%8E%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[事务事务是指满足ACID特性的一组操作，它们要么完全地执行，要么完全地不执行。 ACID特性原子性（Atomicity）一个事务必须被视为一个不可分割的最小工作单元，整个事务中的所有操作要么全部提交成功，要么全部失败回滚。 一致性（Consistency）数据库总是从一个一致性的状态转换到另外一个一致性状态。事务开始和结束之间的中间状态不会被其他事务看到。 隔离性（Isolation）一个事务所作的修改在最终提交前，对其它事务是不可见的。 持久性（Durability）一旦事务提交，则其所作的修改就会永久保存到数据库中。即使系统崩溃，修改的数据也不会丢失。 理解事务的ACID特性概念简单，但不是很好理解，主要是因为这几个特性不是一种平级关系： 只要满足一致性，事务的执行结果才是正确的。 在无并发的情况下，事务串行执行，隔离性一定能够满足。此时只要满足原子性，就一定能满足一致性。 在并发的情况下，多个事务并行执行，事务不仅要满足原子性，还要满足隔离性，才能满足一致性。 事务满足持久化是为了能应对数据库崩溃的情况。 隔离级别在并发环境下需要关注事务的隔离性，SQL标准中定义了以下四种隔离级别。 未提交读（READ UNCOMMITTED）事务中的修改即使没有提交，对其他事务也都是可见的。事务可以读取未提交的数据，这也被称为脏读。 提交读（READ COMMITTED）一个事务从开始直到提交之前，所做的任何修改对其它事务都是不可见的。 这个级别有时候也叫做不可重复读，因为两次执行同样的查询，可能会得到不一样的结果。例如，T2读取一个数据，T1对该数据做了修改并提交，如果T2再次读取这个数据，那么读取的结果和第一次读取的结果不同。 可重复读（REPEATABLE READ）可重复读保证了在同一事物中多次读取同样记录的结果是一致的。 该级别无法解决幻读问题，即当某个事务在读取某个范围内的记录时，另外一个事务又在该范围内插入了新的记录，当之前的事务再次读取该范围的记录时，会产生幻行。 可串行化（SERIALIZABLE）该级别是最高的隔离级别，通过强制事务串行执行避免上面的幻读问题。 总结 隔离级别 脏读 不可重复读 幻读 加锁读 未提交读 √ √ √ × 提交读 × √ √ × 未提交读 × × √ × 未提交读 × × × √ 锁当多个用户并发地存取数据时，在数据库中就会产生多个事务同时存取同一数据的情况。若对并发操作不加控制就可能会读取和存储不正确的数据，破坏数据库的一致性。所以，锁主要用于处理并发问题。 从数据库系统角度分为三种：排他锁、共享锁、更新锁。从程序员角度分为两种：一种是悲观锁，一种乐观锁。 悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁。 传统的关系数据库里用到了很多这种锁机制，比如按使用性质划分的读锁、写锁和按作用范围划分的行锁、表锁。 共享锁共享锁（S锁）又称为读锁，若事务T对数据对象A加上S锁，则事务T只能读A；其他事务只能再对A加S锁，而不能加X锁，直到T释放A上的S锁。这就保证了其他事务可以读A，但在T释放A上的S锁之前不能对A做任何修改。 排他锁排他锁（X锁）又称为写锁，若事务T对数据对象A加上X锁，则只允许T读取和修改A，其他任何事务都不能再对A加任何类型的锁，直到T释放A上的锁。这就保证了其他事务在T释放A上的锁之前不能再读取和修改A。 表锁每次操作锁住整张表，开销小，加锁快，锁粒度大，发生锁冲突的概率最高，并发度最低。 行锁每次操作锁住一行数据，开销大，加锁慢，锁粒度小，发生锁冲突的概率最低，并发度最高。 数据库能够确定哪些行需要锁的情况下使用行锁，如果不知道会影响哪些行的时候就会使用表锁。 乐观锁总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号机制和CAS算法实现。 版本号机制一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值与当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。 CAS算法CAS即compare and swap（比较并交换），是一种有名的无锁算法，在不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步。CAS算法涉及到三个操作数： 要更新的变量V 预期的值E 新值N 仅当V值等于E值时，才会将V的值设置成N，否则什么都不做。最后CAS返回当前V的值。CAS算法需要你额外给出一个期望值，也就是你认为现在变量应该是什么样子，如果变量不是你想象的那样，就说明已经被别人修改过，就重新读取，再次尝试修改即可。 因为CAS需要在操作值的时候检查下值有没有发生变化，如果没有发生变化则更新，但如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时就会误以为它的值没有发生变化，这个问题称为ABA问题。ABA问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加一，那么A-B-A就会变成1A-2B-3A，以此来防止不恰当的写入。 两种锁的适用场景乐观锁适用于写比较少的情况下（多读场景），即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。但如果是多写的情况，一般会经常产生冲突，这就会导致上层应用会不断的进行重试，这样反倒是降低了性能，所以一般多写的场景下用悲观锁比较合适。 关系型数据库设计函数依赖部分函数依赖设X、Y是关系R的两个属性集合，存在X→Y，若X’是X的真子集，存在X’→Y，则称Y部分函数依赖于X。 完全函数依赖设X、Y是关系R的两个属性集合，X’是X的真子集，存在X→Y，但对每一个X’都有X’ !→Y，则称Y完全函数依赖于X。 传递函数依赖设X、Y、Z是关系R中互不相同的属性集合，存在X→Y（Y !→X），Y→Z，则称Z传递函数依赖于X。 范式第一范式（1NF）在任何一个关系数据库中，第一范式（1NF）是对关系模式的基本要求，不满足第一范式（1NF）的数据库就不是关系数据库。 所谓第一范式（1NF）是指数据库表的每一列（每个属性）都是不可分割的基本数据项，同一列中不能有多个值，即实体中的某个属性不能有多个值或者不能有重复的属性。简而言之，第一范式就是无重复的列。 第二范式（2NF）第二范式（2NF）要求实体的属性完全依赖于主关键字。 第三范式（3NF）在满足第二范式的基础上，且不存在传递函数依赖，那么就是第三范式。简而言之，第三范式就是属性不依赖于其它非主属性。 ER图ER图由三个部分组成：实体、属性、联系。 参考资料 CS-NOTE 数据库锁分类和总结 面试必备之乐观锁与悲观锁 并发策略-CAS算法]]></content>
      <categories>
        <category>数据库</category>
        <category>数据库原理</category>
      </categories>
      <tags>
        <tag>事务</tag>
        <tag>锁</tag>
        <tag>范式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[最短路径问题—Dijkstra算法及相关例题]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E9%97%AE%E9%A2%98%E2%80%94Dijkstra%E7%AE%97%E6%B3%95%E5%8F%8A%E7%9B%B8%E5%85%B3%E4%BE%8B%E9%A2%98%2F</url>
    <content type="text"><![CDATA[最近在做算法题的时候总是遇到Dijkstra相关的题目，之前虽然学过图论的一些算法，但第一次做这类题时完全不知从何入手。看了一些博客，并且在PAT上折腾了几题后，发现一些常用的模板与套路，因此在这里进行一个总结。关于Dijkstra的理论知识可以参考这篇博客：最短路径问题-Dijkstra算法详解 Dijkstra算法Dijkstra算法往往和dfs结合在一起考，因此这里给出一个求解基础Dijkstra+dfs相关题目的大致模板： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485public class Main &#123; static int n; //节点数 static int m; //边数 static int C1; //起始点 static int C2; //终点 static int[][] e;//边权 static int[] weight; //点权（非必需，视题目而定） static int[] dis; //到起始点的最短路径长 static boolean[] visit; //是否访问过 static ArrayList&lt;Integer&gt;[] pre; //可构成最短路径的前一个节点 static LinkedList&lt;Integer&gt; tempPath = new LinkedList&lt;Integer&gt;(); //可能的最短路径 static LinkedList&lt;Integer&gt; path = new LinkedList&lt;Integer&gt;(); //最短路径 public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); n = sc.nextInt(); m = sc.nextInt(); C1 = sc.nextInt(); C2 = sc.nextInt(); visit = new boolean[n]; weight = new int[n]; for(int i = 0; i &lt; n; i++) &#123; weight[i] = sc.nextInt(); &#125; e = new int[n][n]; for(int i = 0; i &lt; n; i++) &#123; for(int j = 0; j &lt; n; j++) &#123; e[i][j] = e[j][i] = Integer.MAX_VALUE; &#125; &#125; for(int i = 0; i &lt; m; i++) &#123; int c1 = sc.nextInt(); int c2 = sc.nextInt(); e[c1][c2] = e[c2][c1] = sc.nextInt(); &#125; dis = new int[n]; for(int i = 0; i &lt; n; i++) &#123; dis[i] = Integer.MAX_VALUE; &#125; dis[C1] = 0; pre = new ArrayList[n]; for(int i = 0; i &lt; n; i++) &#123; pre[i] = new ArrayList&lt;&gt;(); &#125; /**************以上为初始化****************/ for(int i = 0; i &lt; n; i++) &#123; int u = -1, min = Integer.MAX_VALUE; for(int j = 0; j &lt; n; j++) &#123; if(!visit[j] &amp;&amp; dis[j] &lt; min) &#123; min = dis[j]; u = j; &#125; &#125; if(u == -1) break; visit[u] = true; for(int v = 0; v &lt; n; v++) &#123; if(!visit[v] &amp;&amp; e[u][v] != Integer.MAX_VALUE) &#123; if(dis[v] &gt; dis[u] + e[u][v]) &#123; dis[v] = dis[u] + e[u][v]; pre[v].clear(); pre[v].add(u); &#125; else if(dis[v] == dis[u] + e[u][v]) &#123; pre[v].add(u); &#125; &#125; &#125; &#125; //至此已经找到多个最短路径，下面的dfs算法将在多个最短路径中找到最终解 dfs(C2); &#125; private static void dfs(int v) &#123; tempPath.push(v); if(v == C1) &#123; //此处进行一些判断，在多个最短路径中确认最终解 tempPath.pop(); return; &#125; for(int i = 0; i &lt; pre[v].size(); i++) dfs(pre[v].get(i)); tempPath.pop(); &#125;&#125; Emergency题目链接：1003 Emergency 此题要求求出两点之间的最短路径，如果存在多条最短路径，那么就选择点权和最大的路径。这里的代码和上面模板几乎一模一样，做题时都需要考虑点权。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798public class Main &#123; private static int n; private static int m; private static int C1; private static int C2; private static int[][] e; private static int[] weight; private static int[] dis; private static boolean[] visit; private static int max = Integer.MIN_VALUE; private static ArrayList&lt;Integer&gt;[] pre; private static LinkedList&lt;Integer&gt; tempPath = new LinkedList&lt;Integer&gt;(); private static LinkedList&lt;Integer&gt; path = new LinkedList&lt;Integer&gt;(); private static int cnt = 0; public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); n = sc.nextInt(); m = sc.nextInt(); C1 = sc.nextInt(); C2 = sc.nextInt(); visit = new boolean[n]; weight = new int[n]; for(int i = 0; i &lt; n; i++) &#123; weight[i] = sc.nextInt(); &#125; e = new int[n][n]; for(int i = 0; i &lt; n; i++) &#123; for(int j = 0; j &lt; n; j++) &#123; e[i][j] = e[j][i] = Integer.MAX_VALUE; &#125; &#125; for(int i = 0; i &lt; m; i++) &#123; int c1 = sc.nextInt(); int c2 = sc.nextInt(); e[c1][c2] = e[c2][c1] = sc.nextInt(); &#125; dis = new int[n]; for(int i = 0; i &lt; n; i++) &#123; dis[i] = Integer.MAX_VALUE; &#125; dis[C1] = 0; pre = new ArrayList[n]; for(int i = 0; i &lt; n; i++) &#123; pre[i] = new ArrayList&lt;&gt;(); &#125; /**********************************************/ for(int i = 0; i &lt; n; i++) &#123; int u = -1, min = Integer.MAX_VALUE; for(int j = 0; j &lt; n; j++) &#123; if(!visit[j] &amp;&amp; dis[j] &lt; min) &#123; min = dis[j]; u = j; &#125; &#125; if(u == -1) break; visit[u] = true; for(int v = 0; v &lt; n; v++) &#123; if(!visit[v] &amp;&amp; e[u][v] != Integer.MAX_VALUE) &#123; if(dis[v] &gt; dis[u] + e[u][v]) &#123; dis[v] = dis[u] + e[u][v]; pre[v].clear(); pre[v].add(u); &#125; else if(dis[v] == dis[u] + e[u][v]) &#123; pre[v].add(u); &#125; &#125; &#125; &#125; /***********************************************/ dfs(C2); System.out.printf("%d %d", cnt, max); &#125; private static void dfs(int v) &#123; tempPath.push(v); if(v == C1) &#123; int a = 0; for(int i = 0; i &lt; tempPath.size(); i++) &#123; a += weight[tempPath.get(i)]; &#125; if(a &gt; max) &#123; max = a; path = new LinkedList&lt;&gt;(tempPath); &#125; cnt++; tempPath.pop(); return; &#125; for(int i = 0; i &lt; pre[v].size(); i++) dfs(pre[v].get(i)); tempPath.pop(); &#125;&#125; 事实上，我们也可以不使用DFS，而在执行Dijkstra就完成最大点权和的判断: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273public class Main &#123; private static int n; //城市数 private static int m; //路径数 private static int c1; //源城市 private static int c2; //目标城市 private static int[][] e; //边长 private static int[] dis; //从出发点到当前节点的最短路径 private static int[] nums; //从出发点到当前节点最短路径的数目 private static int[] w; //从出发点到当前节点救援对数目之和 private static int[] weight; //当前节点的救援队数目 private static boolean[] visit; public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); n = sc.nextInt(); m = sc.nextInt(); c1 = sc.nextInt(); c2 = sc.nextInt(); weight = new int[n]; e = new int[n][n]; dis = new int[n]; nums = new int[n]; w = new int[n]; visit = new boolean[n]; for(int i = 0; i &lt; n; i++) &#123; weight[i] = sc.nextInt(); &#125; for(int i = 0; i &lt; n; i++) &#123; for(int j = 0; j &lt; n; j++) &#123; e[i][j] = Integer.MAX_VALUE; &#125; &#125; for(int i = 0; i &lt; m; i++) &#123; int s = Integer.valueOf(sc.nextInt()); int d = Integer.valueOf(sc.nextInt()); e[s][d] = e[d][s] = Integer.valueOf(sc.nextInt()); &#125; for(int i = 0; i &lt; n; i++) &#123; dis[i] = Integer.MAX_VALUE; &#125; dis[c1] = 0; nums[c1] = 1; w[c1] = weight[c1]; /******************************************/ for(int i = 0; i &lt; n; i++) &#123; int u = -1, min = Integer.MAX_VALUE; for(int j = 0; j &lt; n; j++) &#123; if(!visit[j] &amp;&amp; dis[j] &lt; min) &#123; u = j; min = dis[j]; &#125; &#125; if(u == -1) break; visit[u] = true; for(int v = 0; v &lt; n; v++) &#123; if(!visit[v] &amp;&amp; e[u][v] != Integer.MAX_VALUE) &#123; if(dis[u] + e[u][v] &lt; dis[v]) &#123; dis[v] = dis[u] + e[u][v]; nums[v] = nums[u]; w[v] = w[u] + weight[v]; &#125; else if(dis[u] + e[u][v] == dis[v]) &#123; nums[v] += nums[u]; w[v] = w[u] + weight[v] &gt; w[v] ? w[u] + weight[v] : w[v]; &#125; &#125; &#125; &#125; System.out.printf("%d %d", nums[c2], w[c2]); &#125;&#125; Travel Plan题目链接：1030 Travel Plan 这题对比上题是将点权换成了边权，先通过Dijkstra算法求出多条最短路径，然后用DFS找到最短路径中边权（此题中就是cost）最小的那条路径。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104public class Main &#123; private static int n; private static int m; private static int s; private static int d; private static int[][] e; private static int[][] cost; private static int[] dis; private static boolean[] visit; private static ArrayList&lt;Integer&gt;[] pre; private static LinkedList&lt;Integer&gt; tempPath = new LinkedList&lt;&gt;(); private static LinkedList&lt;Integer&gt; path = new LinkedList&lt;&gt;(); private static int min = Integer.MAX_VALUE; public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); n = sc.nextInt(); m = sc.nextInt(); s = sc.nextInt(); d = sc.nextInt(); visit = new boolean[n]; e = new int[n][n]; cost = new int[n][n]; for(int i = 0; i &lt; n; i++) &#123; for(int j = 0; j &lt; n; j++) &#123; e[i][j] = e[j][i] = Integer.MAX_VALUE; cost[i][j] = cost[j][i] = Integer.MAX_VALUE; &#125; &#125; for(int i = 0; i &lt; m; i++) &#123; int i1 = sc.nextInt(); int i2 = sc.nextInt(); e[i1][i2] = e[i2][i1] = sc.nextInt(); cost[i1][i2] = cost[i2][i1] = sc.nextInt(); &#125; dis = new int[n]; for(int i = 0; i &lt; n; i++) &#123; dis[i] = Integer.MAX_VALUE; &#125; dis[s] = 0; pre = new ArrayList[n]; for(int i = 0; i &lt; n; i++) &#123; pre[i] = new ArrayList&lt;&gt;(); &#125; /***********************************************/ for(int i = 0; i &lt; n; i++) &#123; int u = -1, min = Integer.MAX_VALUE; for(int j = 0; j &lt; n; j++) &#123; if(!visit[j] &amp;&amp; dis[j] &lt; min) &#123; min = dis[j]; u = j; &#125; &#125; if(u == -1) break; visit[u] = true; for(int v = 0; v &lt; n; v++) &#123; if(!visit[v] &amp;&amp; e[u][v] != Integer.MAX_VALUE) &#123; if(dis[v] &gt; dis[u] + e[u][v]) &#123; dis[v] = dis[u] + e[u][v]; pre[v].clear(); pre[v].add(u); &#125; else if(dis[v] == dis[u] + e[u][v]) &#123; pre[v].add(u); &#125; &#125; &#125; &#125; /**********************************************/ ArrayList&lt;Integer&gt;[] temppre = pre; dfs(d); for(int i = 0; i &lt; path.size(); i++) &#123; System.out.print(path.get(i) + " "); &#125; System.out.print(dis[d] + " "); System.out.print(min); &#125; private static void dfs(int v) &#123; tempPath.push(v); if(v == s) &#123; int c = 0; for(int i = 1; i &lt; tempPath.size(); i++) &#123; c += cost[tempPath.get(i)][tempPath.get(i-1)]; &#125; if(c &lt; min) &#123; min = c; path = new LinkedList&lt;&gt;(tempPath); &#125; tempPath.pop(); return; &#125; for(int i = 0; i &lt; pre[v].size(); i++) dfs(pre[v].get(i)); tempPath.pop(); &#125;&#125; All Roads Lead to Rome题目链接：1087 All Roads Lead to Rome 这题和上面两题也没什么不同，基本思路是一样的，只不过题目输入的是城市的名称也就是字符串，并且输出也要用城市的名称，我们直接用map来存储城市名与下标的映射即可。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112public class Main &#123; private static int[][] e; private static int[] dis; private static int[] weight; private static boolean[] visit; private static int n; private static int k; private static HashMap&lt;Integer, String&gt; map1; private static HashMap&lt;String, Integer&gt; map2; private static LinkedList&lt;Integer&gt; path = new LinkedList&lt;&gt;(); private static LinkedList&lt;Integer&gt; tempPath = new LinkedList&lt;&gt;(); private static ArrayList&lt;Integer&gt;[] pre; private static int max = Integer.MIN_VALUE; private static int avg = Integer.MIN_VALUE; private static int cnt = 0; public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); String[] line1 = sc.nextLine().split(" "); n = Integer.valueOf(line1[0]); k = Integer.valueOf(line1[1]); map1 = new HashMap&lt;&gt;(); map2 = new HashMap&lt;&gt;(); map1.put(0, line1[2]); map2.put(line1[2], 0); weight = new int[n]; for(int i = 1; i &lt; n; i++) &#123; String[] line = sc.nextLine().split(" "); map1.put(i, line[0]); map2.put(line[0], i); weight[i] = Integer.valueOf(line[1]); &#125; e = new int[n][n]; for(int i = 0; i &lt; e.length; i++) &#123; for(int j = 0; j &lt; e.length; j++) &#123; e[i][j] = e[j][i] = Integer.MAX_VALUE; &#125; &#125; for(int i = 0; i &lt; k; i++) &#123; String[] line = sc.nextLine().split(" "); int c1 = map2.get(line[0]); int c2 = map2.get(line[1]); e[c1][c2] = e[c2][c1] = Integer.valueOf(line[2]); &#125; dis = new int[n]; dis[0] = 0; for(int i = 1; i &lt; n; i++) &#123; dis[i] = Integer.MAX_VALUE; &#125; visit = new boolean[n]; pre = new ArrayList[n]; for(int i = 0; i &lt; n; i++) &#123; pre[i] = new ArrayList&lt;&gt;(); &#125; for(int i = 0; i &lt; n; i++) &#123; int u = -1, min = Integer.MAX_VALUE; for(int j = 0; j &lt; n; j++) &#123; if(!visit[j] &amp;&amp; dis[j] &lt; min) &#123; u = j; min = dis[j]; &#125; &#125; if(u == -1) break; visit[u] = true; for(int v = 0; v &lt; n; v++) &#123; if(!visit[v] &amp;&amp; e[u][v] != Integer.MAX_VALUE) &#123; if(dis[u] + e[u][v] &lt; dis[v]) &#123; dis[v] = dis[u] + e[u][v]; pre[v].clear(); pre[v].add(u); &#125; else if(dis[u] + e[u][v] == dis[v]) &#123; pre[v].add(u); &#125; &#125; &#125; &#125; dfs(map2.get("ROM")); System.out.printf("%d %d %d %d\n", cnt, dis[map2.get("ROM")], max, avg); System.out.print(map1.get(0)); for(int i = 1; i &lt; path.size(); i++) &#123; System.out.print("-&gt;" + map1.get(path.get(i))); &#125; &#125; private static void dfs(int v) &#123; tempPath.push(v); if(v == 0) &#123; int happy = 0; int average = 0; for(int i = 1; i &lt; tempPath.size(); i++) &#123; happy += weight[tempPath.get(i)]; &#125; average = happy / (tempPath.size()-1); if(happy &gt; max) &#123; max = happy; avg = average; path = new LinkedList&lt;&gt;(tempPath); &#125; else if(happy == max &amp;&amp; average &gt; avg) &#123; avg = average; path = new LinkedList&lt;&gt;(tempPath); &#125; cnt++; tempPath.pop(); return; &#125; for(int i = 0; i &lt; pre[v].size(); i++) dfs(pre[v].get(i)); tempPath.pop(); &#125;&#125; 至此，简单的Dijkstra题都可以套用上述模板很容易地做出来，当然平时做题时还是需要根据具体题目灵活变通，以上代码只是将其思路梳理了一遍，在实现上也依然存在许多可以优化的地方。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>Dijkstra</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用查找算法之散列表]]></title>
    <url>%2F2019%2F01%2F28%2F%E5%B8%B8%E7%94%A8%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95%E4%B9%8B%E6%95%A3%E5%88%97%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[前言散列表类似于数组，可以把散列表的散列值看成数组的索引值。访问散列表和访问数组元素一样快速，它可以在常数时间内实现查找和插入操作。使用散列的查找算法分为两步：用散列函数将被查找的键转化为数组的一个索引；处理碰撞冲突。 散列函数要为一个数据类型实现优秀的散列方法需要满足三个条件： 一致性：等价的键必然产生相等的散列值。 高效性：计算简便。 均匀性：均匀的散列所有的键。 对于一致性，在Java中意味着每一种数据类型的hashCode()方法都必须和equals()方法一致。也就是说，如果a.equals(b)返回true，那么a.hashCode()和b.hashCode()的返回值必然相同。但要注意，如果a.hashCode()和b.hashCode()的返回值相同，a.equals(b)不一定返回true。 保证均匀性的最好办法就是保证键的每一位都在散列值的计算中起到了相同的作用，而常见的错误就是忽略了键的高位。在jdk的HashMap中，为了保证均匀性将默认散列函数得到的散列值与其高16位进行异或运算重新得到新的散列值。 为了将一个32位的整数散列值转换成数组的索引，我们在实现中还要将散列值和除留余数法结合起来产生一个0到M-1（M代表数组的大小）的整数。这在HashMap中是通过这行代码实现的：hash &amp; (table.length - 1)。 碰撞处理基于拉链法的散列表拉链法是将大小为M的数组中的每个元素指向一条链表，链表中的每个节点都存储了散列值为该元素的索引的键值对。基于拉链法的查找分为两步：首先根据散列值找到对应的链表，然后沿着链表顺序查找相应的键。 在实现基于拉链法的散列表时，要选择适当的数组大小M，既不会因为空链表而浪费大量内存，也不会因为链表太长而在查找上浪费太多时间。 基于线性探测法的散列表实现散列表的另一种方式就是用大小为M的数组保存N个键值对，其中M&gt;N。我们需要依靠数组中的空位解决碰撞冲突，基于这种策略的所有方法被统称为开放地址散列表。 开放地址散列表中最简单的方法叫做线性探测法。我们在实现中使用并行数组，一个保存键，一个保存值。 12345678910111213141516171819202122232425262728293031323334public class LinearProbingHashST&lt;Key, Value&gt; &#123; private static final int INIT_CAPACITY = 4; private int n; //符号表中键值对的总数 private int m; //线性探测表的大小 private Key[] keys; //键 private Value[] vals; //值 public LinearProbingHashST() &#123; this(INIT_CAPACITY); &#125; public LinearProbingHashST(int capacity) &#123; m = capacity; n = 0; keys = (Key[]) new Object[m]; vals = (Value[]) new Object[m]; &#125; private int hash(Key key) &#123; return (key.hashCode() &amp; 0x7fffffff) % m; &#125; //实现见下文 private void resize(int capacity) //实现见下文 public void put(Key key, Value val) //实现见下文 public Value get(Key key) //实现见下文 public void delete(Key key) 查找要查找一个键，我们从它的散列值开始顺序查找，如果找到则命中，否则直接检查散列表中的下一个位置（将索引值加1），直到找到该键或者遇到一个空元素。 123456public Value get(Key key) &#123; for (int i = hash(key); keys[i] != null; i = (i + 1) % m) if (keys[i].equals(key)) return vals[i]; return null;&#125; 插入如果新建的散列值是一个空元素，那么就将它保存在那里；如果不是，我们就顺序查找一个空元素来保存它。 1234567891011121314public void put(Key key, Value val) &#123; if (n &gt;= m/2) resize(2*m); int i; for (i = hash(key); keys[i] != null; i = (i + 1) % m) &#123; if (keys[i].equals(key)) &#123; vals[i] = val; return; &#125; &#125; keys[i] = key; vals[i] = val; n++;&#125; 删除直接将要删除的键所在的位置设为null是不行的，因为这会使在此位置之后的元素无法被查找。因此，我们需要将簇中被删除键的右侧的所有键重新插入散列表。 1234567891011121314151617181920212223242526public void delete(Key key) &#123; int i = hash(key); while (keys[i] != null &amp;&amp; !key.equals(keys[i])) i = (i + 1) % M; // 不存在则直接返回 if (keys[i] == null) return; keys[i] = null; values[i] = null; // 将之后相连的键值对重新插入 i = (i + 1) % M; while (keys[i] != null) &#123; Key keyToRedo = keys[i]; Value valToRedo = values[i]; keys[i] = null; values[i] = null; N--; put(keyToRedo, valToRedo); i = (i + 1) % M; &#125; N--; //如果键值对太小，我们就将数组的大小减半 if (n &gt; 0 &amp;&amp; n &lt;= m/8) resize(m/2);&#125; 为了保证性能，我们会动态调整数组的大小来保证使用率在1/8到1/2之间。 调整数组大小线性探测法的成本取决于连续条目的长度，连续条目也叫聚簇。当聚簇很长时，在查找和插入时需要进行很多次探测。为了保证散列表的性能，应当动态调整数组的大小，使得散列表的使用率不超过1/2。 1234567891011private void resize(int capacity) &#123; LinearProbingHashST&lt;Key, Value&gt; temp = new LinearProbingHashST&lt;Key, Value&gt;(capacity); for (int i = 0; i &lt; m; i++) &#123; if (keys[i] != null) &#123; temp.put(keys[i], vals[i]); &#125; &#125; keys = temp.keys; vals = temp.vals; m = temp.m;&#125; 以上实现会将原表中所有的键重新散列并插入到新表中。 参考资料 Algorithms (Fourth Edition) CS-Notes 算法]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>查找</tag>
        <tag>HashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[树的前中后层序遍历（递归与非递归方式）]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%A0%91%E7%9A%84%E5%89%8D%E4%B8%AD%E5%90%8E%E5%B1%82%E5%BA%8F%E9%81%8D%E5%8E%86%EF%BC%88%E9%80%92%E5%BD%92%E4%B8%8E%E9%9D%9E%E9%80%92%E5%BD%92%E6%96%B9%E5%BC%8F%EF%BC%89%2F</url>
    <content type="text"><![CDATA[DescriptionLeetCode的第590题与429、589题型类似，都为树（不一定是二叉树）的各种形式的遍历，因此放在一起总结。 对于上图，要求求出前序遍历、后序遍历和层级遍历的结果。 Example12345678前序遍历结果：[1,3,5,6,2,4]后序遍历结果：[5,6,3,2,4,1]层级遍历结果：[ [1], [3,2,4], [5,6]] Analysis对于树我们一般有两种策略： 广度优先搜索（BFS）：从上到下一层一层的遍历树 ，也就是题目要求的层级遍历。 深度优先搜索（DFS）：从一个根节点开始，一直到达某个叶子节点，然后回到根节点到达另一个分支的叶子节点。根据根节点、左节点和右节点之间的相对顺序，DFS策略可以进一步区分为前序、中序和后序。 根据深度优先搜索与广度优先搜索可以整理出下图的四种情况： Solution对于第一题求前序遍历，我们可以使用递归或者循环来完成，实际上这三道题都是如此。我们先看看递归版本： 12345678910111213141516171819public class Solution &#123; List&lt;Integer&gt; list; public List&lt;Integer&gt; preorder(Node root) &#123; list = new ArrayList&lt;&gt;(); if(root == null) return list; preorderCore(root); return list; &#125; private void preorderCore(Node root) &#123; if(root == null) return; list.add(root.val); for(Node node : root.children) preorderCore(node); &#125;&#125; 前序遍历就是先将根节点放入结果列表中，然后再将左右子节点放入。递归的解法较为简单，下面看看循环的解法： 123456789101112131415161718public class Solution2 &#123; public List&lt;Integer&gt; preorder(Node root) &#123; LinkedList&lt;Integer&gt; res = new LinkedList&lt;&gt;(); if(root == null) return res; Stack&lt;Node&gt; stack = new Stack&lt;&gt;(); stack.push(root); while(!stack.isEmpty()) &#123; Node node = stack.pop(); res.add(node.val); Collections.reverse(node.children); for(Node children : node.children) &#123; stack.push(children); &#125; &#125; return res; &#125;&#125; 在递归中我们使用栈来保存接下来要访问的节点。首先我们将根节点压入栈，栈中元素为[1]，然后我们将它弹出至结果列表并把它的子节点翻转并放入栈，此时栈中元素为[4, 2, 3]；由于栈顶元素为3，因此将3弹出至结果列表并把它的子节点翻转并放入栈，此时栈中元素为[4, 2, 6, 5]；栈顶元素为5，因此将5弹出至结果列表，5没有子节点，再把6弹出至结果列表。如此反复，我们便可以通过这种方式得到前序遍历的结果列表[1, 3, 5, 6, 2, 4]。 求后序遍历与这题异曲同工，同样先看看递归版本： 123456789101112131415161718public class Solution &#123; List&lt;Integer&gt; list; public List&lt;Integer&gt; postorder(Node root) &#123; list = new ArrayList&lt;&gt;(); if(root == null) return list; postorderCore(root); return list; &#125; private void postorderCore(Node root) &#123; if(root == null) return; for(Node node : root.children) postorderCore(node); list.add(root.val); &#125;&#125; 我们仅仅将list.add(root.val); 这行代码放到了遍历子节点的for语句之后，意味着先将所有子节点加入结果列表，最后再将根节点加入结果列表。下面是使用循环的解法： 123456789101112131415161718public class Solution2 &#123; public List&lt;Integer&gt; postorder(Node root) &#123; LinkedList&lt;Integer&gt; res = new LinkedList&lt;&gt;(); if(root == null) return res; Stack&lt;Node&gt; stack = new Stack&lt;&gt;(); stack.push(root); while(!stack.isEmpty()) &#123; Node node = stack.pop(); res.addFirst(node.val); for(Node children : node.children) &#123; stack.push(children); &#125; &#125; return res; &#125;&#125; 与前序遍历不同的是我们不需要翻转子节点列表，但是每次将结果添加到结果列表头而不是尾。 第三题是层序遍历（广度优先搜索），不像上面两题用递归实现更加简单，我们通过循环来实现会更加简洁明了，思路是使用一个队列而非栈来保存每一层节点： 12345678910111213141516171819public class Solution &#123; public List&lt;List&lt;Integer&gt;&gt; levelOrder(Node root) &#123; List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;(); if(root == null) return res; Queue&lt;Node&gt; queue = new LinkedList&lt;&gt;(); queue.add(root); while(!queue.isEmpty()) &#123; int size = queue.size(); List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); while(size-- != 0) &#123; Node node = queue.poll(); for(Node children : node.children) queue.add(children); list.add(node.val); &#125; res.add(list); &#125; return res; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>树的遍历</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用查找算法之B/B+树]]></title>
    <url>%2F2019%2F01%2F28%2F%E5%B8%B8%E7%94%A8%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95%E4%B9%8BB-B-%E6%A0%91%2F</url>
    <content type="text"><![CDATA[前言从算法逻辑上讲二叉查找树的查找和插入操作效率都已经很高，但是在实际应用中由于我们不能将整个索引表加载到内存，只能逐一加载每个磁盘页，这里的磁盘页就对应着索引树的节点。因此我们要将原本“瘦高”的树结构变得“矮胖”，从而减少磁盘IO的次数。 B- 树B-树是一种多路平衡查找树，是对2-3树的一个扩展。一个m阶的B树（m的大小取决于磁盘页的大小）具有如下几个特征： 根结点至少有两个子女。 每个中间节点都包含k-1个元素和k个孩子，其中 k ∈ [m/2, m] 每一个叶子节点都包含k-1个元素，其中 k ∈ [m/2, m] 所有的叶子结点都位于同一层。 每个节点中的元素从小到大排列，节点当中k-1个元素正好是k个孩子包含的元素的值域分划。 查找下图以一个3阶B-树为例，第一次磁盘IO并在内存中和9比较： 第二次磁盘IO并在内存中和2、6比较： 第三次磁盘IO并在内存中和3、5比较： 单从比较次数来说B树相比二叉查找树并不占优势，但由于节点中存储着多个元素，因此它的磁盘IO次数比二叉查找树少很多，而内存中的比较耗时几乎可以忽略，因此查找性能也就比二叉查找树更好。 插入以插入元素4为例，自顶向下查找4的节点位置，发现4应当插入到节点元素3，5之间，而由于此B-树是3阶的，每个节点最多能有2个元素，因此该节点无法再增加，而其父节点也含有两个元素，根节点只有一个元素。 于是拆分节点3，5与节点2，6，让根节点9升级为两元素节点4，9。节点6独立为根节点的第二个孩子。 删除以删除元素11为例，先自顶向下查找元素11的节点位置。 删除11后，节点12只有一个孩子，不符合B树规范。因此找出12,13,15三个节点的中位数13，取代节点12，而节点12自身下移成为第一个孩子（左旋操作）。 B+ 树B+树是B-树的一个变体，有着比B-树更高的查询性能。一个m阶的B+树（m的大小取决于磁盘页的大小）具有如下几个特征： 有k个子树的中间节点包含有k个元素（B-树中是k-1个元素），每个元素不保存数据，只用来索引，所有数据都保存在叶子节点。 所有的叶子结点中包含了全部元素的信息，及指向含这些元素记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。 所有的中间节点元素都同时存在于子节点，在子节点元素中是最大（或最小）元素。 注意，根节点的最大元素（上图中是15）等同于整个B+树的最大元素；由于父节点的元素都出现在子节点，因此所有叶子节点包含了全量元素信息，并且每一个叶子节点都带有指向下一个节点的指针，形成了一个有序链表。 查找在B-树中，无论中间节点还是叶子节点都带有卫星数据（索引元素所指向的数据记录），而Ｂ+树中间节点没有卫星数据，只有索引，这就意味着同样大小的磁盘页可以容纳更多节点元素，在相同的数据量下，B+树更加“矮胖”，IO操作更少。 下图以查找元素3为例，第一次磁盘IO： 第二次磁盘IO： 第三次磁盘IO： B+树除了比B树更加“矮胖”这一点不同外，由于B+树的查询必须最终查找到叶子节点，而B-树中无论匹配元素处于中间节点还是叶子节点只要找到匹配元素即可，所以B+树的查找性能是稳定的，而B-树的查找性能不稳定（最好情况是只查根节点，最坏情况是查到叶子节点）。 范围查找由于B+树的叶子节点构成了一条有序链表，因此B+树的范围查找比B-树简单得多，下面以查询范围为3到11的元素为例。 自顶向下，查找到范围的下限3： 通过链表指针，遍历到元素6、8： 通过链表指针，遍历到元素9、11，遍历结束： 总结为了减少磁盘IO的次数，必须降低树的深度，将“瘦高”的树变得“矮胖，使得磁盘页可以容纳更多节点元素，因此出现了B-树。B+树是B-树的变体，相比B-树有以下优势： 单一节点存储更多的元素，使得查询的IO次数更少。 所有查询都要查找到叶子节点，查询性能稳定。 所有叶子节点形成有序链表，便于范围查询。 参考资料 漫画：什么是B-树？ 漫画：什么是B+树？]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>查找</tag>
        <tag>B树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用查找算法之红黑树]]></title>
    <url>%2F2019%2F01%2F28%2F%E5%B8%B8%E7%94%A8%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BA%A2%E9%BB%91%E6%A0%91%2F</url>
    <content type="text"><![CDATA[前言二叉查找树对于大多数情况下的查找和插入操作在效率上来说是没有问题的，但是在最差的情况下会达到线性级别，其效率取决于插入顺序。平衡查找树的数据结构能够保证在最差的情况下也能是对数级别，要实现这一目标我们需要保证树在插入完成之后始终保持平衡状态。 2-3查找树在学习红黑树之前要先了解2-3查找树作为基础，一棵2-3查找树或为一棵空树，或由以下节点组成： 2-节点：含有一个键值对和两条链接，左链接指向的2-3树中的键都小于该节点，右链接指向的2-3树中的键都大于该节点。 3-节点：含有两个键值对和三条链接，左链接指向的2-3树中的键都小于该节点，中链接指向的2-3树中的键都位于该节点的两个键之间，右链接指向的2-3树中的键都大于该节点。 指向一棵空树的链接称为空链接，一棵完美平衡的2-3查找树的所有空链接到根节点的距离应该是相同的。 查找要判断一个键是否在树中，我们先将它和根节点中的键比较。如果它和其中任意一个相等，查找命中；否则我们就根据比较的结果找到指向相应区间的链接，并在其指向的子树中递归地继续查找。如果这是个空链接，查找未命中。 插入 如果插入到2-节点上，那么直接将新节点和原来的节点组成3-节点即可。 如果是插入到3-节点上，就会产生一个临时4-节点时，需要将4-节点分裂成3个2-节点，并将中间的2-节点移到上层节点中。如果上移操作继续产生临时4-节点则一直进行分裂上移，直到不存在临时4-节点。 如果从插入节点到根节点的路径上全都是3-节点，我们的根节点最终变成一个临时的4-节点，此时我们将临时的4-节点分解为3个2-节点，使得树高加一。这次最后的变换仍然保持了树的完美平衡性，因为它变换的是根节点。 构造轨迹二叉查找树是由上向下生长的，而2-3树的生长是由下向上的。 红黑树2-3查找树实现起来十分复杂，因此我们使用一种名为红黑二叉查找树的简单数据结构来表达并实现它。 我们将树中的链接分为两种类型：红链接将两个2-节点连接起来构成一个3-节点，黑链接则是2-3树中的普通链接。 红黑树有以下性质: 红链接均为左链接。 没有任何一个节点同时和两条红链接相连。 红黑树是完美黑色平衡的，即任意空链接到根节点的路径上的黑链接数量相同。 如果我们将由红链接相连的节点合并，得到的就是一棵2-3树： 基本实现我们将由父节点指向自己的链接的颜色保存在表示节点的Node数据类型的布尔变量Color中。如果是红色则为true，黑色则为false。 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class RedBlackBST&lt;Key extends Comparable&lt;Key&gt;, Value&gt; &#123; private static final boolean RED = true; private static final boolean BLACK = false; private Node root; private class Node &#123; private Key key; private Value val; private Node left, right; private boolean color; //由其父节点指向它的链接的颜色 private int size; //这棵子树中的节点总数 public Node(Key key, Value val, boolean color, int size) &#123; this.key = key; this.val = val; this.color = color; this.size = size; &#125; &#125; public int size() &#123; return size(root); &#125; private int size(Node x) &#123; if (x == null) return 0; return x.size; &#125; private boolean isRed(Node x) &#123; if (x == null) return false; return x.color == RED; &#125; //实现见下文 private Node rotateLeft(Node h) //实现见下文 private Node rotateRight(Node h) //实现见下文 private void flipColors(Node h)&#125; 旋转假设我们有一条红色的右链接需要被转化为左链接，我们要进行左旋转。同理，也有右旋转。 1234567891011121314151617181920212223//左旋转 private Node rotateLeft(Node h) &#123; Node x = h.right; h.right = x.left; x.left = h; x.color = x.left.color; x.left.color = RED; x.size = h.size; h.size = size(h.left) + size(h.right) + 1; return x; &#125;//右旋转private Node rotateRight(Node h) &#123; Node x = h.left; h.left = x.right; x.right = h; x.color = x.right.color; x.right.color = RED; x.size = h.size; h.size = size(h.left) + size(h.right) + 1; return x; &#125; 颜色转换一个4-节点在红黑树中表现为一个节点的左右子节点都是红色的。分裂4- 节点除了需要将子节点的颜色由红变黑之外，同时需要将父节点的颜色由黑变红，从2-3树的角度看就是将中间节点移到上层节点。 12345private void flipColors(Node h) &#123; h.color = !h.color; h.left.color = !h.left.color; h.right.color = !h.right.color;&#125; 插入先将一个节点按二叉查找树的方法插入到正确位置，然后在沿着插入点到根节点的路径向上移动时，在所经过的每个节点中顺序完成如下操作： 如果右子节点是红色的而左子节点是黑色的，进行左旋转； 如果左子节点是红色的，而且左子节点的左子节点也是红色的，进行右旋转； 如果左右子节点均为红色的，进行颜色转换，将红链接在树中向上传递。 颜色转换会使根节点变为红色，但根节点并没有父节点，因此在每次插入后都将根节点设为黑色。注意，每当根节点由红变黑时树的黑链接高度就会加一，因为这意味着它由一个4-节点分裂出去成为2-节点了。 12345678910111213141516171819202122public void put(Key key, Value val) &#123; //查找key，找到则更新其值，否则为它新建一个节点 root = put(root, key, val); root.color = BLACK;&#125;private Node put(Node h, Key key, Value val) &#123; if (h == null) //标准的插入操作，和父节点用红链接相连 return new Node(key, val, RED, 1); int cmp = key.compareTo(h.key); if (cmp &lt; 0) h.left = put(h.left, key, val); else if (cmp &gt; 0) h.right = put(h.right, key, val); else h.val = val; if (isRed(h.right) &amp;&amp; !isRed(h.left)) h = rotateLeft(h); if (isRed(h.left) &amp;&amp; isRed(h.left.left)) h = rotateRight(h); if (isRed(h.left) &amp;&amp; isRed(h.right)) flipColors(h); h.size = size(h.left) + size(h.right) + 1; return h;&#125; 除了递归调用后的三条if语句，红黑树中put()的递归实现和二叉查找树中put()的实现完全相同。 删除最小键为保证树的完美平衡性，沿着左链接向下进行变换，确保不会删除一个2-节点。在最后得到的含有最小键的3-节点或4-节点中，我们可以直接将最小键删除，然后向上分解所有临时的4-节点。 删除在查找路径上进行和删除最小键相同的变换同样可以保证在查找过程中任意当前节点均不是2-节点。如果被查找的键在树的底部，我们可以直接删除它。如果不在，我们需要将它和它的后继节点交换，就和二叉查找树一样。因为当前节点必然不是2-节点，问题已经转化为在一棵根节点不是2-节点的子树中删除最小的键，可以直接使用上文的算法。删除之后我们需要向上回溯并分解余下的4-节点。 查找红黑树的get()方法不会检查节点的颜色，因此实现和二叉查找树一样，但由于树是平衡的，所以查找比二叉查找树更快。 12345678910111213public Value get(Key key) &#123; return get(root, key);&#125;private Value get(Node x, Key key) &#123; while (x != null) &#123; int cmp = key.compareTo(x.key); if (cmp &lt; 0) x = x.left; else if (cmp &gt; 0) x = x.right; else return x.val; &#125; return null;&#125; 复杂度分析无论键的插入顺序如何，红黑树都几乎是完美平衡的，因此查找、插入等操作在最坏的情况下所需的时间仍是对数级别的。 参考资料 Algorithms (Fourth Edition) CS-Notes 算法]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>查找</tag>
        <tag>红黑树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用查找算法之二叉查找树]]></title>
    <url>%2F2019%2F01%2F28%2F%E5%B8%B8%E7%94%A8%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95%E4%B9%8B%E4%BA%8C%E5%8F%89%E6%9F%A5%E6%89%BE%E6%A0%91%2F</url>
    <content type="text"><![CDATA[定义一棵二叉查找树（又称二叉排序树、二叉搜索树）是一棵二叉树，其中每个节点都含有一个Comparable的键以及相关联的值且每个节点的键都大于其左子树中的任意节点的键而小于右子树的任意节点的键。 二叉查找树有一个重要性质，就是它的中序遍历结果递增排序。 基本实现树由Node对象组成，每个对象都含有一对键值、两条链接和一个节点计数器。节点计数器表示以该节点为根的子树中的节点总数，总是满足size(x) = size(x.left) + size(x.right) + 1。 123456789101112131415161718192021222324252627282930313233public class BST&lt;Key extends Comparable&lt;Key&gt;, Value&gt; &#123; private Node root; // 二叉查找树的根节点 private class Node &#123; private Key key; // 键 private Value val; // 值 private Node left, right; // 指向子树的链接 private int size; // 以该节点为根的子树中的节点总数 public Node(Key key, Value val, int size) &#123; this.key = key; this.val = val; this.size = size; &#125; &#125; public int size() &#123; return size(root); &#125; private int size(Node x) &#123; if (x == null) return 0; else return x.size; &#125; //实现见下文 public Value get(Key key) //实现见下文 public void put(Key key, Value val) //其它有序性相关的方法及删除操作见下文&#125; 查找如果树是空的，则查找未命中；如果被查找的键和根节点的键相等，查找命中；否则递归地在子树中查找：如果被查找的键较小就在左子树中查找，较大就在右子树中查找。 当找到一个含有被查找的键的节点（命中）或者当前子树变为空（未命中）时这个过程才会结束。 123456789101112public Value get(Key key) &#123; return get(root, key);&#125;private Value get(Node x, Key key) &#123; if (x == null) return null; int cmp = key.compareTo(x.key); if (cmp &lt; 0) return get(x.left, key); else if (cmp &gt; 0) return get(x.right, key); else return x.val;&#125; 插入如果树是空的，就返回一个含有该键值对的新节点（使上层节点的链接指向该节点）；如果被查找的键小于根节点的键，继续在左子树中插入该键，否则在右子树中插入该键。 1234567891011121314@Overridepublic void put(Key key, Value value) &#123; root = put(root, key, value);&#125; private Node put(Node x, Key key, Value val) &#123; if (x == null) return new Node(key, val, 1); int cmp = key.compareTo(x.key); if (cmp &lt; 0) x.left = put(x.left, key, val); else if (cmp &gt; 0) x.right = put(x.right, key, val); else x.val = val; x.size = 1 + size(x.left) + size(x.right); return x; &#125; 有序性相关的方法及删除操作范围查找利用二叉查找树中序遍历的结果为递增的特点对其进行指定范围的查找。 12345678910111213141516Overridepublic List&lt;Key&gt; keys(Key l, Key h) &#123; List&lt;Key&gt; list = new ArrayList&lt;&gt;(); keys(root, list, l, h); return list;&#125;private void keys(Node x, List&lt;key&gt; list, Key l, Key h) &#123; if (x == null) return; int cmpL = l.compareTo(x.key); int cmpH = h.compareTo(x.key); if (cmpL &lt; 0) keys(x.left, list, l, h); if (cmpL &lt;= 0 &amp;&amp; cmpH &gt;= 0) list.add(x.key); if (cmpH &gt; 0) keys(x.right, list, l, h);&#125; 删除最小节点只需令指向最小节点的链接指向最小节点的右子树。 1234567891011public void deleteMin() &#123; root = deleteMin(root);&#125;private Node deleteMin(Node x) &#123; if (x.left == null) return x.right; x.left = deleteMin(x.left); x.size = size(x.left) + size(x.right) + 1; return x;&#125; 删除指定节点如果待删除的节点只有一个子树， 那么只需要让指向待删除节点的链接指向唯一的子树即可；否则，让右子树的最小节点替换该节点。 1234567891011121314151617181920212223public void delete(Key key) &#123; root = delete(root, key);&#125;private Node delete(Node x, Key key) &#123; if (x == null) return null; int cmp = key.compareTo(x.key); if (cmp &lt; 0) x.left = delete(x.left, key); else if (cmp &gt; 0) x.right = delete(x.right, key); else &#123; if (x.right == null) return x.left; if (x.left == null) return x.right; Node t = x; x = min(t.right); x.right = deleteMin(t.right); x.left = t.left; &#125; x.size = size(x.left) + size(x.right) + 1; return x;&#125; 查找最小键123456789101112@Overridepublic Key min() &#123; return min(root).key;&#125;private Node min(Node x) &#123; if (x == null) return null; if (x.left == null) return x; return min(x.left);&#125; 排名rank(key)返回key的排名，排名从0开始。如果键和根节点的键相等，返回左子树的节点数；如果小于，递归计算在左子树中的排名；如果大于，递归计算在右子树中的排名，加上左子树的节点数，再加上1（根节点）。 123456789101112@Overridepublic int rank(Key key) &#123; return rank(key, root);&#125;private int rank(Key key, Node x) &#123; if (x == null) return 0; int cmp = key.compareTo(x.key); if (cmp &lt; 0) return rank(key, x.left); else if (cmp &gt; 0) return 1 + size(x.left) + rank(key, x.right); else return size(x.left); &#125; 复杂度分析在最好的情况下，一棵含有N个节点的树是完全平衡的，插入和查找的时间复杂度均为O(logn)；在最坏的情况下，搜索路径上可能有N个节点，此时的时间复杂度为O(n)。 参考资料 Algorithms (Fourth Edition) CS-Notes 算法]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>查找</tag>
        <tag>BST</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用查找算法之二分查找]]></title>
    <url>%2F2019%2F01%2F28%2F%E5%B8%B8%E7%94%A8%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95%E4%B9%8B%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE%2F</url>
    <content type="text"><![CDATA[前言符号表是一种存储键值对的数据结构，可以支持高效地插入、查找等操作，因此在这里使用一个有序符号表接口来定义这些操作，这个符号表将保持键的有序性。 12345678910111213141516public interface OrderedST&lt;Key extends Comparable&lt;Key&gt;, Value&gt; &#123; int size(); void put(Key key, Value value); Value get(Key key); Key min(); Key max(); int rank(Key key); List&lt;Key&gt; keys(Key l, Key h);&#125; 二分查找二分查找先将被查找的键和数组的中间键比较，如果被查找的键小于中间键，我们就在左子数组中继续查找，如果大于我们就在右子数组中继续查找，否则中间键就是我们要找的键。如果表中存在该键，此方法将返回该键的位置，否则，将返回该键应该插入的位置。 二分查找有很多种不同的实现方式，但个人更加喜欢用以下的方式实现，这同时也是书上的实现方式： 1234567891011public int binarySearch(int[] nums, int target) &#123; int low = 0; int high = nums.length - 1; while(low &lt;= high) &#123; int mid = low + (high - low) / 2; if(nums[mid] &lt; target) low = mid + 1; else if(nums[mid] &gt; target) high = mid - 1; else return mid; &#125; return low;&#125; 查找数字第一次出现的位置对二分查找可以做一个简单的拓展，即当一个有序数组中有重复的数字时，查找一个数字在数组中第一次出现的位置。例如，对于数组{1, 2, 3, 3, 3, 3, 4}，要查找的数字3的下标应该为2而不是3。我们仅仅需要对普通的二分查找算法做一个简单的修改就能完成此功能： 12345678910public int binarySearchFirst(int[] nums, int target) &#123; int low = 0; int high = nums.length - 1; while(low &lt;= high) &#123; int mid = low + (high - low) / 2; if(nums[mid] &lt; target) low = mid + 1; else if(nums[mid] &gt;= target) high = mid - 1; &#125; return low;&#125; 查找数字最后一次出现的位置同理，我们也可以使用二分查找找到重复数字在有序数组中最后一次出现的位置： 12345678910public int binarySearchLast(int[] nums, int target) &#123; int low = 0; int high = nums.length - 1; while(low &lt;= high) &#123; int mid = low + (high - low) / 2; if(nums[mid] &lt;= target) low = mid + 1; else if(nums[mid] &gt; target) high = mid - 1; &#125; return high;&#125; 二分查找实现有序符号表使用一对平行数组，分别用来存储键和值。 这份实现的核心是rank()方法，它几乎和上面单独列出的二分查找法一样，返回找到的键的位置或者键应该插入的位置。对于put()方法，如果键存在于表中则更新它的值，否则插入到合适的位置，并将所有更大的键向后移动一格。get()方法根据rank()方法的返回值来取键相应的值，如果不存在则返回null。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677public class BinarySearchOrderedST&lt;Key extends Comparable&lt;Key&gt;, Value&gt; implements OrderedST&lt;Key, Value&gt; &#123; private Key[] keys; private Value[] values; private int N = 0; public BinarySearchOrderedST(int capacity) &#123; keys = (Key[]) new Comparable[capacity]; values = (Value[]) new Object[capacity]; &#125; @Override public int size() &#123; return N; &#125; @Override public int rank(Key key) &#123; int l = 0, h = N - 1; while (l &lt;= h) &#123; int m = l + (h - l) / 2; int cmp = key.compareTo(keys[m]); if (cmp == 0) return m; else if (cmp &lt; 0) h = m - 1; else l = m + 1; &#125; return l; &#125; @Override public List&lt;Key&gt; keys(Key l, Key h) &#123; int index = rank(l); List&lt;Key&gt; list = new ArrayList&lt;&gt;(); while (keys[index].compareTo(h) &lt;= 0) &#123; list.add(keys[index]); index++; &#125; return list; &#125; @Override public void put(Key key, Value value) &#123; int index = rank(key); if (index &lt; N &amp;&amp; keys[index].compareTo(key) == 0) &#123; values[index] = value; return; &#125; for (int j = N; j &gt; index; j--) &#123; keys[j] = keys[j - 1]; values[j] = values[j - 1]; &#125; keys[index] = key; values[index] = value; N++; &#125; @Override public Value get(Key key) &#123; int index = rank(key); if (index &lt; N &amp;&amp; keys[index].compareTo(key) == 0) return values[index]; return null; &#125; @Override public Key min() &#123; return keys[0]; &#125; @Override public Key max() &#123; return keys[N - 1]; &#125;&#125; 复杂度分析二分查找的时间复杂度是对数级别的，故使用二分查找实现的符号表的查找操作所需要的时间也是对数级别的，但是插入操作由于需要移动数组元素，因此是线性级别的。 参考资料 Algorithms (Fourth Edition) CS-Notes 算法]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>查找</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap源码分析]]></title>
    <url>%2F2019%2F01%2F28%2FHashMap%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[HashMap简介（jdk1.8）在jdk1.8中，HashMap底层由数组+链表+红黑树来实现，性能较之前有了较大的提升。如下为HashMap的继承体系结构：12public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable 在这里，AbstractMap已经实现了Map接口，再实现一遍并没有任何用处，java集合框架的创始人也承认其为一个小失误。 HashMap中，当链表节点较多时会转为红黑树进行存储，而红黑树这一数据结构涉及的知识点过多，关于红黑树的基础知识需要另外学习，本篇将以链表为主，红黑树为辅的形式分析其源码。 属性123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172/** * 默认的初始化容量为16 */ static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; /** * 最大容量 */ static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; /** * 默认负载因子为0.75 */ static final float DEFAULT_LOAD_FACTOR = 0.75f; /** * 链表转红黑树的阈值，当有8个节点的时候转换 */ static final int TREEIFY_THRESHOLD = 8; /** * 红黑树转链表的阈值，当有6个节点的时候转换 */ static final int UNTREEIFY_THRESHOLD = 6; /** * 转红黑树时table的最小容量，如果当前容量小于64则进行扩容而非转换 */ static final int MIN_TREEIFY_CAPACITY = 64; /** * 基本hash节点 */ static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + &quot;=&quot; + value; &#125; public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125; &#125; 注意：在HashMap中，table的容量只为2的n次方。 构造函数1234567891011121314151617181920212223242526//指定了初始容量和负载因子 public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal initial capacity: " + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal load factor: " + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity); &#125;//指定了初始容量，将会设置默认负载因子 public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR); &#125; public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted &#125; public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false); &#125; 在构造函数中，并没有对table数组进行初始化，而是在第一次put的时候进行初始化，这会在下文进行详细介绍。 tableSizeFortableSizeFor方法的主要功能是返回一个比给定整数大且最接近的2的幂次方整数，如给定10，返回2的4次方16。 12345678910static final int tableSizeFor(int cap) &#123; //防止当容量已经是2的幂次方(2^m)了，进行如下操作得到的最终结果会多乘个2，即2^(m+1) int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; 这个方法比较巧妙，n|=n&gt;&gt;&gt;1这一操作确保第一次出现1的位及其后一位（也就是头两位）都是1，而n |= n &gt;&gt;&gt; 2确保头四位都是1，n |= n &gt;&gt;&gt; 4确保头八位都是1，以此类推，一直到n |= n &gt;&gt;&gt; 16结束后就能确保第一次出现1的位及其后面所有位都为1。而此时，n+1即为最接近指定容量的2的幂次方整数。举个例子：123456789n: 0000 0000 0110 0001 = 97 n|=n&gt;&gt;&gt;1: 0000 0000 0111 0001 n|=n&gt;&gt;&gt;2: 0000 0000 0111 1001n|=n&gt;&gt;&gt;2: 0000 0000 0111 1101 n|=n&gt;&gt;&gt;4: 0000 0000 0111 1111...n|=n&gt;&gt;&gt;16: 0000 0000 0111 1111n+1: 0000 0000 1000 0000 = 128 hash1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 这个方法先得到key的hashCode，然后将其与高16位进行异或运算重新得到哈希值，之后再通过hash &amp; (table.length - 1) 定位到key在table中的索引位置。假设table的长度为16，具体过程如下： 12345h = key.hashCode(): 1111 1111 1111 1111 0000 0000 0011 0101h &gt;&gt;&gt; 16: 0000 0000 0000 0000 1111 1111 1111 1111hash = h ^ (h &gt;&gt;&gt; 16): 1111 1111 1111 1111 1111 1111 1100 1010table.length - 1: 0000 0000 0000 0000 0000 0000 0000 1111hash &amp; (table.length - 1):0000 0000 0000 0000 0000 0000 0000 1010 其中，&gt;&gt;&gt;为无符号右移，左边都将补0，而之所以要进行这一步，是为了当table的值很小时，能让hashCode的高位也参与运算，以减少碰撞的几率，否则仅在高位发生变化总是会发生碰撞。 我们知道，hash如果对table.length取模将得到key在table长度范围内的索引位置，但由于模运算效率较低，这里便采用了与运算进行优化，提高了效率。 get12345678910111213141516171819202122232425262728public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; &#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; //哈希表不为null &amp;&amp; 表的长度大于0 &amp;&amp; 根据hash值算出表索引的第一个节点不为null if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; //如果第一个节点的key与传入的key相同，则直接返回第一个节点 if (first.hash == hash &amp;&amp; //always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; //如果第一个节点是树节点，则调用红黑树的相关方法 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; //向下遍历链表直至找到key相同的节点并返回 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; //未找到符合要求的节点，返回null return null; &#125; getTreeNode12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849final TreeNode&lt;K,V&gt; getTreeNode(int h, Object k) &#123; //如果当前节点有父节点，则先找到其根节点，之后再调用find方法 return ((parent != null) ? root() : this).find(h, k, null);&#125;final TreeNode&lt;K,V&gt; root() &#123; for (TreeNode&lt;K,V&gt; r = this, p;;) &#123; //如果当前节点的父节点为空，则当前节点为根节点，将其返回 if ((p = r.parent) == null) return r; r = p; &#125;&#125;final TreeNode&lt;K,V&gt; find(int h, Object k, Class&lt;?&gt; kc) &#123; TreeNode&lt;K,V&gt; p = this; do &#123; int ph, dir; K pk; TreeNode&lt;K,V&gt; pl = p.left, pr = p.right, q; //传入的哈希值小于当前节点的哈希值，则向左遍历 if ((ph = p.hash) &gt; h) p = pl; //传入的哈希值大于当前节点的哈希值，则向右遍历 else if (ph &lt; h) p = pr; //传入的哈希值等于当前节点的哈希值，则再判断key值是否相同，因为不同的key有可能有相同的hash，这也正是哈希冲突所在 else if ((pk = p.key) == k || (k != null &amp;&amp; k.equals(pk))) return p; //如果左节点为空，则向右开始遍历 else if (pl == null) p = pr; //如果右节点为空，则向左开始遍历 else if (pr == null) p = pl; //走到这里说明左右节点都不为空，要开始判断究竟往左还是往右 else if ((kc != null || (kc = comparableClassFor(k)) != null) &amp;&amp; //如果不为null，说明key实现了Comparable接口 (dir = compareComparables(kc, k, pk)) != 0) //比较k和pk的大小，若k&lt;pk则dir&lt;0，k&gt;pk则dir&gt;0 p = (dir &lt; 0) ? pl : pr; //key所属类没有实现Comparable接口，则直接向右开始遍历 else if ((q = pr.find(h, k, kc)) != null) return q; //向右没有找到，则向左开始遍历 else p = pl; &#125; while (p != null); //找不到符合的返回null return null;&#125; 在这个方法中有些人可能会疑虑在同一个索引位置下的红黑树各节点hash值不应该相同吗，为什么还会有判断哈希值大小进入左右节点的操作。其实，不同的hash值在与table的长度相与后，是有可能进入同一个索引位置下的，考虑以下这种情况：123节点1的hash值： 1110 0000 0000 1000 0111节点2的hash值： 1001 1111 0000 1010 0111table.length-1：0000 0000 0000 0000 0111 可以看出，节点1与节点2在进行了hash &amp; (table.length - 1)后值都为0000 0000 0000 0000 0111，因此会放置在table中同一个索引位置下。 comparableClassFor、compareComparablescomparableClassFor方法判断对象x所属类c是否实现了Comparable接口，如果实现了则返回所属类c，否则返回null 123456789101112131415161718192021222324static Class&lt;?&gt; comparableClassFor(Object x) &#123; if (x instanceof Comparable) &#123; Class&lt;?&gt; c; Type[] ts, as; Type t; ParameterizedType p; //如果x是个字符串对象则直接返回String类，因为String类本身就已经实现了Comparable接口 if ((c = x.getClass()) == String.class) // bypass checks return c; //Type[] getGenericInterfaces，此方法将返回带泛型参数信息的本类直接实现的接口 if ((ts = c.getGenericInterfaces()) != null) &#123; for (int i = 0; i &lt; ts.length; ++i) &#123; //如果此接口为泛型接口 if (((t = ts[i]) instanceof ParameterizedType) &amp;&amp; //如果该泛型接口的原始类型为Comparable ((p = (ParameterizedType)t).getRawType() == Comparable.class) &amp;&amp; //如果该泛型接口只有一个泛型参数，且此泛型参数类型为c，则返回c (as = p.getActualTypeArguments()) != null &amp;&amp; as.length == 1 &amp;&amp; as[0] == c) // type arg is c return c; &#125; &#125; &#125; //如果该对象所属类没有实现Comparable接口，则返回null return null;&#125; 以上代码中，for (int i = 0; i &lt; ts.length; ++i)下的一系列判断其实就是想要看x所属类c是否实现了Comparable&lt;c&gt;。 1234static int compareComparables(Class&lt;?&gt; kc, Object k, Object x) &#123; return (x == null || x.getClass() != kc ? 0 : ((Comparable)k).compareTo(x));&#125; 此方法中，如果x与k的类相同，则进行比较。否则，返回0。 put1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162 public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true); &#125; /** * @param onlyIfAbsent 如果为true，则不改变已经存在的value，仅仅当不存在value的时候put进去 */ final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //如果table为空或者长度为0，则先调用resize()方法进行扩容 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; //如果通过hash计算得到的table该索引位置还没有节点，则创建一个新节点作为头节点 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); //该索引位置已存在节点 else &#123; Node&lt;K,V&gt; e; K k; //判断当前节点的hash与key是否与参数中的hash与key相同，如果相同，则说明p为要查找的节点，将其赋值给e if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //判断节点是否为红黑树节点，如果是则调用红黑树的相关方法 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; //如果节点不为红黑树节点而是链表节点，则遍历链表节点，并统计该链表的节点数binCount for (int binCount = 0; ; ++binCount) &#123; //如果已经到了链表尾部，则根据传入的hash与key等创建一个新节点加入链表尾部 if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); //如果链表的节点数超过阈值，则将其转换为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) //此时e节点即为目标节点，跳出循环 break; //将p设置为下一个节点 p = e; &#125; &#125;//如果e节点不为null，则说明链表中包含目标节点，用新值覆盖旧值并返回旧值 if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; //走到这一步说明插入了新的节点，size大小需要加一 ++modCount; if (++size &gt; threshold) //如果size超过了阈值，则进行扩容 resize(); afterNodeInsertion(evict); return null; &#125; putTreeVal在进行红黑树的操作时，依然会维护链表的结构。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455final TreeNode&lt;K,V&gt; putTreeVal(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, int h, K k, V v) &#123; Class&lt;?&gt; kc = null; boolean searched = false; TreeNode&lt;K,V&gt; root = (parent != null) ? root() : this; for (TreeNode&lt;K,V&gt; p = root;;) &#123; int dir, ph; K pk; //如果目标节点的hash值小于当前节点，则将dir设为-1，代表向左查找 if ((ph = p.hash) &gt; h) dir = -1; //如果目标节点的hash值大于当前节点，则将dir设为1，代表向右查找 else if (ph &lt; h) dir = 1; //如果目标节点的hash值等于当前节点，则判断key是否相等，如果相等，则说明当前节点为目标节点，将其返回 else if ((pk = p.key) == k || (k != null &amp;&amp; k.equals(pk))) return p; //如果要查找的key没有实现Comparable接口或者pk与k的所属类不同 else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) &#123; //第一次执行查找 if (!searched) &#123; TreeNode&lt;K,V&gt; q, ch; searched = true; //左右子树分别调用find进行查找，如果找到了则返回 if (((ch = p.left) != null &amp;&amp; (q = ch.find(h, k, kc)) != null) || ((ch = p.right) != null &amp;&amp; (q = ch.find(h, k, kc)) != null)) return q; &#125; //如果依然没有找到，则再进行最后一次比较 dir = tieBreakOrder(k, pk); &#125; TreeNode&lt;K,V&gt; xp = p; //如果p节点的左节点或者右节点为null，则说明找到了要放入的位置 if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123; Node&lt;K,V&gt; xpn = xp.next; TreeNode&lt;K,V&gt; x = map.newTreeNode(h, k, v, xpn); if (dir &lt;= 0) xp.left = x; else xp.right = x; //到这里维护了xp-&gt;x-&gt;xpn这一链表结构 xp.next = x; x.parent = x.prev = xp; if (xpn != null) ((TreeNode&lt;K,V&gt;)xpn).prev = x; //进行红黑树的插入平衡操作 moveRootToFront(tab, balanceInsertion(root, x)); return null; &#125; &#125;&#125; resize123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; //如果老table为空，则老t int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; //如果老table不为空 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; //且老table的容量已经大于最大容量 //将阈值设置为最大整型 threshold = Integer.MAX_VALUE; //直接返回老table，不再扩容 return oldTab; &#125; //将新容量设置为老容量的两倍 //如果新容量小于最大容量且老容量大于十六，则将新阈值也提高到原来的两倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; //如果table为空，但老阈值大于0，说明构造函数时指定了初始化容量但从未加入过元素，此时将老阈值赋给新容量，详解见下文 else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; //老table为空，且老阈值为0，说明构造函数时未指定初始化容量 else &#123; // zero initial threshold signifies using defaults //将新容量设置为默认初始化容量 newCap = DEFAULT_INITIAL_CAPACITY; //将新阈值设置为默认负载因子*默认初始化容量 newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; //如果新阈值为0，则用新容量*负载因子赋值 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; //如果新容量或者新阈值大于最大容量，则将新阈值设为最大整型，以后不再扩容 newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; //将新阈值赋值给阈值属性 threshold = newThr; @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) //用新容量大小创建一个新table Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; //将新table赋值给table属性 table = newTab; //如果老table不为空，则将其中的元素全部放到新table中去 if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; //如果该索引位置头节点不为空 if ((e = oldTab[j]) != null) &#123; //将老表该索引位置设为空，方便垃圾收集器回收 oldTab[j] = null; //如果该索引位置只有一个节点，则根据其hash计算值放入新表中 if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; //如果为树节点，则调用红黑树相关方法 else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); //该索引位置有多个节点 else &#123; // preserve order //存储原索引位置的头节点与尾节点 Node&lt;K,V&gt; loHead = null, loTail = null; //存储原索引位置+原容量的头节点与尾节点 Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; //如果hash与oldCap相与为0则存储在原索引位置，详解见下方 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) //e为头节点的情况 loHead = e; else loTail.next = e; loTail = e; &#125; //如果hash与oldCap相与不为0则存储在原索引位置+原容量，详解见下方 else &#123; if (hiTail == null) //e为头节点的情况 hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; //尾节点的next属性为空 loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; //尾节点的next属性为空 hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; //返回新表 return newTab;&#125; 我们可以看到在此方法中有一个条件判断else if (oldThr &gt; 0)，当table为空但阈值却大于零时，将阈值赋值给新容量。这里有个疑问是为什么会发生table为空但阈值却大于零这种情况？我们可以回过头看看构造函数，可以发现在所有构造函数中都没有对数组table进行过分配，而仅仅设置了阈值this.threshold = tableSizeFor(initialCapacity);，既然在构造时没有分配，那肯定就是在第一次扩容时分配的，也就正是上面的代码。 此处还有一个疑问是：为什么扩容后新的存储位置只为原位置或原位置+原容量？请看这么一个例子，假设oldCap=0100, newCap=1000,节点a的hash为1110,节点b的hash为1010。oldCap-1的值为0011，显然对于节点来说只有后两位决定了它们的位置（因为前两位无论如何都为0），而newCap-1的值为0111，此时后三位决定了它们的位置，与之前不同正在于节点的第三位是0还是1，而第三位的值正可以通过oldCap(在此也就是0100)相与来进行判断，如果相与结果为0000，则说明第三位的值为0，在和newCap-1相与后结果将不变，依然在原索引位置；而如果相与结果为0100，则说明节点第三位值是1，也就是原索引值加上原容量。 treeifyBin123456789101112131415161718192021222324252627282930313233final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) &#123; int n, index; Node&lt;K,V&gt; e; //如果table为空或者table的长度小于可转换为红黑树的最小容量，则调用resize方法扩容 if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); //如果根据hash计算得到的索引位置下的节点不为空，则遍历整条链表 else if ((e = tab[index = (n - 1) &amp; hash]) != null) &#123; TreeNode&lt;K,V&gt; hd = null, tl = null; do &#123; //将链表节点转换为红黑树节点 TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); //如果为第一次循环 if (tl == null) //将p设置为头节点 hd = p; //否则，不为第一次循环 else &#123; //将当前节点与上一个节点关联起来，维护链表结构 p.prev = tl; tl.next = p; &#125; tl = p; &#125; while ((e = e.next) != null); //将hash计算得到的索引位置的头节点赋为新的树节点 if ((tab[index] = hd) != null) //以头节点为根构建红黑树 hd.treeify(tab); &#125;&#125;TreeNode&lt;K,V&gt; replacementTreeNode(Node&lt;K,V&gt; p, Node&lt;K,V&gt; next) &#123; return new TreeNode&lt;&gt;(p.hash, p.key, p.value, next);&#125; treeify123456789101112131415161718192021222324252627282930313233343536373839404142434445464748final void treeify(Node&lt;K,V&gt;[] tab) &#123; TreeNode&lt;K,V&gt; root = null; //x的初始值为根节点，但开始时还未赋值给root for (TreeNode&lt;K,V&gt; x = this, next; x != null; x = next) &#123; next = (TreeNode&lt;K,V&gt;)x.next; x.left = x.right = null; //如果root还未被赋值，则将根节点赋值给它 if (root == null) &#123; //根节点没有父节点 x.parent = null; //红黑树根节点必须为黑色 x.red = false; root = x; &#125; else &#123; //见下文 K k = x.key; int h = x.hash; Class&lt;?&gt; kc = null; for (TreeNode&lt;K,V&gt; p = root;;) &#123; int dir, ph; K pk = p.key; if ((ph = p.hash) &gt; h) dir = -1; else if (ph &lt; h) dir = 1; else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) dir = tieBreakOrder(k, pk); TreeNode&lt;K,V&gt; xp = p; if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123; x.parent = xp; if (dir &lt;= 0) xp.left = x; else xp.right = x; //红黑树的插入平衡调整 root = balanceInsertion(root, x); break; &#125; &#125; &#125; &#125; //将根节点移到table索引位置的头节点 moveRootToFront(tab, root);&#125; treeify方法用来构建一棵以调用该方法的节点为根节点的红黑树。由于红黑树依然维护着链表结构，每次通过next属性获得下一个节点时，都会从根节点开始向下查找，根据hash值的大小找到合适的位置放入，并设置好parent与left或right属性以关联节点。 remove12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public V remove(Object key) &#123; Node&lt;K,V&gt; e; //如果未找到要删除的节点则返回空，否则返回要删除的节点的value值 return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value;&#125;/** * @param matchValue 如果为true，则只有当value也相等的时候才移除 */final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; //如果table不为空且table的长度不为0且table该索引位置的头节点不为空 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123; Node&lt;K,V&gt; node = null, e; K k; V v; //如果当前节点的hash值和key都与传入的相等，则当前节点就是目标节点，将其赋值给node if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; //如果当前节点不是目标节点，则遍历之后的节点 else if ((e = p.next) != null) &#123; //如果节点为树节点，则调用红黑树相关方法 if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else &#123; do &#123; //如果当前节点是目标节点，则将其赋值给node，并跳出循环 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; //将p设为下一节点 p = e; &#125; while ((e = e.next) != null); &#125; &#125; //如果找到了要删除的节点且要删除的节点的value与传入的value相等或者压根不需要匹配value if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; //如果节点为树节点，则调用红黑树移除方法 if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); //如果要删除的节点是头节点 else if (node == p) //直接将索引位置指向要删除节点的下一个节点 tab[index] = node.next; else //如果要删除的节点不是头节点，则将要删除节点的上下节点关联起来 p.next = node.next; ++modCount; //总节点数减一 --size; afterNodeRemoval(node); //返回被移除的节点 return node; &#125; &#125; //未找到要删除的节点，直接返回null return null;&#125; 常见问题有关HashMap的常见面试题总结请移步 HashMap常见面试题总结]]></content>
      <categories>
        <category>JDK</category>
      </categories>
      <tags>
        <tag>JDK</tag>
        <tag>HashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见排序算法之堆排序]]></title>
    <url>%2F2019%2F01%2F28%2F%E5%B8%B8%E8%A7%81%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E4%B9%8B%E5%A0%86%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[前言排序算法的成本模型计算的是比较和交换的次数。less()方法对元素进行比较，exch()方法将元素交换位置。 123456789private static boolean less(Comparable v, Comparable w) &#123; return (v.compareTo(w) &lt; 0);&#125;private static void exch(Comparable[] a, int i, int j) &#123; Comparable swap = a[i]; a[i] = a[j]; a[j] = swap;&#125; 堆的定义堆的某个节点的值总是大于等于子节点的值，并且堆是一颗完全二叉树。当这棵树的每个结点都大于等于它的两个子节点时，它被称为堆有序。 堆可以用数组来表示，这是因为堆是完全二叉树，而完全二叉树很容易就存储在数组中。位置 k 的节点的父节点位置为 k/2，而它的两个子节点的位置分别为 2k 和 2k+1。 上浮在堆中，当一个节点比父节点大，那么需要交换这个两个节点。交换后还可能比它新的父节点大，因此需要不断地进行比较和交换操作，把这种操作称为上浮。 实现如下： 123456private void swim(int k) &#123; while (k &gt; 1 &amp;&amp; less(k/2, k)) &#123; exch(k, k/2); k = k/2; &#125;&#125; 下沉在堆中，当一个节点比子节点小，需要不断地向下进行比较和交换操作，把这种操作称为下沉。一个节点如果有两个子节点，应当与两个子节点中最大那个节点进行交换。 实现如下： 123456789private void sink(int k) &#123; while (2*k &lt;= N) &#123; int j = 2*k; if (j &lt; N &amp;&amp; less(j, j+1)) j++; if (!less(k, j)) break; exch(k, j); k = j; &#125;&#125; 堆排序堆排序可以分为两个阶段。在堆的构造阶段中，我们将原始数组重新组织安排进一个堆中；然后在下沉排序阶段，我们从堆中按递减顺序取出所有元素并得到排序结果。 堆的构造无序数组建立堆最直接的方法是从左到右遍历数组进行上浮操作。一个更高效的方法是从右至左进行下沉操作，如果一个节点的两个节点都已经是堆有序，那么进行下沉操作可以使得这个节点为根节点的堆有序。叶子节点不需要进行下沉操作，可以忽略叶子节点的元素，因此只需要遍历一半的元素即可。 下沉排序堆排序的主要工作都是在这一阶段完成的。这里我们将堆中的最大元素删除，然后放入堆缩小后数组中空出的位置。 12345678910111213141516171819202122232425262728293031public class Heap &#123; public static void sort(Comparable[] pq) &#123; int n = pq.length; for (int k = n/2; k &gt;= 1; k--) sink(pq, k, n); while (n &gt; 1) &#123; exch(pq, 1, n--); sink(pq, 1, n); &#125; &#125; private static void sink(Comparable[] pq, int k, int n) &#123; while (2*k &lt;= n) &#123; int j = 2*k; if (j &lt; n &amp;&amp; less(pq, j, j+1)) j++; if (!less(pq, k, j)) break; exch(pq, k, j); k = j; &#125; &#125; private static boolean less(Comparable[] pq, int i, int j) &#123; return pq[i-1].compareTo(pq[j-1]) &lt; 0; &#125; private static void exch(Object[] pq, int i, int j) &#123; Object swap = pq[i-1]; pq[i-1] = pq[j-1]; pq[j-1] = swap; &#125;&#125; 复杂度分析一个堆的高度为 logN，因此在堆中插入元素和删除最大元素的复杂度都为 logN。 对于堆排序，由于要对 N 个节点进行下沉操作，因此复杂度为 NlogN。 现代系统的许多应用很少使用它，因为它无法利用缓存。数组元素很少和相邻的其它元素进行比较，因此无法利用局部性原理，缓存未命中的次数很高。 最坏时间复杂度 О(nlogn) 最优时间复杂度 O(nlogn) 平均时间复杂度 O(nlogn) 空间复杂度 O(1) 不稳定 参考资料 Algorithms (Fourth Edition) CS-Notes 算法]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见排序算法之快速排序]]></title>
    <url>%2F2019%2F01%2F28%2F%E5%B8%B8%E8%A7%81%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[前言排序算法的成本模型计算的是比较和交换的次数。less()方法对元素进行比较，exch()方法将元素交换位置。 123456789private static boolean less(Comparable v, Comparable w) &#123; return (v.compareTo(w) &lt; 0);&#125;private static void exch(Comparable[] a, int i, int j) &#123; Comparable swap = a[i]; a[i] = a[j]; a[j] = swap;&#125; 思路快速排序是一种分治的排序算法，它将一个数组分成两个子数组，将两部分独立地排序。 快速排序和归并排序是互补的：归并排序将数组分成两个子数组分别排序，并将有序的子数组归并以将整个数组排序；而快速排序将数组排序的方式则是当两个子数组都有序时整个数组也就自然有序了。前者的递归调用发生在处理整个数组之前，而后者的递归调用则发生在处理整个数组之后。 实现过程 基本算法12345678910111213141516171819public class Quick &#123; public static void sort(Comparable[] a) &#123; shuffle(a); sort(a, 0, a.length - 1); &#125; private static void sort(Comparable[] a, int lo, int hi) &#123; if (hi &lt;= lo) return; int j = partition(a, lo, hi); sort(a, lo, j-1); sort(a, j+1, hi); &#125; private void shuffle(T[] nums) &#123; List&lt;Comparable&gt; list = Arrays.asList(nums); Collections.shuffle(list); list.toArray(nums); &#125;&#125; 该方法的关键在于切分。 切分方法一般策略是先随意地取a[lo]作为切分元素，即那个将会被排序的元素，然后我们从数组的左端开始向右扫描直到找到一个大于等于它的元素，再从数组的右端开始向左扫描直到找到一个小于等于它的元素。这两个元素显然是没有排定的，因此交换它们的位置。如此继续，我们就可以保证左指针i的左侧元素都不大于切分元素，右指针j的右侧元素都不小于切分元素。当两个指针相遇时，我们只需要将切分元素a[lo]和左子数组最右侧的元素（a[j]）交换然后返回j即可。 12345678910111213141516171819private static int partition(Comparable[] a, int lo, int hi) &#123; int i = lo; int j = hi + 1; Comparable v = a[lo]; while (true) &#123; while (less(a[++i], v)) &#123; if (i == hi) break; &#125; while (less(v, a[--j])) &#123; if (j == lo) break; &#125; if (i &gt;= j) break; exch(a, i, j); &#125; exch(a, lo, j); return j;&#125; 这个过程使得数组满足下面三个条件： 对于某个j，a[j]已经排定 a[lo]到a[j-1]中的所有元素都不大于a[j] a[j+1]到a[hi]中的所有元素都不小于a[j] 复杂度分析快速排序的最好情况是每次都正好将数组对半分。在这种情况下快速排序所用的比较次数正好满足分治递归的Cn=2Cn/2+n。2Cn/2表示将两个子数组排序的成本，n表示用切分元素和所有数组元素进行比较的成本，这个递归公式的解Cn~nlogn。（下文有具体数学推导） 而在最坏情况下，切分不平衡使得第一次从最小的元素切分，第二次从第二小的元素切分，如此继续，每次切分后两个子数组之一总是为空的，比较次数为(n - 1) + (n - 2) +...+ 1 = n × (n - 1 ) / 2。 而对于空间复杂度来说，主要考虑的是递归调用使用的栈空间，在最好的情况下（也就是对半分），递归深度为logn，最坏情况下的递归深度为n。 最坏时间复杂度 О(n²) 最优时间复杂度 O(nlogn) 平均时间复杂度 O(nlogn) 最坏空间复杂度 O(n) 最优空间复杂度 O(logn) 不稳定 最优时间复杂度的数学证明 算法改进切换到插入排序因为快速排序在小数组中也会递归调用自己，对于小数组，插入排序比快速排序的性能更好，因此在小数组中可以切换到插入排序。 只需要将代码中的if (hi &lt;= lo) return;改为if (hi &lt;= lo + M) {Insertion.sort(a, lo, hi); return;}。 三取样切分最好的情况下是每次都能取数组的中位数作为切分元素，但是计算中位数的代价很高。人们发现取 3 个元素并将大小居中的元素作为切分元素的效果最好。 三向切分法从左到右遍历数组一次，维护一个指针lt使得a[lo…lt-1]中的元素都小于v，一个指针gt使得a[gt+1…hi]中的元素都大于v，一个指针i使得a[lt..i-1]中的元素都等于v，a[i..gt]中的元素都还未确定。 一开始i和lo相等，对a[i]进行三向比较： a[i]小于v，将a[lt]和a[i]交换，将lt和i加一 a[i]大于v，将a[gt]和a[i]交换，将gt减一 a[i]等于v，将i加一 对于包含大量重复元素的数组，它将排序时间从线性对数级降低到了线性级别。 1234567891011121314151617181920212223242526272829public class Quick3way &#123; public static void sort(Comparable[] a) &#123; shuffle(a); sort(a, 0, a.length - 1); &#125; private static void sort(Comparable[] a, int lo, int hi) &#123; if (hi &lt;= lo) return; int lt = lo, gt = hi; Comparable v = a[lo]; int i = lo + 1; while (i &lt;= gt) &#123; int cmp = a[i].compareTo(v); if (cmp &lt; 0) exch(a, lt++, i++); else if (cmp &gt; 0) exch(a, i, gt--); else i++; &#125; // a[lo..lt-1] &lt; v = a[lt..gt] &lt; a[gt+1..hi]. sort(a, lo, lt-1); sort(a, gt+1, hi); &#125; private void shuffle(T[] nums) &#123; List&lt;Comparable&gt; list = Arrays.asList(nums); Collections.shuffle(list); list.toArray(nums); &#125;&#125; 参考资料 Algorithms (Fourth Edition) CS-NOTE 算法 排序算法之快速排序的时间复杂度和空间复杂度]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见排序算法之归并排序]]></title>
    <url>%2F2019%2F01%2F28%2F%E5%B8%B8%E8%A7%81%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E4%B9%8B%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[前言排序算法的成本模型计算的是比较和交换的次数。less()方法对元素进行比较，exch()方法将元素交换位置。 123456789private static boolean less(Comparable v, Comparable w) &#123; return (v.compareTo(w) &lt; 0);&#125;private static void exch(Comparable[] a, int i, int j) &#123; Comparable swap = a[i]; a[i] = a[j]; a[j] = swap;&#125; 原地归并方法该方法将两个不同的有序数组归并到第三个数组中。 123456789101112131415private static void merge(Comparable[] a, Comparable[] aux, int lo, int mid, int hi) &#123; // copy to aux[] for (int k = lo; k &lt;= hi; k++) &#123; aux[k] = a[k]; &#125; // merge back to a[] int i = lo, j = mid+1; for (int k = lo; k &lt;= hi; k++) &#123; if (i &gt; mid) a[k] = aux[j++]; else if (j &gt; hi) a[k] = aux[i++]; else if (less(aux[j], aux[i])) a[k] = aux[j++]; else a[k] = aux[i++]; &#125;&#125; 自顶向下的归并排序自顶向下的归并排序应用了分治的思想，要对子数组a[lo..hi]进行排序，先将它分为a[lo..mid]和a[mid+1..hi]两部分，分别通过递归调用将它们单独排序，最后将有序的子数组归并为最终的排序结果。 图为自顶向下的归并排序中归并结果的轨迹 1234567891011121314public class Merge &#123; public static void sort(Comparable[] a) &#123; Comparable[] aux = new Comparable[a.length]; sort(a, aux, 0, a.length-1); &#125; private static void sort(Comparable[] a, Comparable[] aux, int lo, int hi) &#123; if (hi &lt;= lo) return; int mid = lo + (hi - lo) / 2; sort(a, aux, lo, mid); sort(a, aux, mid + 1, hi); merge(a, aux, lo, mid, hi); &#125;&#125; 自底向上的归并排序实现归并排序的另一种方法是先归并那些微型数组，然后再成对归并得到子数组，如此这般地多次遍历整个数组，直到我们将整个数组归并到一起。 图为自底向上的归并排序中归并结果的轨迹 12345678910111213public class MergeBU &#123; public static void sort(Comparable[] a) &#123; int n = a.length; Comparable[] aux = new Comparable[n]; for (int len = 1; len &lt; n; len *= 2) &#123; for (int lo = 0; lo &lt; n-len; lo += len+len) &#123; int mid = lo+len-1; int hi = Math.min(lo+len+len-1, n-1); merge(a, aux, lo, mid, hi); &#125; &#125; &#125;&#125; 特点 归并排序的空间复杂度不是最优的 和选择排序一样，排序的性能不受输入数据的影响，但表现比选择排序好的多 复杂度分析 最坏情况时间复杂度 O(nlogn) 最好情况时间复杂度 O(nlogn) 平均情况时间复杂度 O(nlogn) 空间复杂度 O(n) 稳定 参考资料 Wikipedia Algorithms (Fourth Edition) 十大经典排序算法]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初级排序算法]]></title>
    <url>%2F2019%2F01%2F28%2F%E5%88%9D%E7%BA%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[前言排序算法的成本模型计算的是比较和交换的次数。less()方法对元素进行比较，exch()方法将元素交换位置。 123456789private static boolean less(Comparable v, Comparable w) &#123; return (v.compareTo(w) &lt; 0);&#125;private static void exch(Comparable[] a, int i, int j) &#123; Comparable swap = a[i]; a[i] = a[j]; a[j] = swap;&#125; 选择排序首先找到数组中最小的那个元素，其次将它和数组的第一个元素交换位置。再次，在剩下的元素中找到最小的元素，将它与数组的第二个元素交换位置。如此反复，直到将整个数组排序。 上图为选择排序的示例动画。红色表示当前最小值，黄色表示已排序序列，蓝色表示当前位置。 特点 运行时间和输入无关：一个已经有序的数组或主键全部相等的数组和一个元素随机排列的数组所用的排序时间一样长。 数据移动是最少的：每次交换都会改变两个数组的元素的值，因此选择排序用了N次交换。 复杂度分析比较次数与关键字的初始状态无关，总的比较次数N = (n - 1) + (n - 2) +...+ 1 = n × (n - 1 ) / 2。交换次数最好情况是已经有序，交换0次；最坏情况是逆序，交换n-1次。 最坏时间复杂度 О(n²) 最优时间复杂度 О(n²) 平均时间复杂度 О(n²) 空间复杂度 O(1) 不稳定 实现123456789101112public class Selection &#123; public static void sort(Comparable[] a) &#123; int n = a.length; for (int i = 0; i &lt; n; i++) &#123; int min = i; for (int j = i+1; j &lt; n; j++) &#123; if (less(a[j], a[min])) min = j; &#125; exch(a, i, min); &#125; &#125;&#125; 插入排序插入排序是一种简单直观的排序算法。它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。 特点 插入排序所需时间取决于输入中元素的初始顺序。 插入排序对于部分有序的数组十分高效。 复杂度分析最好情况是序列已经是升序排列了，在这种情况下，需要进行的比较操作需n-1次即可，不需要进行交换；最坏情况是降序排列，那么此时需要进行的比较共有n × (n - 1) / 2次，交换同样需要n × (n - 1) / 2次。 最坏时间复杂度 О(n²) 最优时间复杂度 О(n) 平均时间复杂度 О(n²) 空间复杂度 O(1) 稳定 实现12345678910public class Insertion &#123; public static void sort(Comparable[] a) &#123; int n = a.length; for (int i = 1; i &lt; n; i++) &#123; for (int j = i; j &gt; 0 &amp;&amp; less(a[j], a[j-1]); j--) &#123; exch(a, j, j-1); &#125; &#125; &#125;&#125; 希尔排序希尔排序，也称递减增量排序算法，是插入排序的一种更高效的改进版本。希尔排序的思想是使数组中任意间隔为h的元素都是有序的，这样的数组称为h有序数组。 实现希尔排序只需要在插入排序的代码中将移动元素的距离由1改为h即可。 一个h有序数组即一个由h个有序子数组组成的数组 上图表示以23, 10, 4, 1的步长序列进行希尔排序。 特点 希尔排序的时间复杂度与递增序列密切相关，所以分析希尔排序的时间复杂度是个比较麻烦的事。 希尔排序对于中等大小规模表现良好，对规模非常大的数据排序不是最优选择。 希尔排序实现简单，几乎任何排序工作在开始时都可以用希尔排序，若在实际使用中证明它不够快，再改成快速排序这样更高级的排序算法。 实现12345678910111213141516171819public class Shell &#123; public static void sort(Comparable[] a) &#123; int n = a.length; // 3x+1 increment sequence: 1, 4, 13, 40, 121, 364, 1093, ... int h = 1; while (h &lt; n/3) h = 3*h + 1; while (h &gt;= 1) &#123; // h-sort the array for (int i = h; i &lt; n; i++) &#123; for (int j = i; j &gt;= h &amp;&amp; less(a[j], a[j-h]); j -= h) &#123; exch(a, j, j-h); &#125; &#125; h /= 3; &#125; &#125;&#125; 参考资料 Wikipedia Algorithms (Fourth Edition) 十大经典排序算法]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ATR-CKN算法的研究与实现]]></title>
    <url>%2F2019%2F01%2F28%2FATR-CKN%E7%AE%97%E6%B3%95%E7%9A%84%E7%A0%94%E7%A9%B6%E4%B8%8E%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[前言最近在学校做了无线传感器网络（WSN）睡眠调度算法方面的一些研究，本篇文章主要对其中的CKN、EC-CKN算法的学习做个总结，并给出基于这两种算法而改进后的ATR-CKN算法的核心实现以及在Nettopo上的运行结果。 CKN与EC-CKN算法K-邻居节点连通算法（CKN）是一个有效的分布式睡眠/工作时序安排算法。该算法可以在有效的减少网络中处于工作状态的节点个数的同时保证整个网络处于连通状态和需求的路径延迟。执行CKN算法时对WSN中的每个节点u主要进行以下几步： 针对CKN算法在能量消耗方面存在的问题，基于能量消耗的睡眠/工作时序安排算法（EC-CKN）可以延长网络的寿命。EC-CKN算法利用节点当前的剩余能量信息作为参数来决定节点是否进入睡眠状态。EC-CKN算法不仅可以保证整个网络处于K邻居节点连通状态，同时还可以保证每个节点处于工作状态的K个邻居节点当前的剩余能量在所有邻居节点当前剩余能量排序中为最大的K个。 存在的问题EC-CKN对CKN有了一定的改进，但在某些场景下仍然会存在一些问题，例如下文将介绍的死亡加速与网络隔离。 死亡加速在下图的场景中，节点B有很多个邻居节点，按理是可以进入睡眠状态的，但是由于它的其中一个邻居节点A只有它一个邻居节点，因此节点A和B永远得不到睡眠机会，这导致的后果就是：节点B的能量很快就被消耗完了，而节点B周围原本刚好满足睡眠条件的节点由于少了一个醒着的邻居节点，睡眠的几率也因此下降，从而加速了整个网络的死亡。 网络隔离类似于死亡加速，在下面的场景中节点A和B永远也得不到睡眠机会，因此会更快的消耗完能量，导致相连的两个网络被隔离开了。 ATR-CKN算法ATR-CKN算法优于原始的基于CKN的睡眠调度算法，它的优势在于可以在物理上调整传感器节点的传输半径，从而执行CKN使部分节点进入睡眠状态。ATR-CKN算法在继承了EC-CKN算法的所有主要属性的同时，通过提高节点的睡眠率为延长网络生命周期做出了重要贡献。 相较于EC-CKN，ATR-CKN只用在之前加入一个判断逻辑即可： 核心实现下面给出在Nettopo上对于ATR-CKN算法的实现，其关键在于执行EC-CKN之前加入下面一段判断逻辑： 123456789101112131415161718192021private void ATRCKN_Function() &#123;//... boolean flag = false; Integer[] neighbors1 = neighbors.get(currentID); if(neighbors1.length &lt; k) &#123; while(!isUsingMaxTR(currentID)) &#123; increaseTR(currentID); neighbors1 = neighbors.get(currentID); if(neighbors1.length &gt;= k) &#123; for(int j = 0; j &lt; neighbors1.length; j++) &#123; int tr = ((SensorNode)wsn.getNodeByID(currentID)).getMaxTR(); ((SensorNode)wsn.getNodeByID(neighbors1[j])).setMaxTR(tr); &#125; flag = true; break; &#125; &#125; if(!flag) setDefaultTR(currentID); &#125; //...&#125; 运行结果下面将在Nettopo上简单的演示一遍ATR-CKN算法对于死亡加速问题的解决。 k = 2，round = 1的时候： k = 2，round = 10的时候： k = 2，round = 30的时候 k = 2，round = 43的时候： 由于增大了传感器节点的物理传输半径，可以看到两个关键节点都可以进入睡眠状态，以此延长了网络的整体寿命。虽然增大传输半径的同时也增加了能量消耗，但在进行了大量实验并对统计数据进行详细分析后，我们可以发现ATR-CKN的生命周期相比EC-CKN平均增加了19％，最大增加了41%，因此可以得出其更优于EC-CKN的结论。]]></content>
      <categories>
        <category>项目</category>
      </categories>
      <tags>
        <tag>WSN</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM-垃圾收集与内存分配]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM-%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E4%B8%8E%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%2F</url>
    <content type="text"><![CDATA[对象存活判断判断对象是否存活一般有引用计数法和可达性分析两种方式。 引用计数算法为每个对象添加一个引用计数器，新增一个引用时计数器加1，引用释放时计数器减1，计数器为0时该对象可以被回收。 引用计数法实现简单且高效，但无法解决对象之间相互循环引用的问题。 可达性分析算法通过一系列GC Roots作为起始点向下搜索，搜索所走过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可引用的。 可作为GC Roots的对象包括下面几种： 虚拟机栈中引用的对象。 方法区中类静态属性引用的对象。 方法区中常量引用的对象。 本地方法栈中JNI引用的对象。 finalize如果对象在进行可达性分析后发现没有与GC Roots相连接的引用链，那它将会被第一次标记。如果没有覆盖finalize()方法或者该方法已经被虚拟机调用过，那么它将被回收；否则，会将这个对象放置在一个叫做F-Queue的队列中，要想不被回收，就要在finalize()中重新与引用链上的任何一个对象建立关联。 引用类型对象的引用类型分为强引用、软引用、弱引用、虚引用，这四种引用强度依次减弱。 强引用：类似Object obj = new Object()这类的引用，强引用关联的对象永远不会被回收。 软引用：软引用是用来描述一些还有用但并非必需的对象。在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中进行第二次回收，如果这次回收还没有足够的内存才会抛出内存溢出异常。简单的说，被软引用关联的对象只有在内存不够的情况下才会被回收。 弱引用：强度比软引用更弱一些，无论当前内存是否足够，被弱引用关联的对象一定会被回收。 虚引用：一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用取得一个对象。为一个对象设置虚引用关联的唯一目的就是能在这个对象被回收时收到一个系统通知。 垃圾收集算法最基础的垃圾收集算法有三种：标记-清除算法、复制算法、标记-整理算法，我们常用的垃圾回收器一般都采用分代收集算法。 标记-清除算法首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。 不足：标记和清除的两个过程的效率都不高；会产生大量不连续的内存碎片，导致无法给大对象分配内存。 复制算法将内存划分为大小相等的两块，每次只使用其中一块，当这一块内存用完了就将还存活的对象复制到另一块上面，然后再把使用过的内存空间进行一次清理。 现在的商业虚拟机都采用这种收集算法来回收新生代，但并不需要按照1：1的比例来划分内存空间，而是将内存分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中一块Survivor。当回收时，将Eden和Survivor中还活着的对象一次性地复制到另外一块Survivor空间上，最后清理掉Eden和刚才用过的Survivor空间。 如果每次回收有多于 10% 的对象存活，那么一块 Survivor 空间就不够用了，此时需要依赖于老年代进行分配担保，也就是借用老年代的空间存储放不下的对象。 标记-整理算法复制算法在对象存活率较高时要进行较多的复制操作，也有可能需要额外的空间进行分配担保，所以在老年代一般不能直接选用这种算法。 标记-整理算法的标记过程仍与标记-清除算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。 分代收集算法现在的商业虚拟机采用分代收集算法，它根据对象存活周期将内存划分为新生代和老年代，新生代使用复制算法，老年代使用标记-清除或者标记-整理算法。 垃圾收集器如果说收集算法是内存回收的方法论，垃圾收集器就是内存回收的具体实现。 Serial收集器串行收集器是最古老，最稳定以及效率高的收集器，可能会产生较长的停顿，只使用一个线程去回收。 ParNew收集器ParNew收集器其实就是Serial收集器的多线程版本。 Parallel Scavenge收集器Parallel是一个多线程收集器。其它收集器关注点是尽可能缩短垃圾收集时用户线程的停顿时间，而Parallel Scavenge收集器的目标是达到一个可控制的吞吐量，它被称为“吞吐量优先”收集器。这里的吞吐量指 CPU 用于运行用户代码的时间占总时间的比值。 停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验。而高吞吐量则可以高效率地利用 CPU 时间，尽快完成程序的运算任务，适合在后台运算而不需要太多交互的任务。缩短停顿时间是以牺牲吞吐量和新生代空间来换取的：新生代空间变小，收集时间缩短，但同时垃圾回收也变得频繁，导致吞吐量下降。 可以通过一个开关参数打开GC自适应的调节策略（GC Ergonomics），就不需要手工指定新生代的大小、Eden和Survivor区的比例、晋升老年代对象年龄等细节参数了。虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量。 Serial Old收集器Seriol Old是Serial收集器的老年代版本，同样是一个单线程收集器。 Parallel Old收集器Parallel Old是Parallel Scavenge收集器的老年代版本，同样是一个多线程收集器。 CMS收集器CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。目前很大一部分的Java应用都集中在互联网站或B/S系统的服务端上，这类应用尤其重视服务的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。 从名字（包含“Mark Sweep”）上就可以看出CMS收集器是基于“标记-清除”算法实现的，它的运作过程相对于前面几种收集器来说要更复杂一些，整个过程分为4个步骤，包括： 初始标记 并发标记 重新标记 并发清除 其中初始标记、重新标记这两个步骤仍然需要“Stop The World”。初始标记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，并发标记阶段就是进行GC Roots Tracing的过程，而重新标记阶段则是为了修正并发标记期间，因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。 由于整个过程中耗时最长的并发标记和并发清除过程中，收集器线程都可以与用户线程一起工作，所以总体上来说，CMS收集器的内存回收过程是与用户线程一起并发地执行。 CMS收集器具有以下三个缺点： 在并发阶段，CMS虽然不会导致用户线程停顿，但是会因为占用了一部分线程（或者说CPU资源）而导致应用程序变慢，总吞吐量会降低。 CMS无法处理浮动垃圾。 需要预留一部分空间提供并发收集时的程序运作使用，因此不能等到老年代完全被填满再进行收集，要是CMS运行期间预留的内存无法满足程序需要，就会出现“Concurrent Mode Failure”失败，这时将会启用Serial Old收集器重新进行老年代的垃圾收集，停顿时间就很长了。 CMS是基于“标记-清除”算法实现的收集器，会产生大量空间碎片。 浮动垃圾：由于CMS并发清理阶段用户线程还在运行着，伴随程序运行自然就还会有新的垃圾不断产生，这一部分垃圾出现在标记过程之后，CMS无法在当次收集中处理掉它们，只好留待下一次GC时再清理掉，这一部分垃圾就称为“浮动垃圾”。 G1收集器G1（Garbage-First）收集器是一款面向服务端应用的垃圾收集器，在多CPU和大内存的场景下有很好的性能。HotSpot开发团队赋予它的使命是未来可以替换掉 CMS 收集器。G1收集器具有以下几个特点： 并行与并发。 分代收集：不需要其它收集器配合就能独立管理整个GC堆，采用不同的方式去收集 新生代和老年代。 空间整合：整体来看是基于“标记 - 整理”算法实现的收集器，从局部（两个Region之间）上来看是基于“复制”算法实现的，这意味着运行期间不会产生内存空间碎片。 可预测的停顿：能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在GC上的时间不得超过N毫秒。 G1收集器的范围不再是整个新生代或者整个老年代，它将整个Java堆划分为多个大小相等的独立区域Region，虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔离的了，它们都是一部分不需要连续的Region的集合。 G1跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region，这保证了G1收集器在有限的时间内可以获取尽可能高的收集效率。 每个Region都有一个Remembered Set，用来记录该Region对象的引用对象所在的Region。通过使用Remembered Set，在做可达性分析的时候就可以避免全堆扫描。 G1收集器的运作大致可划分为以下几个步骤： 初始标记 并发标记 最终标记 筛选回收 前三个步骤与CMS收集器相似，最后的筛选回收阶段对各个Region的回收价值和成本进行排序，根据用户所期望的GC停顿时间来制定回收计划。 内存分配策略 对象优先分配在Eden区：如果Eden区没有足够的空间时，虚拟机执行一次Minor GC。 大对象直接进入老年代：大对象是指需要大量连续内存空间的对象，这样做的目的是避免在Eden区和两个Survivor区之间发生大量的内存拷贝（新生代采用复制算法收集内存）。 长期存活的对象进入老年代：为对象定义年龄计数器，对象在Eden区出生并经过Minor GC依然存活，将被移动到Survivor区中，年龄增加1岁，增加到年龄阈值则移动到老年代中。 动态判断对象的年龄：如果在Survivor区中相同年龄所有对象大小的总和大于Survivor空间的一半，则年龄大于或等于该年龄的对象可以直接进入老年代而无需达到年龄阈值。 空间分配担保：在发生Minor GC之前，虚拟机先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果这个条件成立的话，那么Minor GC可以确保是安全的。如果不成立的话虚拟机会查看HandlePromotionFailure设置值是否允许担保失败，如果允许那么就会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试着进行一次Minor GC，尽管这次Minor GC是有风险的；如果小于，或者 HandlePromotionFailure设置不允许冒险，那么就改为进行一次Full GC。 方法区的回收垃圾收集主要针对于Java堆进行，方法区虽然也有垃圾收集，但性价比很低，主要回收两部分内容：废弃常量和无用的类。 无用的类需要满足下面三个条件： 该类所有的实例都已经被回收，也就是堆中不存在该类的任何实例。 加载该类的ClassLoader已经被回收。 该类对应的Class对象没有在任何地方被引用，也就无法在任何地方通过反射访问该类方法。 参考资料 周志明. 深入理解 Java 虚拟机 [M]. 机械工业出版社, 2011.]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>垃圾收集</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM-类加载机制]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM-%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[类的生命周期 类加载过程类加载的过程包括了加载、验证、准备、解析、初始化五个阶段。 在这五个阶段中，加载、验证、准备和初始化这四个阶段发生的顺序是确定的，而解析阶段则不一定，它在某些情况下可以在初始化阶段之后开始，这是为了支持Java语言的运行时绑定（也称为动态绑定或晚期绑定）。另外注意这里的几个阶段是按顺序开始，而不是按顺序进行或完成，因为这些阶段通常都是互相交叉地混合进行的，通常在一个阶段执行的过程中调用或激活另一个阶段。 加载在加载阶段，虚拟机需要完成以下三件事情： 通过一个类的全限定名来获取其定义的二进制字节流。 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。 在Java堆中生成一个代表这个类的java.lang.Class对象，作为对方法区中这些数据的访问入口。 相对于类加载的其他阶段而言，加载阶段（准确地说，是加载阶段获取类的二进制字节流的动作）是可控性最强的阶段，因为开发人员既可以使用系统提供的类加载器来完成加载，也可以自定义自己的类加载器来完成加载。 加载阶段完成后，虚拟机外部的二进制字节流就按照虚拟机所需的格式存储在方法区之中，而且在Java堆中也创建一个java.lang.Class类的对象，这样便可以通过该对象访问方法区中的这些数据。 二进制字节流不一定要从一个Class文件中获取，还可以通过以下几种方式获取： 从ZIP包读取，成为JAR、EAR、WAR格式的基础。 从网络中获取，最典型的应用是Applet。 运行时计算生成，例如动态代理技术，在java.lang.reflect.Proxy中使用ProxyGenerator.generateProxyClass来为特定接口生成代理类的二进制字节流。 由其他文件生成，例如由JSP文件生成对应的Class类。 验证确保 Class 文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。验证阶段大致会完成4个阶段的检验动作： 文件格式验证：验证字节流是否符合Class文件格式的规范。 元数据验证：对类的元数据信息进行语义校验，保证不存在不符合Java语言规范的元数据信息。（例如：这个类是否有父类）。 字节码验证：通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的，保证被校验类的方法在运行时不会做出危害虚拟机安全的事件。 符号引用验证：确保解析动作能正确执行。 验证阶段是非常重要的，但不是必须的，它对程序运行期没有影响，如果所引用的类经过反复验证，那么可以考虑采用-Xverifynone参数来关闭大部分的类验证措施，以缩短虚拟机类加载的时间。 准备准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些变量所使用的内存都将在方法区中进行分配。 注意： 这时候进行内存分配的仅包括类变量（被static修饰的变量），实例变量将会在对象实例化时（实例化不是类加载的一个过程）随着对象一起分配在Java堆中。 初始值通常情况下是数据类型的零值，但如果类字段同时被final和static修饰（即为常量），那么在准备阶段就会被初始化为所指定的值。 解析解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。 符号引用：符号引用以一组符号来描述所引用的目标，可以是任何形式的字面量，与虚拟机实现的内存布局无关，引用的目标不一定已经加载到内存中。 直接引用：直接引用可以是直接指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄。直接引用是和虚拟机实现的内存布局相关的，引用的目标必定已经在内存中存在。 其中解析过程在某些情况下可以在初始化阶段之后再开始，这是为了支持Java的动态绑定。 初始化初始化阶段才真正开始执行类中定义的Java程序代码。初始化阶段即虚拟机执行类构造器&lt;clinit&gt;()方法的过程。 &lt;clinit&gt;()方法是由编译器自动收集类中所有类变量的赋值动作和静态语句块中的语句合并产生的，编译器收集的顺序由语句在源文件中出现的顺序决定。特别注意的是，静态语句块只能访问到定义在它之前的类变量，定义在它之后的类变量只能赋值，不能访问。 与类的构造函数（或者说实例构造器&lt;init&gt;()）不同，不需要显式的调用父类的构造器。虚拟机会自动保证在子类的&lt;clinit&gt;()方法运行之前，父类的&lt;clinit&gt;()方法已经执行结束。因此虚拟机中第一个执行&lt;clinit&gt;()方法的类肯定为java.lang.Object。 由于父类的&lt;clinit&gt;()方法先执行，也就意味着父类中定义的静态语句块的执行要优先于子类。 &lt;clinit&gt;()方法对于类或接口不是必须的，如果一个类中不包含静态语句块，也没有对类变量的赋值操作，编译器可以不为该类生成&lt;clinit&gt;()方法。 接口中不可以使用静态语句块，但仍然有类变量初始化的赋值操作，因此接口与类一样都会生成&lt;clinit&gt;()方法。但接口与类不同的是，执行接口的&lt;clinit&gt;()方法不需要先执行父接口的&lt;clinit&gt;()方法。只有当父接口中定义的变量使用时，父接口才会初始化。另外，接口的实现类在初始化时也一样不会执行接口的&lt;clinit&gt;()方法。 虚拟机会保证一个类的&lt;clinit&gt;()方法在多线程环境下被正确的加锁和同步，如果多个线程同时初始化一个类，只会有一个线程执行这个类的&lt;clinit&gt;()方法，其它线程都会阻塞等待，直到活动线程执行&lt;clinit&gt;()方法完毕。如果在一个类的&lt;clinit&gt;()方法中有耗时的操作，就可能造成多个线程阻塞，在实际过程中此种阻塞很隐蔽。 在准备阶段，类变量已经赋过一次系统要求的初始值，而在初始化阶段，根据程序员通过程序制定的主观计划去初始化类变量和其它资源。在Java中对类变量进行初始值设定有两种方式： 声明类变量时指定初始值。 使用静态代码块为类变量指定初始值。 只有当对类主动引用的时候才会导致类的初始化，主动引用有以下几种： 创建类的实例，也就是new的方式。 访问某个类或接口的静态变量，或者对该静态变量赋值。 调用类的静态方法。 使用java.lang.reflect包的方法对类进行反射调用的时候。 当初始化一个类的时候，如果其父类还没有进行过初始化，则需要先触发其父类的初始化。 当虚拟机启动时，用户需要指定一个要执行的主类（包含 main() 方法的那个类），虚拟机会先初始化这个主类。 除主动引用外的所有引用类的方式都不会触发初始化，被称为被动引用，常见有以下几个例子: 通过子类引用父类的静态字段，不会导致子类初始化。 通过数组定义来引用类，不会触发此类的初始化。该过程会对数组类进行初始化，数组类是一个由虚拟机自动生成的、直接继承自Object的子类，其中包含了数组的属性和方法。 类加载器两个类相等需要类本身相等，并且使用同一个类加载器进行加载。这是因为每一个类加载器都拥有一个独立的类名称空间。 从 Java 虚拟机的角度来讲，只存在以下两种不同的类加载器： 启动类加载器（Bootstrap ClassLoader），这个类加载器用C++实现，是虚拟机自身的一部分。 所有其他类的加载器，这些类由Java实现，独立于虚拟机外部，并且全都继承自抽象类java.lang.ClassLoader，这些类加载器需要由启动类加载器加载到内存中之后才能去加载其他的类。 站在Java开发人员的角度来看，类加载器可以大致划分为以下三类： 启动类加载器（Bootstrap ClassLoader）：此类加载器负责将存放在 &lt;JRE_HOME&gt;\lib目录中的，或者被-Xbootclasspath参数所指定的路径中的，并且是虚拟机识别的（仅按照文件名识别，如rt.jar，名字不符合的类库即使放在lib目录中也不会被加载）类库加载到虚拟机内存中。启动类加载器无法被Java程序直接引用，用户在编写自定义类加载器时，如果需要把加载请求委派给启动类加载器，直接使用null代替即可。 扩展类加载器（Extension ClassLoader）：此类加载器是由ExtClassLoader（sun.misc.Launcher$ExtClassLoader）实现的。它负责将&lt;JAVA_HOME&gt;/lib/ext或者被java.ext.dir系统变量所指定路径中的所有类库加载到内存中，开发者可以直接使用扩展类加载器。 应用程序类加载器（Application ClassLoader）：此类加载器是由AppClassLoader（sun.misc.Launcher$AppClassLoader）实现的。由于这个类加载器是ClassLoader中的getSystemClassLoader()方法的返回值，因此一般称为系统类加载器。它负责加载用户类路径（ClassPath）上所指定的类库，开发者可以直接使用这个类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。 双亲委派模型双亲委派模型的工作流程是：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把请求委托给父加载器去完成，依次向上，因此，所有的类加载请求最终都应该被传递到顶层的启动类加载器中，只有当父加载器在它的搜索范围中没有找到所需的类时，即无法完成该加载，子加载器才会尝试自己去加载该类。 该模型要求除了顶层的启动类加载器外，其余的类加载器都应有自己的父类加载器。这里类加载器之间的父子关系一般通过组合关系来实现，而不是通过继承的关系实现。 具体过程 当AppClassLoader加载一个class时，它首先不会自己去尝试加载这个类，而是把类加载请求委派给父类加载器ExtClassLoader去完成。 当ExtClassLoader加载一个class时，它首先也不会自己去尝试加载这个类，而是把类加载请求委派给BootStrapClassLoader去完成。 如果BootStrapClassLoader加载失败（例如在&lt;JRE_HOME&gt;\lib里未查找到该class），会使用ExtClassLoader来尝试加载。 若ExtClassLoader也加载失败，则会使用AppClassLoader来加载，如果AppClassLoader也加载失败，则会报出异常ClassNotFoundException。 优点使得Java类随着它的类加载器一起具有一种带有优先级的层次关系，从而使得基础类得到统一。 例如java.lang.Object存放在rt.jar中，如果编写另外一个java.lang.Object的类并放到ClassPath中，程序可以编译通过。由于双亲委派模型的存在，所以在rt.jar中的Object比在ClassPath中的Object优先级更高，这是因为rt.jar中的Object使用的是启动类加载器，而ClassPath中的Object使用的是应用程序类加载器。rt.jar中的Object优先级更高，那么程序中所有的Object都是这个Object。 自定义类加载器通常情况下，我们都是直接使用系统类加载器，但是有的时候，我们也需要自定义类加载器。 自定义类加载器一般都是继承自ClassLoader类，而java.lang.ClassLoader的loadClass()实现了双亲委派模型的逻辑，因此自定义类加载器最好不要去重写它。 参考资料 周志明. 深入理解 Java 虚拟机 [M]. 机械工业出版社, 2011.]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM-内存模型]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM-%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[Java内存模型由于计算机上的内存模型涉及到物理的主内存、高速缓存和寄存器等。这些不同的计算机不同的操场系统可能会存在差异，Java虚拟机规范中试图定义一种Java内存模型，来屏蔽掉各种硬件和操作系统的内存访问差异，让Java程序在各个平台下都能达到一致的访问效果。 主内存与工作内存 Java内存模型规定了所有变量都存储在主内存内（主内存包括方法区和堆），此处主内存隶属于Java虚拟机内存的一部分，而虚拟机内存是操作系统分配的。每条Java线程还有自己的工作内存，工作内存中保存了被该线程使用到的变量的主内存的副本，线程对变量的所有操作都在工作内存中进行，Java线程之间的变量值传递都通过主内存来完成。 内存间的交互关于主内存和工作内存间的交互协议，即一个变量如何从工作内存拷贝到工作内存、又是如何从工作内存同步回主内存之类的实现细节，Java内存模型中定义了8种操作，这8种操作实现时必须保证每一种操作都是原子的、不可再分的，其中前4条是作用于主内存，后4条作用于工作内存： lock锁定：将一个变量标识为线程独占状态 unlock解锁：将锁定状态的变量解除锁定，释放后的变量才可以被其他变量锁定 read读取：将变量从主内存传输到线程的工作内存中，待之后的load加载 write写入：把store操作从工作内存中得到的变量值写入主内存的变量中 load加载：将read后从主内存得到的变量值加载到工作内存的变量副本中 use使用：把工作内存中的一个变量值传递给字节码执行引擎，等待字节码指令使用 assign赋值：把一个从执行引擎接收到的值赋值给工作内存的变量 store存储：把工作内存中一个变量的值传送到主内存中，以便随后的write使用 volatile关键字volatile关键字具有以下两种特性： 保证此变量对所有变量的可见性 禁止指令重排序优化 对于第一种特性，即volatile关键字保证了新值能立即同步到主内存，以及每个线程在每次使用volatile变量前都立即从主内存刷新。因此我们可以说volatile保证了多线程操作时变量的可见性，而普通变量则不能保证这一点。 而对于第二种特性，volatile关键字本身就包含了禁止指令重排序的语义。 运行时数据区域Java虚拟机在执行Java程序的过程中会把它所管理的内存划分为若干个不同的数据区域。其中程序计数器、JVM栈、本地方法栈是线程私有的，而方法区和堆是所有线程共享的。 程序计数器一块较小的内存空间，可以看作当前线程所执行的字节码的行号指示器：如果线程正在执行一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行Native方法，这个计数器值则为空。 Java虚拟机栈Java虚拟机栈描述的是Java方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。 局部变量表：存放了编译器可知的各种基本数据类型、对象引用和returnAddress类型（指向了一条字节码指令的地址）。局部变量表所需的内存空间在编译期间完成分配。 动态链接：动态链接是指编译系统在链接阶段并不把目标文件和函数库文件链接在一起，是等到程序在运行过程中需要使用时才链接函数库。 操作数：参与运算的常量或者变量称为操作数。 该区域可能抛出以下异常： 当线程请求的栈深度超过最大值，会抛出StackOverflowError异常。 栈进行动态扩展时如果无法申请到足够内存，会抛出OutOfMemoryError异常。 本地方法栈本地方法栈与Java虚拟机栈类似，它们的区别只不过是虚拟机栈为虚拟机执行Java方法服务，而本地方法栈为本地方法服务。该区域可能抛出的异常与Java虚拟机栈一样。 Java堆Java堆是Java虚拟机所管理的内存中最大的一块，是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。 Java堆是垃圾收集器管理的主要区域，还可以细分为新生代和老年代。 一般情况下，新创建的对象都会存放到新生代中。 在新生代每进行一次垃圾收集后，就会给存活的对象“加1岁”，当年龄达到一定数量的时候就会进入老年代，另外，比较大的对象也会进入老年代。 Java堆不需要物理上连续的内存空间，逻辑上连续即可。如果堆中没有内存完成实例分配且堆也无法再扩展时，将抛出OutOfMemoryError异常。 方法区方法区常被称为“永久代”，也是各个线程共享的内存区域，用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。 和堆一样不需要连续的内存，并且可以动态扩展，动态扩展失败将抛出OutOfMemoryError异常。 运行时常量池运行时常量池是方法区的一部分，用于存放编译期生成的各种字面量和符号引用。 相较于Class文件常量池，运行时常量池更具动态性，在运行期间也可以将新的变量放入常量池中，而不是一定要在编译时确定的常量才能放入，这种特性用的比较多的便是String类的intern()方法。 控制参数汇总可以通过如下参数来控制各区域的内存大小：12345678910111213-Xms设置堆的最小空间大小-Xmx设置堆的最大空间大小-XX:NewSize设置新生代最小空间大小-XX:MaxNewSize设置新生代最大空间大小-XX:PermSize设置永久代最小空间大小-XX:MaxPermSize设置永久代最大空间大小-Xss设置每个线程的堆栈大小 参考资料 周志明. 深入理解 Java 虚拟机 [M]. 机械工业出版社, 2011.]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>内存模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统原理-死锁]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86-%E6%AD%BB%E9%94%81%2F</url>
    <content type="text"><![CDATA[死锁的定义一组进程中，每个进程都无限等待被该组进程中另一进程所占有的资源，因而永远无法得到的资源，这种现象称为进程死锁，这一组进程就称为死锁进程。 死锁与活锁的区别活锁指的是一组进程既无进展也没有阻塞 ，由于某些条件没有满足，导致一直重复尝试并失败。例如错误地使用Pertonson算法： 产生死锁的必要条件 互斥使用（资源独占）：一个资源每次只能给一个进程使用。 占有且等待（请求和保持）：进程在申请新的资源的同时保持对原有资源的占有。 不可抢占：资源申请者不能强行的从资源占有者手中夺取资源，资源只能由占有者自愿释放。 循环等待：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。 资源分配图系统由若干类资源构成，一类资源称为一个资源类；每个资源类中包含若干个同种资源，称为资源实例。用方框表示资源类，用方框中的黑圆点表示资源实例，用圆圈中加进程名表示进程。如果资源分配图中没有环路，则系统中没有死锁， 如果图中存在环路则系统中可能存在死锁。 资源分配图化简 找一个非孤立、且只有分配边的进程结点，去掉分配边，将其变为孤立结点。 再把相应的资源分配给一个等待该资源的进程，即将该进程的申请边变为分配边。 如果一个图可完全化简（所有的资源和进程都变成孤立的点），则不会产生死锁；如果一个图不可完全化简（即图中还有边存在），则会产生死锁。 死锁预防防止产生死锁的四个必要条件中任何一个条件发生，以此排除发生死锁的可能性。 破坏“互斥使用”条件把独占资源变为共享资源。例如在SPOOLing系统中，实际上并没有为任何进程分配这台打印机，而只是在输入井和输出井中，为进程分配一存储区和建立一章I/O请求表。这样，便把独占设备改造为共享设备。 破坏“占有且等待”条件实现方案一：要求每个进程在运行前必须一次性申请它所要求的所有资源，且仅当该进程所要资源均可满足时才给予一次性分配。 实现方案二：在允许进程动态申请资源前提下规定，一个进程在申请新的资源不能立即得到满足而变为等待状态之前，必须释放已占有的全部资 源，若需要再重新申请。 破坏“不可抢占”条件当一个进程申请的资源被其他进程占用时，可以通过操作系统抢占这一资源(两个进程优先级不同) 。 破坏“循环等待”条件通过定义资源类型的线性顺序实现。 把系统中所有资源编号，进程在申请资源时必须严格按资源编号的递增次序进行，否则操作系统不予分配。 死锁避免在系统运行过程中，对进程发出的每一个系统能够满足的资源申请进行动态检查，并根据检查结果决定是否分配资源，若分配后系统发生死锁或可能发生死锁，则不予分配，否则予以分配。 安全状态如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也仍然存在某种调度次序能够使得每一个进程运行完毕，则称该状态是安全的。 例如，图a的第二列Has表示已拥有的资源数，第三列Max表示总共需要的资源数，Free表示还有可以使用的资源数。从图a开始出发，先让B拥有所需的所有资源（图b），运行结束后释放B，此时Free变为5（图c）；接着以同样的方式运行C和A，使得所有进程都能成功运行，因此可以称图a所示的状态时安全的。 单个资源的银行家算法一个小城镇的银行家，他向一群客户分别承诺了一定的贷款额度，算法要做的是判断对请求的满足是否会进入不安全状态，如果是，就拒绝请求；否则予以分配。 由图可知，状态b进入状态c是进入了一个不安全的状态，因此恢复原来状态，避免了进入不安全状态。 多个资源的银行家算法上图中有五个进程，四个资源。左边的图表示已经分配的资源，右边的图表示还需要分配的资源。最右边的E、P以及A分别表示：总资源、已分配资源以及可用资源。 检查一个状态是否安全的算法如下： 查找右边的矩阵是否存在一行小于等于向量A。如果不存在这样的行，那么系统将会发生死锁，状态是不安全的。 假若找到这样一行，将该进程标记为终止，并将其已分配资源加到A 中。 重复以上两步，直到所有进程都标记为终止，则状态是安全的。 如果一个状态不是安全的，需要拒绝进入这个状态。 死锁检测与解除允许死锁发生，但是操作系统会不断监视系统进展情况，判断死锁是否真的发生，一旦死锁发生则采取专门的措施，解除死锁并以最小的代价恢复操作系统运行。 死锁的检测死锁的检测与银行家算法几乎一样，此处不再阐述。 死锁的解除 利用抢占恢复 利用回滚恢复 通过杀死进程恢复 鸵鸟算法把头埋在沙子里，假装根本没发生问题。 因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。 哲学家就餐问题五个哲学家围着一张圆桌，每个哲学家面前放着食物。哲学家的生活有两种交替活动：吃饭以及思考。当一个哲学家吃饭时，需要先拿起自己左右两边的两根筷子，并且一次只能拿起一根筷子。 下面是一种错误的解法，考虑到如果所有哲学家同时拿起左手边的筷子，那么就无法拿起右手边的筷子，造成死锁。 123456789101112#define N 5void philosopher(int i) &#123; while(true) &#123; think(); take(i); // 拿起左边的筷子 take((i+1)%N); // 拿起右边的筷子 eat(); put(i); put((i+1)%N); &#125;&#125; 为了防止死锁的发生，有以下几种解法： 仅当一个哲学家左右两边的筷子都可用时，才允许他拿筷子。 最多允许4个哲学家同时坐在桌子周围。 规定奇数号哲学家先拿左筷子再拿右筷子，而偶数号哲学家相反。 参考资料 Tanenbaum A S, Bos H. Modern operating systems[M]. Prentice Hall Press, 2014. 北京大学操作系统原理（Operating Systems） 计算机操作系统]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>死锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统原理-文件系统]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[文件的分类 普通文件：包含了用户的信息，一般为ASCII或二进制文件 目录文件：管理文件系统的系统文件 特殊文件（设备文件） 文件的逻辑结构逻辑结构是从用户观点出发看到的文件的组织形式。分为以下两类： 流式文件：无结构，对文件内信息不再划分单位，它是依次的一串字符流构成的文件。 记录式文件：有结构，文件由若干个记录组成，可以按记 录进行读、写、查找等操作。 存储介质与物理块典型的存储介质磁盘(包括固态盘SSD)、磁带、光盘、U盘等等，以下为典型的磁盘结构： 物理块 信息存储、传输、分配的独立单位 存储设备划分为大小相等的物理块，统一编号 磁盘访问 寻道：磁头移动定位到指定磁道 旋转延迟：等待指定扇区从磁头下旋转经过 数据传输：数据在磁盘与内存之间的实际传输 文件控制块（FCB）为管理文件而设置的数据结构，保存管理文件所需的所有有关信息（文件属性或元数据）。 文件控制块一般包含下列常用属性： 文件名 文件号 文件大小 文件地址 创建时间 最后修改时间 最后访问时间 各种标志(只读、隐藏、系统、归档等) … 文件目录 文件目录：文件目录由目录项构成，统一管理每个文件的元数据，以支持文件名到文件物理地址的转换。 目录文件：将文件目录以文件的形式存放在磁盘上。 目录项：可以看成是FCB。 文件的物理结构文件的物理结构指的是文件在存储介质上的存放方式。 连续结构文件的信息存放在若干连续的物理块中。 连续结构实现简单，且所需的磁盘寻道次数和寻道时间最少，支持顺序存取和随机存取，但文件不能动态增长，且会产生许多外部碎片。 链接结构一个文件的信息存放在若干不连续的物理块中，各块之间通过指针连接，前一个物理块指向下一 个物理块。 使用链接结构不存在外部碎片的问题，提高了磁盘空间利用率，有利于文件的动态扩充，但是比起连续结构需要更多的寻道次数和寻道时间，且存取速度慢，不适于随机存取。 索引结构一个文件的信息存放在若干不连续物理块中，系统为每个文件建立一个专用数据结构索引表，并将这些物理块的块号存放在该索引表中。 索引结构保持了链接结构的优点，也解决了其缺点：既能顺序存取又能随机存取，满足了文件动态增长的要求，能充分利用磁盘空间。但是索引结构依然有较多的寻道次数和寻道时间，而索引表本身也带来了额外系统开销。 多级索引结构（综合模式） UNIX文件系统采用的便是这种多级索引结构（综合模式）：每个文件的索引表有15个索引项，每项2个字节，前12项直接存放文件的物理块号，如果文件大于12块，则利用第13项指向一个物理块作为一级索引表。假设扇区大小为512字节，物理块等于扇区块大小，那么一级索引表可以存放256个物理块号。对于更大的文件还可利用第14和第15项作为二级和三级索引表。 文件目录检索用户给出文件名，按文件名查找到目录项/FCB，根据目录项/FCB中文件物理地址等信息，计算出文件中任意记录或字符在存储介质上的地址。 目录项分解法通过目录项分解法可以加快文件目录的检索速度。 目录项分解法即把FCB分解成两部分：符号目录项（文件名，文件号）、基本目录项（除文件名外的所有字段）。目录文件改进后减少了访盘次数，提高了文件检索速度。 磁盘调度算法当有多个访盘请求等待时，采用一定的策略，对这些请求的服务顺序调整安排，以降低平均磁盘服务时间，达到公平、高效。 先来先服务（FCFS）按访问请求到达的先后次序服务。 优点是简单公平，但效率不高，相临两次请求可能会造成最内到最外的柱面寻道，使磁头反复移动，增加了服务时间，对机械也不利。 最短寻道时间优先（Shortest Seek Time First）优先选择距当前磁头最近的访问请求进行服务。 虽然改善了磁盘平均服务时间，但是造成某些访问请求长期等待得不到服务，也就是饥饿现象。 扫描算法（SCAN）扫描算法又称为电梯算法，当设备无访问请求时，磁头不动；当有访问请求时，磁头按一个方向移动，在移动过程中对遇到的访问请求进行服务，然后判断该方向上是否还有访问请求，如果有则继续扫描；否则改变移动方向，并为经过的访问请求服务，如此反复。 单向扫描算法（CSCAN）扫描调度算法（SCAN）存在这样的问题：当磁头刚从里向外移动过某一磁道时，恰有一进程请求访问此磁道，这时该进程必须等待，待磁头从里向外，然后再从外向里扫描完所有要访问的磁道后，才处理该进程的请求，致使该进程的请求被严重地推迟。 为了减少这种延迟，CSCAN算法规定磁头只做单向移动。例如，磁头只自里向外移动，当磁头移到最外的被访问磁道时，磁头立即返回到最里的欲访磁道，即将最小磁道号紧接着最大磁道号构成循环，进行扫描。 旋转调度算法旋转调度算法根据延迟时间来决定执行次序的调度，请求访问分为以下三种情况： 若干等待访问者请求访问同一磁头上的不同扇区 若干等待访问者请求访问不同磁头上的不同编号的扇区 若干等待访问者请求访问不同磁头上具有相同的扇区 对于前两种情况总是让首先到达读写磁头位置下的扇区先进行传送操作，而对于第三种情况，这些扇区同时到达读写磁头位置下，可任意选择一个读写磁头进行传送操作。 参考资料 Tanenbaum A S, Bos H. Modern operating systems[M]. Prentice Hall Press, 2014. 北京大学操作系统原理（Operating Systems） 计算机操作系统]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统原理-存储模型]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86-%E5%AD%98%E5%82%A8%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[地址重定位为了保证CPU执行指令时可正确访问内存单元，需要将用户程序中的逻辑地址转换为运行时可由机器直接寻址的物理地址，这一过程称为地址重定位（又称地址转换、地址变换、地址翻译、地址映射）。 逻辑地址（相对地址，虚拟地址）：目标代码通常采用相对地址的形式，其首地址为0， 其余地址都相对于首地址而编址。不能用逻辑地址在内存中读取信息。 物理地址（绝对地址，实地址）：内存中存储单元的地址，可直接寻址。 地址重定位分为静态重定位和动态重定位： 静态重定位：当用户程序加载到内存时，一次性实现逻辑地址到物理地址的转换。 动态重定位：在进程执行过程中进行地址变换，即逐条指令执行时完成地址转换。 伙伴系统Linux底层内存管理采用伙伴系统这一种经典的内存分配方案。 主要思想：将内存按2的幂进行划分，组成若干空闲块链表；查找该链表找到能满足进程需求的最佳匹配块。 过程： 首先将整个可用空间看作一块： 2^u 假设进程申请的空间大小为 s，如果满足 2^u-1 &lt; s &lt;= 2^u，则分配整个块；否则，将块划分为两个大小相等的伙伴，大小为2^u-1 一直划分下去直到产生大于或等于 s 的最小块 基本内存管理方案一整个进程进入内存中一片连续区域。 单一连续区内存在此方式下分为系统区和用户区，系统区仅提供给操作系统使用，用户区是为用户提供的、除系统区之外的内存空间。一段时间内只有一个进程在内存，简单但内存利用率低。 固定分区把内存空间分割成若干区域，称为分区，每个分区的大小可以相同也可以不同，但分区大小固定不变，每个分区装一个且只能装一个进程。 这种方式会产生两个问题：一是程序太大而放不进任何一个分区中；二是容易产生内部碎片。 可变分区可变分区是一种动态划分内存的分区方法。这种分区方法不预先将内存划分，而是在进程装入内存时，根据进程的大小动态地建立分区，并使分区的大小正好适合进程的需要。因此系统中分区的大小和数目是可变的。 可变分区虽然不会产生内部碎片，但容易产生外部碎片，导致内存利用率下降。 在进程装入或换入主存时，如果内存中有多个足够大的空闲块，操作系统必须确定分配哪个内存块给进程使用，考虑以下几种分配算法： 首次适配（first fit）：在空闲区表中找到第一个满足进程要求的空闲区。该算法优先使用低址部分空闲区，在低址空间造成许多小的空闲区，在高地址空间保留大的空闲区。 下次适配（next fit）：从上次找到的空闲区处接着查找。 最佳适配（best fit）：查找整个空闲区表，找到能够满足进程要求的最小空闲区。该算法保留大的空闲区，但造成许多小的空闲区。 最差适配（worst fit ）：总是分配满足进程要求的最大空闲区。该算法保留小的空闲区，尽量减少小的碎片产生。 基本内存管理方案二一个进程进入内存中若干片不连续的区域。 页式存储管理方案用户进程地址空间被划分为大小相等的部分，称为页（page）或页面，从0开始编号。内存空间按同样大小划分为大小相等的区域，称为页框（page frame）或物理页面或内存块，从0开始编号。 内存分配规则：以页为单位进行分配，并按进程需要的页数来分配；逻辑上相邻的页，物理上不一定相邻。 每个进程一个页表，存放在内存。 地址转换CPU取到逻辑地址，自动划分为页号和页内地址；用页号查页表，得到页框号，再与页内偏移拼接成为物理地址。 段式存储管理方案将用户进程地址空间按程序自身的逻辑关系划分为若干个程序段，每个程序段都有一个段号。内存空间被动态划分为若干长度不相同的区域， 称为物理段，每个物理段由起始地址和长度确定。 内存分配规则：以段为单位进行分配，每段在内存中占据连续空间，但各段之间可以不相邻。 地址转换CPU取到逻辑地址，自动划分为段号和段内地址；用段号查段表，得到该段在内存的起始地址，与段内偏移地址计算出物理地址。 覆盖技术把一个程序划分为一系列功能相对独立的程序段，让执行时不要求同时装入内存的程序段组成一组（称为覆盖段），共享同一块内存区域 ，这种内存扩充技术就是覆盖技术。 程序段先保存在磁盘上，当有关程序段的前一部分执行结束，把后续程序段调入内存，覆盖前面的程序段。 一般要求作业各模块之间有明确的调用结构，程序员要向系统指明覆盖结构，然后由操作系统完成自动覆盖。 交换技术内存空间紧张时，系统将内存中某些进程暂时移到外存，把外存中某些进程换进内存，占据前者所占用的区域（进程在内存与磁盘之间的动态调度）。 虚拟存储技术所谓虚拟存储技术是指：当进程运行时，先将其一部分装入内存，另一部分暂留在磁盘，当要执行的指令或访问的数据不在内存时，由操作系统自动完成将它们从磁盘调入内存的工作。 虚拟地址空间：分配给进程的虚拟内存 虚拟地址：在虚拟内存中指令或数据的位置， 该位置可以被访问，仿佛它是内存的一部分 虚拟内存：把内存与磁盘有机地结合起来使用，从而得到一个容量很大的“内存” 虚拟页式存储管理系统虚拟页式即将虚拟存储技术和页式存储管理方案结合起来，以CPU时间和磁盘空间换取昂贵内存空间。 基本思想：进程开始运行之前，不是装入全部页面， 而是装入一个或零个页面，之后，根据进程运行的需要，动态装入其他页面。当内存空间已满，而又需要装入新的页面时，则根据某种算法置换内存中的某个页面，以便装入新的页面。 内存管理单元（MMU）内存管理单元（MMU）管理着地址空间和物理内存的转换，其中的页表（Page table）存储着页（程序地址空间）和页框（物理内存空间）的映射表。 上图为一级页表结构的地址转换，下图为二级页表结构的地址转换及MMU的位置。 二级页表结构及地址映射页目录表共有2^10 = 1K个表项，每个表项是4B，因此页目录大小为4K，存储在一个4K字节的页面中。同理，一个页表也存储在一个4K字节的页面中。 为什么要使用多级页表系统分配给每个进程的虚拟地址都是4G，那么采用一级页表需要4G／4K = 2^20个表项，如果每个页表项是4B，那么需要4MB的内存空间。但是大多数程序根本用不到4G的虚拟内存空间，比如hello world程序，这样一个几kb的程序却需要4MB的内存空间是很浪费的。如果采用二级页表，那么一级页表只需要4KB的空间用来索引二级页表的地址，像hello world这样的程序可能只需要一个物理页，那么只需要一条记录就可以了，故对于二级页表也只要4KB就足够了，所以这样只需要8KB就能解决问题。 TLB（快表）页表一般都很大，并且存放在内存中，所以处理器引入MMU后，读取指令、数据需要访问两次内存：首先通过查询页表得到物理地址，然后访问该物理地址读取指令、数据。由于CPU的指令处理速度与内存指令的访问速度差异大，CPU的速度得不到充分利用，为了减少因为MMU导致的处理器性能下降，引入了TLB。 TLB(Translation Lookaside Buffer)转换检测缓冲区相当于页表的缓存，利用程序访问的局部性原理改进虚拟地址到物理地址的转换速度。TLB保存正在运行进程的页表的子集(部分页表项)，只有在TLB无法完成地址转换任务时，才会到内存中查询页表，这样就减少了页表查询导致的处理器性能下降。 缺页异常缺页异常是一种Page Fault（页错误）。在地址映射过程中，硬件检查页表时发现所要访问的页面不在内存，则产生缺页异常，操作系统执行缺页异常处理程序：获得磁盘地址，启动磁盘，将该页调入内存。此时分为两种情况： 如果内存中有空闲页框，则分配一个页框， 将新调入页装入，并修改页表中相应页表项的有效位及相应的页框号。 若内存中没有空闲页框，则要置换内存中某一页框；若该页框内容被修改过，则要将其写回磁盘。 页面置换算法最佳页面置换算法（OPT，Optimal）置换以后不再需要的或最远的将来才会用到的页面。 这是一种理论上的算法，因为无法知道一个页面多长时间不再被访问，它作为一种标准来衡量其他算法的性能。 先进先出算法（FIFO）选择在内存中驻留时间最长的页并置换它。 该算法会将那些经常被访问的页面也被换出，从而使缺页率升高。 第二次机会算法（SCR，Second Chance）当页面被访问 (读或写) 时设置该页面的R位为1。需要替换的时候，检查最老页面的R位。如果R位是0，那么这个页面既老又没有被使用，可以立刻置换掉；如果是1，就将R位清0，并把该页面放到链表的尾端，修改它的装入时间使它就像刚装入的一样，然后继续从链表的头部开始搜索。 这个算法是对FIFO算法的改进，不会像FIFO一样把经常使用的页面置换出去。 时钟算法（CLOCK）第二次机会算法需要在链表中移动页面，降低了效率。时钟算法使用环形链表将页面连接起来，再使用一个指针指向最老的页面。 最近未使用算法（NRU，Not Recently Used）选择在最近一段时间内未使用过的一页并置换。 每个页面都有两个状态位：R与M，当页面被访问时设置页面的R=1，当页面被修改时设置M=1。其中R位会定时被清零。可以将页面分成以下四类： R=0，M=0 R=0，M=1 R=1，M=0 R=1，M=1 当发生缺页中断时，NRU算法随机地从类编号最小的非空类中挑选一个页面将它换出。 NRU算法优先换出已经被修改的脏页面（R=0，M=1），而不是被频繁使用的干净页面（R=1，M=0）。 最近最久未使用算法（LRU，Least Recently Used ）虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。LRU算法选择最后一次访问时间距离当前时间最长的一页并置换，即置换未使用时间最长的一页。 为了实现LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最长时间未访问的。 LRU的性能接近OPT，但因为每次访问都需要更新链表，因此这种方式实现的LRU代价很高。 最不经常使用算法（NFU，Not Frequently Used）NFU算法选择访问次数最少的页面置换。 因为LRU算法的实现比较麻烦而且开销很大，所以提出了用软件来模拟LRU算法的NFU算法，该算法为每一页设置一个软件计数器，初值为0，每次时钟中断的时候就将计数器加R，发生缺页中断时选择计数器值最小的一页置换。 老化算法（AGING）在NFU算法中存在一个问题：在第一次时钟中断的时候其中一页可能被访问了很多次，之后再未被访问过，然而在以后的时钟中断这一页计数器的值仍然高于其它页，因此其虽然长时间未被访问也不会被置换出去。 为了更好地模拟LRU算法，老化算法对NFU进行了改进，计数器在加R前先右移一位，R位加到计数器的最左端。 工作集算法基本思想：根据程序的局部性原理，一般情况下，进程在一段时间内总是集中访问一些页面，这些页面称为活跃页面，如果分配给一个进程的物理页面数太少了，使该进程所需的活跃页面不能全部装入内存，则进程在运行过程中将频繁发生中断 。如果能为进程提供与活跃页面数相等的物理页 面数，则可减少缺页中断次数。 工作集W(t, Δ) = 该进程在过去的Δ个虚拟时间单位中访问到的页面的集合 工作集算法就是找出一个不在工作集中的页面并置换它。具体过程为：扫描所有页表项，如果一个页面的R位是1，则将该页面的最后一次访问时间设为当前时间，将R位清零；如果一个页面的R位是0，则检查该页面的访问 时间是否在“当前时间-T”之前，如果是，则该页面为被置换的页面；如果不是，记录当前所有被扫描过页面的最后访问时间里面的最小值，扫描下一个页面并重复上述过程。 参考资料 Tanenbaum A S, Bos H. Modern operating systems[M]. Prentice Hall Press, 2014. 北京大学操作系统原理（Operating Systems） 计算机操作系统 内存连续分配方式的几种算法及优劣 多级页表]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统原理-同步机制]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86-%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[进程互斥由于各进程要求使用共享资源（变量、文件等），而这些资源需要排他性使用，各进程之间竞争使用这些资源，这一关系称为进程互斥。 临界资源与临界区系统中某些资源一次只允许一个进程使用，称这样的资源为临界资源或互斥资源或共享变量。 而各个进程中对某个临界资源（共享变量）实施操作的程序片段称为临界区或互斥区。 临界区的使用原则 没有进程在临界区时，想进入临界区的进程可进入 不允许两个进程同时处于其临界区中 临界区外运行的进程不得阻塞其他进程进入临界区 不得使进程无限期等待进入临界区 进程互斥的软件解决方案错误解法考虑两个进程p和q，pturn与qturn表示哪个进程要进入临界区，P进入临界区的条件为pturn &amp;&amp; not qturn，而Q进入临界区的条件为not pturn &amp;&amp; qturn: 12345//进程p：pturn = true; while (qturn) ; visit(); //访问临界区pturn = false; 12345//进程q：qturn = true; while (pturn) ; visit(); //访问临界区qturn = false; 如果由于CPU调度使得两个进程都执行完了第一行语句，也就是pturn和qturn都为true了，那么就都会在下一行while语句上死循环，互相都在谦让对方执行，也就不满足了临界区的使用原则—不得使进程无限期等待进入临界区。 Dekker算法Dekker互斥算法是由荷兰数学家Dekker提出的一种解决并发进程互斥与同步的软件实现方法。假设有p和q两个进程，变量pturn、qturn表示p和q进程是否想要资源（可以想象为举手示意想要），变量turn表示安排资源给谁： 123456789101112//进程P：pturn = true; //进程p举手示意想要访问while (qturn) &#123; //如果进程q也举手了 if (turn == 2) &#123; //资源被安排给了q pturn = false; //进程p把手放下 while (turn == 2); //资源安排给q的时候一直等待 pturn = true; //此时资源安排给了自己，进程p再举手 &#125;&#125;visit(); //访问临界区turn = 2; //进程p使用完了，安排资源给qpturn = false; //进程p把手放下 123456789101112//进程q：qturn = true; while (pturn) &#123; if (turn == 1) &#123; qturn = false; while (turn == 1); qturn = true; &#125;&#125;visit(); //访问临界区turn = 1;qturn = false; 如果两个进程都执行完了第一行语句，也就是pturn和qturn都为true了，那么会根据变量turn进一步查看究竟是把资源安排给了谁，如果安排给了另一个进程，那么自己就先把手放下，等待安排资源给自己。 与之前的错误解法相比，可以发现Dekker算法就是在原本的while死循环上做了进一步的判断，引入的turn变量总是会安排一个进程访问临界区。 Peterson算法Peterson算法是另一种解决并发进程互斥与同步的软件实现方法，而且克服了强制轮流法的缺点。其使用十分方便，只需要向如下这样调用即可: 123enter_region(i);visit(); //访问临界区leave_region(i); 其中的enter_region方法实现如下： 1234567891011121314#define FALSE 0#define TRUE 1#define N 2 //进程的个数int turn; //轮到谁int interested[N]; //兴趣数组，初始值均为FALSE void enter_region(int process) // process = 0 或 1&#123; int other; // 另外一个进程的进程号 other = 1 - process; interested[process] = TRUE; // 表明本进程感兴趣 turn = process; // 设置标志位 while(turn == process &amp;&amp; interested[other] == TRUE); &#125; 如果有两个进程都要执行的话，turn会被设置成后一个进程的进程号，这时候因为要按照先来后到的规矩，后一个进程在判断while条件的时候turn == process成立，也就进行循环等待，而先进入的进程可以访问临界区。当先进入的进程离开了临界区，就调用leave_region方法，将自己的兴趣设为FALSE，后一个进程判断interested[other] == TRUE不成立时就可以跳出while循环进入临界区了。 123void leave_region(int process)&#123; interested[process] = FALSE; // 本进程已离开临界区&#125; 进程互斥的硬件解决方案“测试并加锁”指令 “交换”指令 进程同步进程同步指系统中多个进程中发生的事件存在某种时序关系，需要相互合作，共同完成一项任务。具体地说，一个进程运行到某一点时， 要求另一伙伴进程为它提供消息，在未获得消息之前，该进程进入阻塞态，获得消息后被唤醒进入就绪态。 信号量及PV操作信号量是一个特殊变量，用于进程间传递信息的一个整数值，定义如下： 12345struct semaphore&#123; int count; queueType queue;&#125; 可以对其执行down和up操作，也就是常见的P和V操作（PV操作均为原语操作），定义如下： 12345678910111213141516171819P(semaphore s) &#123; s.count--; if (s.count &lt; 0) &#123; //该进程状态置为阻塞状态； //将该进程插入相应的等待队列s.queue末尾; //重新调度； &#125;&#125;V(semaphore s) &#123; s.count++; if (s.count &lt;= 0) &#123; //唤醒相应等待队列s.queue中等待的一个进程； //改变其状态为就绪态，并将其插入就绪队列； &#125; &#125; 用PV操作解决进程间互斥问题 分析并发进程的关键活动，划定临界区 设置信号量 mutex，初值为1 在临界区前实施 P(mutex) 在临界区之后实施 V(mutex) 用信号量解决生产者-消费者问题问题描述：使用一个缓冲区来保存物品，只有缓冲区没有满，生产者才可以放入物品；只有缓冲区不为空，消费者才可以拿走物品。 这里使用三个信号量，其中mutex用于解决互斥问题，empty和full用于解决同步问题。 123456789101112131415161718192021222324252627#define N 100 //缓冲区个数typedef int semaphore; //信号量是一种特殊的整型数据semaphore mutex = 1; //互斥信号量：控制对临界区的访问semaphore empty = N; //空缓冲区个数，初始为Nsemaphore full = 0; //满缓冲区个数，初始为0void producer() &#123; while(TRUE) &#123; int item = produce_item(); p(&amp;empty); p(&amp;mutex); insert_item(item); v(&amp;mutex); v(&amp;full); &#125;&#125;void consumer() &#123; while(TRUE) &#123; p(&amp;full); p(&amp;mutex); int item = remove_item(); v(&amp;mutex); v(&amp;empty); consume_item(item); &#125;&#125; 注意：不能交换p(&amp;empty);和p(&amp;mutex);的顺序，否则会导致死锁。 用信号量解决读者-写者问题问题描述：多个进程共享一个数据区，这些进程分为只读数据区中的数据的读者进程和只往数据区中写数据的写者进程。允许多个读者同时执行读操作，不允许多个写者同时操作，不允许读者、写者同时操作。 1234567891011121314151617181920212223242526typedef int semaphore;semaphore count_mutex = 1; //对count加锁semaphore data_mutex = 1; //对读写的数据加锁int count = 0; //对数据进行读操作的进程数量void reader() &#123; while(TRUE) &#123; p(&amp;count_mutex); count = count + 1; if(count == 1) p(&amp;data_mutex); // 第一个读者需要对数据进行加锁，防止写进程访问 v(&amp;count_mutex); read(); p(&amp;count_mutex); count = count - 1; if(count == 0) v(&amp;data_mutex); v(&amp;count_mutex); &#125;&#125;void writer() &#123; while(TRUE) &#123; p(&amp;data_mutex); write(); v(&amp;data_mutex); &#125;&#125; 管程由于信号量机制程序编写困难、易出错，所以在程序设计语言中引入管程。 管程是一个抽象数据类型，由关于共享资源的数据结构及在其上操作的一组过程组成，进程只能通过调用管程中的过程来间接地访问管程中的数据结构。 互斥/同步互斥：管程是互斥进入的，管程的互斥性是由编译器负责保证的。 同步：管程中设置条件变量及等待/唤醒操作以解决同步问题，可以让一个进程或线程在条件变量上等待（此时，应先释放管程的使用权），也可以通过发送信号将等待在条件变量上的进程或线程唤醒。 Hoare管程因为管程是互斥进入的，所以当一个进程试图进入一个已被占用的管程时，应当在管程的入口处等待，为此，管程的入口处设置一个进程等待队列，称作入口等待队列。 如果进程P唤醒进程Q，则P等待Q执行；如果进程Q执行中又唤醒进程R，则Q等待R执行；如此， 在管程内部可能会出现多个等待进程。在管程内需要设置一个进程等待队列，称为紧急等待队列，紧急等待队列的优先级高于入口等待队列的优先级。 条件变量条件变量是在管程内部说明和使用的一种特殊类型的变量，对于条件变量，可以执行wait和signal操作： wait(c)：如果紧急等待队列非空，则唤醒第一个等待者；否则释放管程的互斥权，执行此操作的进程进入c链末尾。 signal(c)：如果c链为空，则相当于空操作，执行此操作的进程继续执行；否则唤醒第一个等待者，执行此操作的进程进入紧急等待队列的末尾。 用管程解决生产者-消费者问题12345678910111213141516171819202122232425262728293031323334353637383940//管程monitor ProducerConsumer condition full, empty; //条件变量 integer count; procedure insert (item: integer); begin if count == N then wait(full); insert_item(item); count++; if count ==1 then signal(empty); end; function remove: integer; begin if count==0 then wait(empty); remove = remove_item; count--; if count==N-1 then signal(full); end; count:=0; end monitor; //生产者procedure producer; begin while true do begin item = produce_item; ProducerConsumer.insert(item); end end; //消费者procedure consumer; begin while true do begin item=ProducerConsumer.remove; consume_item(item); end end; MESA管程Hoare管程有个缺点就是会有两次额外的进程切换，因此MESA管程将原本的signal操作变为notify操作：当一个正在管程中的进程执行notify(x)时，它使得x条件队列得到通知，发信号的进程继续执行，而位于条件队列头的进程在将来合适的时候且当处理器可用时恢复执行。 由于收到通知时并未执行，且对等待进程在notify之后何时运行没有任何限制，所以当进程真正被调度时，条件不一定成立，因而这个进程必须重新检查条件，也就是用while循环取代if语句。 IPC（进程间通信）进程间通信（IPC，InterProcess Communication）是指在不同进程之间传播或交换信息。 进程通信是一种手段，而进程同步是一种目的。也可以说，为了能够达到进程同步的目的，需要让进程进行通信，传输一些进程同步所需要的信息。 进程通信的方式通常有管道（包括无名管道和命名管道）、消息队列、信号量、共享存储、Socket、Streams等。其中 Socket和Streams支持不同主机上的两个进程IPC。 管道管道，通常指无名管道，是 UNIX 系统IPC最古老的形式。 管道是通过调用 pipe 函数创建的，当一个管道建立时，它会创建两个文件描述符：fd[0]为读而打开，fd[1]为写而打开，要关闭管道只需将这两个文件描述符关闭即可。 单个进程中的管道几乎没有任何用处。所以，通常调用 pipe 的进程接着调用 fork，这样就创建了父进程与子进程之间的 IPC 通道。若要数据流从父进程流向子进程，则关闭父进程的读端（fd[0]）与子进程的写端（fd[1]）；反之，则可以使数据流从子进程流向父进程。 特点: 它是半双工的（即数据只能在一个方向上流动），具有固定的读端和写端。 它只能用于具有亲缘关系的进程之间的通信（也是父子进程或者兄弟进程之间）。 FIFOFIFO也称为命名管道，它是一种文件类型，可以在无关的进程之间交换数据，与无名管道不同。 FIFO 常用于客户-服务器应用程序中，FIFO 用作汇聚点，在客户进程和服务器进程之间传递数据。 消息队列消息队列，是消息的链接表，存放在内核中。一个消息队列由一个标识符（即队列ID）来标识。 消息队列是面向记录的，其中的消息具有特定的格式以及特定的优先级。 消息队列独立于发送与接收进程。进程终止时，消息队列及其内容并不会被删除。 消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取。 信号量信号量是一个计数器。信号量用于实现进程间的互斥与同步，而不是用于存储进程间通信数据。 共享内存共享内存指两个或多个进程共享一个给定的存储区，因为数据不需要在进程之间复制，所以这是最快的一种 IPC。由于多个进程可以同时操作，所以信号量与共享内存通常结合在一起使用，信号量用来同步对共享内存的访问。 套接字与其它通信机制不同的是，它可用于不同机器间的进程通信。 参考资料 Tanenbaum A S, Bos H. Modern operating systems[M]. Prentice Hall Press, 2014. 北京大学操作系统原理（Operating Systems） 计算机操作系统 进程间的五种通信方式介绍]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>同步</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统原理-进程线程模型]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86-%E8%BF%9B%E7%A8%8B%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[进程的定义进程是具有独立功能的程序关于某个数据集合上的一次运行活动，是系统进行资源分配和调度的独立单位。 进程控制块PCBPCB：Process Control Block，又称进程描述符、进程属性，是操作系统用于管理控制进程的一个专门数据结构，是系统感知进程存在的唯一标志。 PCB的内容包括： 进程描述信息 进程控制信息 所拥有的资源和使用情况 CPU现场信息 进程状态及状态转换进程的三种基本状态 运行态（Running）：占有CPU，并在CPU上运行 就绪态（Ready）：已经具备运行条件，但由于没有空闲CPU，而暂时不能运行 等待态（Waiting/Blocked）：因等待某一事件而暂时不能运行（如等待读盘结果，又称为阻塞态、睡眠态） 三状态模型及状态转换 其中，只有就绪态和运行态可以相互转换，其它的都是单向转换。 进程的其它状态 创建：已完成创建一进程所必要的工作，但因为资源有限尚未同意执行该进程 终止：终止执行后，进程进入该状态，回收资源 挂起：用于调节负载，进程不占用内存空间，其进程映像交换到磁盘上 进程的五状态模型 进程队列操作系统为每一类进程建立一个或多个队列，队列元素为PCB，伴随进程状态的改变，其PCB从一个队列进入另一个队列。以下为五状态进程模型的队列模型： 进程控制进程控制操作完成进程各状态之间的转换，由具有特定功能的原语完成： 进程创建原语 进程撤消原语 阻塞原语 唤醒原语 挂起原语… 原语：完成某种特定功能的一段程序，具有不可分割性或不可中断性，即原语的执行必须是连续的，在执行过程中不允许被中断 进程的创建 给新进程分配一个唯一标识以及进程控制块 为进程分配地址空间 初始化进程控制块 设置相应的队列指针（如: 把新进程加到就绪队列链表中） 进程的撤销 收回进程所占有的资源（如：关闭打开的文件、断开网络连接、回收分配的内存） 撤消该进程的PCB 进程阻塞处于运行状态的进程，在其运行过程中期待某一事件发生，如等待键盘输入、等待磁盘数据传输完成、等待其它进程发送消息，当被等待的事件未发生时，由进程自己执行阻塞原语，使自己由运行态变为阻塞态。 上下文切换将CPU硬件状态从一个进程换到另一个进程的过程称为上下文切换。 进程运行时，其硬件状态保存在CPU上的寄存器中；进程不运行时，这些寄存器的值保存在进程控制块PCB中；当操作系统要运行一个新的进程时，将PCB中的相关值送到对应的寄存器中。 线程的定义进程中的一个运行实体，是CPU的调度单位，有时将线程称为轻量级进程。 线程共享所在进程的地址空间和其他资源。 线程机制的实现用户级线程在用户空间建立线程库：提供一组管理线程的过程。运行时系统完成线程的管理工作，内核管理的还是进程，不知道线程的存在，线程切换不需要内核态特权。 优点： 线程切换快 调度算法是应用程序特定的 用户级线程可运行在任何操作系统上（只需要实现线程库） 缺点： 大多数系统调用是阻塞的，因此，由于内核阻塞进程，故进程中所有线程也被阻塞 核心级线程内核管理所有线程管理，并向应用程序提供API接口。内核维护进程和线程的上下文，且线程的切换需要内核支持。 混合模型线程创建在用户空间完成，线程调度等在核心态完成。 线程与进程的区别 拥有资源：进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。 调度：线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。 系统开销：由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。 通信方面：线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC。 参考资料 Tanenbaum A S, Bos H. Modern operating systems[M]. Prentice Hall Press, 2014. 北京大学操作系统原理（Operating Systems） 计算机操作系统]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统 </tag>
        <tag>进程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统原理-处理器调度]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86%E2%80%94%2F</url>
    <content type="text"><![CDATA[CPU调度即按一定的调度算法从就绪队列中选择一个进程， 把CPU的使用权交给被选中的进程，其任务是控制、协调进程对CPU的竞争。 调度算法衡量指标吞吐量：每单位时间完成的进程数目 周转时间：每个进程从提出请求到运行完成的时间 响应时间：从提出请求到第一次回应的时间 进程调度算法批处理系统目标：吞吐量，周转时间，cpu利用率，包含以下四种调度算法： 先来先服务（FCFS） 短作业优先（SJF） 最短剩余时间优先（SRTN） 最高响应比优先（HRRN） 先来先服务（FCFS） First Come First Serve 按照进程就绪的先后顺序使用CPU 非抢占 长进程后面的短进程需要等很长时间，不利于用户体验。 短作业优先（SJF） Shortest Job First 具有最短完成时间的进程优先执行 非抢占式 最短剩余时间优先（SRTN） Shortest Remaining Time Next SJF的抢占式版本，即当一个新就绪的进程比当前运行进程具有更短的完成时间时，系统抢占当前进程， 选择新就绪的进程执行 短作业优先的调度算法可以得到最短的平均周转时间，但随着源源不断的短任务到来，可能使长的任务长时间得不到运行，即产生 “饥饿”现象。 最高响应比优先（HRRN） Highest Response Ratio Next 调度时，首先计算每个进程的响应比R；之后，总是选择R最高的进程执行 响应比R = 周转时间 / 处理时间 =（处理时间 + 等待时间）/ 处理时间 = 1 +（等待时间 / 处理时间） 交互式系统目标：响应时间，包含以下三种调度算法： 时间片轮转（RR） 最高优先级（HPF） 多级反馈队列（Multiple feedback queue） 时间片轮转 Round Robin 将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。 时间片轮转算法中选择合适的时间片很重要： 如果太长，会降级为先来先服务算法，延长短进程的响应时间 如果太短，进程切换会浪费CPU时间 最高优先级 Highest Priority First 选择优先级最高的进程投入运行 优先级可以是静态不变的，也可以是动态调整的 不公平 会导致优先级翻转问题，解决方案：1、优先级天花板；2、优先级继承 优先级翻转是当一个高优先级任务通过信号量机制访问共享资源时，该信号量已被一低优先级任务占有，因此造成高优先级任务被许多具有较低优先级任务阻塞，实时性难以得到保证。 例如：有优先级为A、B和C三个任务，优先级A&gt;B&gt;C，任务A，B处于挂起状态，等待某一事件发生，任务C正在运行，此时任务C开始使用某一共享资源S。在使用中，任务A等待事件到来，任务A转为就绪态，因为它比任务C优先级高，所以立即执行。当任务A要使用共享资源S时，由于其正在被任务C使用，因此任务A被挂起，任务C开始运行。如果此时任务B等待事件到来，则任务B转为就绪态。由于任务B优先级比任务C高，因此任务B开始运行，直到其运行完毕，任务C才开始运行。直到任务C释放共享资源S后，任务A才得以执行。在这种情况下，优先级发生了翻转，任务B先于任务A运行。 解决优先级翻转问题有优先级天花板(priority ceiling)和优先级继承(priority inheritance)两种办法。 优先级天花板是当任务申请某资源时， 把该任务的优先级提升到可访问这个资源的所有任务中的最高优先级， 这个优先级称为该资源的优先级天花板。这种方法简单易行， 不必进行复杂的判断， 不管任务是否阻塞了高优先级任务的运行， 只要任务访问共享资源都会提升任务的优先级。 优先级继承是当任务A 申请共享资源S 时， 如果S正在被任务C 使用，通过比较任务C 与自身的优先级，如发现任务C 的优先级小于自身的优先级， 则将任务C的优先级提升到自身的优先级， 任务C 释放资源S 后，再恢复任务C 的原优先级。这种方法只在占有资源的低优先级任务阻塞了高优先级任务时才动态的改变任务的优先级，如果过程较复杂， 则需要进行判断。 多级反馈队列设置多个就绪队列，第一级队列优先级最高，给不同就绪队列中的进程分配长度不同的时间片，第一级队列时间片最小；随着队列优先级别的降低，时间片增大。当第一级队列为空时，在第二级队列调度，以此类推。当一个新创建进程就绪后，进入第一级队列，进程用完时间片而放弃CPU，进入下一级就绪队列。由于阻塞而放弃CPU的进程进入相应的等待队列，一旦等待的事件发生，该进程回到原来一级就绪队列。 调度算法总结 调度算法 占用CPU方式 吞吐量 响应时间 开销 对进程的影响 饥饿问题 FCFS 非抢占式 不强调 可能很慢，特别是当进程的执行时间差别很大时 最小 对短进程不利；对I/O型的进程不利 无 RR 抢占式(时间片用完时) 若时间片小，吞吐量会很低 为短进程提供好的响应时间 较大 公平对待 无 SJF 非抢占式 高 为短进程提供好的响应时间 可能较大 对长进程不利 可能 SRTN 抢占式(到达时) 高 提供好的响应时间 可能较大 对长进程不利 可能 HRRN 非抢占式 高 提供好的响应时间 可能较大 很好的平衡性 无 Feedback 抢占式(时间片用完时) 不强调 不强调 可能较大 对I/O型进程有利 可能 参考资料 Tanenbaum A S, Bos H. Modern operating systems[M]. Prentice Hall Press, 2014. 北京大学操作系统原理（Operating Systems） 计算机操作系统 优先级翻转]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LinkedList源码分析]]></title>
    <url>%2F2018%2F09%2F11%2FLinkedList%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[LinkedList简介（jdk1.8)LinkedList是基于双向链表实现的。如下为LinkedList的继承体系结构： 123public class LinkedList&lt;E&gt; extends AbstractSequentialList&lt;E&gt; implements List&lt;E&gt;, Deque&lt;E&gt;, Cloneable, java.io.Serializable 可以看到，LinkedList实现了Deque接口，Deque表示双端队列，即在两端都可以进行插入和删除的队列。Deque是一个比Stack和Queue功能更强大的接口，它同时实现了栈和队列的功能。Deque接口的部分方法如下：1234567891011// *** Queue methods *** boolean add(E e); boolean offer(E e); E remove(); E poll(); E element(); E peek(); // *** Stack methods *** void push(E e); E pop(); 从代码可以看出，Deque既可以用作后进先出的栈，也可以用作先进先出的队列。 与ArrayList一样，LinkedList也不是线程安全的，因此只能在单线程环境下使用。 属性LinkedList有size、first、last三个属性： 12345678//LinkedList中元素的数量transient int size = 0;//指向第一个元素transient Node&lt;E&gt; first;//指向最后一个元素transient Node&lt;E&gt; last; Node既然LinkedList是基于链表实现的，那就必须要介绍一下它的内部类Node：1234567891011private static class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; next; Node&lt;E&gt; prev; Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element; this.next = next; this.prev = prev; &#125;&#125; 因为是双向链表，所以每个节点都包含前一个节点的指向与后一个节点的指向。 构造函数 无参构造函数 12public LinkedList() &#123;&#125; 有参构造函数 1234public LinkedList(Collection&lt;? extends E&gt; c) &#123; this(); addAll(c);&#125; 此方法先调用一个无参构造函数构造一个空列表，然后再将集合内的所有元素添加进去。 addAll将集合内的所有元素加入到LinkedLiist中。 123public boolean addAll(Collection&lt;? extends E&gt; c) &#123; return addAll(size, c);&#125; 123456789101112131415161718192021222324252627282930313233343536373839 public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123;//判断是否满足index &gt;= 0 &amp;&amp; index &lt;= size，若不满足，则抛出异常 checkPositionIndex(index); Object[] a = c.toArray(); int numNew = a.length; if (numNew == 0) return false; Node&lt;E&gt; pred, succ; if (index == size) &#123; succ = null; pred = last; &#125; else &#123; succ = node(index); pred = succ.prev; &#125; for (Object o : a) &#123; @SuppressWarnings("unchecked") E e = (E) o; Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, null); if (pred == null) first = newNode; else pred.next = newNode; pred = newNode; &#125; if (succ == null) &#123; last = pred; &#125; else &#123; pred.next = succ; succ.prev = pred; &#125; size += numNew; modCount++; return true; &#125; 此段代码中，succ表示后节点，pred表示前节点。 在进行了下标检查与长度检查后，首先判断要加入的元素是加入在末尾还是中间，如果在末尾，则succ应指向null，而pred应指向last，否则，succ应指向下标为index的节点，而pred指向该节点的前一个节点。这样，要插入的节点的前后节点就都有了，接下来就可以将要插入的节点的前后节点都连接好，从而完成插入操作。 这里有必要介绍一下取出指定位置的节点的方法：123456789101112131415Node&lt;E&gt; node(int index) &#123; // assert isElementIndex(index); if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125;&#125; 与数组不同，链表无法直接通过下标找到指定的元素，而需要依次遍历。由于LinkedList是通过双向链表实现的，所以既可以从头也可以从尾开始遍历。为了提高效率，该方法先判断指定的位置index在链表的前半段还是后半段，从而决定从头还是从尾开始遍历。 linkFirst，linkLast，linkBefore在介绍add方法与其它相关方法前，有必要先介绍一下这三个辅助方法：123456789101112131415161718192021222324252627282930313233343536private void linkFirst(E e) &#123; final Node&lt;E&gt; f = first; final Node&lt;E&gt; newNode = new Node&lt;&gt;(null, e, f); first = newNode; if (f == null) last = newNode; else f.prev = newNode; size++; modCount++;&#125;void linkLast(E e) &#123; final Node&lt;E&gt; l = last; final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); last = newNode; if (l == null) first = newNode; else l.next = newNode; size++; modCount++;&#125;void linkBefore(E e, Node&lt;E&gt; succ) &#123; // assert succ != null; final Node&lt;E&gt; pred = succ.prev; final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ); succ.prev = newNode; if (pred == null) first = newNode; else pred.next = newNode; size++; modCount++;&#125; linkFirst、linkLast、linkBefore方法分别将元素加入到链表头部、链表尾部与链表中指定节点之前。 以linkFirst为例，先创建一个新的节点，并将first指向该节点。然后判断以前的first节点是否为null，如果为null，则说明之前链表中没有元素，应将last指向新节点，否则，将原first节点的prev指向新节点。 add，addFirst，addLast介绍完上面三个辅助方法后，我们再来看看add相关的方法。 123456789101112131415161718192021public boolean add(E e) &#123; linkLast(e); return true;&#125;public void add(int index, E element) &#123; checkPositionIndex(index); if (index == size) linkLast(element); else linkBefore(element, node(index));&#125;public void addFirst(E e) &#123; linkFirst(e);&#125;public void addLast(E e) &#123; linkLast(e);&#125; 由源码可以看到，add相关的代码都是直接调用上面介绍的辅助方法，十分简单。 unlink，unlinkFirst，unlinkLast同样，在介绍remove及相关方法时，先介绍这三个辅助方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657E unlink(Node&lt;E&gt; x) &#123; // assert x != null; final E element = x.item; final Node&lt;E&gt; next = x.next; final Node&lt;E&gt; prev = x.prev; if (prev == null) &#123; first = next; &#125; else &#123; prev.next = next; x.prev = null; &#125; if (next == null) &#123; last = prev; &#125; else &#123; next.prev = prev; x.next = null; &#125; x.item = null; size--; modCount++; return element;&#125;private E unlinkFirst(Node&lt;E&gt; f) &#123; // assert f == first &amp;&amp; f != null; final E element = f.item; final Node&lt;E&gt; next = f.next; f.item = null; f.next = null; // help GC first = next; if (next == null) last = null; else next.prev = null; size--; modCount++; return element;&#125;private E unlinkLast(Node&lt;E&gt; l) &#123; // assert l == last &amp;&amp; l != null; final E element = l.item; final Node&lt;E&gt; prev = l.prev; l.item = null; l.prev = null; // help GC last = prev; if (prev == null) first = null; else prev.next = null; size--; modCount++; return element;&#125; 这三个方法也很好理解。以unlink方法为例，将要删除的元素的前后节点相连接，并且把要删除的节点的属性设为null以帮助垃圾回收机制回收，从而达到移除该节点的目的。最后，将要删除的节点的值返回。 remove，removeFirst，removeLast接下来介绍移除链表中元素的几个方法。 123456789101112131415161718192021222324252627public E remove() &#123; return removeFirst();&#125;public E remove(int index) &#123; checkElementIndex(index); return unlink(node(index));&#125;public boolean remove(Object o) &#123; if (o == null) &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (x.item == null) &#123; unlink(x); return true; &#125; &#125; &#125; else &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) &#123; unlink(x); return true; &#125; &#125; &#125; return false;&#125; 前两个方法比较简单，而对于remove(Object o)方法，要先判断对象是否为null，如果为null，则遍历链表找到值为null的节点，并调用unlink方法移除该节点，否则，同样遍历链表并用equals方法根据内容进行等值比较，如果找到值相等的节点，调用unlink方法将其移除。 12345678910111213public E removeFirst() &#123; final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return unlinkFirst(f);&#125; public E removeLast() &#123; final Node&lt;E&gt; l = last; if (l == null) throw new NoSuchElementException(); return unlinkLast(l);&#125; 这两个方法先判断链表中是否有元素，如果没有，则抛出异常，否则就调用辅助方法将其移除。 get，getFirst，getLast123456789101112131415161718public E get(int index) &#123; checkElementIndex(index); return node(index).item;&#125;public E getFirst() &#123; final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return f.item;&#125;public E getLast() &#123; final Node&lt;E&gt; l = last; if (l == null) throw new NoSuchElementException(); return l.item;&#125; get(int index)方法在进行了下标检查后，直接通过node方法找到该节点并返回节点的值。而getFirst和getLast先判断first和last是否为null，如果不为null则返回节点的值，否则抛出异常。 setset方法将替换链表中指定位置的节点的值。 1234567public E set(int index, E element) &#123; checkElementIndex(index); Node&lt;E&gt; x = node(index); E oldVal = x.item; x.item = element; return oldVal;&#125; 该方法先判断index是否合法，然后获取到该下标的节点，并将该节点的值重新设置即可。 linkedList总结 linkedList是通过双向链表实现的，因此删除效率很高，而查找效率很低，且不存在扩容问题。 linkedList实现了Deque接口，因此既可以当作栈，也可以当作队列。 与ArrayList一样，linkedList也是非线程安全的，只能在单线程环境下使用。]]></content>
      <categories>
        <category>JDK</category>
      </categories>
      <tags>
        <tag>JDK</tag>
        <tag>LinkedList</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ArrayList源码分析]]></title>
    <url>%2F2018%2F09%2F06%2FArrayList%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[ArrayList简介（jdk1.8）ArrayList就是动态数组，其容量能够自动增长。如下为ArrayList的继承体系结构： 12public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable ArrayList实现了List, RandomAccess, Cloneable, java.io.Serializable接口，且不是线程安全的，因此只能用在单线程环境下。 属性ArrayList主要有elementData和size两个属性：12transient Object[] elementData; private int size; elementData数组是用来存储元素的，而size表示ArrayList中已有的元素数量（不等于elementData.length）。 构造方法ArrayList共有三种构造方法： 指定容量的构造函数 123456789public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException("Illegal Capacity: " + initialCapacity); &#125;&#125; 此方法接受一个初始化容量来初始化底层数组elementData，如果初始化容量值为0则将其初始化为一个空的常量数组：private static final Object[] EMPTY_ELEMENTDATA = {}; ，如果值小于零，则抛出异常。 无参构造函数 12345private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;; public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; &#125; 此方法中的DEFAULTCAPACITY_EMPTY_ELEMENTDATA区别于EMPTY_ELEMENTDATA，通过将数组设为前者，在添加元素的时候会将容量设置为默认值10。 Collection作为参数的构造函数 1234567891011public ArrayList(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); if ((size = elementData.length) != 0) &#123; // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // replace with empty array. this.elementData = EMPTY_ELEMENTDATA; &#125;&#125; 此方法接受一个Collection，并且将其转换为数组赋给elementData，如果被赋值后的elementData长度为0，则将空的常量数组赋值给它。相反，则再判断Collection是否转化为了Object数组，如果没有则将其进行转化。 这里用到了Arrays.copyof()方法：123456789public static &lt;T,U&gt; T[] copyOf(U[] original, int newLength, Class&lt;? extends T[]&gt; newType) &#123; @SuppressWarnings("unchecked") T[] copy = ((Object)newType == (Object)Object[].class) ? (T[]) new Object[newLength] : (T[]) Array.newInstance(newType.getComponentType(), newLength); System.arraycopy(original, 0, copy, 0, Math.min(original.length, newLength)); return copy;&#125; 可以看出，该方法构造了一个新的长度为newLength的Object类型数组，并且将原数组复制到新的数组中 。而此处的复制用了System.arraycopy()方法，该方法被标记了native，调用了系统的C/C++代码，可以在openJDK中查看到源码。 get123456789public E get(int index) &#123; rangeCheck(index); return elementData(index);&#125;E elementData(int index) &#123; return (E) elementData[index];&#125; 此方法可以得到指定下标的元素，先对下标进行越界检查，然后再通过一个间接方法获取到elementData的index下标的元素。 set1234567public E set(int index, E element) &#123; rangeCheck(index); E oldValue = elementData(index); elementData[index] = element; return oldValue;&#125; 此方法用于设置指定下标的元素，并将该下标原有的元素返回。 addadd方法比较复杂，也是ArrayList核心所在，有下面两种形式： 将元素加入到列表末尾 12345public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true;&#125; 12345678910private void ensureCapacityInternal(int minCapacity) &#123; ensureExplicitCapacity(calculateCapacity(elementData, minCapacity));&#125;private static int calculateCapacity(Object[] elementData, int minCapacity) &#123; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; return Math.max(DEFAULT_CAPACITY, minCapacity); &#125; return minCapacity;&#125; 此处的calculateCapacity正是与上文DEFAULTCAPACITY_EMPTY_ELEMENTDATA常量相照应的方法。如果ArrayList是默认构造函数构造的话，在添加元素的时候此方法将返回DEFAULT_CAPACITY也就是10。而size已经大于10的情况，该方法便也失去了意义。12345678910111213141516171819202122232425262728private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // overflow-conscious code if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125;private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity);&#125;private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE;&#125; 从源码可以看出，当需要的容量大于elementData数组的长度时，就需要对其进行扩张。而扩张的大小则根据if条件判断。一般情况下，会将长度扩张为原来的1.5倍，但是当1.5倍仍小于所需的容量时，会将长度直接设为所需容量。而新容量如果大于最大数组长度MAX_ARRAY_SIZE ，则根据所需容量分配Integer.MAX_VALUE或者MAX_ARRAY_SIZE。 ensureExplicitCapacity方法的第一行语句modCount++;的作用是记录修改次数。我们知道，ArrayList不是线程安全的，因此在迭代ArrayList的时候如果有其它线程修改了内容，那么就会导致modCount与迭代器初始化时的modCount不同，从而抛出异常ConcurrentModificationException。说白了，就是防止一个线程正在迭代遍历，另一个线程修改了这个列表的结构。 将元素添加到指定位置上 123456789public void add(int index, E element) &#123; rangeCheckForAdd(index); ensureCapacityInternal(size + 1); // Increments modCount!! System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++;&#125; 在此方法中，先对index进行越界检查，然后再进行扩容。这里用了System.arraycopy方法，j将包括index在内的之后的所有元素均向右移动一位，再将要添加的元素放置在elementData的index下标下。 addAll 将集合中的元素全部添加到ArrayList末尾 12345678public boolean addAll(Collection&lt;? extends E&gt; c) &#123; Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); // Increments modCount System.arraycopy(a, 0, elementData, size, numNew); size += numNew; return numNew != 0;&#125; 将Collection对象转化为Object数组后，先根据其长度进行扩容，再同样利用System.arraycopy函数把数组中的所有元素添加到elementData数组末尾。 将集合中的元素全部添加到ArrayList指定位置 12345678910111213141516public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; rangeCheckForAdd(index); Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); // Increments modCount int numMoved = size - index; if (numMoved &gt; 0) System.arraycopy(elementData, index, elementData, index + numNew, numMoved); System.arraycopy(a, 0, elementData, index, numNew); size += numNew; return numNew != 0;&#125; 原理与add(int index, E element)类似，都是通过将已有元素右移实现，此处将不再阐述。 remove 移除指定下标上的元素 1234567891011121314public E remove(int index) &#123; rangeCheck(index); modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work return oldValue;&#125; 在这里，移除操作是将要移除的元素后面的所有元素均向左移动一位，并将size数减小实现的。此方法将返回要移除的元素。 移除指定的元素 12345678910111213141516171819202122232425public boolean remove(Object o) &#123; if (o == null) &#123; for (int index = 0; index &lt; size; index++) if (elementData[index] == null) &#123; fastRemove(index); return true; &#125; &#125; else &#123; for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) &#123; fastRemove(index); return true; &#125; &#125; return false;&#125;private void fastRemove(int index) &#123; modCount++; int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work&#125; 先找到指定元素的下标，再根据下标进行移除。指定的元素有可能为null，而不为null的情况下将根据元素内容进行比较，因此将分为两种情况遍历数组。fastRemove的实现与remove(int index)基本一致，区别在于fastRemove不需要对下标进行检查，也不返回被移除的元素。 indexOf1234567891011121314151617181920212223242526272829public int indexOf(Object o) &#123; if (o == null) &#123; for (int i = 0; i &lt; size; i++) if (elementData[i]==null) return i; &#125; else &#123; for (int i = 0; i &lt; size; i++) if (o.equals(elementData[i])) return i; &#125; return -1;&#125;public int lastIndexOf(Object o) &#123; if (o == null) &#123; for (int i = size-1; i &gt;= 0; i--) if (elementData[i]==null) return i; &#125; else &#123; for (int i = size-1; i &gt;= 0; i--) if (o.equals(elementData[i])) return i; &#125; return -1;&#125;public boolean contains(Object o) &#123; return indexOf(o) &gt;= 0;&#125; 由源码可以看出，indexOf和lastIndexOf与remove(Object o)方法类似，并且找到元素时返回下标，没找到时返回-1，而contains方法正是通过indexOf判断是否找到元素实现的。 ArrayList总结 ArrayList底层是通过数组实现的，随机访问速度快，但插入和移除由于要移动大量的元素，所以性能较差。 ArrayList不是线程安全的，在多线程环境下，通过modCount域检测是否出现问题。 ArrayList每次扩容为原本的1.5倍，若依然不够，则会直接设置为所需容量大小。]]></content>
      <categories>
        <category>JDK</category>
      </categories>
      <tags>
        <tag>JDK</tag>
        <tag>ArrayList</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈对尾递归的理解]]></title>
    <url>%2F2018%2F08%2F22%2F%E6%B5%85%E8%B0%88%E5%AF%B9%E5%B0%BE%E9%80%92%E5%BD%92%E7%9A%84%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[今天在做《剑指Offer》第十题时，发现了一个用尾递归的解法，由于之前对于尾递归并没有太多了解，于是查阅了一些资料，在此对其进行一个简单的总结。关于其它题目的题解与笔记，感兴趣的朋友可以到我的Github或个人博客上看看：剑指Offer笔记 Cenjie’s Blog ， 以下是正文。 递归本质递归的本质是自己调用自己，因为是嵌套调用，所以栈帧无法回收，在递归调用的层级太多时，往往会引发调用栈溢出，也就是内存溢出。 尾递归概述尾递归本质与递归并无区别，只不过是递归的一种特殊写法。尾递归要求递归调用是整个函数体中最后执行的语句且它的返回值不属于表达式的一部分，例如 return 3f(n)或者return f(n)+f(n-1) 都是不允许的。 由于尾递归也是一种递归，因此这种写法本身并不会有任何的优化效果，内存依旧会溢出，只不过一些编译器中会加入对尾递归的优化机制，在编译代码时自动根据尾递归的特性对其进行优化。 如何优化尾递归因为在递归调用自身的时候，这一层函数已经没有要做的事情了，虽然被递归调用的函数是在当前的函数里，但是他们之间的关系已经在传参的时候了断了，也就是这一层函数的所有变量什么的都不会再被用到了，所以当前函数虽然没有执行完，不能弹出栈，但它确实已经可以出栈了，这是一方面。 另一方面，正因为调用的是自身，所以需要的存储空间是一模一样的，那干脆重新刷新这些空间给下一层利用就好了，不用销毁再另开空间。 因此，为尾递归进行优化主要分两个步骤：1、写成尾递归的形式。2、编译器遇到此形式时自动为其优化。 而在第十题：斐波那契数列中，由于Java没有对尾递归进行优化，因此与使用普通递归并无太大区别，依然会产生内存溢出的问题。 本文参考：https://www.cnblogs.com/bellkosmos/p/5280619.html]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[README文档的规范写法总结]]></title>
    <url>%2F2018%2F06%2F25%2FREADME%E6%96%87%E6%A1%A3%E7%9A%84%E8%A7%84%E8%8C%83%E5%86%99%E6%B3%95%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[俗话说的好：“一个好开源项目一定有一个好的 README”。 要想自己放到github上的项目能吸引更多人的眼球，就必须写一个规范舒适的README.md，这么做不仅可以梳理自己对于项目的思路，也方便他人上手使用或学习。因此，此文根据Github上众多项目以及查阅相关资料对README做了一个小小的总结， 方便以后写README的时候可以直接套用该模板。 XXX系统（如果有Logo可以加上Logo）xxx系统是一个..系统，支持…，…（此处为简要描述） 官方网站 | 文档手册 | 别的东西 目前，此系统包含有以下功能： 功能1 功能2 功能3 准备 依赖1 依赖2 依赖3 搭建环境IntelliJ IDEA + MySQL 或者 eclipse + MySQL，… 快速开始 步骤1 步骤2 步骤3 相关截图截图1截图2 To Do List 功能1 功能2 功能3 CHANGE LOG此处填写版本更新记录 至此，我们可以看到一个相对规范的README.md模板，在开源项目时可以直接套用该模板，而不必每次都采用不同的零零散散的格式去书写README。Markdown代码在下方给出，当然，大家也可以根据项目具体情况进行修改而使用。 12345678910111213141516171819202122232425262728293031323334## XXX系统（如果有Logo可以加上Logo）xxx系统是一个..系统，支持...，...（此处为简要描述）[官方网站](http://example.com) | [文档手册](http://example.com) | [别的东西](http://example.com) 目前，此系统包含有以下功能：* 功能1* 功能2* 功能3### 准备* 依赖1* 依赖2* 依赖3### 搭建环境IntelliJ IDEA + MySQL 或者 eclipse + MySQL，...### 快速开始* 步骤1* 步骤2* 步骤3### 相关截图截图1截图2### To Do List* 功能1* 功能2* 功能3### CHANGE LOG此处填写版本更新记录 ContactIf you have some questions after you see this article, you can just find some info by clicking these links. Cenjie’s CSDN Cenjie’s Github Cenjie’s Gmail Cenjie’s Weibo]]></content>
      <categories>
        <category>Github</category>
      </categories>
      <tags>
        <tag>README</tag>
        <tag>markdown</tag>
        <tag>Github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Welcome To My Blog]]></title>
    <url>%2F2018%2F06%2F22%2FWelcome-To-My-Blog%2F</url>
    <content type="text"><![CDATA[写在前面的话大家好！我是就读于南京某高校的一名大二学生，在昨天搭建了这个个人博客网站用于记录自己在学习以及项目过程中的技术积累，希望通过这个平台能与大家分享自己的经验与教训，同时也欢迎大家随时可以联系我，期待与大家共同进步。 关于我我在学校的专业是电子信息科学与技术，曾利用课余时间学习过C、C++、Python等多门语言(仅限于皮毛)，经过两年的不断试错，终于在大二下学期确定了自己以后的发展方向—Java后台研发工程师。于是从基础语法到各大框架，这半年里接触到了许多新技术，看似学了许多东西却仍浮于水面终无所获，逐渐了解到自己要走的路还很长，而自己目前对于基础方面知识也尤为欠缺。因此需记住，沉下心，耐下性子，Coding the World。 铭记Work hard in silence, let success make the noise. ContactIf you have some questions after you see this article, you can just find some info by clicking these links. Cenjie’s CSDN Cenjie’s Github Cenjie’s Gmail]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>hello</tag>
        <tag>杂谈</tag>
      </tags>
  </entry>
</search>
